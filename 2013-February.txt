From Achim.Zeileis at uibk.ac.at  Fri Feb  1 10:21:10 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Fri, 1 Feb 2013 10:21:10 +0100 (CET)
Subject: [Rd] CRAN task views: markdown? better .CSS?
In-Reply-To: <510AE25D.5010407@yorku.ca>
References: <510A84B9.7010907@yorku.ca>
	<alpine.DEB.2.02.1301311752470.22598@paninaro.uibk.ac.at>
	<510AE25D.5010407@yorku.ca>
Message-ID: <alpine.DEB.2.02.1302011015280.17247@paninaro.uibk.ac.at>

On Thu, 31 Jan 2013, Michael Friendly wrote:

> On 1/31/2013 12:01 PM, Achim Zeileis wrote:
>> Michael:
>> 
>>> CRAN task views are useful, but they seem difficult to write and maintain 
>>> because the XML format is rather limited (no sectioning)
>> 
>> What type of sectioning would you like to have? In the HTML part, you can 
>> use the usual structuring tools like <h*>, <p>, etc. It's not
>
> OK. I think you mean the <info> ... </info> section, where I failed to 
> read the vignette sufficiently closely, which talks about using HTML.
>> 
>>> and the <packagelist> must be maintained manually.
>> 
>> Yes, but I recently started adding tools to help checking this. Hopefully 
>> I'll also get round to add some more convenience features for this.
>
> Something simple might be a tool to scan the <info> ... </info> section 
> for <pkg> ... </pkg> mentions and just print a new <packagelist> section 
> to the console.  This would avoid having to remember what you added 
> recently and manually add to the <packagelist>

This is (almost) possible with the latest version of "ctv" (0.7-6). You 
can do:

pkg <- check_ctv_packages("MyView.ctv")
pkg

This shows mismatches between the <info> and <packagelist> sections and 
with CRAN. And then you can do:

writeLines(paste("  <pkg>", pkg[[1]], "</pkg>"))

possibly altering the indentation.

As I wrote in my previous post: I would like to better integrate these 
tools with read.ctv() but didn't get round to it, yet.

Best,
Z

> -Michael
>
>
> -- 
> Michael Friendly     Email: friendly AT yorku DOT ca
> Professor, Psychology Dept. & Chair, Quantitative Methods
> York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
> 4700 Keele Street    Web:   http://www.datavis.ca
> Toronto, ONT  M3J 1P3 CANADA
>
>
>


From karl.forner at gmail.com  Fri Feb  1 10:25:09 2013
From: karl.forner at gmail.com (Karl Forner)
Date: Fri, 1 Feb 2013 10:25:09 +0100
Subject: [Rd] Problem using raw vectors with inline cfunction
Message-ID: <CAMd4_AeG-shk9q6vsf3C9KP=VnfAdu77D4j=W-qE9vmjJJLcYA@mail.gmail.com>

Hello,

>From what I understood from the documentation I found, when using the
inline cfunction with convention=".C",
R raw vectors should be given as unsigned char* to the C function.

But consider the following script:

library(inline)

testRaw <- cfunction(signature(raw='raw', len='integer')
    , body='
        int l = *len;
        int i = 0;
        Rprintf("sizeof(raw[0])=%i\\n", sizeof(raw[0]));
        for (i = 0; i < l; ++i) Rprintf("%i, ", (int)raw[i]);
        for (i = 0; i < l; ++i) raw[i] = i*10;
        '
    , convention=".C", language='C', verbose=TRUE
)

tt <- as.raw(1:10)
testRaw(tt, length(tt))


When I execute it:

$ R --vanilla --quiet < work/inline_cfunction_raw_bug.R

sizeof(raw[0])=1
192, 216, 223, 0, 0, 0, 0, 0, 224, 214,
 *** caught segfault ***
address (nil), cause 'unknown'

Traceback:
 1: .Primitive(".C")(<pointer: 0x7eff8bd605c0>, raw =
as.character(raw),     len = as.integer(len))
 2: testRaw(tt, length(tt))
aborting ...
Segmentation fault (core dumped)


I was expecting to get in the C function a pointer on a byte array of
values (1,2,3,4,5,6,7,8,9,10).
Apparently that is not the case. I guess that the "raw =
as.character(raw)," printed in the traceback is responsible for the
observed behavior.

If it is expected behavior, how can I get a pointer on my array of bytes ?


Thanks.

Karl


From romain at r-enthusiasts.com  Fri Feb  1 13:54:13 2013
From: romain at r-enthusiasts.com (Romain Francois)
Date: Fri, 01 Feb 2013 13:54:13 +0100
Subject: [Rd] Problem using raw vectors with inline cfunction
In-Reply-To: <CAMd4_AeG-shk9q6vsf3C9KP=VnfAdu77D4j=W-qE9vmjJJLcYA@mail.gmail.com>
References: <CAMd4_AeG-shk9q6vsf3C9KP=VnfAdu77D4j=W-qE9vmjJJLcYA@mail.gmail.com>
Message-ID: <510BBAF5.9030207@r-enthusiasts.com>

Hello,

That is a bug in inline indeed. I just commited a fix in r-forge.

The fix is to obviously replace this as.character by an as.raw.

Thanks for teh report.

Romain

Le 01/02/13 10:25, Karl Forner a ?crit :
> Hello,
>
>>From what I understood from the documentation I found, when using the
> inline cfunction with convention=".C",
> R raw vectors should be given as unsigned char* to the C function.
>
> But consider the following script:
>
> library(inline)
>
> testRaw <- cfunction(signature(raw='raw', len='integer')
>      , body='
>          int l = *len;
>          int i = 0;
>          Rprintf("sizeof(raw[0])=%i\\n", sizeof(raw[0]));
>          for (i = 0; i < l; ++i) Rprintf("%i, ", (int)raw[i]);
>          for (i = 0; i < l; ++i) raw[i] = i*10;
>          '
>      , convention=".C", language='C', verbose=TRUE
> )
>
> tt <- as.raw(1:10)
> testRaw(tt, length(tt))
>
>
> When I execute it:
>
> $ R --vanilla --quiet < work/inline_cfunction_raw_bug.R
>
> sizeof(raw[0])=1
> 192, 216, 223, 0, 0, 0, 0, 0, 224, 214,
>   *** caught segfault ***
> address (nil), cause 'unknown'
>
> Traceback:
>   1: .Primitive(".C")(<pointer: 0x7eff8bd605c0>, raw =
> as.character(raw),     len = as.integer(len))
>   2: testRaw(tt, length(tt))
> aborting ...
> Segmentation fault (core dumped)
>
>
> I was expecting to get in the C function a pointer on a byte array of
> values (1,2,3,4,5,6,7,8,9,10).
> Apparently that is not the case. I guess that the "raw =
> as.character(raw)," printed in the traceback is responsible for the
> observed behavior.
>
> If it is expected behavior, how can I get a pointer on my array of bytes ?
>
>
> Thanks.
>
> Karl


-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30

R Graph Gallery: http://gallery.r-enthusiasts.com

blog:            http://romainfrancois.blog.free.fr
|- http://bit.ly/RE6sYH : OOP with Rcpp modules
`- http://bit.ly/Thw7IK : Rcpp modules more flexible


From pauljohn32 at gmail.com  Sat Feb  2 22:02:12 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Sat, 2 Feb 2013 15:02:12 -0600
Subject: [Rd] best practice for packages using mclapply to avoid tcltk
Message-ID: <CAErODj_1hg8+x5SvOmoL8V9RMNgMAN_fXGBLcsJhgnH_k2jOgw@mail.gmail.com>

Dear R-devel friends:

I'm back to bother you again about the conflict between mclapply and
tcltk. I've been
monitoring several packages that want to use mclapply to parallelize
computations and
need to figure out what should be done.

It appears tcltk cannot be safely unloaded, so the best we can do is
check for the presence of tcltk and stop if it is found before
mclapply() is used.

I wish you would please review my suggestion below.  Maybe checkForTcltk()
could be used in the parallel package. Otherwise, we are letting
people run with scissors.

There's a warning about this in ?mclapply

It is _strongly discouraged_ to use these functions in GUI or
    embedded environments, because it leads to several processes
    sharing the same GUI which will likely cause chaos (and possibly
    crashes).  Child processes should never use on-screen graphics
    devices.(Warning in ?mclapply)

Bug report: (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15040 )

By the way, what is "embedded environments" in ?mclapply

## I don't want to crash your system, but if you want to see a freeze-up:
## change 0 to 1 and run this:
if (0){
library(parallel)
library(tcltk)
example(mclapply)
}

## What are packagers supposed to do if they want to call mclapply?
## It appears to me the best a package can do is scan for tcltk and
## stop. Here's a function that does so.

checkForTcltk <- function(){
    if ("tcltk" %in% loadedNamespaces()){
        stop("This function cannot be used because the R tcltk
    package is loaded. It is necessary to Close R, and re-run
    the program making sure that tcltk is never loaded before
    this function is called.")
    }
}

## put that to use.
MCLApply <- function(){
    if (!require(parallel)) stop ("parallel wouldn't load")
    checkForTcltk()
    example(mclapply)
}

## test that:

checkForTcltk()
MCLApply()

library(tcltk)
checkForTcltk()


## Why can't tcltk just be unloaded? I don't understand, but it is a deep
## problem.

## Consider the ominous warnings in R detach's help:
##
## "Unloading some namespaces has undesirable side effects: e.g.
##  unloading ?grid? closes all graphics devices, and on most systems
##  ?tcltk? cannot be reloaded once it has been unloaded and may crash
##  R if this is attempted." (Note: section of ?detach).
##
## To be fair, that does not say unloading tcltk is fatal, but
## reloading it is fatal. And I've seen plenty of times when
## unloading it is fatal.

## Example 1. Crash on library.dynam.unload()
detach("package:tcltk", unload = TRUE)
library.dynam.unload("tcltk", system.file(package = "tcltk"))

## Output
## > library.dynam.unload("tcltk", system.file(package = "tcltk"))
## >
##  *** caught segfault ***
## address 0x7f69c9d99580, cause 'memory not mapped'

## Possible actions:
## 1: abort (with core dump, if enabled)
## 2: normal R exit
## 3: exit R without saving workspace
## 4: exit R saving workspace
## Selection:
## Process R segmentation fault at Sat Feb  2 13:55:08 2013


## Example 2.
library(tcltk)
detach("package:tcltk", unload = TRUE)
library.dynam.unload("tcltk", system.file(package = "tcltk"))
example(mclapply)

## Output:

## > example(mclapply)

##  *** caught segfault ***
## address 0x7f25ccbfe000, cause 'memory not mapped'

## Possible actions:
## 1: abort (with core dump, if enabled)
## 2: normal R exit
## 3: exit R without saving workspace
## 4: exit R saving workspace
## Selection:


pj

-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From timb at metrumrg.com  Sat Feb  2 23:34:14 2013
From: timb at metrumrg.com (Tim Bergsma)
Date: Sat, 2 Feb 2013 17:34:14 -0500
Subject: [Rd] setGeneric() gives "must supply skeleton" when checking package
Message-ID: <CAK0Ebm4h44AiFkFa4BZ8BmeXsJnDg+6YjO4NyNQDkrZXvQE9bg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130202/73b7756e/attachment.pl>

From lgautier at gmail.com  Sun Feb  3 16:19:00 2013
From: lgautier at gmail.com (Laurent Gautier)
Date: Sun, 03 Feb 2013 23:19:00 +0800
Subject: [Rd] Bug: C-level and _set_rl_word_breaks
In-Reply-To: <510A7735.6090200@gmail.com>
References: <5109DB9A.3000606@gmail.com> <510A6D1C.7080002@gmail.com>
	<510A7735.6090200@gmail.com>
Message-ID: <510E7FE4.6060003@gmail.com>

On 2013-01-31 21:52, Laurent Gautier wrote:
> On 2013-01-31 21:09, Duncan Murdoch wrote:
>> On 13-01-30 9:48 PM, Laurent Gautier wrote:
>>> Hi,
>>>
>>> I filed a bug report in the tracker (id #15169) a short while ago,
>>> along with a patch, but I came back to it to see that there is
>>> relatively little movement or participation on the tracker so I
>>> thought I'd pitch it here (patch attached).
>>>
>>> The function `set_rl_word_breaks` in src/unix/sys-std.c relies on
>>> statically-allocated strings local to the function, making other C
>>> code using the readline library, such as a program embedding
>>> R and using readline as well, at risk of creating a segfault when
>>> trying to free `rl_basic_word_break_characters` or
>>> `rl_completer_word_break_characters` when changing them.
>>>
>>> The issue was noticed when embedding R in Python (rpy2); I had an
>>> ugly hack for a long time (less work than champion the inclusion
>>> of a patch in R) but the iPython developers pushed what could be
>>> demanded from the rpy2 with their "R magic" extension and
>>> so I wrote a patch (and they have made a brittle workaround in
>>> the meantime).
>>>
>>> The fix would be of interest to anyone embedding R in C and using
>>> readline (e.g., language interface developers if the language either
>>> has a console using readline - and chances are that it does - or
>>> an interface to readline).
>>>
>>> The patch attached is against today's R-dev and will likely apply to
>>> current R-2.15 branch. With the patch applied, R is building and is
>>> passing `make check`. It could be slightly expanded by handling
>>> cases where the calloc() or realloc() faills, although not an absolute
>>> priority (if allocating 200 bytes fails, the system might have
>>> bigger worries than keeping R from crashing).
>>
>> I suspect the reason your bug hasn't been dealt with in the 2 weeks 
>> since you posted it is that you don't show any code that illustrates 
>> the problem it causes.  It is much easier to run some code and see 
>> that code that should be valid is causing a crash, than it is to 
>> develop code to illustrate it.
>
> Fair enough. Now I realize that this might be a part of R codebase 
> that is hardly touched; while the problem makes sense to me after 
> spending time on it, a demonstrating what it causes in a minimal 
> example might be best).
>
>> Easily illustrated bugs get solved before hard ones.
>
> I guess I had a free pass since I provide a solution to the bug.
>
>>
>> Your post here gives a lot more detail, but still no code.  This 
>> isn't an area I'd work on (it seems to be a Unix-only bug), but you 
>> might attract someone else to look at it if you include a minimal 
>> self-contained trigger for it.
>
> I'll work on that.

A minimal example to demonstrate the problem is now in the bug tracker. 
It shows that either a C-extension or a part of a application in which R 
is embedded
crash R (segfault) by trying to change break delimiters.

Best,


Laurent


>
> Thanks,
>
> L.
>>
>> Duncan Murdoch
>


From mtmorgan at fhcrc.org  Sun Feb  3 18:36:34 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 03 Feb 2013 09:36:34 -0800
Subject: [Rd] setGeneric() gives "must supply skeleton" when checking
 package
In-Reply-To: <CAK0Ebm4h44AiFkFa4BZ8BmeXsJnDg+6YjO4NyNQDkrZXvQE9bg@mail.gmail.com>
References: <CAK0Ebm4h44AiFkFa4BZ8BmeXsJnDg+6YjO4NyNQDkrZXvQE9bg@mail.gmail.com>
Message-ID: <510EA022.3030402@fhcrc.org>

On 02/02/2013 02:34 PM, Tim Bergsma wrote:
> r-devel,
>
> In a development version of the CRAN package metrumrg, I write ...
>
> require(reshape)
> setGeneric('cast')
> setOldClass(c('keyed','data.frame'))
> setMethod('cast','keyed', function ...)
>
> The result is satisfactory when sourcing the code directly, but when
> checking the package (which has 'reshape' as a dependency in the
> DESCRIPTION file) I get the following:
>
> "Error in setGeneric("cast") : must supply a function skeleton for
> ???cast???, explicitly or via an existing function."

You haven't mentioned your DESCRIPTION or NAMEPSACE file, but the right thing to 
do is

DESCRIPTION:

Depends: reshape

NAMESPACE:

importFrom(reshape, cast)

R/somefile.R:

setGeneric("cast")

Perhaps your current setGeneric is being performed inside the namespace when 
cast is not yet available (e.g., because it has not been imported)?

Martin Morgan

>
> The help for setGeneric() seems to suggest that no function skeleton is
> needed  when creating a generic for a function defined in some other
> package.  I found one or two previous related posts, but no obvious
> resolution.
>
> Comments appreciated,
>
> Tim Bergsma, PhD
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From mtmorgan at fhcrc.org  Sun Feb  3 18:41:11 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 03 Feb 2013 09:41:11 -0800
Subject: [Rd] setGeneric() gives "must supply skeleton" when checking
 package
In-Reply-To: <510EA022.3030402@fhcrc.org>
References: <CAK0Ebm4h44AiFkFa4BZ8BmeXsJnDg+6YjO4NyNQDkrZXvQE9bg@mail.gmail.com>
	<510EA022.3030402@fhcrc.org>
Message-ID: <510EA137.7080004@fhcrc.org>

On 02/03/2013 09:36 AM, Martin Morgan wrote:
> On 02/02/2013 02:34 PM, Tim Bergsma wrote:
>> r-devel,
>>
>> In a development version of the CRAN package metrumrg, I write ...
>>
>> require(reshape)
>> setGeneric('cast')
>> setOldClass(c('keyed','data.frame'))
>> setMethod('cast','keyed', function ...)
>>
>> The result is satisfactory when sourcing the code directly, but when
>> checking the package (which has 'reshape' as a dependency in the
>> DESCRIPTION file) I get the following:
>>
>> "Error in setGeneric("cast") : must supply a function skeleton for
>> ???cast???, explicitly or via an existing function."
>
> You haven't mentioned your DESCRIPTION or NAMEPSACE file, but the right thing to
> do is
>
> DESCRIPTION:
>
> Depends: reshape

Should be Imports: reshape


>
> NAMESPACE:
>
> importFrom(reshape, cast)
>
> R/somefile.R:
>
> setGeneric("cast")
>
> Perhaps your current setGeneric is being performed inside the namespace when
> cast is not yet available (e.g., because it has not been imported)?
>
> Martin Morgan
>
>>
>> The help for setGeneric() seems to suggest that no function skeleton is
>> needed  when creating a generic for a function defined in some other
>> package.  I found one or two previous related posts, but no obvious
>> resolution.
>>
>> Comments appreciated,
>>
>> Tim Bergsma, PhD
>>
>>     [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From simon.urbanek at r-project.org  Sun Feb  3 20:34:09 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 3 Feb 2013 15:34:09 -0400
Subject: [Rd] best practice for packages using mclapply to avoid tcltk
In-Reply-To: <CAErODj_1hg8+x5SvOmoL8V9RMNgMAN_fXGBLcsJhgnH_k2jOgw@mail.gmail.com>
References: <CAErODj_1hg8+x5SvOmoL8V9RMNgMAN_fXGBLcsJhgnH_k2jOgw@mail.gmail.com>
Message-ID: <F667EFC5-41D0-4F56-AE80-FCBDBE65F46E@r-project.org>

As Peter pointed out earlier, this is better addressed by disabling the Tcl/Tk event loop in forked processes.

Cheers,
Simon

On Feb 2, 2013, at 5:02 PM, Paul Johnson wrote:

> Dear R-devel friends:
> 
> I'm back to bother you again about the conflict between mclapply and
> tcltk. I've been
> monitoring several packages that want to use mclapply to parallelize
> computations and
> need to figure out what should be done.
> 
> It appears tcltk cannot be safely unloaded, so the best we can do is
> check for the presence of tcltk and stop if it is found before
> mclapply() is used.
> 
> I wish you would please review my suggestion below.  Maybe checkForTcltk()
> could be used in the parallel package. Otherwise, we are letting
> people run with scissors.
> 
> There's a warning about this in ?mclapply
> 
> It is _strongly discouraged_ to use these functions in GUI or
>    embedded environments, because it leads to several processes
>    sharing the same GUI which will likely cause chaos (and possibly
>    crashes).  Child processes should never use on-screen graphics
>    devices.(Warning in ?mclapply)
> 
> Bug report: (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15040 )
> 
> By the way, what is "embedded environments" in ?mclapply
> 
> ## I don't want to crash your system, but if you want to see a freeze-up:
> ## change 0 to 1 and run this:
> if (0){
> library(parallel)
> library(tcltk)
> example(mclapply)
> }
> 
> ## What are packagers supposed to do if they want to call mclapply?
> ## It appears to me the best a package can do is scan for tcltk and
> ## stop. Here's a function that does so.
> 
> checkForTcltk <- function(){
>    if ("tcltk" %in% loadedNamespaces()){
>        stop("This function cannot be used because the R tcltk
>    package is loaded. It is necessary to Close R, and re-run
>    the program making sure that tcltk is never loaded before
>    this function is called.")
>    }
> }
> 
> ## put that to use.
> MCLApply <- function(){
>    if (!require(parallel)) stop ("parallel wouldn't load")
>    checkForTcltk()
>    example(mclapply)
> }
> 
> ## test that:
> 
> checkForTcltk()
> MCLApply()
> 
> library(tcltk)
> checkForTcltk()
> 
> 
> ## Why can't tcltk just be unloaded? I don't understand, but it is a deep
> ## problem.
> 
> ## Consider the ominous warnings in R detach's help:
> ##
> ## "Unloading some namespaces has undesirable side effects: e.g.
> ##  unloading ?grid? closes all graphics devices, and on most systems
> ##  ?tcltk? cannot be reloaded once it has been unloaded and may crash
> ##  R if this is attempted." (Note: section of ?detach).
> ##
> ## To be fair, that does not say unloading tcltk is fatal, but
> ## reloading it is fatal. And I've seen plenty of times when
> ## unloading it is fatal.
> 
> ## Example 1. Crash on library.dynam.unload()
> detach("package:tcltk", unload = TRUE)
> library.dynam.unload("tcltk", system.file(package = "tcltk"))
> 
> ## Output
> ## > library.dynam.unload("tcltk", system.file(package = "tcltk"))
> ## >
> ##  *** caught segfault ***
> ## address 0x7f69c9d99580, cause 'memory not mapped'
> 
> ## Possible actions:
> ## 1: abort (with core dump, if enabled)
> ## 2: normal R exit
> ## 3: exit R without saving workspace
> ## 4: exit R saving workspace
> ## Selection:
> ## Process R segmentation fault at Sat Feb  2 13:55:08 2013
> 
> 
> ## Example 2.
> library(tcltk)
> detach("package:tcltk", unload = TRUE)
> library.dynam.unload("tcltk", system.file(package = "tcltk"))
> example(mclapply)
> 
> ## Output:
> 
> ## > example(mclapply)
> 
> ##  *** caught segfault ***
> ## address 0x7f25ccbfe000, cause 'memory not mapped'
> 
> ## Possible actions:
> ## 1: abort (with core dump, if enabled)
> ## 2: normal R exit
> ## 3: exit R without saving workspace
> ## 4: exit R saving workspace
> ## Selection:
> 
> 
> pj
> 
> -- 
> Paul E. Johnson
> Professor, Political Science      Assoc. Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org               http://quant.ku.edu
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From m.blackwell at rochester.edu  Sun Feb  3 22:12:37 2013
From: m.blackwell at rochester.edu (Matt Blackwell)
Date: Sun, 3 Feb 2013 16:12:37 -0500
Subject: [Rd] best practice for packages using mclapply to avoid tcltk
In-Reply-To: <F667EFC5-41D0-4F56-AE80-FCBDBE65F46E@r-project.org>
References: <CAErODj_1hg8+x5SvOmoL8V9RMNgMAN_fXGBLcsJhgnH_k2jOgw@mail.gmail.com>
	<F667EFC5-41D0-4F56-AE80-FCBDBE65F46E@r-project.org>
Message-ID: <CAK1YySGcjbeRjB8LOMYX26wtZ7EjrTS_i90r3DN+F94d=NbE5g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130203/d782d36d/attachment.pl>

From suharto_anggono at yahoo.com  Mon Feb  4 06:28:44 2013
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sun, 3 Feb 2013 21:28:44 -0800 (PST)
Subject: [Rd] Suggestions for 'diff.default'
In-Reply-To: <1359430353.97928.YahooMailClassic@web125103.mail.ne1.yahoo.com>
Message-ID: <1359955724.91890.YahooMailClassic@web125104.mail.ne1.yahoo.com>

Inspired by discussion in "Need very fast application of 'diff' - ideas?" (around https://stat.ethz.ch/pipermail/r-help/2012-January/301873.html), I have another suggestion.

Suggestion 3: Make 'diff.default' run faster.

For vector case (if suggestion 2 is not applied or if unclassed input is treated specially), without resorting to C, I found that a speedup may be gained by changing
r[-length(r):-(length(r)-lag+1L)]
with
`length<-`(r, length(r)-lag)

Another way, with similar idea, that triggers warning, is doing as follows.

    {
        for (i in seq_len(differences)) r <- r[i1] - r
        length(r) <- xlen - lag * differences
    }

Variables 'i1' and 'xlen' are as defined in function 'diff.default' in R.


--- On Tue, 29/1/13, Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com> wrote:

> From: Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com>
> Subject: Re: Suggestions for 'diff.default'
> To: R-devel at lists.R-project.org
> Date: Tuesday, 29 January, 2013, 10:32 AM
> 
> 
> --- On Mon, 28/1/13, Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com>
> wrote:
> 
> > From: Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com>
> > Subject: Suggestions for 'diff.default'
> > To: R-devel at lists.R-project.org
> > Date: Monday, 28 January, 2013, 5:31 PM
> > I have suggestions for function
> > 'diff.default' in R.
> > 
> > 
> > Suggestion 1: If the input is matrix, always return
> matrix,
> > even if empty.
> > 
> > What happens in R 2.15.2:
> > 
> > > rbind(1:2)? ? # matrix
> > ? ???[,1] [,2]
> > [1,]? ? 1? ? 2
> > > diff(rbind(1:2))???# not matrix
> > integer(0)
> > > sessionInfo()
> > R version 2.15.2 (2012-10-26)
> > Platform: i386-w64-mingw32/i386 (32-bit)
> > 
> > locale:
> > [1] LC_COLLATE=English_United States.1252
> > [2] LC_CTYPE=English_United States.1252
> > [3] LC_MONETARY=English_United States.1252
> > [4] LC_NUMERIC=C
> > [5] LC_TIME=English_United States.1252
> > 
> > attached base packages:
> > [1] stats? ???graphics? grDevices
> > utils? ???datasets?
> > methods???base
> > 
> > 
> > The documentation for 'diff' says, "If 'x' is a matrix
> then
> > the difference operations are carried out on each
> column
> > separately."
> > If the result is empty, I expect that the result still
> has
> > as many columns as the input.
> > 
> > 
> > Suggestion 2: Make 'diff.default' applicable more
> generally
> > by
> > (a) not performing 'unclass';
> > (b) generalizing (changing)
> > ismat <- is.matrix(x)
> > to become
> > ismat <- length(dim(x)) == 2L
> > 
> > 
> > If suggestion 1 is to be applied, if 'unclass' is not
> wanted
> > (point (a) in suggestion 2 is also to be applied),
> > 
> > ? ? if (lag * differences >= xlen)
> > ??? return(x[0L])
> > 
> > can be changed to
> > 
> > ? ? if (lag * differences >= xlen)
> > ??? return(
> > ? ? ? ? ? ? if (ismat) x[0L, ,
> > drop = FALSE] - x[0L, , drop = FALSE] else
> > ? ? ? ? ? ? x[0L] - x[0L])
> > 
> > It will handle class where subtraction (minus)
> operation
> > change class.
> Sorry, I wasn't careful enough. To obtain the correct class
> for the result, differencing should be done as many times as
> specified by argument 'differences'.
> 
> I consider the case of
> diff(as.POSIXct(c("2012-01-01", "2012-02-01"), tz="UTC"),
> d=2)
> versus
> diff(diff(as.POSIXct(c("2012-01-01", "2012-02-01"),
> tz="UTC")))
> To be safe, maybe just compute as usual, even when it is
> known that the end result will be empty. It can be done like
> this.
> 
> ? ? empty <- integer()
> ? ? if (ismat)
> ??? for (i in seq_len(differences))
> ??? ? ? r <- if (lag >=
> nrow(r))
> ? ? ? ? ? ? ? ?
> r[empty, , drop = FALSE] - r[empty, , drop = FALSE] else
> ? ? ? ? ? ? ? ? ...
> ? ? else
> ? ? ? ? for (i in seq_len(differences))
> ? ? ? ? ? ? r <- if (lag
> >= length(r))
> ? ? ? ? ? ? ? ?
> r[empty] - r[empty] else
> ? ? ? ? ? ? ? ? ...
> 
> If that way is used, 'xlen' is no longer needed.
> > 
> > Otherwise, if 'unclass' is wanted, maybe the handling
> of
> > empty result can be moved to be after 'unclass', to be
> > consistent with non-empty result.
> > 
> > 
> > If point (a) in suggestion 2 is applied, 'diff.default'
> can
> > handle input of class "Date" and "POSIXt". If, in
> addition,
> > point (b) in suggestion 2 is also applied,
> 'diff.default'
> > can handle data frame as input.
> >
>


From jon at thon.cc  Mon Feb  4 03:52:50 2013
From: jon at thon.cc (Jonathon Love)
Date: Mon, 04 Feb 2013 13:52:50 +1100
Subject: [Rd] Error building R from SVN - unable to run 'pdflatex' on
	'example-1.tex'
Message-ID: <510F2282.90005@thon.cc>

G'day,

I'm trying to build R using the code from SVN. I am able to successfully 
build the source from here:

http://cran.r-project.org/src/base/R-2/R-2.15.2.tar.gz

However, when building the code checked out from SVN (either from 2.15.2 
tag, or the trunk) I get the following error:


Error: running Sweave on vignette 
'/home/jonathon/projects/R/src/library/utils/vignettes/Sweave.Rnw' 
failed with message:
  chunk 2
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
   unable to run 'pdflatex' on 'example-1.tex'
Execution halted
make[1]: *** [vignettes] Error 1


Is there a way I can fix this?

with thanks

Jonathon Love


From florent.angly at gmail.com  Mon Feb  4 12:14:41 2013
From: florent.angly at gmail.com (Florent Angly)
Date: Mon, 04 Feb 2013 21:14:41 +1000
Subject: [Rd] [R] gettext weirdness
In-Reply-To: <alpine.LFD.2.03.1302040823330.21486@stats.ox.ac.uk>
References: <510F601E.8030805@gmail.com>
	<alpine.LFD.2.03.1302040823330.21486@stats.ox.ac.uk>
Message-ID: <510F9821.40406@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130204/96e84404/attachment.pl>

From murdoch.duncan at gmail.com  Mon Feb  4 13:47:27 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 04 Feb 2013 07:47:27 -0500
Subject: [Rd] Error building R from SVN - unable to run 'pdflatex' on
 'example-1.tex'
In-Reply-To: <510F2282.90005@thon.cc>
References: <510F2282.90005@thon.cc>
Message-ID: <510FADDF.6080602@gmail.com>

On 13-02-03 9:52 PM, Jonathon Love wrote:
> G'day,
>
> I'm trying to build R using the code from SVN. I am able to successfully
> build the source from here:
>
> http://cran.r-project.org/src/base/R-2/R-2.15.2.tar.gz
>
> However, when building the code checked out from SVN (either from 2.15.2
> tag, or the trunk) I get the following error:
>
>
> Error: running Sweave on vignette
> '/home/jonathon/projects/R/src/library/utils/vignettes/Sweave.Rnw'
> failed with message:
>    chunk 2
> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>     unable to run 'pdflatex' on 'example-1.tex'
> Execution halted
> make[1]: *** [vignettes] Error 1
>
>
> Is there a way I can fix this?

Probably, but if you want help you're going to need to give some more 
information first, such as what exactly you installed from SVN, what OS 
you are using, what target you tried to build, and anything else 
necessary so that a potential helper can duplicate what you did.

Duncan Murdoch


From ripley at stats.ox.ac.uk  Mon Feb  4 15:02:25 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 04 Feb 2013 14:02:25 +0000
Subject: [Rd] [R] gettext weirdness
In-Reply-To: <510F9821.40406@gmail.com>
References: <510F601E.8030805@gmail.com>
	<alpine.LFD.2.03.1302040823330.21486@stats.ox.ac.uk>
	<510F9821.40406@gmail.com>
Message-ID: <510FBF71.4060400@stats.ox.ac.uk>

On 04/02/2013 11:14, Florent Angly wrote:
> Hi Brian,
>
> I appreciate your clarifications. I am sending this reply to the
> R-devel, as per you suggestion.
>
> As mentioned in my post, I have no prior experience with this R function
> and logically, I looked up its help page, which states:
>> Conventionally the domain for *R* warning/error messages in package
>> pkg is |"R-pkg"|, and that for C-level messages is |"pkg"|.
> While it certainly mentions messages in the C-realm, it does not state
> that they cannot be translated using gettext(). This is less than
> obvious and could perhaps be explicitly stated.

You are asking us to state what *can not* be done?  It does clearly 
state the the domain for *R* messages in a package is "R-pkg".   Domain 
"R" is not of that form.

> If gettext() cannot be used to get the translation for the "Error in "
> message in some supported language, then is there an alternative?

You put it in a domain named "R-pkg", prepared using xgetttext().

>
> Best,
>
> Florent
>
>
>
> On 04/02/13 18:27, Prof Brian Ripley wrote:
>> The 'wierdness' is that 'R' is a domain of C messages and you are
>> trying to use it from R.  How messages are massaged before being sent
>> for translation depends on the language, including how trailing spaces
>> are handled.   There is no reason to expect domains intended for C
>> code to work in R-level gettext(), nor in stop() etc.
>>
>> This was really an R-devel question: see the posting guide.
>>
>> On Mon, 4 Feb 2013, Florent Angly wrote:
>>
>>> Hi,
>>>
>>> I am trying to use the gettext() function to translate some text. I
>>> have never used this function before, so, it's entirely possible that
>>> I am doing something wrong. The issue that I am encountering is that
>>> gettext() properly translates some text, but not some other.
>>>
>>> Natural language was compiled in my R (installed from the Debian
>>> repositories):
>>> $ R
>>> R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows"
>>> [...]
>>>   Natural language support but running in an English locale
>>> [...]
>>>> q()
>>>
>>> Here is some text that has some translation in the file ./po/fr.po:
>>>     #: src/main/errors.c:290
>>>     msgid "invalid option \"warning.expression\""
>>>     msgstr "option incorrecte \"warning.expression\""
>>>     [...]
>>>     #: src/main/errors.c:582
>>>     msgid "Error in "
>>>     msgstr "Erreur dans "
>>>
>>> Start R in French and see if I can get something translated to French:
>>> $ LANG=fr_FR.UTF8  R
>>>> stop('This is an error')
>>> Erreur : This is an error
>>>
>>>> bindtextdomain("R") # does not seem necessary, but just to be safe...
>>> [1] "/usr/share/R/share/locale"
>>>
>>>> gettext("Error in ", domain="R")
>>> [1] "Error in "
>>>
>>>> "invalid option \"warning.expression\"" -> msg; gettext(msg,
>>>> domain="R")
>>> [1] "option incorrecte \"warning.expression\""
>>>
>>>
>>> So, the stop() function successfully translates. I can also manually
>>> translate some entries, but why can does it not work for
>>> gettext("Error in ", domain="R")?
>>> Any idea?
>>> Thanks
>>>
>>> Florent
>>>
>>> ______________________________________________
>>> R-help at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-help
>>> PLEASE do read the posting guide
>>> http://www.R-project.org/posting-guide.html
>>> and provide commented, minimal, self-contained, reproducible code.
>>>
>>
>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From jon at thon.cc  Mon Feb  4 15:27:30 2013
From: jon at thon.cc (Jonathon Love)
Date: Tue, 05 Feb 2013 01:27:30 +1100
Subject: [Rd] Error building R from SVN - unable to run 'pdflatex' on
 'example-1.tex'
In-Reply-To: <510FADDF.6080602@gmail.com>
References: <510F2282.90005@thon.cc> <510FADDF.6080602@gmail.com>
Message-ID: <510FC552.2050002@thon.cc>

On 04/02/13 23:47, Duncan Murdoch wrote:
 > Probably, but if you want help you're going to need to give some more
 > information first, such as what exactly you installed from SVN, what OS
 > you are using, what target you tried to build, and anything else
 > necessary so that a potential helper can duplicate what you did.

my bad. sorry.

on ubuntu 12.10 i did a checkout of the 2.15.2 tag

https://svn.r-project.org/R/tags/R-2-15-2

next i ran the tools/rsync-recommended script

then i ran:

./configure

(it did give me these warnings)
configure: WARNING: you cannot build info or HTML versions of the R manuals
configure: WARNING: inconsolata.sty not found: PDF vignettes and package 
manuals will not be rendered optimally

then i ran:

make

giving me the error:

building/updating vignettes for package 'utils' ...
processing 'Sweave.Rnw'
Error: running Sweave on vignette 
'/home/jonathon/projects/R/src/library/utils/vignettes/Sweave.Rnw' 
failed with message:
  chunk 2
Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
   unable to run 'pdflatex' on 'example-1.tex'
Execution halted
make[1]: *** [vignettes] Error 1
make[1]: Leaving directory `/home/jonathon/projects/R/src/library'
make: *** [vignettes] Error 2

other things that may be helpful:

gcc (Ubuntu/Linaro 4.7.2-2ubuntu1) 4.7.2
pdfTeX 3.1415926-2.4-1.40.13 (TeX Live 2012/Debian)

The problem seems to be with building vignette's for the recommended 
packages. Any assistance would be appreciated.

with thanks

Jonathon Love



> On 13-02-03 9:52 PM, Jonathon Love wrote:
>> G'day,
>>
>> I'm trying to build R using the code from SVN. I am able to successfully
>> build the source from here:
>>
>> http://cran.r-project.org/src/base/R-2/R-2.15.2.tar.gz
>>
>> However, when building the code checked out from SVN (either from 2.15.2
>> tag, or the trunk) I get the following error:
>>
>>
>> Error: running Sweave on vignette
>> '/home/jonathon/projects/R/src/library/utils/vignettes/Sweave.Rnw'
>> failed with message:
>>    chunk 2
>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet =
>> quiet,  :
>>     unable to run 'pdflatex' on 'example-1.tex'
>> Execution halted
>> make[1]: *** [vignettes] Error 1
>>
>>
>> Is there a way I can fix this?
>

>
> Duncan Murdoch
>


From ripley at stats.ox.ac.uk  Mon Feb  4 17:47:24 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 04 Feb 2013 16:47:24 +0000
Subject: [Rd] Error building R from SVN - unable to run 'pdflatex' on
 'example-1.tex'
In-Reply-To: <510FC552.2050002@thon.cc>
References: <510F2282.90005@thon.cc> <510FADDF.6080602@gmail.com>
	<510FC552.2050002@thon.cc>
Message-ID: <510FE61C.6030705@stats.ox.ac.uk>

Well, if all else fails read the manual:

The PDF documentation (including doc/NEWS.pdf) and building vignettes 
needs tex and latex, or pdftex and pdflatex. We require LaTeX version 
2005/12/01 or later (for UTF-8 support). Building PDF package manuals 
(including the R reference manual) and vignettes is sensitive to the 
version of the LaTeX package hyperref and we recommend that the TeX 
distribution used is keep up-to-date. A number of LaTeX packages are 
required (including url.sty, and listings.sty) and others such as 
hyperref and inconsolata are desirable (and without them you will need 
to change R's defaults: see Making the manuals).

The default can be overridden by setting the environment variable 
R_RD4PDF. (On Unix-alikes, this will be picked up at install time and 
stored in etc/Renviron, but can still be overridden when the manuals are 
built.) The default value for R_RD4PDF is ?times,inconsolata,hyper?: 
omit ?hyper? if you do not want hyperlinks (e.g. for printing the 
manual) or do not have LaTeX package hyperref, and omit ?inconsolata? if 
you do not have LaTeX package inconsolata installed.


On 04/02/2013 14:27, Jonathon Love wrote:
> On 04/02/13 23:47, Duncan Murdoch wrote:
>  > Probably, but if you want help you're going to need to give some more
>  > information first, such as what exactly you installed from SVN, what OS
>  > you are using, what target you tried to build, and anything else
>  > necessary so that a potential helper can duplicate what you did.
>
> my bad. sorry.
>
> on ubuntu 12.10 i did a checkout of the 2.15.2 tag
>
> https://svn.r-project.org/R/tags/R-2-15-2
>
> next i ran the tools/rsync-recommended script
>
> then i ran:
>
> ./configure
>
> (it did give me these warnings)
> configure: WARNING: you cannot build info or HTML versions of the R manuals
> configure: WARNING: inconsolata.sty not found: PDF vignettes and package
> manuals will not be rendered optimally
>
> then i ran:
>
> make
>
> giving me the error:
>
> building/updating vignettes for package 'utils' ...
> processing 'Sweave.Rnw'
> Error: running Sweave on vignette
> '/home/jonathon/projects/R/src/library/utils/vignettes/Sweave.Rnw'
> failed with message:
>   chunk 2
> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet = quiet,  :
>    unable to run 'pdflatex' on 'example-1.tex'
> Execution halted
> make[1]: *** [vignettes] Error 1
> make[1]: Leaving directory `/home/jonathon/projects/R/src/library'
> make: *** [vignettes] Error 2
>
> other things that may be helpful:
>
> gcc (Ubuntu/Linaro 4.7.2-2ubuntu1) 4.7.2
> pdfTeX 3.1415926-2.4-1.40.13 (TeX Live 2012/Debian)
>
> The problem seems to be with building vignette's for the recommended
> packages. Any assistance would be appreciated.
>
> with thanks
>
> Jonathon Love
>
>
>
>> On 13-02-03 9:52 PM, Jonathon Love wrote:
>>> G'day,
>>>
>>> I'm trying to build R using the code from SVN. I am able to successfully
>>> build the source from here:
>>>
>>> http://cran.r-project.org/src/base/R-2/R-2.15.2.tar.gz
>>>
>>> However, when building the code checked out from SVN (either from 2.15.2
>>> tag, or the trunk) I get the following error:
>>>
>>>
>>> Error: running Sweave on vignette
>>> '/home/jonathon/projects/R/src/library/utils/vignettes/Sweave.Rnw'
>>> failed with message:
>>>    chunk 2
>>> Error in texi2dvi(file = file, pdf = TRUE, clean = clean, quiet =
>>> quiet,  :
>>>     unable to run 'pdflatex' on 'example-1.tex'
>>> Execution halted
>>> make[1]: *** [vignettes] Error 1
>>>
>>>
>>> Is there a way I can fix this?
>>
>
>>
>> Duncan Murdoch
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From joshmobrien at gmail.com  Mon Feb  4 18:20:46 2013
From: joshmobrien at gmail.com (Josh O'Brien)
Date: Mon, 4 Feb 2013 09:20:46 -0800
Subject: [Rd] R-lang edit: deparse(1:2) is no longer a good example of the R
 parser's non-invertibility
Message-ID: <CAOwKfPTb6WdevsSYe_9Z_pikN3tivcS_1Or_mQDJ6ZtakZhmJg@mail.gmail.com>

Hello,

Apparently thanks to improvements to the R parser, this example from
section 6.1 of the R Language Definition no longer holds.

> deparse(quote(c(1, 2)))
[1] "c(1, 2)"
> deparse(1:2)
[1] "c(1, 2)"

Even running R-2.14.2, I get instead

> deparse(1:2)
[1] "1:2"


From murdoch.duncan at gmail.com  Mon Feb  4 18:36:04 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 04 Feb 2013 12:36:04 -0500
Subject: [Rd] R-lang edit: deparse(1:2) is no longer a good example of
 the R parser's non-invertibility
In-Reply-To: <CAOwKfPTb6WdevsSYe_9Z_pikN3tivcS_1Or_mQDJ6ZtakZhmJg@mail.gmail.com>
References: <CAOwKfPTb6WdevsSYe_9Z_pikN3tivcS_1Or_mQDJ6ZtakZhmJg@mail.gmail.com>
Message-ID: <510FF184.7050407@gmail.com>

On 04/02/2013 12:20 PM, Josh O'Brien wrote:
> Hello,
>
> Apparently thanks to improvements to the R parser, this example from
> section 6.1 of the R Language Definition no longer holds.
>
> > deparse(quote(c(1, 2)))
> [1] "c(1, 2)"
> > deparse(1:2)
> [1] "c(1, 2)"
>
>

Thanks, I'll replace that example with this one:

 > str(quote(c(1,2)))
  language c(1, 2)
 > str(c(1,2))
  num [1:2] 1 2
 > deparse(quote(c(1,2)))
[1] "c(1, 2)"
 > deparse(c(1,2))
[1] "c(1, 2)"

Duncan Murdoch


From edd at debian.org  Mon Feb  4 18:52:44 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 4 Feb 2013 11:52:44 -0600
Subject: [Rd] Error building R from SVN - unable to run 'pdflatex' on
 'example-1.tex'
In-Reply-To: <510FC552.2050002@thon.cc>
References: <510F2282.90005@thon.cc> <510FADDF.6080602@gmail.com>
	<510FC552.2050002@thon.cc>
Message-ID: <20751.62828.971668.382535@max.nulle.part>


On 5 February 2013 at 01:27, Jonathon Love wrote:
| On 04/02/13 23:47, Duncan Murdoch wrote:
|  > Probably, but if you want help you're going to need to give some more
|  > information first, such as what exactly you installed from SVN, what OS
|  > you are using, what target you tried to build, and anything else
|  > necessary so that a potential helper can duplicate what you did.
| 
| my bad. sorry.
| 
| on ubuntu 12.10 i did a checkout of the 2.15.2 tag

Try this:

   sudo apt-get build-dep r-base

which will install what the distro itself uses to build the package.

Also look into './configure --help' to learn about different aspects of the
build which you can turn on or off.  I keep a little shell script with my
prefered configuration to create a local build of r-devel from SVN.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From ivo.welch at anderson.ucla.edu  Mon Feb  4 22:53:02 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Mon, 4 Feb 2013 13:53:02 -0800
Subject: [Rd] Contract Syntactic Sugar
Message-ID: <CAPr7RtX787PFPCYtqPROOnUSSgdSyPq9dq7yTF780q4syEA1jw@mail.gmail.com>

## the following is a dream: add some sugar syntax to allow for
contracts with teeth (in and out checking)

> is.positive <- function(x) (all(x>0))

> exponentiate <- function( x ::is.data.frame , exponent ::is.numeric is.positive)  :: is.vector is.numeric  {
    x$base :: is.positive        ## error also if base does not exist
in x; may need some special IQ
    x$base^exponent
}

should be self-explanatory.  anything that has '::' means "run what is
before through all the functions after and barf if it is not true".
any other operator rather than :: or other syntax would be as
good---this is just illustratory.  in the end, this code should be
viewed by R as the same as

> exponentiate <- function( x, exponent ) {
    stopifnot( is.data.frame(x) )
    stopifnot( is.numeric(exponent) )
    stopifnot( is.positive(exponent) )
    stopifnot( exists("base", "x") )
    stopifnot( is.positive( x$base ) )
    return.value <- x$base^exponent
    stopifnot( is.vector(return.value) )
    stopifnot( is.numeric(return.value) )
    return.value
 }

is this a feasible summer project for a student with a prospect of
inclusion of the completed code in the R core language itself if I pay
for the development time?  {or does better syntax already exist and I
am just ignorant (which I often am)?}

regards,

/iaw
----
Ivo Welch (ivo.welch at gmail.com)


From gmbecker at ucdavis.edu  Mon Feb  4 23:07:56 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 4 Feb 2013 14:07:56 -0800
Subject: [Rd] Contract Syntactic Sugar
In-Reply-To: <CAPr7RtX787PFPCYtqPROOnUSSgdSyPq9dq7yTF780q4syEA1jw@mail.gmail.com>
References: <CAPr7RtX787PFPCYtqPROOnUSSgdSyPq9dq7yTF780q4syEA1jw@mail.gmail.com>
Message-ID: <CADwqtCOJ+WYLd=LFsBNVatX9SnaJ4pOzcv5T3SouTicfY5293w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130204/1457c420/attachment.pl>

From rowe at muxspace.com  Mon Feb  4 23:10:32 2013
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Mon, 4 Feb 2013 17:10:32 -0500
Subject: [Rd] Contract Syntactic Sugar
In-Reply-To: <CAPr7RtX787PFPCYtqPROOnUSSgdSyPq9dq7yTF780q4syEA1jw@mail.gmail.com>
References: <CAPr7RtX787PFPCYtqPROOnUSSgdSyPq9dq7yTF780q4syEA1jw@mail.gmail.com>
Message-ID: <489BC778-DB7A-46CD-9574-089B69D9D068@muxspace.com>

Ivo, 

You might be interested in my lambda.r package which provides syntax (using the %::% operator) for type constraints. Given a function with n arguments, the type constraint requires n + 1 types, as the last type listed is the return type. Lambda.r also provides syntax for specifying any arbitrary condition on the input arguments via the %when% operator. For your example below you could do the following:

exponentiate(x, exponent) %::% data.frame : numeric : numeric
exponentiate(x, exponent) %when% {
  is.positive(x)
} %as% {
  x$base ^ exponent 
}

You can see more examples in the package (available on CRAN) or in the source (https://github.com/muxspace/lambda.r).

HTH,
Brian


On Feb 4, 2013, at 4:53 PM, ivo welch <ivo.welch at anderson.ucla.edu> wrote:

> ## the following is a dream: add some sugar syntax to allow for
> contracts with teeth (in and out checking)
> 
>> is.positive <- function(x) (all(x>0))
> 
>> exponentiate <- function( x ::is.data.frame , exponent ::is.numeric is.positive)  :: is.vector is.numeric  {
>    x$base :: is.positive        ## error also if base does not exist
> in x; may need some special IQ
>    x$base^exponent
> }
> 
> should be self-explanatory.  anything that has '::' means "run what is
> before through all the functions after and barf if it is not true".
> any other operator rather than :: or other syntax would be as
> good---this is just illustratory.  in the end, this code should be
> viewed by R as the same as
> 
>> exponentiate <- function( x, exponent ) {
>    stopifnot( is.data.frame(x) )
>    stopifnot( is.numeric(exponent) )
>    stopifnot( is.positive(exponent) )
>    stopifnot( exists("base", "x") )
>    stopifnot( is.positive( x$base ) )
>    return.value <- x$base^exponent
>    stopifnot( is.vector(return.value) )
>    stopifnot( is.numeric(return.value) )
>    return.value
> }
> 
> is this a feasible summer project for a student with a prospect of
> inclusion of the completed code in the R core language itself if I pay
> for the development time?  {or does better syntax already exist and I
> am just ignorant (which I often am)?}
> 
> regards,
> 
> /iaw
> ----
> Ivo Welch (ivo.welch at gmail.com)
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ivo.welch at gmail.com  Tue Feb  5 00:22:37 2013
From: ivo.welch at gmail.com (ivo welch)
Date: Mon, 4 Feb 2013 15:22:37 -0800
Subject: [Rd] Contract Syntactic Sugar
In-Reply-To: <489BC778-DB7A-46CD-9574-089B69D9D068@muxspace.com>
References: <CAPr7RtX787PFPCYtqPROOnUSSgdSyPq9dq7yTF780q4syEA1jw@mail.gmail.com>
	<489BC778-DB7A-46CD-9574-089B69D9D068@muxspace.com>
Message-ID: <CAPr7RtXkee7NaR31Ha3xYC9oq+vR5DRxzZR82uUqBBZHr6hCfg@mail.gmail.com>

hi brian---interesting and very impressive.  is it possible to move
everything into one definition and/or to chain multiple conditions?

exponentiate(x, exponent) %::% data.frame : c(numeric,allpositive) :
integer  %as% {
  x %has% base  ## my invention, since this is not checked, and R is
not strict enough
  x$base %::% allpositive
  x$base ^ exponent
}

multiple creations as in your doc examples on the same function are a
recipe for errors for me.  it's also why I am not too fond of
TypeInfo.  chaining conditions in my c() is not important, as long as
I can define my own types (which can check multiple aspects at the
same time).  suggestion: in your doc example, can you define a
different type than an integer?  it's a little confusing.  how about
defining a strictly positive integer?

regards,

/iaw
----
Ivo Welch (ivo.welch at gmail.com)
http://www.ivo-welch.info/
J. Fred Weston Professor of Finance
Anderson School at UCLA, C519
Director, UCLA Anderson Fink Center for Finance and Investments
Free Finance Textbook, http://book.ivo-welch.info/
Editor, Critical Finance Review, http://www.critical-finance-review.org/



On Mon, Feb 4, 2013 at 2:10 PM, Brian Lee Yung Rowe <rowe at muxspace.com> wrote:
> Ivo,
>
> You might be interested in my lambda.r package which provides syntax (using the %::% operator) for type constraints. Given a function with n arguments, the type constraint requires n + 1 types, as the last type listed is the return type. Lambda.r also provides syntax for specifying any arbitrary condition on the input arguments via the %when% operator. For your example below you could do the following:
>
> exponentiate(x, exponent) %::% data.frame : numeric : numeric
> exponentiate(x, exponent) %when% {
>   is.positive(x)
> } %as% {
>   x$base ^ exponent
> }
>
> You can see more examples in the package (available on CRAN) or in the source (https://github.com/muxspace/lambda.r).
>
> HTH,
> Brian
>
>
> On Feb 4, 2013, at 4:53 PM, ivo welch <ivo.welch at anderson.ucla.edu> wrote:
>
>> ## the following is a dream: add some sugar syntax to allow for
>> contracts with teeth (in and out checking)
>>
>>> is.positive <- function(x) (all(x>0))
>>
>>> exponentiate <- function( x ::is.data.frame , exponent ::is.numeric is.positive)  :: is.vector is.numeric  {
>>    x$base :: is.positive        ## error also if base does not exist
>> in x; may need some special IQ
>>    x$base^exponent
>> }
>>
>> should be self-explanatory.  anything that has '::' means "run what is
>> before through all the functions after and barf if it is not true".
>> any other operator rather than :: or other syntax would be as
>> good---this is just illustratory.  in the end, this code should be
>> viewed by R as the same as
>>
>>> exponentiate <- function( x, exponent ) {
>>    stopifnot( is.data.frame(x) )
>>    stopifnot( is.numeric(exponent) )
>>    stopifnot( is.positive(exponent) )
>>    stopifnot( exists("base", "x") )
>>    stopifnot( is.positive( x$base ) )
>>    return.value <- x$base^exponent
>>    stopifnot( is.vector(return.value) )
>>    stopifnot( is.numeric(return.value) )
>>    return.value
>> }
>>
>> is this a feasible summer project for a student with a prospect of
>> inclusion of the completed code in the R core language itself if I pay
>> for the development time?  {or does better syntax already exist and I
>> am just ignorant (which I often am)?}
>>
>> regards,
>>
>> /iaw
>> ----
>> Ivo Welch (ivo.welch at gmail.com)
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From florent.angly at gmail.com  Tue Feb  5 01:44:43 2013
From: florent.angly at gmail.com (Florent Angly)
Date: Tue, 05 Feb 2013 10:44:43 +1000
Subject: [Rd] [R] gettext weirdness
In-Reply-To: <510FBF71.4060400@stats.ox.ac.uk>
References: <510F601E.8030805@gmail.com>
	<alpine.LFD.2.03.1302040823330.21486@stats.ox.ac.uk>
	<510F9821.40406@gmail.com> <510FBF71.4060400@stats.ox.ac.uk>
Message-ID: <511055FB.9080900@gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130205/37853f9f/attachment.pl>

From rowe at muxspace.com  Tue Feb  5 02:17:10 2013
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Mon, 4 Feb 2013 20:17:10 -0500
Subject: [Rd] Contract Syntactic Sugar
In-Reply-To: <CAPr7RtXkee7NaR31Ha3xYC9oq+vR5DRxzZR82uUqBBZHr6hCfg@mail.gmail.com>
References: <CAPr7RtX787PFPCYtqPROOnUSSgdSyPq9dq7yTF780q4syEA1jw@mail.gmail.com>
	<489BC778-DB7A-46CD-9574-089B69D9D068@muxspace.com>
	<CAPr7RtXkee7NaR31Ha3xYC9oq+vR5DRxzZR82uUqBBZHr6hCfg@mail.gmail.com>
Message-ID: <ECD80B44-2836-41A8-85F2-656E803BF68F@muxspace.com>

Ivo,

If you don't like the multipart function syntax you can write a single definition. Personally I prefer this as it isolates data management logic and control flow from model/application logic. There are duck typing operators that you can use in the guard similar to the syntax you wrote. You can also create your own types and use that in a type constraint. However the type constraint syntax must be a distinct statement although you could embed it all within a guard. Here are three different approaches using lambda.r. 

NaturalNumber(x) %when% {
  all(is.positive(x))
} %as% { x }

# Using an explicit type constraint with a custom type
exponentiate(x, exponent) %::% data.frame : NaturalNumber : integer 
exponentiate(x, exponent) %when% {
  x %hasa% base
} %as% { x$base ^ exponent }

 -- or --

# Embedding everything in a guard
exponentiate(x, exponent) %when% {
  x %hasa% base
  x %isa% NaturalNumber
} %as% { x$base ^ exponent }

 -- or --

# Eschewing a custom type for explicit statements
exponentiate(x, exponent) %when% {
  x %hasa% base
  all(is.positive(x$base))
} %as% { x$base ^ exponent 

Warm Regards,
Brian

?????
Brian Lee Yung Rowe
917 496 4583


On Feb 4, 2013, at 6:23 PM, ivo welch <ivo.welch at gmail.com> wrote:

> hi brian---interesting and very impressive.  is it possible to move
> everything into one definition and/or to chain multiple conditions?
> 
> exponentiate(x, exponent) %::% data.frame : c(numeric,allpositive) :
> integer  %as% {
>  x %has% base  ## my invention, since this is not checked, and R is
> not strict enough
>  x$base %::% allpositive
>  x$base ^ exponent
> }
> 
> multiple creations as in your doc examples on the same function are a
> recipe for errors for me.  it's also why I am not too fond of
> TypeInfo.  chaining conditions in my c() is not important, as long as
> I can define my own types (which can check multiple aspects at the
> same time).  suggestion: in your doc example, can you define a
> different type than an integer?  it's a little confusing.  how about
> defining a strictly positive integer?
> 
> regards,
> 
> /iaw
> ----
> Ivo Welch (ivo.welch at gmail.com)
> http://www.ivo-welch.info/
> J. Fred Weston Professor of Finance
> Anderson School at UCLA, C519
> Director, UCLA Anderson Fink Center for Finance and Investments
> Free Finance Textbook, http://book.ivo-welch.info/
> Editor, Critical Finance Review, http://www.critical-finance-review.org/
> 
> 
> 
> On Mon, Feb 4, 2013 at 2:10 PM, Brian Lee Yung Rowe <rowe at muxspace.com> wrote:
>> Ivo,
>> 
>> You might be interested in my lambda.r package which provides syntax (using the %::% operator) for type constraints. Given a function with n arguments, the type constraint requires n + 1 types, as the last type listed is the return type. Lambda.r also provides syntax for specifying any arbitrary condition on the input arguments via the %when% operator. For your example below you could do the following:
>> 
>> exponentiate(x, exponent) %::% data.frame : numeric : numeric
>> exponentiate(x, exponent) %when% {
>>  is.positive(x)
>> } %as% {
>>  x$base ^ exponent
>> }
>> 
>> You can see more examples in the package (available on CRAN) or in the source (https://github.com/muxspace/lambda.r).
>> 
>> HTH,
>> Brian
>> 
>> 
>> On Feb 4, 2013, at 4:53 PM, ivo welch <ivo.welch at anderson.ucla.edu> wrote:
>> 
>>> ## the following is a dream: add some sugar syntax to allow for
>>> contracts with teeth (in and out checking)
>>> 
>>>> is.positive <- function(x) (all(x>0))
>>> 
>>>> exponentiate <- function( x ::is.data.frame , exponent ::is.numeric is.positive)  :: is.vector is.numeric  {
>>>   x$base :: is.positive        ## error also if base does not exist
>>> in x; may need some special IQ
>>>   x$base^exponent
>>> }
>>> 
>>> should be self-explanatory.  anything that has '::' means "run what is
>>> before through all the functions after and barf if it is not true".
>>> any other operator rather than :: or other syntax would be as
>>> good---this is just illustratory.  in the end, this code should be
>>> viewed by R as the same as
>>> 
>>>> exponentiate <- function( x, exponent ) {
>>>   stopifnot( is.data.frame(x) )
>>>   stopifnot( is.numeric(exponent) )
>>>   stopifnot( is.positive(exponent) )
>>>   stopifnot( exists("base", "x") )
>>>   stopifnot( is.positive( x$base ) )
>>>   return.value <- x$base^exponent
>>>   stopifnot( is.vector(return.value) )
>>>   stopifnot( is.numeric(return.value) )
>>>   return.value
>>> }
>>> 
>>> is this a feasible summer project for a student with a prospect of
>>> inclusion of the completed code in the R core language itself if I pay
>>> for the development time?  {or does better syntax already exist and I
>>> am just ignorant (which I often am)?}
>>> 
>>> regards,
>>> 
>>> /iaw
>>> ----
>>> Ivo Welch (ivo.welch at gmail.com)
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 


From suharto_anggono at yahoo.com  Tue Feb  5 12:09:45 2013
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Tue, 5 Feb 2013 03:09:45 -0800 (PST)
Subject: [Rd] 'ecdf': how about exploiting property that 'x' is sorted?
Message-ID: <1360062585.31414.YahooMailClassic@web125106.mail.ne1.yahoo.com>

In the code of function 'ecdf' di R (for example, version 2.15.2), input 'x' is sorted first. Because the values are sorted, same values are contiguous. So, how about using an approach as inside function 'rle'? Because missing values is removed by 'sort', it can be done like this.

i <- c(which(x[-1L] != x[-n]), n)
rval <- approxfun(x[i], i/n, ...)


From jon at thon.cc  Tue Feb  5 12:55:25 2013
From: jon at thon.cc (Jonathon Love)
Date: Tue, 05 Feb 2013 22:55:25 +1100
Subject: [Rd] Error building R from SVN - unable to run 'pdflatex' on
 'example-1.tex'
In-Reply-To: <20751.62828.971668.382535@max.nulle.part>
References: <510F2282.90005@thon.cc> <510FADDF.6080602@gmail.com>
	<510FC552.2050002@thon.cc>
	<20751.62828.971668.382535@max.nulle.part>
Message-ID: <5110F32D.6090405@thon.cc>

yup. that fixed it. thanks for your help.

there are a handful of extra files in the source tarball (some pdfs, 
etc.), that aren't in the SVN. it appears that building these requires a 
bunch more stuff installed, and that's why building the source tarball 
worked, but not the SVN contents.

with thanks

Jonathon


>
> On 5 February 2013 at 01:27, Jonathon Love wrote:
> | On 04/02/13 23:47, Duncan Murdoch wrote:
> |  > Probably, but if you want help you're going to need to give some more
> |  > information first, such as what exactly you installed from SVN, what OS
> |  > you are using, what target you tried to build, and anything else
> |  > necessary so that a potential helper can duplicate what you did.
> |
> | my bad. sorry.
> |
> | on ubuntu 12.10 i did a checkout of the 2.15.2 tag
>
> Try this:
>
>     sudo apt-get build-dep r-base
>
> which will install what the distro itself uses to build the package.
>
> Also look into './configure --help' to learn about different aspects of the
> build which you can turn on or off.  I keep a little shell script with my
> prefered configuration to create a local build of r-devel from SVN.
>
> Dirk
>


From ivo.welch at anderson.ucla.edu  Tue Feb  5 17:44:17 2013
From: ivo.welch at anderson.ucla.edu (ivo welch)
Date: Tue, 5 Feb 2013 08:44:17 -0800
Subject: [Rd] Money
Message-ID: <CAPr7RtVbUS8hXDRBpgYUB_JU6R61A-rEsVVCbi2BCuv_FkTg7w@mail.gmail.com>

ladies and gents---is there a list of what the R core team would like
to get funded?  let's presume that we could raise $100,000 or
$1,000,000 (or even $10,000,000) for the core team.  what would the R
core team do with the money?  is there a list somewhere, perhaps like
kickstarter?

my preference would be improving up the default error hunting
process---from greater strictness to assertions to line numbers on
errors, followed by a POD.  I know there are many clever ways to go
about every one of these issues in R, but they are not so "standard"
and built into the core language that every beginning R student will
benefit.

/iaw
----
Ivo Welch (ivo.welch at gmail.com)


From benjamin.hofner at fau.de  Tue Feb  5 12:01:37 2013
From: benjamin.hofner at fau.de (Benjamin Hofner)
Date: Tue, 05 Feb 2013 12:01:37 +0100
Subject: [Rd] How to use summary.mer inside a package?
Message-ID: <5110E691.1010407@fau.de>

I have a question regarding the build of my project papeR (hosted on 
R-forge http://r-forge.r-project.org/R/?group_id=1574) with respect to 
lme4.

Both, Windows and MacOS are complaining that lme4 doesn't export summary:

   Error : object 'summary' is not exported by 'namespace:lme4'
   ERROR: lazy loading failed for package 'papeR'

Linux however builds the project as desired.

I now did check my package using Uwe Ligges' winbuilder project and got 
positive results i.e. no errors for Windows there. See (for the next 72 
hours):

http://win-builder.r-project.org/y3uwwx93nJ92
http://win-builder.r-project.org/10mtpspKx7us

Can anyone tell me why this happens (only on R-forge and only for 
certain systems) and how to prevent this?

[I already asked the R-forge maintainers and was redirected to the 
general R mailing lists]

As a side note: The reason for importing lme4's summary is that 
otherwise my function summary.fixef, which extracts fixed effects from 
nlme and lme4 models for printing e.g. in reports, doesn't use/find 
summary.mer on "mer" objects -- even if lme4 is loaded earlier. On the 
other hand, lme models (from package nlme) are handled correctly despite 
the fact that I do not import the corresponding summary function.

Thank you very much
   Benjamin


From timb at metrumrg.com  Tue Feb  5 16:35:55 2013
From: timb at metrumrg.com (Tim Bergsma)
Date: Tue, 5 Feb 2013 10:35:55 -0500
Subject: [Rd] setGeneric() gives "must supply skeleton" when checking
	package
In-Reply-To: <510EA022.3030402@fhcrc.org>
References: <CAK0Ebm4h44AiFkFa4BZ8BmeXsJnDg+6YjO4NyNQDkrZXvQE9bg@mail.gmail.com>
	<510EA022.3030402@fhcrc.org>
Message-ID: <CAK0Ebm7FYxdixfS5PXjpSCsxTWhcn8nzgy5unO2O8a=8JOLADg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130205/0fe80664/attachment.pl>

From pauljohn32 at gmail.com  Wed Feb  6 05:25:01 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 5 Feb 2013 22:25:01 -0600
Subject: [Rd] best practice for packages using mclapply to avoid tcltk
In-Reply-To: <F667EFC5-41D0-4F56-AE80-FCBDBE65F46E@r-project.org>
References: <CAErODj_1hg8+x5SvOmoL8V9RMNgMAN_fXGBLcsJhgnH_k2jOgw@mail.gmail.com>
	<F667EFC5-41D0-4F56-AE80-FCBDBE65F46E@r-project.org>
Message-ID: <CAErODj9qtvB=s0zphXywin5ZpXozVKdj0qeRvAp9cyFy3O8coA@mail.gmail.com>

On Sun, Feb 3, 2013 at 1:34 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> As Peter pointed out earlier, this is better addressed by disabling the Tcl/Tk event loop in forked processes.
>
Dear Simon:

I don't understand.  Can you please try to say it again?

I find Peter's comment (on Jan 3, 2013, thread title: weird bug with
parallel, RSQlite and tcltk):

"More likely, the wisdom of calling R_ProcessEvents and R_PolledEvents
in parallel processes should be questioned. I tend to think that they
should both be disabled completely conditionally on R_isForkedChild.
At least in the Tk loop, some of the events are generated as responses
to specific queries, and having one process ask for something and
another one handling the reply, leaving the first one waiting
indefinitely, is just Not Right."

That suggested to me the problem is in R itself, or the tcltk package

If package writers don't follow my suggestion, what do they think they
should do  instead?

pj
> Cheers,
> Simon
>
> On Feb 2, 2013, at 5:02 PM, Paul Johnson wrote:
>
>> Dear R-devel friends:
>>
>> I'm back to bother you again about the conflict between mclapply and
>> tcltk. I've been
>> monitoring several packages that want to use mclapply to parallelize
>> computations and
>> need to figure out what should be done.
>>
>> It appears tcltk cannot be safely unloaded, so the best we can do is
>> check for the presence of tcltk and stop if it is found before
>> mclapply() is used.
>>
>> I wish you would please review my suggestion below.  Maybe checkForTcltk()
>> could be used in the parallel package. Otherwise, we are letting
>> people run with scissors.
>>
>> There's a warning about this in ?mclapply
>>
>> It is _strongly discouraged_ to use these functions in GUI or
>>    embedded environments, because it leads to several processes
>>    sharing the same GUI which will likely cause chaos (and possibly
>>    crashes).  Child processes should never use on-screen graphics
>>    devices.(Warning in ?mclapply)
>>
>> Bug report: (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15040 )
>>
>> By the way, what is "embedded environments" in ?mclapply
>>
>> ## I don't want to crash your system, but if you want to see a freeze-up:
>> ## change 0 to 1 and run this:
>> if (0){
>> library(parallel)
>> library(tcltk)
>> example(mclapply)
>> }
>>
>> ## What are packagers supposed to do if they want to call mclapply?
>> ## It appears to me the best a package can do is scan for tcltk and
>> ## stop. Here's a function that does so.
>>
>> checkForTcltk <- function(){
>>    if ("tcltk" %in% loadedNamespaces()){
>>        stop("This function cannot be used because the R tcltk
>>    package is loaded. It is necessary to Close R, and re-run
>>    the program making sure that tcltk is never loaded before
>>    this function is called.")
>>    }
>> }
>>
>> ## put that to use.
>> MCLApply <- function(){
>>    if (!require(parallel)) stop ("parallel wouldn't load")
>>    checkForTcltk()
>>    example(mclapply)
>> }
>>
>> ## test that:
>>
>> checkForTcltk()
>> MCLApply()
>>
>> library(tcltk)
>> checkForTcltk()
>>
>>
>> ## Why can't tcltk just be unloaded? I don't understand, but it is a deep
>> ## problem.
>>
>> ## Consider the ominous warnings in R detach's help:
>> ##
>> ## "Unloading some namespaces has undesirable side effects: e.g.
>> ##  unloading ?grid? closes all graphics devices, and on most systems
>> ##  ?tcltk? cannot be reloaded once it has been unloaded and may crash
>> ##  R if this is attempted." (Note: section of ?detach).
>> ##
>> ## To be fair, that does not say unloading tcltk is fatal, but
>> ## reloading it is fatal. And I've seen plenty of times when
>> ## unloading it is fatal.
>>
>> ## Example 1. Crash on library.dynam.unload()
>> detach("package:tcltk", unload = TRUE)
>> library.dynam.unload("tcltk", system.file(package = "tcltk"))
>>
>> ## Output
>> ## > library.dynam.unload("tcltk", system.file(package = "tcltk"))
>> ## >
>> ##  *** caught segfault ***
>> ## address 0x7f69c9d99580, cause 'memory not mapped'
>>
>> ## Possible actions:
>> ## 1: abort (with core dump, if enabled)
>> ## 2: normal R exit
>> ## 3: exit R without saving workspace
>> ## 4: exit R saving workspace
>> ## Selection:
>> ## Process R segmentation fault at Sat Feb  2 13:55:08 2013
>>
>>
>> ## Example 2.
>> library(tcltk)
>> detach("package:tcltk", unload = TRUE)
>> library.dynam.unload("tcltk", system.file(package = "tcltk"))
>> example(mclapply)
>>
>> ## Output:
>>
>> ## > example(mclapply)
>>
>> ##  *** caught segfault ***
>> ## address 0x7f25ccbfe000, cause 'memory not mapped'
>>
>> ## Possible actions:
>> ## 1: abort (with core dump, if enabled)
>> ## 2: normal R exit
>> ## 3: exit R without saving workspace
>> ## 4: exit R saving workspace
>> ## Selection:
>>
>>
>> pj
>>
>> --
>> Paul E. Johnson
>> Professor, Political Science      Assoc. Director
>> 1541 Lilac Lane, Room 504      Center for Research Methods
>> University of Kansas                 University of Kansas
>> http://pj.freefaculty.org               http://quant.ku.edu
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>



-- 
Paul E. Johnson
Professor, Political Science      Assoc. Director
1541 Lilac Lane, Room 504      Center for Research Methods
University of Kansas                 University of Kansas
http://pj.freefaculty.org               http://quant.ku.edu


From maechler at stat.math.ethz.ch  Wed Feb  6 10:29:15 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 6 Feb 2013 10:29:15 +0100
Subject: [Rd] best practice for packages using mclapply to avoid tcltk
In-Reply-To: <CAErODj9qtvB=s0zphXywin5ZpXozVKdj0qeRvAp9cyFy3O8coA@mail.gmail.com>
References: <CAErODj_1hg8+x5SvOmoL8V9RMNgMAN_fXGBLcsJhgnH_k2jOgw@mail.gmail.com>
	<F667EFC5-41D0-4F56-AE80-FCBDBE65F46E@r-project.org>
	<CAErODj9qtvB=s0zphXywin5ZpXozVKdj0qeRvAp9cyFy3O8coA@mail.gmail.com>
Message-ID: <20754.8811.443519.383545@stat.math.ethz.ch>

>>>>> "PJ" == Paul Johnson <pauljohn32 at gmail.com>
>>>>>     on Tue, 5 Feb 2013 22:25:01 -0600 writes:

    > On Sun, Feb 3, 2013 at 1:34 PM, Simon Urbanek
    > <simon.urbanek at r-project.org> wrote:
    >> As Peter pointed out earlier, this is better addressed by
    >> disabling the Tcl/Tk event loop in forked processes.
    >> 
    > Dear Simon:

    > I don't understand.  Can you please try to say it again?

    > I find Peter's comment (on Jan 3, 2013, thread title:
    > weird bug with parallel, RSQlite and tcltk):

    > "More likely, the wisdom of calling R_ProcessEvents and
    > R_PolledEvents in parallel processes should be
    > questioned. I tend to think that they should both be
    > disabled completely conditionally on R_isForkedChild.
    > At least in the Tk loop, some of the events are
    > generated as responses to specific queries, and having
    > one process ask for something and another one handling
    > the reply, leaving the first one waiting indefinitely,
    > is just Not Right."

    > That suggested to me the problem is in R itself, or the
    > tcltk package

Well, it should have suggested that the problem should be
addressed "in R itself"...
and it now has been:

The NEWS  for R 2.15.2 patched (and hence "R devel" and all
    	      	       	       	future versions of R)
now contain

      The Tcl/Tk event loop is inhibited in a forked child (as in e.g.
      mclapply().


    > If package writers don't follow my suggestion, what do
    > they think they should do instead?

Package writers should  add a 
---------------------------
Depends:  R (>= 2.15.3)
---------------------------
to their DESCRIPTION .... but probably only after that is released  :-)

--
Martin


    > pj
    >> Cheers, Simon
    >> 
    >> On Feb 2, 2013, at 5:02 PM, Paul Johnson wrote:
    >> 
    >>> Dear R-devel friends:
    >>> 
    >>> I'm back to bother you again about the conflict between
    >>> mclapply and tcltk. I've been monitoring several
    >>> packages that want to use mclapply to parallelize
    >>> computations and need to figure out what should be done.
    >>> 
    >>> It appears tcltk cannot be safely unloaded, so the best
    >>> we can do is check for the presence of tcltk and stop if
    >>> it is found before mclapply() is used.
    >>> 
    >>> I wish you would please review my suggestion below.
    >>> Maybe checkForTcltk() could be used in the parallel
    >>> package. Otherwise, we are letting people run with
    >>> scissors.
    >>> 
    >>> There's a warning about this in ?mclapply
    >>> 
    >>> It is _strongly discouraged_ to use these functions in
    >>> GUI or embedded environments, because it leads to
    >>> several processes sharing the same GUI which will likely
    >>> cause chaos (and possibly crashes).  Child processes
    >>> should never use on-screen graphics devices.(Warning in
    >>> ?mclapply)
    >>> 
    >>> Bug report:
    >>> (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15040
    >>> )
    >>> 
    >>> By the way, what is "embedded environments" in ?mclapply
    >>> 
    >>> ## I don't want to crash your system, but if you want to
    >>> see a freeze-up: ## change 0 to 1 and run this: if (0){
    >>> library(parallel) library(tcltk) example(mclapply) }
    >>> 
    >>> ## What are packagers supposed to do if they want to
    >>> call mclapply?  ## It appears to me the best a package
    >>> can do is scan for tcltk and ## stop. Here's a function
    >>> that does so.
    >>> 
    >>> checkForTcltk <- function(){ if ("tcltk" %in%
    >>> loadedNamespaces()){ stop("This function cannot be used
    >>> because the R tcltk package is loaded. It is necessary
    >>> to Close R, and re-run the program making sure that
    >>> tcltk is never loaded before this function is called.")
    >>> } }
    >>> 
    >>> ## put that to use.  MCLApply <- function(){ if
    >>> (!require(parallel)) stop ("parallel wouldn't load")
    >>> checkForTcltk() example(mclapply) }
    >>> 
    >>> ## test that:
    >>> 
    >>> checkForTcltk() MCLApply()
    >>> 
    >>> library(tcltk) checkForTcltk()
    >>> 
    >>> 
    >>> ## Why can't tcltk just be unloaded? I don't understand,
    >>> but it is a deep ## problem.
    >>> 
    >>> ## Consider the ominous warnings in R detach's help:
    >>> ##
    >>> ## "Unloading some namespaces has undesirable side
    >>> effects: e.g.  ## unloading ?grid? closes all graphics
    >>> devices, and on most systems ## ?tcltk? cannot be
    >>> reloaded once it has been unloaded and may crash ## R if
    >>> this is attempted." (Note: section of ?detach).
    >>> ##
    >>> ## To be fair, that does not say unloading tcltk is
    >>> fatal, but ## reloading it is fatal. And I've seen
    >>> plenty of times when ## unloading it is fatal.
    >>> 
    >>> ## Example 1. Crash on library.dynam.unload()
    >>> detach("package:tcltk", unload = TRUE)
    >>> library.dynam.unload("tcltk", system.file(package =
    >>> "tcltk"))
    >>> 
    >>> ## Output ## > library.dynam.unload("tcltk",
    >>> system.file(package = "tcltk"))
    >>> ## >
    >>> ## *** caught segfault *** ## address 0x7f69c9d99580,
    >>> cause 'memory not mapped'
    >>> 
    >>> ## Possible actions: ## 1: abort (with core dump, if
    >>> enabled) ## 2: normal R exit ## 3: exit R without saving
    >>> workspace ## 4: exit R saving workspace ## Selection: ##
    >>> Process R segmentation fault at Sat Feb 2 13:55:08 2013
    >>> 
    >>> 
    >>> ## Example 2.  library(tcltk) detach("package:tcltk",
    >>> unload = TRUE) library.dynam.unload("tcltk",
    >>> system.file(package = "tcltk")) example(mclapply)
    >>> 
    >>> ## Output:
    >>> 
    >>> ## > example(mclapply)
    >>> 
    >>> ## *** caught segfault *** ## address 0x7f25ccbfe000,
    >>> cause 'memory not mapped'
    >>> 
    >>> ## Possible actions: ## 1: abort (with core dump, if
    >>> enabled) ## 2: normal R exit ## 3: exit R without saving
    >>> workspace ## 4: exit R saving workspace ## Selection:
    >>> 
    >>> 
    >>> pj
    >>> 
    >>> --
    >>> Paul E. Johnson Professor, Political Science


From pdalgd at gmail.com  Wed Feb  6 12:06:21 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 6 Feb 2013 12:06:21 +0100
Subject: [Rd] best practice for packages using mclapply to avoid tcltk
In-Reply-To: <20754.8811.443519.383545@stat.math.ethz.ch>
References: <CAErODj_1hg8+x5SvOmoL8V9RMNgMAN_fXGBLcsJhgnH_k2jOgw@mail.gmail.com>
	<F667EFC5-41D0-4F56-AE80-FCBDBE65F46E@r-project.org>
	<CAErODj9qtvB=s0zphXywin5ZpXozVKdj0qeRvAp9cyFy3O8coA@mail.gmail.com>
	<20754.8811.443519.383545@stat.math.ethz.ch>
Message-ID: <93EFFCAA-BC1A-4218-B92D-12EE55B3BA2B@gmail.com>


On Feb 6, 2013, at 10:29 , Martin Maechler wrote:

>>>>>> "PJ" == Paul Johnson <pauljohn32 at gmail.com>
>>>>>>    on Tue, 5 Feb 2013 22:25:01 -0600 writes:
> 
>> On Sun, Feb 3, 2013 at 1:34 PM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>> As Peter pointed out earlier, this is better addressed by
>>> disabling the Tcl/Tk event loop in forked processes.
>>> 
>> Dear Simon:
> 
>> I don't understand.  Can you please try to say it again?
> 
>> I find Peter's comment (on Jan 3, 2013, thread title:
>> weird bug with parallel, RSQlite and tcltk):
> 
>> "More likely, the wisdom of calling R_ProcessEvents and
>> R_PolledEvents in parallel processes should be
>> questioned. I tend to think that they should both be
>> disabled completely conditionally on R_isForkedChild.
>> At least in the Tk loop, some of the events are
>> generated as responses to specific queries, and having
>> one process ask for something and another one handling
>> the reply, leaving the first one waiting indefinitely,
>> is just Not Right."
> 
>> That suggested to me the problem is in R itself, or the
>> tcltk package
> 
> Well, it should have suggested that the problem should be
> addressed "in R itself"?

Exactly. Except that I worried about possible side effects enough that I didn't go in and fix things myself (I am not completely up to speed on the internals of the parallel stuff). So Brian did it.

> and it now has been:
> 
> The NEWS  for R 2.15.2 patched (and hence "R devel" and all
>    	      	       	       	future versions of R)

In principle, that is a non sequitur, but in this case, the change was ported FROM R-devel (r61839).

(As a general matter, it is possible for R-devel to diverge from R-patched to such an extent that modifications to one don't make sense for the other. This usually doesn't happen, though.)

> now contain
> 
>      The Tcl/Tk event loop is inhibited in a forked child (as in e.g.
>      mclapply().

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From tim.triche at gmail.com  Wed Feb  6 16:34:17 2013
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Wed, 6 Feb 2013 07:34:17 -0800
Subject: [Rd] slotName defined in object, present in instance,
	but inaccessible
Message-ID: <CAC+N9BVeP-tnEJKhRvifEe8qixJ37qs8ZWQD50=vB6ZkL=Z9tQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130206/db5050ba/attachment.pl>

From tim.triche at gmail.com  Wed Feb  6 16:34:17 2013
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Wed, 6 Feb 2013 07:34:17 -0800
Subject: [Rd] [R] slotName defined in object, present in instance,
 but inaccessible [SCL:4]
Message-ID: <CAC+N9BVeP-tnEJKhRvifEe8qixJ37qs8ZWQD50=vB6ZkL=Z9tQ@mail.gmail.com>

from a package I'm writing....

##setClass('Occupancy',contains="DataFrame",
##                 representation(states="StatesORNULL"))
##
R> foo <- occupancy(pooledMethSegs)
R> plotOccupancy(foo)
Error in slot(object, "states") :
  no slot of name "states" for this object of class "Occupancy"
R> slotNames(foo)
[1] "states"          "rownames"        "nrows"           "listData"
[5] "elementType"     "elementMetadata" "metadata"
R> foo at states
Error: no slot of name "states" for this object of class "Occupancy"


Any ideas as to what's going on here?


R> sessionInfo()
R Under development (unstable) (2013-01-29 r61783)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=C                 LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] grid      parallel  stats     graphics  grDevices datasets  utils
[8] methods   base

other attached packages:
 [1] rtracklayer_1.19.9    chromophobe_0.49      pheatmap_0.7.4
 [4] ggplot2_0.9.3         reshape2_1.2.2        GenomicRanges_1.11.28
 [7] IRanges_1.17.31       BiocGenerics_0.5.6    BiocInstaller_1.9.6
[10] gtools_2.7.0          devtools_1.0

loaded via a namespace (and not attached):
 [1] Biostrings_2.27.10 bitops_1.0-5       BSgenome_1.27.1
 colorspace_1.2-1
 [5] dichromat_2.0-0    digest_0.6.2       evaluate_0.4.3     gtable_0.1.2

 [9] httr_0.2           labeling_0.1       lattice_0.20-13    MASS_7.3-23

[13] Matrix_1.0-10      memoise_0.1        munsell_0.4        plyr_1.8

[17] proto_0.3-10       RColorBrewer_1.0-5 RCurl_1.95-3
Rsamtools_1.11.15
[21] scales_0.2.3       stats4_3.0.0       stringr_0.6.2      tools_3.0.0

[25] whisker_0.1        XML_3.95-0.1       zlibbioc_1.5.0

	[[alternative HTML version deleted]]

______________________________________________
R-help at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-help
PLEASE do read the posting guide http://www.R-project.org/posting-guide.html
and provide commented, minimal, self-contained, reproducible code.


From mtmorgan at fhcrc.org  Thu Feb  7 03:33:31 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Wed, 06 Feb 2013 18:33:31 -0800
Subject: [Rd] How to NAMESPACE OS-specific importFrom?
Message-ID: <5113127B.9050407@fhcrc.org>

I'd like to importFrom(parallel, mccollect, mcparallel) but on Windows these are 
not exported because this

if(tools:::.OStype() == "unix") {
     export(mccollect, mcparallel, mc.reset.stream, mcaffinity)
}

appears at src/library/parallel/NAMESPACE:6 of svn r61857. So should I be doing

if (tools:::.OStype() == "unix") {
     importFrom(parallel, mccollect, mcparallel)
}

in my NAMESPACE? I have a recollection that this has come up before, perhaps 
even in the parallel package, but I'm not able to find anything.

Thanks,

Martin Morgan
-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From ripley at stats.ox.ac.uk  Thu Feb  7 08:42:40 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 07 Feb 2013 07:42:40 +0000
Subject: [Rd] How to NAMESPACE OS-specific importFrom?
In-Reply-To: <5113127B.9050407@fhcrc.org>
References: <5113127B.9050407@fhcrc.org>
Message-ID: <51135AF0.5040203@stats.ox.ac.uk>

On 07/02/2013 02:33, Martin Morgan wrote:
> I'd like to importFrom(parallel, mccollect, mcparallel) but on Windows
> these are not exported because this
>
> if(tools:::.OStype() == "unix") {
>      export(mccollect, mcparallel, mc.reset.stream, mcaffinity)
> }
>
> appears at src/library/parallel/NAMESPACE:6 of svn r61857. So should I
> be doing
>
> if (tools:::.OStype() == "unix") {
>      importFrom(parallel, mccollect, mcparallel)
> }
>
> in my NAMESPACE? I have a recollection that this has come up before,
> perhaps even in the parallel package, but I'm not able to find anything.

Yes.

Those are low-level functions in 'parallel': we provide stubs on Windows 
for user-level functions (which is where it came up before these were 
added).

> Thanks,
>
> Martin Morgan


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From davide.rambaldi at ieo.eu  Thu Feb  7 11:05:54 2013
From: davide.rambaldi at ieo.eu (Davide Rambaldi)
Date: Thu, 7 Feb 2013 11:05:54 +0100
Subject: [Rd] It's a BUG or a Feature? Generating seq break comparing
	operators
Message-ID: <DB673033-01F6-49EA-B3C0-E6E9215E51A8@ieo.eu>

Hello everybody:

I get a strange behavior with seq, take a look at this:

> msd <- seq(0.05,0.3, 0.01)
> msd[13]
[1] 0.17
> class(msd)
[1] "numeric"
> class(msd[13])
[1] "numeric"
> typeof(msd[13])
[1] "double"

now the problem:

> msd[13] == 0.17
[1] FALSE

It is strange only to me?

Consider that:

> 0.17 == 0.17
[1] TRUE

and also

> a <- c(0,1,0.17)
> a
[1] 0.00 1.00 0.17
> a[3] == 0.17
[1] TRUE

It's a BUG in seq? I suspect something related to doubles ? 

sessionInfo():

R version 2.15.2 (2012-10-26)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

loaded via a namespace (and not attached):
[1] tools_2.15.2


-----------------------------------------------------------
PLEASE NOTE MY NEW EMAIL ADDRESS
-----------------------------------------------------------

-----------------------------------------------------
Davide Rambaldi, PhD.
-----------------------------------------------------
IEO ~ MolMed
[e] davide.rambaldi at ieo.eu
[e] davide.rambaldi at gmail.com


From michael.weylandt at gmail.com  Thu Feb  7 11:13:31 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt)
Date: Thu, 7 Feb 2013 10:13:31 +0000
Subject: [Rd] It's a BUG or a Feature? Generating seq break comparing
	operators
In-Reply-To: <DB673033-01F6-49EA-B3C0-E6E9215E51A8@ieo.eu>
References: <DB673033-01F6-49EA-B3C0-E6E9215E51A8@ieo.eu>
Message-ID: <CAAmySGMHJiUEEWv4UwjyZo4FcQizygwikGF6yuy6WTpUdo7yyA@mail.gmail.com>

R FAQ 7.31

Cheers,
MW

On Thu, Feb 7, 2013 at 10:05 AM, Davide Rambaldi <davide.rambaldi at ieo.eu> wrote:
> Hello everybody:
>
> I get a strange behavior with seq, take a look at this:
>
>> msd <- seq(0.05,0.3, 0.01)
>> msd[13]
> [1] 0.17
>> class(msd)
> [1] "numeric"
>> class(msd[13])
> [1] "numeric"
>> typeof(msd[13])
> [1] "double"
>
> now the problem:
>
>> msd[13] == 0.17
> [1] FALSE
>
> It is strange only to me?
>
> Consider that:
>
>> 0.17 == 0.17
> [1] TRUE
>
> and also
>
>> a <- c(0,1,0.17)
>> a
> [1] 0.00 1.00 0.17
>> a[3] == 0.17
> [1] TRUE
>
> It's a BUG in seq? I suspect something related to doubles ?
>
> sessionInfo():
>
> R version 2.15.2 (2012-10-26)
> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] tools_2.15.2
>
>
> -----------------------------------------------------------
> PLEASE NOTE MY NEW EMAIL ADDRESS
> -----------------------------------------------------------
>
> -----------------------------------------------------
> Davide Rambaldi, PhD.
> -----------------------------------------------------
> IEO ~ MolMed
> [e] davide.rambaldi at ieo.eu
> [e] davide.rambaldi at gmail.com
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jari.oksanen at oulu.fi  Thu Feb  7 11:20:34 2013
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Thu, 7 Feb 2013 10:20:34 +0000
Subject: [Rd] It's a BUG or a Feature? Generating seq break
	comparing	operators
In-Reply-To: <CAAmySGMHJiUEEWv4UwjyZo4FcQizygwikGF6yuy6WTpUdo7yyA@mail.gmail.com>
References: <DB673033-01F6-49EA-B3C0-E6E9215E51A8@ieo.eu>
	<CAAmySGMHJiUEEWv4UwjyZo4FcQizygwikGF6yuy6WTpUdo7yyA@mail.gmail.com>
Message-ID: <66C03CD1145C95448A4D73676DD9C2ED40D5EA@nippu1.univ.yo.oulu.fi>

This should be FAQ 0.0. No other thing is asked as frequently as this. This is the FAQest of all FAQs, and a mother of all FAQs. At least this should be in R posting guide: "Read FAQ 7.31 before posting!"

Cheers, Jari Oksanen

On 07/02/2013, at 12:13 PM, R. Michael Weylandt wrote:

> R FAQ 7.31
> 
> Cheers,
> MW
> 
> On Thu, Feb 7, 2013 at 10:05 AM, Davide Rambaldi <davide.rambaldi at ieo.eu> wrote:
>> Hello everybody:
>> 
>> I get a strange behavior with seq, take a look at this:
>> 
>>> msd <- seq(0.05,0.3, 0.01)
>>> msd[13]
>> [1] 0.17
>>> class(msd)
>> [1] "numeric"
>>> class(msd[13])
>> [1] "numeric"
>>> typeof(msd[13])
>> [1] "double"
>> 
>> now the problem:
>> 
>>> msd[13] == 0.17
>> [1] FALSE
>> 
>> It is strange only to me?
>> 
>> Consider that:
>> 
>>> 0.17 == 0.17
>> [1] TRUE
>> 
>> and also
>> 
>>> a <- c(0,1,0.17)
>>> a
>> [1] 0.00 1.00 0.17
>>> a[3] == 0.17
>> [1] TRUE
>> 
>> It's a BUG in seq? I suspect something related to doubles ?
>> 
>> sessionInfo():
>> 
>> R version 2.15.2 (2012-10-26)
>> Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)
>> 
>> locale:
>> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> loaded via a namespace (and not attached):
>> [1] tools_2.15.2
>> 
>> 
>> -----------------------------------------------------------
>> PLEASE NOTE MY NEW EMAIL ADDRESS
>> -----------------------------------------------------------
>> 
>> -----------------------------------------------------
>> Davide Rambaldi, PhD.
>> -----------------------------------------------------
>> IEO ~ MolMed
>> [e] davide.rambaldi at ieo.eu
>> [e] davide.rambaldi at gmail.com
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Jari Oksanen, Dept Biology, Univ Oulu, 90014 Finland
jari.oksanen at oulu.fi, Ph. +358 400 408593, http://cc.oulu.fi/~jarioksa


From davide.rambaldi at ieo.eu  Thu Feb  7 11:34:39 2013
From: davide.rambaldi at ieo.eu (Davide Rambaldi)
Date: Thu, 7 Feb 2013 11:34:39 +0100
Subject: [Rd] It's a BUG or a Feature? Generating seq break comparing
	operators
In-Reply-To: <66C03CD1145C95448A4D73676DD9C2ED40D5EA@nippu1.univ.yo.oulu.fi>
References: <DB673033-01F6-49EA-B3C0-E6E9215E51A8@ieo.eu>
	<CAAmySGMHJiUEEWv4UwjyZo4FcQizygwikGF6yuy6WTpUdo7yyA@mail.gmail.com>
	<66C03CD1145C95448A4D73676DD9C2ED40D5EA@nippu1.univ.yo.oulu.fi>
Message-ID: <251CD23F-0073-4313-BDC9-E08CB7CE74C5@ieo.eu>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130207/6dfc31a4/attachment.pl>

From f.harrell at vanderbilt.edu  Thu Feb  7 14:32:04 2013
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Thu, 7 Feb 2013 05:32:04 -0800 (PST)
Subject: [Rd] Regression stars
Message-ID: <1360243924659-4657795.post@n4.nabble.com>

Today's GNU R tutorial in
http://how-to.linuxcareer.com/a-quick-gnu-r-tutorial-to-statistical-models-and-graphics
points out how bad statistical practice is being further perpetuated, by
virtue of "significance stars" still being the default in printed output
from lm models.




-----
Frank Harrell
Department of Biostatistics, Vanderbilt University
--
View this message in context: http://r.789695.n4.nabble.com/Regression-stars-tp4657795.html
Sent from the R devel mailing list archive at Nabble.com.


From jfox at mcmaster.ca  Thu Feb  7 15:27:18 2013
From: jfox at mcmaster.ca (John Fox)
Date: Thu, 07 Feb 2013 09:27:18 -0500
Subject: [Rd] Regression stars
In-Reply-To: <1360243924659-4657795.post@n4.nabble.com>
References: <1360243924659-4657795.post@n4.nabble.com>
Message-ID: <web-443795516@cgpsrv2.cis.mcmaster.ca>

Dear Frank,

I'd like to second your implicit motion to make options(show.signif.stars=FALSE) the default.

Thanks for raising this point.

John

On Thu, 7 Feb 2013 05:32:04 -0800 (PST)
 Frank Harrell <f.harrell at vanderbilt.edu> wrote:
> Today's GNU R tutorial in
> http://how-to.linuxcareer.com/a-quick-gnu-r-tutorial-to-statistical-models-and-graphics
> points out how bad statistical practice is being further perpetuated, by
> virtue of "significance stars" still being the default in printed output
> from lm models.
> 
> 
> 
> 
> -----
> Frank Harrell
> Department of Biostatistics, Vanderbilt University
> --
> View this message in context: http://r.789695.n4.nabble.com/Regression-stars-tp4657795.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From peter.ruckdeschel at itwm.fraunhofer.de  Thu Feb  7 15:41:05 2013
From: peter.ruckdeschel at itwm.fraunhofer.de (Dr. Peter Ruckdeschel)
Date: Thu, 07 Feb 2013 15:41:05 +0100
Subject: [Rd] large sysdata.rda file --- strategies?
Message-ID: <5113BD01.8090604@itwm.fraunhofer.de>

Hi,

to speed up computations in our RobASt family of packages, we use
interpolation on a grid of precomputed values which we save together
with the interpolating functions (results of splinefun essentially)
in sysdata.rda in the R folder of our pkg.

After adding grids for some more models, this file has grown
considerably, even after application of tools::resaveRdaFiles.
At the moment we are at about 2MB (compressed) and 8.8 MB
(uncompressed) and hence R CMD check --as-cran issues a NOTE.

We want to comply with cran policies,
      http://cran.r-project.org/web/packages/policies.html
in particular with
> Where a large amount of data is required (even after compression),
> consideration should be given to a separate data-only package which
> can be updated only rarely (since older versions of packages are
> archived in perpetuity).

Q1: Are packages only consisting of a sysdata.rda file thinkable for
submission on CRAN ? Are such pkgs the way to go for w.r.t. to the
cited policy?

If this is the case, how  would one document such a package, in particular
if we do not export any objects in the NAMESPACE file?
In addition, with a sysdata.rda-only pkg,  R CMD check issues a warning
"Found directory 'R' with no source files"  Of course a workaround is
adding a comment-only file comment.R to the R folder.

Q2: Is there a lazy load / lazy data mechanism available for
sysdata.rda ? If so how would one enforce it?

Any suggestions appreciated,

Best, Peter

-- 
Dr. habil. Peter Ruckdeschel, Abteilung Finanzmathematik, F3.17
Fraunhofer ITWM, Fraunhofer Platz 1, 67663 Kaiserslautern
Telefon:  +49 631/31600-4699   Fax    :  +49 631/31600-5699
E-Mail :  peter.ruckdeschel at itwm.fraunhofer.de
http://www.itwm.fraunhofer.de/abteilungen/finanzmathematik/mitarbeiterinnen/mitarbeiter/dr-peter-ruckdeschel.html


From marc_schwartz at me.com  Thu Feb  7 18:50:07 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Thu, 07 Feb 2013 11:50:07 -0600
Subject: [Rd] Regression stars
In-Reply-To: <web-443795516@cgpsrv2.cis.mcmaster.ca>
References: <1360243924659-4657795.post@n4.nabble.com>
	<web-443795516@cgpsrv2.cis.mcmaster.ca>
Message-ID: <C06C7690-811D-4B09-BA17-2CEC6E28B5F9@me.com>

FWIW, that has been my default setting for years in my .Rprofile.

If there is some agreement on this from R Core, it would seem that version 3.0.0 would be a reasonable breakpoint for this change in default behavior.

Regards,

Marc Schwartz

On Feb 7, 2013, at 8:27 AM, John Fox <jfox at mcmaster.ca> wrote:

> Dear Frank,
> 
> I'd like to second your implicit motion to make options(show.signif.stars=FALSE) the default.
> 
> Thanks for raising this point.
> 
> John
> 
> On Thu, 7 Feb 2013 05:32:04 -0800 (PST)
> Frank Harrell <f.harrell at vanderbilt.edu> wrote:
>> Today's GNU R tutorial in
>> http://how-to.linuxcareer.com/a-quick-gnu-r-tutorial-to-statistical-models-and-graphics
>> points out how bad statistical practice is being further perpetuated, by
>> virtue of "significance stars" still being the default in printed output
>> from lm models.


From friendly at yorku.ca  Thu Feb  7 22:49:20 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Thu, 07 Feb 2013 16:49:20 -0500
Subject: [Rd] assignInNamespace to create a setwd() replacement: how to use
	unlockBinding()?
Message-ID: <51142160.7010104@yorku.ca>

In my .Rprofile for Windows, I had the following functions defined to 
mirror a few features
I miss from linux:

(a) replace setwd() with a version that stashes the current directory so 
it can be easily restored
(b) writes a short version of the current R directory to the Windows 
title bar: I can always see where I am,
with multiple Rgui windows.
(c) creates a cd() shorthand for setwd(), but with the difference that 
cd() acts like cd - under the tcsh shell,
returning to the previously stored directory.

#### setwd-new.R ######
# .Rprofile functions to set current directory in WindowTitle

#======================
# setwd() replacement functions
#======================

oldsetwd <- base::setwd
utils::assignInNamespace("setwd",
function(dir) {
.lastdir <<- oldsetwd(dir)
utils::setWindowTitle( short.path(base::getwd()) )
.lastdir
}, "base")

# setwd replacement, allowing cd() to be like 'cd -' on unix (return to 
last dir)
cd <- function(dir) {
if(missing(dir)) dir <- .lastdir
.lastdir <<- base::setwd(dir)
utils::setWindowTitle( short.path(base::getwd()) )
}

short.path <- function(dir, len=2) {
np <-length(parts <- unlist(strsplit(dir, '/')))
parts <-rev( rev(parts)[1:min(np,len)] )
dots <- ifelse (np>len, '...', '')
paste(dots,paste(parts, '/', sep='', collapse=''))
}


These all worked for all R versions up to R 2.15.0, where it began to 
break as follows:

 > source("setwd-new.R")
Error in utils::assignInNamespace("setwd", function(dir) { :
locked binding of ?setwd? cannot be changed
 >

I understand what the error means, and I think that unlockBinding() 
somewhere in my code gives a solution,
but I don't see where or how.

I should also add that in my actual .Rprofile, I source these functions 
into a local environment & attach
so they are always available, but don't clutter up ls()

.my.env <- local({
# all my local definitions
})
attach(.my.env)



-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From gdsayshi at gmail.com  Fri Feb  8 07:57:25 2013
From: gdsayshi at gmail.com (Gaurav Dasgupta)
Date: Fri, 8 Feb 2013 12:27:25 +0530
Subject: [Rd] ClassNotFoundException when running distributed job using
	rJava package
Message-ID: <CACq8Ys2_ngjjhWcma=8Q3maZY8xabcn-7iDybSZbDhUk-H574Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130208/ee0b8467/attachment.pl>

From ripley at stats.ox.ac.uk  Fri Feb  8 08:16:53 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 08 Feb 2013 07:16:53 +0000
Subject: [Rd] ClassNotFoundException when running distributed job using
 rJava package
In-Reply-To: <CACq8Ys2_ngjjhWcma=8Q3maZY8xabcn-7iDybSZbDhUk-H574Q@mail.gmail.com>
References: <CACq8Ys2_ngjjhWcma=8Q3maZY8xabcn-7iDybSZbDhUk-H574Q@mail.gmail.com>
Message-ID: <5114A665.8080804@stats.ox.ac.uk>

This is not the rJava support list: that is at 
http://www.rosuda.org/lists.shtml.

On 08/02/2013 06:57, Gaurav Dasgupta wrote:
> Hi,
>
> I have a MapReduce Java code, which I am calling from R using rJava. I have
> prepared the R package and tested that successfully. But when I deployed
> the package in a cluster and executed it, I am getting
> ClassNotFoundException. If I run the same job directly without integrating
> with R, it runs perfectly.
> Here is my R code:
>
> library(rJava)
> muMstSpark <- function(mesosMaster = NULL, input = NULL, output = NULL,
> scalaLib = NULL, sparkCore = NULL, inputSplits = 8) {
>    if (is.null(mesosMaster) || is.null(input) || is.null(output) ||
> is.null(scalaLib) || is.null(sparkCore)) {
>      stop("Usage: muMST(<mesosMaster>, <input>, <output>, <scalaLib>,
> <sparkCore>, [<inputSplits>]")
>    }
>
>    # Gets the absolute path of the external Scala and Java JARS
>    pkgPath = paste(system.file(package="MuMstBig"), "/jars", sep="")
>
>    # Initializes the JVM specifying the directory where the main Java class
> resides:
>    .jinit("pkgPath")
>
>    # Adds all the required JARs to the class path:
>    .jaddClassPath(paste(pkgPath, "Prims.jar", sep="/"))
>    .jaddClassPath(paste(pkgPath, "MSTInSpark.jar", sep="/"))
>    .jaddClassPath(scalaLib)
>    .jaddClassPath(sparkCore)
>
>    # Creates the R object for the main Java class:
>    obj <- .jnew("MSTInSpark")
>
>    # Calls the Java main class
>    .jcall(obj, "V", "mst", c(mesosMaster, input, output, inputSplits))
> }
> Here is the error log:
>
> 13/02/08 00:54:48 INFO cluster.TaskSetManager: Loss was due to
> java.lang.ClassNotFoundException: Prims$$anonfun$PrimsExecute$1
>   at java.net.URLClassLoader$1.run(URLClassLoader.java:202)
>   at java.security.AccessController.doPrivileged(Native Method)
>   at java.net.URLClassLoader.findClass(URLClassLoader.java:190)
>   at java.lang.ClassLoader.loadClass(ClassLoader.java:306)
>   at java.lang.ClassLoader.loadClass(ClassLoader.java:247)
>   at java.lang.Class.forName0(Native Method)
>   at java.lang.Class.forName(Class.java:247)
>   at
> spark.JavaDeserializationStream$$anon$1.resolveClass(JavaSerializer.scala:20)
>   at java.io.ObjectInputStream.readNonProxyDesc(ObjectInputStream.java:1574)
>   at java.io.ObjectInputStream.readClassDesc(ObjectInputStream.java:1495)
>   at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1731)
>   at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1328)
>   at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1946)
>   at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1870)
>   at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1752)
>   at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1328)
>   at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1946)
>   at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1870)
>   at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1752)
>   at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1328)
>   at java.io.ObjectInputStream.readObject(ObjectInputStream.java:350)
>   at scala.collection.immutable.$colon$colon.readObject(List.scala:435)
>   at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
>   at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
>   at java.lang.reflect.Method.invoke(Method.java:597)
>   at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:969)
>   at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1848)
>   at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1752)
>   at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1328)
>   at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1946)
>   at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1870)
>   at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1752)
>   at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1328)
>   at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1946)
>   at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1870)
>   at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1752)
>   at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1328)
>   at java.io.ObjectInputStream.readObject(ObjectInputStream.java:350)
>   at scala.collection.immutable.$colon$colon.readObject(List.scala:435)
>   at sun.reflect.GeneratedMethodAccessor2.invoke(Unknown Source)
>   at
> sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:25)
>   at java.lang.reflect.Method.invoke(Method.java:597)
>   at java.io.ObjectStreamClass.invokeReadObject(ObjectStreamClass.java:969)
>   at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1848)
>   at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1752)
>   at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1328)
>   at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1946)
>   at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1870)
>   at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1752)
>   at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1328)
>   at java.io.ObjectInputStream.defaultReadFields(ObjectInputStream.java:1946)
>   at java.io.ObjectInputStream.readSerialData(ObjectInputStream.java:1870)
>   at
> java.io.ObjectInputStream.readOrdinaryObject(ObjectInputStream.java:1752)
>   at java.io.ObjectInputStream.readObject0(ObjectInputStream.java:1328)
>   at java.io.ObjectInputStream.readObject(ObjectInputStream.java:350)
>   at spark.JavaDeserializationStream.readObject(JavaSerializer.scala:23)
>   at spark.JavaSerializerInstance.deserialize(JavaSerializer.scala:45)
>   at spark.executor.Executor$TaskRunner.run(Executor.scala:93)
>   at
> java.util.concurrent.ThreadPoolExecutor$Worker.runTask(ThreadPoolExecutor.java:886)
>   at
> java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:908)
>   at java.lang.Thread.run(Thread.java:662)
>
> I think R is unable to find the classpath. But I have specified that in the
> script by taking the absolute path of the JARs in the package. The
> package's installed across the cluster. Any idea, whats going wrong?
>
> Thanks,
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From ligges at statistik.tu-dortmund.de  Fri Feb  8 15:17:48 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 08 Feb 2013 15:17:48 +0100
Subject: [Rd] assignInNamespace to create a setwd() replacement: how to
 use unlockBinding()?
In-Reply-To: <51142160.7010104@yorku.ca>
References: <51142160.7010104@yorku.ca>
Message-ID: <5115090C.1090405@statistik.tu-dortmund.de>

On 07.02.2013 22:49, Michael Friendly wrote:
> In my .Rprofile for Windows, I had the following functions defined to
> mirror a few features
> I miss from linux:
>
> (a) replace setwd() with a version that stashes the current directory so
> it can be easily restored
> (b) writes a short version of the current R directory to the Windows
> title bar: I can always see where I am,
> with multiple Rgui windows.
> (c) creates a cd() shorthand for setwd(), but with the difference that
> cd() acts like cd - under the tcsh shell,
> returning to the previously stored directory.
>
> #### setwd-new.R ######
> # .Rprofile functions to set current directory in WindowTitle
>
> #======================
> # setwd() replacement functions
> #======================
>
> oldsetwd <- base::setwd
> utils::assignInNamespace("setwd",
> function(dir) {
> .lastdir <<- oldsetwd(dir)
> utils::setWindowTitle( short.path(base::getwd()) )
> .lastdir
> }, "base")
>
> # setwd replacement, allowing cd() to be like 'cd -' on unix (return to
> last dir)
> cd <- function(dir) {
> if(missing(dir)) dir <- .lastdir
> .lastdir <<- base::setwd(dir)
> utils::setWindowTitle( short.path(base::getwd()) )
> }
>
> short.path <- function(dir, len=2) {
> np <-length(parts <- unlist(strsplit(dir, '/')))
> parts <-rev( rev(parts)[1:min(np,len)] )
> dots <- ifelse (np>len, '...', '')
> paste(dots,paste(parts, '/', sep='', collapse=''))
> }
>
>
> These all worked for all R versions up to R 2.15.0, where it began to
> break as follows:
>
>  > source("setwd-new.R")
> Error in utils::assignInNamespace("setwd", function(dir) { :
> locked binding of ?setwd? cannot be changed
>  >
>
> I understand what the error means, and I think that unlockBinding()
> somewhere in my code gives a solution,
> but I don't see where or how.
>
> I should also add that in my actual .Rprofile, I source these functions
> into a local environment & attach
> so they are always available, but don't clutter up ls()
>
> .my.env <- local({
> # all my local definitions
> })
> attach(.my.env)
>

Replacing base functionality is bad practice, since some packages may 
rely on the actual functionality from base. Why not provide such 
functions in a private package that masks the base functionality for 
your interactive work only (and keeps base clean to be used by other 
packages).
Finally, you can load that package in your startup code.

Best,
Uwe Ligges


From ligges at statistik.tu-dortmund.de  Fri Feb  8 15:22:18 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 08 Feb 2013 15:22:18 +0100
Subject: [Rd] How to use summary.mer inside a package?
In-Reply-To: <5110E691.1010407@fau.de>
References: <5110E691.1010407@fau.de>
Message-ID: <51150A1A.5030904@statistik.tu-dortmund.de>



On 05.02.2013 12:01, Benjamin Hofner wrote:
> I have a question regarding the build of my project papeR (hosted on
> R-forge http://r-forge.r-project.org/R/?group_id=1574) with respect to
> lme4.
>
> Both, Windows and MacOS are complaining that lme4 doesn't export summary:
>
>    Error : object 'summary' is not exported by 'namespace:lme4'
>    ERROR: lazy loading failed for package 'papeR'
>
> Linux however builds the project as desired.
>
> I now did check my package using Uwe Ligges' winbuilder project and got
> positive results i.e. no errors for Windows there. See (for the next 72
> hours):
>
> http://win-builder.r-project.org/y3uwwx93nJ92
> http://win-builder.r-project.org/10mtpspKx7us
>
> Can anyone tell me why this happens (only on R-forge and only for
> certain systems) and how to prevent this?

Perhaps the R-forge results are outdated? Looks like the R-forge builds 
(and hence probably also the checks) are stuck since some days.





> [I already asked the R-forge maintainers and was redirected to the
> general R mailing lists]
>
> As a side note: The reason for importing lme4's summary is that
> otherwise my function summary.fixef, which extracts fixed effects from

So, are summary.fixef and summary.mer methods or generics? If the 
former, why not call them via the generic?

Best,
Uwe Ligges




> nlme and lme4 models for printing e.g. in reports, doesn't use/find
> summary.mer on "mer" objects -- even if lme4 is loaded earlier. On the
> other hand, lme models (from package nlme) are handled correctly despite
> the fact that I do not import the corresponding summary function.
>
> Thank you very much
>    Benjamin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Fri Feb  8 16:01:03 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 08 Feb 2013 09:01:03 -0600
Subject: [Rd] regression stars
Message-ID: <5115132F.2080701@mayo.edu>

  There are only a few things in R where we override the global defaults on a departmental 
level -- we really don't like to do so.  But "show.signif.stars" is one of the 3.

   The other 2 if you are curious: set stringsAsFactors=FALSE and make NA included by 
default in the output of table. We've been overriding both of these for 10+ years.

Terry Therneau


From edzer.pebesma at uni-muenster.de  Fri Feb  8 16:41:51 2013
From: edzer.pebesma at uni-muenster.de (Edzer Pebesma)
Date: Fri, 08 Feb 2013 16:41:51 +0100
Subject: [Rd] r-forge
In-Reply-To: <51150A1A.5030904@statistik.tu-dortmund.de>
References: <5110E691.1010407@fau.de>
	<51150A1A.5030904@statistik.tu-dortmund.de>
Message-ID: <51151CBF.7030408@uni-muenster.de>



On 02/08/2013 03:22 PM, Uwe Ligges wrote:
>
> Perhaps the R-forge results are outdated? Looks like the R-forge builds
> (and hence probably also the checks) are stuck since some days.

Nice understatement.

Several of my packages don't build on r-forge for some months now 
because some other packages are out of date on r-forge (far behind the 
CRAN version, for instance) or because of the obscure

Error in setwd(libdir) : cannot change working directory

error. I've written support requests, recieved answers, but haven't seen 
solutions. It seems I'm not the only one facing this.

Maybe the r-forge team can tap into the potential of some of its 6000 
users, assuming most of these are developers wanting a good, working 
system? Or are financial resources a problem?
-- 
Edzer Pebesma
Institute for Geoinformatics (ifgi), University of M?nster
Weseler Stra?e 253, 48151 M?nster, Germany. Phone: +49 251
8333081, Fax: +49 251 8339763  http://ifgi.uni-muenster.de
http://www.52north.org/geostatistics      e.pebesma at wwu.de


From ligges at statistik.tu-dortmund.de  Fri Feb  8 16:50:14 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 08 Feb 2013 16:50:14 +0100
Subject: [Rd] r-forge
In-Reply-To: <51151CBF.7030408@uni-muenster.de>
References: <5110E691.1010407@fau.de>
	<51150A1A.5030904@statistik.tu-dortmund.de>
	<51151CBF.7030408@uni-muenster.de>
Message-ID: <51151EB6.4070706@statistik.tu-dortmund.de>



On 08.02.2013 16:41, Edzer Pebesma wrote:
>
>
> On 02/08/2013 03:22 PM, Uwe Ligges wrote:
>>
>> Perhaps the R-forge results are outdated? Looks like the R-forge builds
>> (and hence probably also the checks) are stuck since some days.
>
> Nice understatement.
>
> Several of my packages don't build on r-forge for some months now
> because some other packages are out of date on r-forge (far behind the
> CRAN version, for instance) or because of the obscure
>
> Error in setwd(libdir) : cannot change working directory
>
> error. I've written support requests, recieved answers, but haven't seen
> solutions. It seems I'm not the only one facing this.
>
> Maybe the r-forge team can tap into the potential of some of its 6000
> users, assuming most of these are developers wanting a good, working
> system? Or are financial resources a problem?

I think you should discuss it with Stefan who has another day job for 
some time now...

Best,
Uwe


From julien at nozav.org  Fri Feb  8 16:13:49 2013
From: julien at nozav.org (Julien Barnier)
Date: Fri, 8 Feb 2013 15:13:49 +0000
Subject: [Rd] Localization of Rd files
Message-ID: <loom.20130208T160835-448@post.gmane.org>

Hi,

I'm currently developing a small package essentially used by non-english
speaking people, So I wrote the help pages (Rd files) in french.

What I'd like to know is if there is a way to localize these Rd files, ie
provide the same file in different languages to have it displayed according
to the locale of the user's system.

I've found that there are possibilities to translate text messages from
package functions with gettext, but nothing about Rd files.

Thanks in advance for any hints.

Sincerely,

-- 
Julien


From ripley at stats.ox.ac.uk  Fri Feb  8 17:23:29 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 08 Feb 2013 16:23:29 +0000
Subject: [Rd] Localization of Rd files
In-Reply-To: <loom.20130208T160835-448@post.gmane.org>
References: <loom.20130208T160835-448@post.gmane.org>
Message-ID: <51152681.8060802@stats.ox.ac.uk>

On 08/02/2013 15:13, Julien Barnier wrote:
> Hi,
>
> I'm currently developing a small package essentially used by non-english
> speaking people, So I wrote the help pages (Rd files) in french.
>
> What I'd like to know is if there is a way to localize these Rd files, ie
> provide the same file in different languages to have it displayed according
> to the locale of the user's system.

No.  Apart from anything else, .Rd files are processed at installation 
time, when the locale may well be different from the user's locale.

You might as well have different versions of the package for different 
languages -- people have done that.

> I've found that there are possibilities to translate text messages from
> package functions with gettext, but nothing about Rd files.
>
> Thanks in advance for any hints.
>
> Sincerely,
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From friendly at yorku.ca  Fri Feb  8 17:32:05 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 08 Feb 2013 11:32:05 -0500
Subject: [Rd] assignInNamespace to create a setwd() replacement: how to
 use unlockBinding()?
In-Reply-To: <5115090C.1090405@statistik.tu-dortmund.de>
References: <51142160.7010104@yorku.ca>
	<5115090C.1090405@statistik.tu-dortmund.de>
Message-ID: <51152885.2000002@yorku.ca>

Thanks, Uwe
Yes, that was evil, but like other evil practices, it worked for many R 
generations.  Your suggestion wasn't hard to implement
and makes my .Rprofile healthier & happier.
-Michael


On 2/8/2013 9:17 AM, Uwe Ligges wrote:
>
> Replacing base functionality is bad practice, since some packages may 
> rely on the actual functionality from base. Why not provide such 
> functions in a private package that masks the base functionality for 
> your interactive work only (and keeps base clean to be used by other 
> packages).
> Finally, you can load that package in your startup code.
>
> Best,
> Uwe Ligges


-- 
Michael Friendly     Email: friendly AT yorku DOT ca
Professor, Psychology Dept. & Chair, Quantitative Methods
York University      Voice: 416 736-2100 x66249 Fax: 416 736-5814
4700 Keele Street    Web:   http://www.datavis.ca
Toronto, ONT  M3J 1P3 CANADA


From peter.meilstrup at gmail.com  Sat Feb  9 10:29:43 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Sat, 9 Feb 2013 01:29:43 -0800
Subject: [Rd] Arguments passing through dot-dot-dot lose ability to
	check for missing()?
In-Reply-To: <CAJoaRhZe9qCgoLKhZSOQm4HLp1h_BNr-VFq+C4rO1X3smRLcOQ@mail.gmail.com>
References: <CAJoaRhZe9qCgoLKhZSOQm4HLp1h_BNr-VFq+C4rO1X3smRLcOQ@mail.gmail.com>
Message-ID: <CAJoaRhb-N5Gh3ZtfDMn5bZHwPVYMhyXxTCiSa3SiwtYv+UXS_Q@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130209/7515cafd/attachment.pl>

From LaurentRdevel at free.fr  Sat Feb  9 19:27:44 2013
From: LaurentRdevel at free.fr (LaurentRdevel)
Date: Sat, 9 Feb 2013 19:27:44 +0100
Subject: [Rd] trouble with accentuated characters in \title tag in Rd file
Message-ID: <51169520.2070702@free.fr>

Dear R-devel-list,

   Since I had no answer on the R-help-list 
(http://permalink.gmane.org/gmane.comp.lang.r.general/284539) I try to 
present my trouble on the R-devel-list. I am sure in the past (one year 
ago) to succeed in putting accentuated characters in the \title tag in a 
.Rd file. Recently, creating a package, I have NA in the title function 
instead of the text containing the accentuated character.

Could you please tell me what I missed in the understanding of package 
documentation creation ? Except the title, all works fine.

Best regards
Laurent


From matloff at cs.ucdavis.edu  Sat Feb  9 19:48:01 2013
From: matloff at cs.ucdavis.edu (Norm Matloff)
Date: Sat, 9 Feb 2013 10:48:01 -0800
Subject: [Rd] Regression stars
Message-ID: <20130209184801.GD14037@laura>

Thanks for bringing this up, Frank.

Since many of us are "educators," I'd like to suggest a bolder approach.
Discontinue even offering the stars as an option.  Sadly, we can't stop
reporting p-values, as the world expects them, but does R need to cater
to that attitude by offering star display?  For that matter, why not
have R report confidence intervals as a default?

Many years ago, I wrote a short textbook on stat, and included a
substantial section on the dangers of significance testing.  All three
internal reviewers liked it, but the funny part is that all three said,
"I agree with this, but no one else will." :-)

Norm


From ligges at statistik.tu-dortmund.de  Sat Feb  9 19:54:13 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 9 Feb 2013 19:54:13 +0100
Subject: [Rd] trouble with accentuated characters in \title tag in Rd
 file
In-Reply-To: <51169520.2070702@free.fr>
References: <51169520.2070702@free.fr>
Message-ID: <51169B55.5080205@statistik.tu-dortmund.de>

See Writing R Extensions:

"Since R version 2.12.0 markup has been supported in the text, but use 
of characters other than English text and punctuation (e.g., ?<?) may 
limit portability."

So the answer is: Don't do that.

Best,
Uwe Ligges



On 09.02.2013 19:27, LaurentRdevel wrote:
> Dear R-devel-list,
>
>    Since I had no answer on the R-help-list
> (http://permalink.gmane.org/gmane.comp.lang.r.general/284539) I try to
> present my trouble on the R-devel-list. I am sure in the past (one year
> ago) to succeed in putting accentuated characters in the \title tag in a
> .Rd file. Recently, creating a package, I have NA in the title function
> instead of the text containing the accentuated character.
>
> Could you please tell me what I missed in the understanding of package
> documentation creation ? Except the title, all works fine.
>
> Best regards
> Laurent
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tim.triche at gmail.com  Sat Feb  9 21:44:45 2013
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Sat, 9 Feb 2013 12:44:45 -0800
Subject: [Rd] Regression stars
In-Reply-To: <20130209184801.GD14037@laura>
References: <20130209184801.GD14037@laura>
Message-ID: <CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130209/efc70643/attachment.pl>

From tim.triche at gmail.com  Sat Feb  9 21:49:10 2013
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Sat, 9 Feb 2013 12:49:10 -0800
Subject: [Rd] Regression stars
In-Reply-To: <CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
Message-ID: <CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130209/c447f0ae/attachment.pl>

From matloff at cs.ucdavis.edu  Sat Feb  9 22:19:48 2013
From: matloff at cs.ucdavis.edu (Norm Matloff)
Date: Sat, 9 Feb 2013 13:19:48 -0800
Subject: [Rd] Regression stars
Message-ID: <20130209211948.GA14670@laura>

I appreciate Tim's comments.

I myself have a "social science" paper coming out soon in which I felt
forced to use p-values, given their ubiquity.  However, I also told
readers of the paper that confidence intervals are much more informative
and I do provide them.  As I said earlier, there is no avoiding that,
and R needs to report p-values for that reason.  

Instead, the question is what to do about the stars; I proposed
eliminating them altogether.  Star-crazed users know how to determine
them themselves from the p-values, but deleting them from R would send a
message.

I did say my proposal was "bold," which really meant I was suggesting
that R do SOMETHING to send that message, not necessarily star
elimination.

One such "something" would be the proposal I made, which would be to add
confidence intervals to the output.  This too could be just an option,
but again offering that option would send a message.  Indeed, I would
suggest that the help page explain that confidence intervals are more
informative.  (The help page could make a similar statement regarding
the stars.)

When I pitch R to people, I say that in addition to the large function
and library base and the nice graphics capabilities, R is above all
Statistically Correct--it's written by statisticians who know what they
are doing, rather than some programmer simply implementing a formula
from a textbook.  I know that a lot of people feel this is one of R's
biggest strengths.  Given that, one might argue that R should do what it
can to help users engage in good statistical practice.  I think this was
Frank's point.

Norm


From LaurentRdevel at free.fr  Sun Feb 10 09:49:44 2013
From: LaurentRdevel at free.fr (LaurentRdevel)
Date: Sun, 10 Feb 2013 09:49:44 +0100
Subject: [Rd] trouble with accentuated characters in \title tag in Rd
 file
In-Reply-To: <51169B55.5080205@statistik.tu-dortmund.de>
References: <51169520.2070702@free.fr>
	<51169B55.5080205@statistik.tu-dortmund.de>
Message-ID: <51175F28.5040807@free.fr>

Le 09/02/2013 19:54, Uwe Ligges a ?crit :
> See Writing R Extensions:
>
> "Since R version 2.12.0 markup has been supported in the text, but use 
> of characters other than English text and punctuation (e.g., ?<?) may 
> limit portability."
>
> So the answer is: Don't do that.
>
> Best,
> Uwe Ligges
>
>
>
> On 09.02.2013 19:27, LaurentRdevel wrote:
>> Dear R-devel-list,
>>
>>    Since I had no answer on the R-help-list
>> (http://permalink.gmane.org/gmane.comp.lang.r.general/284539) I try to
>> present my trouble on the R-devel-list. I am sure in the past (one year
>> ago) to succeed in putting accentuated characters in the \title tag in a
>> .Rd file. Recently, creating a package, I have NA in the title function
>> instead of the text containing the accentuated character.
>>
>> Could you please tell me what I missed in the understanding of package
>> documentation creation ? Except the title, all works fine.
>>
>> Best regards
>> Laurent
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
Thank you very much for your answer.

I didn't think that it was the cause of my trouble because it worked for 
the \description tag, so I will not do that in title tags.

Thank you again
Laurent


From f.harrell at vanderbilt.edu  Sun Feb 10 15:22:49 2013
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Sun, 10 Feb 2013 06:22:49 -0800 (PST)
Subject: [Rd] Regression stars
In-Reply-To: <20130209211948.GA14670@laura>
References: <1360243924659-4657795.post@n4.nabble.com>
	<20130209211948.GA14670@laura>
Message-ID: <1360506169506-4658084.post@n4.nabble.com>

Great discussion.   Tim's Sinclair quote is priceless and relates to the
non-reproducible research done in some quarters.   Norm's wish to remove
stars altogether is entirely consistent with good statistical practice and
would make a statement that R base adheres to good practice.  I don't think
it will work to add confidence intervals because models can have nonlinear
or interaction terms, and the reference cell for a factor variable may not
be what the analyst chooses for a comparison group.

I would like for us to find a way to, over time, implement Norm's wish to
de-emphasize P-values in general.  The harm done  by P-values is
immeasureable.

Frank

Norm Matloff wrote
> I appreciate Tim's comments.
> 
> I myself have a "social science" paper coming out soon in which I felt
> forced to use p-values, given their ubiquity.  However, I also told
> readers of the paper that confidence intervals are much more informative
> and I do provide them.  As I said earlier, there is no avoiding that,
> and R needs to report p-values for that reason.  
> 
> Instead, the question is what to do about the stars; I proposed
> eliminating them altogether.  Star-crazed users know how to determine
> them themselves from the p-values, but deleting them from R would send a
> message.
> 
> I did say my proposal was "bold," which really meant I was suggesting
> that R do SOMETHING to send that message, not necessarily star
> elimination.
> 
> One such "something" would be the proposal I made, which would be to add
> confidence intervals to the output.  This too could be just an option,
> but again offering that option would send a message.  Indeed, I would
> suggest that the help page explain that confidence intervals are more
> informative.  (The help page could make a similar statement regarding
> the stars.)
> 
> When I pitch R to people, I say that in addition to the large function
> and library base and the nice graphics capabilities, R is above all
> Statistically Correct--it's written by statisticians who know what they
> are doing, rather than some programmer simply implementing a formula
> from a textbook.  I know that a lot of people feel this is one of R's
> biggest strengths.  Given that, one might argue that R should do what it
> can to help users engage in good statistical practice.  I think this was
> Frank's point.
> 
> Norm
> 
> ______________________________________________

> R-devel@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel





-----
Frank Harrell
Department of Biostatistics, Vanderbilt University
--
View this message in context: http://r.789695.n4.nabble.com/Regression-stars-tp4657795p4658084.html
Sent from the R devel mailing list archive at Nabble.com.


From ligges at statistik.tu-dortmund.de  Sun Feb 10 17:23:25 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sun, 10 Feb 2013 17:23:25 +0100
Subject: [Rd] large sysdata.rda file --- strategies?
In-Reply-To: <5113BD01.8090604@itwm.fraunhofer.de>
References: <5113BD01.8090604@itwm.fraunhofer.de>
Message-ID: <5117C97D.6070501@statistik.tu-dortmund.de>



On 07.02.2013 15:41, Dr. Peter Ruckdeschel wrote:
> Hi,
>
> to speed up computations in our RobASt family of packages, we use
> interpolation on a grid of precomputed values which we save together
> with the interpolating functions (results of splinefun essentially)
> in sysdata.rda in the R folder of our pkg.
>
> After adding grids for some more models, this file has grown
> considerably, even after application of tools::resaveRdaFiles.
> At the moment we are at about 2MB (compressed) and 8.8 MB
> (uncompressed) and hence R CMD check --as-cran issues a NOTE.
>
> We want to comply with cran policies,
>        http://cran.r-project.org/web/packages/policies.html
> in particular with
>> Where a large amount of data is required (even after compression),
>> consideration should be given to a separate data-only package which
>> can be updated only rarely (since older versions of packages are
>> archived in perpetuity).
>
> Q1: Are packages only consisting of a sysdata.rda file thinkable for
> submission on CRAN ? Are such pkgs the way to go for w.r.t. to the
> cited policy?

Yes, given this package needs less updates than the main package, one 
should consider such a data only package that needs rare updates and 
does not flood the space with archived versions.


> If this is the case, how  would one document such a package, in particular
> if we do not export any objects in the NAMESPACE file?
> In addition, with a sysdata.rda-only pkg,  R CMD check issues a warning
> "Found directory 'R' with no source files"  Of course a workaround is
> adding a comment-only file comment.R to the R folder.

If the checks will be changed not to warn in such a case, this can only 
happen for R >= 3.0.0, so your workaround to tell the checks you really 
intended such a package with R folder not containing any code sounds 
plausible for now.


> Q2: Is there a lazy load / lazy data mechanism available for
> sysdata.rda ? If so how would one enforce it?

It is lazy loaded. From WRE:
"if the ?R? subdirectory contains a file ?sysdata.rda? [...] this will 
be lazy-loaded into the namespace/package environment"


Best,
Uwe



> Any suggestions appreciated,
>
> Best, Peter
>


From murdoch.duncan at gmail.com  Sun Feb 10 21:37:23 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 10 Feb 2013 15:37:23 -0500
Subject: [Rd] Regression stars
In-Reply-To: <CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
Message-ID: <51180503.1080605@gmail.com>

On 13-02-09 3:49 PM, Tim Triche, Jr. wrote:
> To clarify, I favor changing the defaults for stringsAsFactors and
> show.signif.stars to FALSE in R-3.0.0, and view any attempt to remove
> either functionality as a seemingly simple but fundamentally misguided idea.

Both of these were discussed by R Core.  I think it's unlikely the 
default for stringsAsFactors will be changed (some R Core members like 
the current behaviour), but it's fairly likely the show.signif.stars 
default will change.  (That's if someone gets around to it:  I 
personally don't care about that one.  P-values are commonly used 
statistics, and the stars are just a simple graphical display of them. 
I find some p-values to be useful, and the display to be harmless.)

I think it's really unlikely the more extreme changes (i.e. dropping 
show.signif.stars completely, or dropping p-values) will happen.

Regarding stringsAsFactors:  I'm not going to defend keeping it as is, 
I'll let the people who like it defend it.  What I will likely do is 
make a few changes so that character vectors are automatically changed 
to factors in modelling functions, so that operating with 
stringsAsFactors=FALSE doesn't trigger silly warnings.

Duncan Murdoch

>
> This is just my opinion, of course.  The change could easily be accompanied
> by a startup notice or release notes indicating that the changes have been
> made, and can be reverted to past behavior if the user so desires.  Perhaps
> more users will investigate the various settings, as a happy side effect.
>
> My thanks to everyone who spends time supporting and working on R-core.
>
>
>
> On Sat, Feb 9, 2013 at 12:44 PM, Tim Triche, Jr. <tim.triche at gmail.com>wrote:
>
>> Changing the default for show.signif.stars should be sufficient to ensure
>> that, if people are going to get themselves into trouble, they will have to
>> do it on purpose.  It's just a visual cue; removing it will not remove the
>> underlying issue, namely blind acceptance of unlikely null models and
>> distributions.
>>
>> For any complex problem, there is a solution that is simple, elegant, and
>> wrong.  As grants and careers can depend on these magic numbers, Upton
>> Sinclair might save everyone some trouble... It is difficult to get a man
>> to understand something, when his salary depends upon his not
>> understanding.
>>
>> stringsAsFactors, however, is responsible for an endless stream of mildly
>> irritating misunderstandings, and defaulting that to FALSE would be very
>> nice.
>>
>> Just my $0.02.  Defaults are one of the most powerful forces in the
>> universe.
>>
>> Also, I liked your book.
>>
>>
>>
>> On Sat, Feb 9, 2013 at 10:48 AM, Norm Matloff <matloff at cs.ucdavis.edu>wrote:
>>
>>> Thanks for bringing this up, Frank.
>>>
>>> Since many of us are "educators," I'd like to suggest a bolder approach.
>>> Discontinue even offering the stars as an option.  Sadly, we can't stop
>>> reporting p-values, as the world expects them, but does R need to cater
>>> to that attitude by offering star display?  For that matter, why not
>>> have R report confidence intervals as a default?
>>>
>>> Many years ago, I wrote a short textbook on stat, and included a
>>> substantial section on the dangers of significance testing.  All three
>>> internal reviewers liked it, but the funny part is that all three said,
>>> "I agree with this, but no one else will." :-)
>>>
>>> Norm
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>>
>> --
>> *A model is a lie that helps you see the truth.*
>> *
>> *
>> Howard Skipper<http://cancerres.aacrjournals.org/content/31/9/1173.full.pdf>
>>
>
>
>


From peter.ruckdeschel at itwm.fraunhofer.de  Mon Feb 11 00:07:58 2013
From: peter.ruckdeschel at itwm.fraunhofer.de (Dr. Peter Ruckdeschel)
Date: Mon, 11 Feb 2013 00:07:58 +0100
Subject: [Rd] large sysdata.rda file --- strategies?
In-Reply-To: <5117C97D.6070501@statistik.tu-dortmund.de>
References: <5113BD01.8090604@itwm.fraunhofer.de>
	<5117C97D.6070501@statistik.tu-dortmund.de>
Message-ID: <5118284E.4090307@itwm.fraunhofer.de>

Dear Uwe,
>
> On 07.02.2013 15:41, Dr. Peter Ruckdeschel wrote:
>> Hi,
>>
>> to speed up computations in our RobASt family of packages, we use
>> interpolation on a grid of precomputed values which we save together
>> with the interpolating functions (results of splinefun essentially)
>> in sysdata.rda in the R folder of our pkg.
>>
>> After adding grids for some more models, this file has grown
>> considerably, even after application of tools::resaveRdaFiles.
>> At the moment we are at about 2MB (compressed) and 8.8 MB
>> (uncompressed) and hence R CMD check --as-cran issues a NOTE.
>>
>> We want to comply with cran policies,
>>        http://cran.r-project.org/web/packages/policies.html
>> in particular with
>>> Where a large amount of data is required (even after compression),
>>> consideration should be given to a separate data-only package which
>>> can be updated only rarely (since older versions of packages are
>>> archived in perpetuity).
>>
>> Q1: Are packages only consisting of a sysdata.rda file thinkable for
>> submission on CRAN ? Are such pkgs the way to go for w.r.t. to the
>> cited policy?
>
> Yes, given this package needs less updates than the main package, one
> should consider such a data only package that needs rare updates and
> does not flood the space with archived versions.
>
Fine. We are going to do this then (albeit possibly not yet with
the next release). 

BTW: Of course the code to generate the grids would be accessible in
the main package to be compliant with open source ideas.
>> If this is the case, how  would one document such a package, in
>> particular
>> if we do not export any objects in the NAMESPACE file?
>> In addition, with a sysdata.rda-only pkg,  R CMD check issues a warning
>> "Found directory 'R' with no source files"  Of course a workaround is
>> adding a comment-only file comment.R to the R folder.
>
> If the checks will be changed not to warn in such a case, this can
> only happen for R >= 3.0.0, so your workaround to tell the checks you
> really intended such a package with R folder not containing any code
> sounds plausible for now.
>
>
>> Q2: Is there a lazy load / lazy data mechanism available for
>> sysdata.rda ? If so how would one enforce it?
>
> It is lazy loaded. From WRE:
> "if the ?R? subdirectory contains a file ?sysdata.rda? [...] this will
> be lazy-loaded into the namespace/package environment"
>
Ah must have missed this.

Many thanks for your comments.

Best, Peter
>
> Best,
> Uwe
>
>
>
>> Any suggestions appreciated,
>>
>> Best, Peter
>>


-- 
Dr. habil. Peter Ruckdeschel, Abteilung Finanzmathematik, F3.17
Fraunhofer ITWM, Fraunhofer Platz 1, 67663 Kaiserslautern
Telefon:  +49 631/31600-4699   Fax    :  +49 631/31600-5699
E-Mail :  peter.ruckdeschel at itwm.fraunhofer.de
http://www.itwm.fraunhofer.de/abteilungen/finanzmathematik/mitarbeiterinnen/mitarbeiter/dr-peter-ruckdeschel.html


From therneau at mayo.edu  Mon Feb 11 14:50:02 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 11 Feb 2013 07:50:02 -0600
Subject: [Rd] stringsAsFactors
In-Reply-To: <mailman.19.1360580413.23621.r-devel@r-project.org>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
Message-ID: <5118F70A.6060100@mayo.edu>

I think your idea to remove the warnings is excellent, and a good compromise.  Characters 
already work fine in modeling functions except for the silly warning.

It is interesting how often the defaults for a program reflect the data sets in use at the 
time the defaults were chosen.  There are some such in my own survival package whose 
proper value is no longer as "obvious" as it was when I chose them.  Factors are very 
handy for variables which have only a few levels and will be used in modeling.  Every 
character variable of every dataset in "Statistical Models in S", which introduced 
factors, is of this type so auto-transformation made a lot of sense.  The "solder" data 
set there is one for which Helmert contrasts are proper so guess what the default contrast 
option was?  (I think there are only a few data sets in the world for which Helmert makes 
sense, however, and R eventually changed the default.)

For character variables that should not be factors such as a street adress 
stringsAsFactors can be a real PITA, and I expect that people's preference for the option 
depends almost entirely on how often these arise in their own work.  As long as there is 
an option that can be overridden I'm okay.  Yes, I'd prefer FALSE as the default, partly 
because the current value is a tripwire in the hallway that eventually catches every new user.

Terry Therneau

On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
> Both of these were discussed by R Core.  I think it's unlikely the
> default for stringsAsFactors will be changed (some R Core members like
> the current behaviour), but it's fairly likely the show.signif.stars
> default will change.  (That's if someone gets around to it:  I
> personally don't care about that one.  P-values are commonly used
> statistics, and the stars are just a simple graphical display of them.
> I find some p-values to be useful, and the display to be harmless.)
>
> I think it's really unlikely the more extreme changes (i.e. dropping
> show.signif.stars completely, or dropping p-values) will happen.
>
> Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
> I'll let the people who like it defend it.  What I will likely do is
> make a few changes so that character vectors are automatically changed
> to factors in modelling functions, so that operating with
> stringsAsFactors=FALSE doesn't trigger silly warnings.


From wdunlap at tibco.com  Mon Feb 11 18:13:09 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 11 Feb 2013 17:13:09 +0000
Subject: [Rd] stringsAsFactors
In-Reply-To: <5118F70A.6060100@mayo.edu>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
Message-ID: <E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>

Note that changing this does not just mean getting rid of "silly warnings".
Currently, predict.lm() can give wrong answers when stringsAsFactors is FALSE.

  > d <- data.frame(x=1:10, f=rep(c("A","B","C"), c(4,3,3)), y=c(1:4, 15:17, 28.1,28.8,30.1))
  > fit_ab <- lm(y ~ x + f, data = d, subset = f!="B")
  Warning message:
  In model.matrix.default(mt, mf, contrasts) :
    variable 'f' converted to a factor
  > predict(fit_ab, newdata=d)
   1  2  3  4  5  6  7  8  9 10
   1  2  3  4 25 26 27  8  9 10
  Warning messages:
  1: In model.matrix.default(Terms, m, contrasts.arg = object$contrasts) :
    variable 'f' converted to a factor
  2: In predict.lm(fit_ab, newdata = d) :
    prediction from a rank-deficient fit may be misleading

fit_ab is not rank-deficient and the predict should report
   1 2 3 4 NA NA NA 28 29 30 

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Terry Therneau
> Sent: Monday, February 11, 2013 5:50 AM
> To: r-devel at r-project.org; Duncan Murdoch
> Subject: Re: [Rd] stringsAsFactors
> 
> I think your idea to remove the warnings is excellent, and a good compromise.
> Characters
> already work fine in modeling functions except for the silly warning.
> 
> It is interesting how often the defaults for a program reflect the data sets in use at the
> time the defaults were chosen.  There are some such in my own survival package whose
> proper value is no longer as "obvious" as it was when I chose them.  Factors are very
> handy for variables which have only a few levels and will be used in modeling.  Every
> character variable of every dataset in "Statistical Models in S", which introduced
> factors, is of this type so auto-transformation made a lot of sense.  The "solder" data
> set there is one for which Helmert contrasts are proper so guess what the default
> contrast
> option was?  (I think there are only a few data sets in the world for which Helmert makes
> sense, however, and R eventually changed the default.)
> 
> For character variables that should not be factors such as a street adress
> stringsAsFactors can be a real PITA, and I expect that people's preference for the option
> depends almost entirely on how often these arise in their own work.  As long as there is
> an option that can be overridden I'm okay.  Yes, I'd prefer FALSE as the default, partly
> because the current value is a tripwire in the hallway that eventually catches every new
> user.
> 
> Terry Therneau
> 
> On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
> > Both of these were discussed by R Core.  I think it's unlikely the
> > default for stringsAsFactors will be changed (some R Core members like
> > the current behaviour), but it's fairly likely the show.signif.stars
> > default will change.  (That's if someone gets around to it:  I
> > personally don't care about that one.  P-values are commonly used
> > statistics, and the stars are just a simple graphical display of them.
> > I find some p-values to be useful, and the display to be harmless.)
> >
> > I think it's really unlikely the more extreme changes (i.e. dropping
> > show.signif.stars completely, or dropping p-values) will happen.
> >
> > Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
> > I'll let the people who like it defend it.  What I will likely do is
> > make a few changes so that character vectors are automatically changed
> > to factors in modelling functions, so that operating with
> > stringsAsFactors=FALSE doesn't trigger silly warnings.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Mon Feb 11 18:50:42 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 11 Feb 2013 12:50:42 -0500
Subject: [Rd] stringsAsFactors
In-Reply-To: <E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
Message-ID: <51192F72.4090904@gmail.com>

On 11/02/2013 12:13 PM, William Dunlap wrote:
> Note that changing this does not just mean getting rid of "silly warnings".
> Currently, predict.lm() can give wrong answers when stringsAsFactors is FALSE.
>
>    > d <- data.frame(x=1:10, f=rep(c("A","B","C"), c(4,3,3)), y=c(1:4, 15:17, 28.1,28.8,30.1))
>    > fit_ab <- lm(y ~ x + f, data = d, subset = f!="B")
>    Warning message:
>    In model.matrix.default(mt, mf, contrasts) :
>      variable 'f' converted to a factor
>    > predict(fit_ab, newdata=d)
>     1  2  3  4  5  6  7  8  9 10
>     1  2  3  4 25 26 27  8  9 10
>    Warning messages:
>    1: In model.matrix.default(Terms, m, contrasts.arg = object$contrasts) :
>      variable 'f' converted to a factor
>    2: In predict.lm(fit_ab, newdata = d) :
>      prediction from a rank-deficient fit may be misleading
>
> fit_ab is not rank-deficient and the predict should report
>     1 2 3 4 NA NA NA 28 29 30

In R-devel, the two warnings about factor conversions are no longer 
given, but the predictions are the same and the warning about rank 
deficiency still shows up.  If f is set to be a factor, an error is 
generated:

Error in model.frame.default(Terms, newdata, na.action = na.action, xlev 
= object$xlevels) :
   factor f has new levels B

I think both the warning and error are somewhat reasonable responses.  
The fit is rank deficient relative to the model that includes f == "B",  
because the column of the design matrix corresponding to f level B would 
be completely zero.  In this particular model, we could still do 
predictions for the other levels, but it also seems reasonable to quit, 
given that clearly something has gone wrong.

I do think that it's unfortunate that we don't get the same result in 
both cases, and I'd like to have gotten the predictions you suggested, 
but I don't think that's going to happen.  The reason for the difference 
is that the subsetting is done before the conversion to a factor, but I 
think that is unavoidable without really big changes.

Duncan Murdoch


>
> Bill Dunlap
> Spotfire, TIBCO Software
> wdunlap tibco.com
>
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> > Of Terry Therneau
> > Sent: Monday, February 11, 2013 5:50 AM
> > To: r-devel at r-project.org; Duncan Murdoch
> > Subject: Re: [Rd] stringsAsFactors
> >
> > I think your idea to remove the warnings is excellent, and a good compromise.
> > Characters
> > already work fine in modeling functions except for the silly warning.
> >
> > It is interesting how often the defaults for a program reflect the data sets in use at the
> > time the defaults were chosen.  There are some such in my own survival package whose
> > proper value is no longer as "obvious" as it was when I chose them.  Factors are very
> > handy for variables which have only a few levels and will be used in modeling.  Every
> > character variable of every dataset in "Statistical Models in S", which introduced
> > factors, is of this type so auto-transformation made a lot of sense.  The "solder" data
> > set there is one for which Helmert contrasts are proper so guess what the default
> > contrast
> > option was?  (I think there are only a few data sets in the world for which Helmert makes
> > sense, however, and R eventually changed the default.)
> >
> > For character variables that should not be factors such as a street adress
> > stringsAsFactors can be a real PITA, and I expect that people's preference for the option
> > depends almost entirely on how often these arise in their own work.  As long as there is
> > an option that can be overridden I'm okay.  Yes, I'd prefer FALSE as the default, partly
> > because the current value is a tripwire in the hallway that eventually catches every new
> > user.
> >
> > Terry Therneau
> >
> > On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
> > > Both of these were discussed by R Core.  I think it's unlikely the
> > > default for stringsAsFactors will be changed (some R Core members like
> > > the current behaviour), but it's fairly likely the show.signif.stars
> > > default will change.  (That's if someone gets around to it:  I
> > > personally don't care about that one.  P-values are commonly used
> > > statistics, and the stars are just a simple graphical display of them.
> > > I find some p-values to be useful, and the display to be harmless.)
> > >
> > > I think it's really unlikely the more extreme changes (i.e. dropping
> > > show.signif.stars completely, or dropping p-values) will happen.
> > >
> > > Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
> > > I'll let the people who like it defend it.  What I will likely do is
> > > make a few changes so that character vectors are automatically changed
> > > to factors in modelling functions, so that operating with
> > > stringsAsFactors=FALSE doesn't trigger silly warnings.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Mon Feb 11 20:34:04 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 11 Feb 2013 13:34:04 -0600
Subject: [Rd] stringsAsFactors
In-Reply-To: <51192F72.4090904@gmail.com>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
	<51192F72.4090904@gmail.com>
Message-ID: <511947AC.7060100@mayo.edu>

The root of this problem is that the .getXlevels function does not return the levels for 
character variables.
Future predictions depend on that information.

On 02/11/2013 11:50 AM, Duncan Murdoch wrote:
> On 11/02/2013 12:13 PM, William Dunlap wrote:
>> Note that changing this does not just mean getting rid of "silly warnings".
>> Currently, predict.lm() can give wrong answers when stringsAsFactors is FALSE.
>>
>> > d <- data.frame(x=1:10, f=rep(c("A","B","C"), c(4,3,3)), y=c(1:4, 15:17, 
>> 28.1,28.8,30.1))
>> > fit_ab <- lm(y ~ x + f, data = d, subset = f!="B")
>>    Warning message:
>>    In model.matrix.default(mt, mf, contrasts) :
>>      variable 'f' converted to a factor
>> > predict(fit_ab, newdata=d)
>>     1  2  3  4  5  6  7  8  9 10
>>     1  2  3  4 25 26 27  8  9 10
>>    Warning messages:
>>    1: In model.matrix.default(Terms, m, contrasts.arg = object$contrasts) :
>>      variable 'f' converted to a factor
>>    2: In predict.lm(fit_ab, newdata = d) :
>>      prediction from a rank-deficient fit may be misleading
>>
>> fit_ab is not rank-deficient and the predict should report
>>     1 2 3 4 NA NA NA 28 29 30
>
> In R-devel, the two warnings about factor conversions are no longer given, but the 
> predictions are the same and the warning about rank deficiency still shows up.  If f is 
> set to be a factor, an error is generated:
>
> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev = 
> object$xlevels) :
>   factor f has new levels B
>
> I think both the warning and error are somewhat reasonable responses.  The fit is rank 
> deficient relative to the model that includes f == "B",  because the column of the 
> design matrix corresponding to f level B would be completely zero.  In this particular 
> model, we could still do predictions for the other levels, but it also seems reasonable 
> to quit, given that clearly something has gone wrong.
>
> I do think that it's unfortunate that we don't get the same result in both cases, and 
> I'd like to have gotten the predictions you suggested, but I don't think that's going to 
> happen.  The reason for the difference is that the subsetting is done before the 
> conversion to a factor, but I think that is unavoidable without really big changes.
>
> Duncan Murdoch
>
>
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>> > -----Original Message-----
>> > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
>> > Of Terry Therneau
>> > Sent: Monday, February 11, 2013 5:50 AM
>> > To: r-devel at r-project.org; Duncan Murdoch
>> > Subject: Re: [Rd] stringsAsFactors
>> >
>> > I think your idea to remove the warnings is excellent, and a good compromise.
>> > Characters
>> > already work fine in modeling functions except for the silly warning.
>> >
>> > It is interesting how often the defaults for a program reflect the data sets in use 
>> at the
>> > time the defaults were chosen.  There are some such in my own survival package whose
>> > proper value is no longer as "obvious" as it was when I chose them.  Factors are very
>> > handy for variables which have only a few levels and will be used in modeling.  Every
>> > character variable of every dataset in "Statistical Models in S", which introduced
>> > factors, is of this type so auto-transformation made a lot of sense.  The "solder" data
>> > set there is one for which Helmert contrasts are proper so guess what the default
>> > contrast
>> > option was?  (I think there are only a few data sets in the world for which Helmert 
>> makes
>> > sense, however, and R eventually changed the default.)
>> >
>> > For character variables that should not be factors such as a street adress
>> > stringsAsFactors can be a real PITA, and I expect that people's preference for the 
>> option
>> > depends almost entirely on how often these arise in their own work.  As long as there is
>> > an option that can be overridden I'm okay.  Yes, I'd prefer FALSE as the default, partly
>> > because the current value is a tripwire in the hallway that eventually catches every new
>> > user.
>> >
>> > Terry Therneau
>> >
>> > On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
>> > > Both of these were discussed by R Core.  I think it's unlikely the
>> > > default for stringsAsFactors will be changed (some R Core members like
>> > > the current behaviour), but it's fairly likely the show.signif.stars
>> > > default will change.  (That's if someone gets around to it:  I
>> > > personally don't care about that one.  P-values are commonly used
>> > > statistics, and the stars are just a simple graphical display of them.
>> > > I find some p-values to be useful, and the display to be harmless.)
>> > >
>> > > I think it's really unlikely the more extreme changes (i.e. dropping
>> > > show.signif.stars completely, or dropping p-values) will happen.
>> > >
>> > > Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
>> > > I'll let the people who like it defend it.  What I will likely do is
>> > > make a few changes so that character vectors are automatically changed
>> > > to factors in modelling functions, so that operating with
>> > > stringsAsFactors=FALSE doesn't trigger silly warnings.
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>


From diggsb at ohsu.edu  Mon Feb 11 21:15:21 2013
From: diggsb at ohsu.edu (Brian Diggs)
Date: Mon, 11 Feb 2013 12:15:21 -0800
Subject: [Rd] stringsAsFactors
In-Reply-To: <5118F70A.6060100@mayo.edu>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
Message-ID: <51195159.3050503@ohsu.edu>

On 2/11/2013 5:50 AM, Terry Therneau wrote:
> I think your idea to remove the warnings is excellent, and a good
> compromise.  Characters already work fine in modeling functions except
> for the silly warning.
>
> It is interesting how often the defaults for a program reflect the data
> sets in use at the time the defaults were chosen.  There are some such
> in my own survival package whose proper value is no longer as "obvious"
> as it was when I chose them.  Factors are very handy for variables which
> have only a few levels and will be used in modeling.  Every character
> variable of every dataset in "Statistical Models in S", which introduced
> factors, is of this type so auto-transformation made a lot of sense.
> The "solder" data set there is one for which Helmert contrasts are
> proper so guess what the default contrast option was?  (I think there
> are only a few data sets in the world for which Helmert makes sense,
> however, and R eventually changed the default.)
>
> For character variables that should not be factors such as a street
> adress stringsAsFactors can be a real PITA, and I expect that people's
> preference for the option depends almost entirely on how often these
> arise in their own work.  As long as there is an option that can be
> overridden I'm okay.  Yes, I'd prefer FALSE as the default, partly
> because the current value is a tripwire in the hallway that eventually
> catches every new user.

I also agree that stringsAsFactors should not be TRUE, at least by 
default. I do not change the default in my .Rprofile because I have seen 
examples where people have gotten tripped up having changed this and 
forgotten about it or when sharing code and getting different, 
unexpected, results. However, my code is littered with this additional 
argument so that I get, to me, the more sensible behavior.

My preference follows from my conceptualization of what a factor is. To 
me, a factor is the representation of a data type which has a fixed, 
finite, set of values which it can take which are known a priori. In 
terms of sample and population, a variable could only be a factor if all 
possible values that the variable could take in the population are known 
(not just those in the given sample). Automatic conversion of strings to 
factors assumes that the values that are present constitute the complete 
and exclusive set of values which that variable could ever have, an 
assumption which is often not correct in my experience. Examples such as 
names, street addresses, or unique alphanumeric identifiers all fit this 
criteria.

In contrast, a character variable is just vector of arbitrary length 
character strings; it makes no further assumptions.

A secondary reason why I don't like a default conversion of strings to 
factors is, on importing data, I often have to do some data cleaning 
(unifying case, noting specific missing value encoding, collapsing 
redundant entries) before I have a clean set of possible values to 
convert to a factor. Once I have converted those variables which should 
be factors to factors and left those that are just character strings as 
character strings, I don't want later functions changing those choices 
on me.

I realize that, historically, a factor was also a more efficient storage 
mechanism for strings (store each unique string only once and then 
record an index to that string), but with the global string table, my 
understanding is that that is no longer the case.

Finally, stringsAsFactors being TRUE by default effectively says that 
the is no place for character vectors; all character vectors should be 
converted to factors as soon as possible. Take this to the (absurd) 
extreme, why even have a character vector type, then? The (appropriate) 
existence of both a factor type and character vector type is a further 
argument that the latter should no be converted to the former automatically.

> Terry Therneau
>
> On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
>> Both of these were discussed by R Core.  I think it's unlikely the
>> default for stringsAsFactors will be changed (some R Core members like
>> the current behaviour), but it's fairly likely the show.signif.stars
>> default will change.  (That's if someone gets around to it:  I
>> personally don't care about that one.  P-values are commonly used
>> statistics, and the stars are just a simple graphical display of them.
>> I find some p-values to be useful, and the display to be harmless.)
>>
>> I think it's really unlikely the more extreme changes (i.e. dropping
>> show.signif.stars completely, or dropping p-values) will happen.
>>
>> Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
>> I'll let the people who like it defend it.  What I will likely do is
>> make a few changes so that character vectors are automatically changed
>> to factors in modelling functions, so that operating with
>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>


-- 
Brian S. Diggs, PhD
Senior Research Associate, Department of Surgery
Oregon Health & Science University


From murdoch.duncan at gmail.com  Mon Feb 11 21:17:37 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 11 Feb 2013 15:17:37 -0500
Subject: [Rd] stringsAsFactors
In-Reply-To: <511947AC.7060100@mayo.edu>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
	<51192F72.4090904@gmail.com> <511947AC.7060100@mayo.edu>
Message-ID: <511951E1.20302@gmail.com>

On 11/02/2013 2:34 PM, Terry Therneau wrote:
> The root of this problem is that the .getXlevels function does not return the levels for
> character variables.
Thanks, that looks easy to fix (not by changing .getXlevels, but by 
having model.frame convert the character variables, instead
of waiting for model.matrix).

Duncan
> Future predictions depend on that information.
>
> On 02/11/2013 11:50 AM, Duncan Murdoch wrote:
> > On 11/02/2013 12:13 PM, William Dunlap wrote:
> >> Note that changing this does not just mean getting rid of "silly warnings".
> >> Currently, predict.lm() can give wrong answers when stringsAsFactors is FALSE.
> >>
> >> > d <- data.frame(x=1:10, f=rep(c("A","B","C"), c(4,3,3)), y=c(1:4, 15:17,
> >> 28.1,28.8,30.1))
> >> > fit_ab <- lm(y ~ x + f, data = d, subset = f!="B")
> >>    Warning message:
> >>    In model.matrix.default(mt, mf, contrasts) :
> >>      variable 'f' converted to a factor
> >> > predict(fit_ab, newdata=d)
> >>     1  2  3  4  5  6  7  8  9 10
> >>     1  2  3  4 25 26 27  8  9 10
> >>    Warning messages:
> >>    1: In model.matrix.default(Terms, m, contrasts.arg = object$contrasts) :
> >>      variable 'f' converted to a factor
> >>    2: In predict.lm(fit_ab, newdata = d) :
> >>      prediction from a rank-deficient fit may be misleading
> >>
> >> fit_ab is not rank-deficient and the predict should report
> >>     1 2 3 4 NA NA NA 28 29 30
> >
> > In R-devel, the two warnings about factor conversions are no longer given, but the
> > predictions are the same and the warning about rank deficiency still shows up.  If f is
> > set to be a factor, an error is generated:
> >
> > Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
> > object$xlevels) :
> >   factor f has new levels B
> >
> > I think both the warning and error are somewhat reasonable responses.  The fit is rank
> > deficient relative to the model that includes f == "B",  because the column of the
> > design matrix corresponding to f level B would be completely zero.  In this particular
> > model, we could still do predictions for the other levels, but it also seems reasonable
> > to quit, given that clearly something has gone wrong.
> >
> > I do think that it's unfortunate that we don't get the same result in both cases, and
> > I'd like to have gotten the predictions you suggested, but I don't think that's going to
> > happen.  The reason for the difference is that the subsetting is done before the
> > conversion to a factor, but I think that is unavoidable without really big changes.
> >
> > Duncan Murdoch
> >
> >
> >>
> >> Bill Dunlap
> >> Spotfire, TIBCO Software
> >> wdunlap tibco.com
> >>
> >> > -----Original Message-----
> >> > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> >> > Of Terry Therneau
> >> > Sent: Monday, February 11, 2013 5:50 AM
> >> > To: r-devel at r-project.org; Duncan Murdoch
> >> > Subject: Re: [Rd] stringsAsFactors
> >> >
> >> > I think your idea to remove the warnings is excellent, and a good compromise.
> >> > Characters
> >> > already work fine in modeling functions except for the silly warning.
> >> >
> >> > It is interesting how often the defaults for a program reflect the data sets in use
> >> at the
> >> > time the defaults were chosen.  There are some such in my own survival package whose
> >> > proper value is no longer as "obvious" as it was when I chose them.  Factors are very
> >> > handy for variables which have only a few levels and will be used in modeling.  Every
> >> > character variable of every dataset in "Statistical Models in S", which introduced
> >> > factors, is of this type so auto-transformation made a lot of sense.  The "solder" data
> >> > set there is one for which Helmert contrasts are proper so guess what the default
> >> > contrast
> >> > option was?  (I think there are only a few data sets in the world for which Helmert
> >> makes
> >> > sense, however, and R eventually changed the default.)
> >> >
> >> > For character variables that should not be factors such as a street adress
> >> > stringsAsFactors can be a real PITA, and I expect that people's preference for the
> >> option
> >> > depends almost entirely on how often these arise in their own work.  As long as there is
> >> > an option that can be overridden I'm okay.  Yes, I'd prefer FALSE as the default, partly
> >> > because the current value is a tripwire in the hallway that eventually catches every new
> >> > user.
> >> >
> >> > Terry Therneau
> >> >
> >> > On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
> >> > > Both of these were discussed by R Core.  I think it's unlikely the
> >> > > default for stringsAsFactors will be changed (some R Core members like
> >> > > the current behaviour), but it's fairly likely the show.signif.stars
> >> > > default will change.  (That's if someone gets around to it:  I
> >> > > personally don't care about that one.  P-values are commonly used
> >> > > statistics, and the stars are just a simple graphical display of them.
> >> > > I find some p-values to be useful, and the display to be harmless.)
> >> > >
> >> > > I think it's really unlikely the more extreme changes (i.e. dropping
> >> > > show.signif.stars completely, or dropping p-values) will happen.
> >> > >
> >> > > Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
> >> > > I'll let the people who like it defend it.  What I will likely do is
> >> > > make a few changes so that character vectors are automatically changed
> >> > > to factors in modelling functions, so that operating with
> >> > > stringsAsFactors=FALSE doesn't trigger silly warnings.
> >> >
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >


From pdalgd at gmail.com  Mon Feb 11 23:46:49 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 11 Feb 2013 23:46:49 +0100
Subject: [Rd] stringsAsFactors
In-Reply-To: <51192F72.4090904@gmail.com>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
	<51192F72.4090904@gmail.com>
Message-ID: <ADD801D2-8E0E-4397-8923-87DD38C9659A@gmail.com>


On Feb 11, 2013, at 18:50 , Duncan Murdoch wrote:

> 
> I do think that it's unfortunate that we don't get the same result in both cases, and I'd like to have gotten the predictions you suggested, but I don't think that's going to happen.  The reason for the difference is that the subsetting is done before the conversion to a factor, but I think that is unavoidable without really big changes.

It's logically impossible I'd say. If you want to do conversion from character to factor on an as-needed basis, you _will_ have issues with subsetting operations affecting the set of levels. 

The logical way out is to define factors before subsetting. As far as possible, create them up front. Doing it automagically in read.table is far from infallible, but at least has some chance of getting in roughly right. In my view, this is actually a pretty strong argument for keeping stringsAsFactors==TRUE. 

(Praeterea censeo: The real issue is that plain-text data file formats contain insufficient metadata, so what we probably should do is to start thinking about ways to encode type and level set information in the files themselves.) 

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From therneau at mayo.edu  Tue Feb 12 00:05:22 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 11 Feb 2013 17:05:22 -0600
Subject: [Rd] stringsAsFactors
In-Reply-To: <ADD801D2-8E0E-4397-8923-87DD38C9659A@gmail.com>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
	<51192F72.4090904@gmail.com>
	<ADD801D2-8E0E-4397-8923-87DD38C9659A@gmail.com>
Message-ID: <51197932.2030506@mayo.edu>

Peter,
   I had an earlier response to Duncan that I should have copied to the list.

The subset issue can be fixed.  When the model changes character to factor, it needs to 
remember the levels; just like it does with the factors.  We are simply seeing a reprise 
of problems that occured whem models didn't remember factor levels -- I've been down this 
road before.  Lot's of ideas and work arounds were tried, none of which worked until that 
memory was added ($xlevels in lm, glm, coxph, etc fits).  Can everything be fixed, in the 
sense that R always makes the right choices for my data?   I seriously doubt it.

As to stringsAsFactors -- the right answer is the one that causes each person the least 
bother.  For me that is stringsAsFactors = "some", which means that I turn it off and 
build the ones I need.  The right global default, likely, is whichever one that causes 
members of R Core the least bother :-)

On 02/11/2013 04:46 PM, peter dalgaard wrote:
> It's logically impossible I'd say. If you want to do conversion from character to factor on an as-needed basis, you_will_  have issues with subsetting operations affecting the set of levels.
>
> The logical way out is to define factors before subsetting. As far as possible, create them up front. Doing it automagically in read.table is far from infallible, but at least has some chance of getting in roughly right. In my view, this is actually a pretty strong argument for keeping stringsAsFactors==TRUE.
>
> (


From istazahn at gmail.com  Mon Feb 11 19:01:33 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 11 Feb 2013 13:01:33 -0500
Subject: [Rd] stringsAsFactors
In-Reply-To: <51192F72.4090904@gmail.com>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
	<51192F72.4090904@gmail.com>
Message-ID: <CA+vqiLH_OzKKcYLxK3jsrQRtpvN=Uj6xoEJpsCAwX3yLQG-vzA@mail.gmail.com>

FWIW my view is that for data cleaning and organizing factors just get
it the way. For modeling I like them because they make it easier to
understand what is happening. For example I can look at the levels()
to see what the reference group will be. With characters one has to
know a) that levels are created in alphabetical order and b) the
alphabetical order of the the unique values in the character vector.
Ugh. So my habit is to turn off stringsAsFactors, then explicitly
convert to factors before modeling (I also use factors to change the
order in which things are displayed in tables and graphs, another
place where converting to factors myself is useful but the creating
them in alphabetical order by default is not)

All this is to say that I would like options(stingsAsFactors=FALSE) to
be the default, but I like the warning about converting to factors in
modeling functions because it reminds me that I forgot to covert them,
which I like to do anyway...

Best,
Ista

On Mon, Feb 11, 2013 at 12:50 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 11/02/2013 12:13 PM, William Dunlap wrote:
>>
>> Note that changing this does not just mean getting rid of "silly
>> warnings".
>> Currently, predict.lm() can give wrong answers when stringsAsFactors is
>> FALSE.
>>
>>    > d <- data.frame(x=1:10, f=rep(c("A","B","C"), c(4,3,3)), y=c(1:4,
>> 15:17, 28.1,28.8,30.1))
>>    > fit_ab <- lm(y ~ x + f, data = d, subset = f!="B")
>>    Warning message:
>>    In model.matrix.default(mt, mf, contrasts) :
>>      variable 'f' converted to a factor
>>    > predict(fit_ab, newdata=d)
>>     1 2 3 4 5 6 7 8 9 10
>>     1  2  3  4 25 26 27  8  9 10
>>    Warning messages:
>>    1: In model.matrix.default(Terms, m, contrasts.arg = object$contrasts)
>> :
>>      variable 'f' converted to a factor
>>    2: In predict.lm(fit_ab, newdata = d) :
>>      prediction from a rank-deficient fit may be misleading
>>
>> fit_ab is not rank-deficient and the predict should report
>>     1 2 3 4 NA NA NA 28 29 30
>
>
> In R-devel, the two warnings about factor conversions are no longer given,
> but the predictions are the same and the warning about rank deficiency still
> shows up.  If f is set to be a factor, an error is generated:
>
> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
> object$xlevels) :
>   factor f has new levels B
>
> I think both the warning and error are somewhat reasonable responses.  The
> fit is rank deficient relative to the model that includes f == "B",  because
> the column of the design matrix corresponding to f level B would be
> completely zero.  In this particular model, we could still do predictions
> for the other levels, but it also seems reasonable to quit, given that
> clearly something has gone wrong.
>
> I do think that it's unfortunate that we don't get the same result in both
> cases, and I'd like to have gotten the predictions you suggested, but I
> don't think that's going to happen.  The reason for the difference is that
> the subsetting is done before the conversion to a factor, but I think that
> is unavoidable without really big changes.
>
> Duncan Murdoch
>
>
>
>>
>> Bill Dunlap
>> Spotfire, TIBCO Software
>> wdunlap tibco.com
>>
>> > -----Original Message-----
>> > From: r-devel-bounces at r-project.org
>> > [mailto:r-devel-bounces at r-project.org] On Behalf
>> > Of Terry Therneau
>> > Sent: Monday, February 11, 2013 5:50 AM
>> > To: r-devel at r-project.org; Duncan Murdoch
>> > Subject: Re: [Rd] stringsAsFactors
>> >
>> > I think your idea to remove the warnings is excellent, and a good
>> > compromise.
>> > Characters
>> > already work fine in modeling functions except for the silly warning.
>> >
>> > It is interesting how often the defaults for a program reflect the data
>> > sets in use at the
>> > time the defaults were chosen.  There are some such in my own survival
>> > package whose
>> > proper value is no longer as "obvious" as it was when I chose them.
>> > Factors are very
>> > handy for variables which have only a few levels and will be used in
>> > modeling.  Every
>> > character variable of every dataset in "Statistical Models in S", which
>> > introduced
>> > factors, is of this type so auto-transformation made a lot of sense.
>> > The "solder" data
>> > set there is one for which Helmert contrasts are proper so guess what
>> > the default
>> > contrast
>> > option was?  (I think there are only a few data sets in the world for
>> > which Helmert makes
>> > sense, however, and R eventually changed the default.)
>> >
>> > For character variables that should not be factors such as a street
>> > adress
>> > stringsAsFactors can be a real PITA, and I expect that people's
>> > preference for the option
>> > depends almost entirely on how often these arise in their own work.  As
>> > long as there is
>> > an option that can be overridden I'm okay.  Yes, I'd prefer FALSE as the
>> > default, partly
>> > because the current value is a tripwire in the hallway that eventually
>> > catches every new
>> > user.
>> >
>> > Terry Therneau
>> >
>> > On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
>> > > Both of these were discussed by R Core.  I think it's unlikely the
>> > > default for stringsAsFactors will be changed (some R Core members like
>> > > the current behaviour), but it's fairly likely the show.signif.stars
>> > > default will change.  (That's if someone gets around to it:  I
>> > > personally don't care about that one.  P-values are commonly used
>> > > statistics, and the stars are just a simple graphical display of them.
>> > > I find some p-values to be useful, and the display to be harmless.)
>> > >
>> > > I think it's really unlikely the more extreme changes (i.e. dropping
>> > > show.signif.stars completely, or dropping p-values) will happen.
>> > >
>> > > Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
>> > > I'll let the people who like it defend it.  What I will likely do is
>> > > make a few changes so that character vectors are automatically changed
>> > > to factors in modelling functions, so that operating with
>> > > stringsAsFactors=FALSE doesn't trigger silly warnings.
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From groemping at bht-berlin.de  Tue Feb 12 14:45:41 2013
From: groemping at bht-berlin.de (=?ISO-8859-15?Q?Ulrike_Gr=F6mping?=)
Date: Tue, 12 Feb 2013 14:45:41 +0100
Subject: [Rd] Private environments and/or assignInMyNamespace
Message-ID: <511A4785.5070504@bht-berlin.de>

Dear DevelopeRs,

I've been struggling with the new regulations regarding modifications to 
the search path, regarding my Rcmdr plugin package RcmdrPlugin.DoE. John 
Fox made Rcmdr comply with the new policy by removing the environment 
RcmdrEnv from the search path. For the time being, he developed an 
option that allows users to put the environment from Rcmdr (RcmdrEnv) on 
the search path, like in earlier versions of Rcmdr (thanks John!), which 
rescues my package for the immediate future; however, in the long run it 
would be nice to be able to make it work without that.

The reason why I currently need the environment on the search path (may 
be due to my lack of understanding how tcltk widgets are handled): I 
have quite elaborate notebook widgets on which users can make many 
entries. Some entries are only checked after clicking OK, and if an 
error is found at that point, the user receives a small message window 
that has to be confirmed and is subsequently returned to the notebook 
widget in the state it was in when pressing OK. These widgets are 
currently held in the environment RcmdrEnv; they work when RcmdrEnv is 
on the search path; however, it is not sufficient to retrieve them with 
John's function getRcmdr, which works fine for objects other than widgets.

Here my question: Would it be an option to place the widgets in a 
private environment of my plugin package (then I would have to learn how 
to create one and work with it), or won't they be found that way? 
Alternatively, I could have unexported objects of all required names in 
my namespace and modify these via assignInMyNamespace (I don't think 
that anybody from somewhere else would import that namespace, it's not 
that kind of package). Would that be a viable alternative, and would the 
widgets be found that way? Any further ideas?

Best regards,
Ulrike

-- 
*****************************************************
* Ulrike Groemping                                  *
* BHT Berlin - University of Applied Sciences       *
*****************************************************
* +49 (30) 39404863 (Home Office)                   *
* +49 (30) 4504 5127 (BHT)                          *
*****************************************************
* http://prof.beuth-hochschule.de/groemping         *
* groemping at bht-berlin.de                           *


From bbolker at gmail.com  Tue Feb 12 14:54:37 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 12 Feb 2013 13:54:37 +0000
Subject: [Rd] Regression stars
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
Message-ID: <loom.20130212T145313-215@post.gmane.org>

Duncan Murdoch <murdoch.duncan <at> gmail.com> writes:

  [snip]
> 
> Regarding stringsAsFactors:  I'm not going to defend keeping it as is, 
> I'll let the people who like it defend it.  

  Would someone (anyone) like to come forward and give us a defense
of stringsAsFactors=TRUE -- even someone who doesn't personally like
it but would like to play devil's advocate?

> What I will likely do is 
> make a few changes so that character vectors are automatically changed 
> to factors in modelling functions, so that operating with 
> stringsAsFactors=FALSE doesn't trigger silly warnings.
> 
> Duncan Murdoch
> 

 [apologies for snipping context: "gmane made me do it"]


From h.wickham at gmail.com  Tue Feb 12 15:03:48 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 12 Feb 2013 08:03:48 -0600
Subject: [Rd] Private environments and/or assignInMyNamespace
In-Reply-To: <511A4785.5070504@bht-berlin.de>
References: <511A4785.5070504@bht-berlin.de>
Message-ID: <CABdHhvFurEGjSQpQ=aNp2u+QHm6qvzQO2Orr1hxdXVqeC19UGQ@mail.gmail.com>

> Here my question: Would it be an option to place the widgets in a private
> environment of my plugin package (then I would have to learn how to create
> one and work with it), or won't they be found that way?

It sounds like you want to maintain state across function calls within
your package, and a private environment is a good solution.  See the
notes on local() at
https://github.com/hadley/devtools/wiki/Environments for a few
details.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From ligges at statistik.tu-dortmund.de  Tue Feb 12 15:20:08 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 12 Feb 2013 15:20:08 +0100
Subject: [Rd] Regression stars
In-Reply-To: <loom.20130212T145313-215@post.gmane.org>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
Message-ID: <511A4F98.50209@statistik.tu-dortmund.de>



On 12.02.2013 14:54, Ben Bolker wrote:
> Duncan Murdoch <murdoch.duncan <at> gmail.com> writes:
>
>    [snip]
>>
>> Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
>> I'll let the people who like it defend it.
>
>    Would someone (anyone) like to come forward and give us a defense
> of stringsAsFactors=TRUE -- even someone who doesn't personally like
> it but would like to play devil's advocate?

Sure:
I will have to change all my scripts, my teaching examples, my book, and 
lots of code examples for research and particularly consulting jobs.

Personally, I think having stringsAsFactors=TRUE is not too bad for 
read.table() but less useful for data.frame().

And since you ask for the devil's advocate already, related to the 
subject line: Removing stars is horrible for consulting: With all those 
people from biology, medicine and other fields who even ask us questions 
in term of significance stars that are obviously very common for them. 
Many of them will certainly ask us for the stars, and ask us to switch 
to another software product once they do not get it from R. They may not 
be interested in being taught about the advantages or disadvantages of 
p-values or stars.

There are different use cases of R, and I want to keep stars for 
consulting tasks where things have to be delivered within minutes. I am 
happy with or without for teaching, where I have the time and can easily 
talk about the sense and nonsense of p-values.


Best,
Uwe













>
>> What I will likely do is
>> make a few changes so that character vectors are automatically changed
>> to factors in modelling functions, so that operating with
>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>>
>> Duncan Murdoch
>>
>
>   [apologies for snipping context: "gmane made me do it"]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From f.harrell at vanderbilt.edu  Tue Feb 12 15:42:49 2013
From: f.harrell at vanderbilt.edu (Frank Harrell)
Date: Tue, 12 Feb 2013 06:42:49 -0800 (PST)
Subject: [Rd] Regression stars
In-Reply-To: <511A4F98.50209@statistik.tu-dortmund.de>
References: <1360243924659-4657795.post@n4.nabble.com>
	<20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
Message-ID: <1360680169120-4658268.post@n4.nabble.com>

Uwe I've been consulting for decades and have never once been asked for such
stars.  And when a clinical researcher puts a sentence in a study protocol
that P<0.05 will be considered "significant" I get them to take it out.
Frank

Uwe Ligges-3 wrote
> On 12.02.2013 14:54, Ben Bolker wrote:
>> Duncan Murdoch 
> <murdoch.duncan <at>
>  gmail.com> writes:
>>
>>    [snip]
>>>
>>> Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
>>> I'll let the people who like it defend it.
>>
>>    Would someone (anyone) like to come forward and give us a defense
>> of stringsAsFactors=TRUE -- even someone who doesn't personally like
>> it but would like to play devil's advocate?
> 
> Sure:
> I will have to change all my scripts, my teaching examples, my book, and 
> lots of code examples for research and particularly consulting jobs.
> 
> Personally, I think having stringsAsFactors=TRUE is not too bad for 
> read.table() but less useful for data.frame().
> 
> And since you ask for the devil's advocate already, related to the 
> subject line: Removing stars is horrible for consulting: With all those 
> people from biology, medicine and other fields who even ask us questions 
> in term of significance stars that are obviously very common for them. 
> Many of them will certainly ask us for the stars, and ask us to switch 
> to another software product once they do not get it from R. They may not 
> be interested in being taught about the advantages or disadvantages of 
> p-values or stars.
> 
> There are different use cases of R, and I want to keep stars for 
> consulting tasks where things have to be delivered within minutes. I am 
> happy with or without for teaching, where I have the time and can easily 
> talk about the sense and nonsense of p-values.
> 
> 
> Best,
> Uwe
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
>>
>>> What I will likely do is
>>> make a few changes so that character vectors are automatically changed
>>> to factors in modelling functions, so that operating with
>>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>>>
>>> Duncan Murdoch
>>>
>>
>>   [apologies for snipping context: "gmane made me do it"]
>>
>> ______________________________________________
>> 

> R-devel@

>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________

> R-devel@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel





-----
Frank Harrell
Department of Biostatistics, Vanderbilt University
--
View this message in context: http://r.789695.n4.nabble.com/Regression-stars-tp4657795p4658268.html
Sent from the R devel mailing list archive at Nabble.com.


From murdoch.duncan at gmail.com  Tue Feb 12 15:48:43 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 12 Feb 2013 09:48:43 -0500
Subject: [Rd] Regression stars
In-Reply-To: <511A4F98.50209@statistik.tu-dortmund.de>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
Message-ID: <511A564B.5020700@gmail.com>

On 12/02/2013 9:20 AM, Uwe Ligges wrote:
>
> On 12.02.2013 14:54, Ben Bolker wrote:
> > Duncan Murdoch <murdoch.duncan <at> gmail.com> writes:
> >
> >    [snip]
> >>
> >> Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
> >> I'll let the people who like it defend it.
> >
> >    Would someone (anyone) like to come forward and give us a defense
> > of stringsAsFactors=TRUE -- even someone who doesn't personally like
> > it but would like to play devil's advocate?
>
> Sure:
> I will have to change all my scripts, my teaching examples, my book, and
> lots of code examples for research and particularly consulting jobs.

Could you post an example of a non-trivial one?  (By trivial, I mean one 
that says "data.frame() converts character vectors to factors". 
Obviously that would need to change.  I mean one that just assumes 
current behaviour, and would be broken by the change.)

Duncan Murdoch
>
> Personally, I think having stringsAsFactors=TRUE is not too bad for
> read.table() but less useful for data.frame().
>
> And since you ask for the devil's advocate already, related to the
> subject line: Removing stars is horrible for consulting: With all those
> people from biology, medicine and other fields who even ask us questions
> in term of significance stars that are obviously very common for them.
> Many of them will certainly ask us for the stars, and ask us to switch
> to another software product once they do not get it from R. They may not
> be interested in being taught about the advantages or disadvantages of
> p-values or stars.
>
> There are different use cases of R, and I want to keep stars for
> consulting tasks where things have to be delivered within minutes. I am
> happy with or without for teaching, where I have the time and can easily
> talk about the sense and nonsense of p-values.
>
>
> Best,
> Uwe
>
>
>
>
>
>
>
>
>
>
>
>
>
> >
> >> What I will likely do is
> >> make a few changes so that character vectors are automatically changed
> >> to factors in modelling functions, so that operating with
> >> stringsAsFactors=FALSE doesn't trigger silly warnings.
> >>
> >> Duncan Murdoch
> >>
> >
> >   [apologies for snipping context: "gmane made me do it"]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From gparthasarathy93 at gmail.com  Tue Feb 12 15:37:50 2013
From: gparthasarathy93 at gmail.com (Parthasarathy Gopavarapu)
Date: Tue, 12 Feb 2013 20:07:50 +0530
Subject: [Rd] Contribution
Message-ID: <CAG6ADrSNRm_z9_An+EpaiTtvQbnUpHp07aqGUW8iR0gCAa3yrQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130212/6f7bd8ab/attachment.pl>

From ravi.varadhan at jhu.edu  Tue Feb 12 15:54:50 2013
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Tue, 12 Feb 2013 14:54:50 +0000
Subject: [Rd] Regression stars
In-Reply-To: <1360680169120-4658268.post@n4.nabble.com>
References: <1360243924659-4657795.post@n4.nabble.com>
	<20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com> <loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<1360680169120-4658268.post@n4.nabble.com>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3365202@DOM-EB-MAIL2.win.ad.jhu.edu>

I think that we should use P < .03 (which approximates the probability of 5 consecutive heads) for assigning significance!

Ravi

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Frank Harrell
Sent: Tuesday, February 12, 2013 9:43 AM
To: r-devel at r-project.org
Subject: Re: [Rd] Regression stars

Uwe I've been consulting for decades and have never once been asked for such stars.  And when a clinical researcher puts a sentence in a study protocol that P<0.05 will be considered "significant" I get them to take it out.
Frank

Uwe Ligges-3 wrote
> On 12.02.2013 14:54, Ben Bolker wrote:
>> Duncan Murdoch
> <murdoch.duncan <at>
>  gmail.com> writes:
>>
>>    [snip]
>>>
>>> Regarding stringsAsFactors:  I'm not going to defend keeping it as 
>>> is, I'll let the people who like it defend it.
>>
>>    Would someone (anyone) like to come forward and give us a defense 
>> of stringsAsFactors=TRUE -- even someone who doesn't personally like 
>> it but would like to play devil's advocate?
> 
> Sure:
> I will have to change all my scripts, my teaching examples, my book, 
> and lots of code examples for research and particularly consulting jobs.
> 
> Personally, I think having stringsAsFactors=TRUE is not too bad for
> read.table() but less useful for data.frame().
> 
> And since you ask for the devil's advocate already, related to the 
> subject line: Removing stars is horrible for consulting: With all 
> those people from biology, medicine and other fields who even ask us 
> questions in term of significance stars that are obviously very common for them.
> Many of them will certainly ask us for the stars, and ask us to switch 
> to another software product once they do not get it from R. They may 
> not be interested in being taught about the advantages or 
> disadvantages of p-values or stars.
> 
> There are different use cases of R, and I want to keep stars for 
> consulting tasks where things have to be delivered within minutes. I 
> am happy with or without for teaching, where I have the time and can 
> easily talk about the sense and nonsense of p-values.
> 
> 
> Best,
> Uwe
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
> 
>>
>>> What I will likely do is
>>> make a few changes so that character vectors are automatically 
>>> changed to factors in modelling functions, so that operating with 
>>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>>>
>>> Duncan Murdoch
>>>
>>
>>   [apologies for snipping context: "gmane made me do it"]
>>
>> ______________________________________________
>> 

> R-devel@

>  mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
> 
> ______________________________________________

> R-devel@

>  mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel





-----
Frank Harrell
Department of Biostatistics, Vanderbilt University
--
View this message in context: http://r.789695.n4.nabble.com/Regression-stars-tp4657795p4658268.html
Sent from the R devel mailing list archive at Nabble.com.

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Tue Feb 12 16:01:27 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 12 Feb 2013 16:01:27 +0100
Subject: [Rd] Regression stars
In-Reply-To: <1360680169120-4658268.post@n4.nabble.com>
References: <1360243924659-4657795.post@n4.nabble.com>
	<20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<1360680169120-4658268.post@n4.nabble.com>
Message-ID: <511A5947.2010002@statistik.tu-dortmund.de>



On 12.02.2013 15:42, Frank Harrell wrote:
> Uwe I've been consulting for decades and have never once been asked for such
> stars.

Honestly: last time I have been asked last week.

And when I answered (in another case few months ago) "OK, I can add you 
another 5 stars for p values smaller than 0.5" they did not find it too 
funny.

Best,
Uwe

> And when a clinical researcher puts a sentence in a study protocol
> that P<0.05 will be considered "significant" I get them to take it out.
>
> Frank
>
> Uwe Ligges-3 wrote
>> On 12.02.2013 14:54, Ben Bolker wrote:
>>> Duncan Murdoch
>> <murdoch.duncan <at>
>>   gmail.com> writes:
>>>
>>>     [snip]
>>>>
>>>> Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
>>>> I'll let the people who like it defend it.
>>>
>>>     Would someone (anyone) like to come forward and give us a defense
>>> of stringsAsFactors=TRUE -- even someone who doesn't personally like
>>> it but would like to play devil's advocate?
>>
>> Sure:
>> I will have to change all my scripts, my teaching examples, my book, and
>> lots of code examples for research and particularly consulting jobs.
>>
>> Personally, I think having stringsAsFactors=TRUE is not too bad for
>> read.table() but less useful for data.frame().
>>
>> And since you ask for the devil's advocate already, related to the
>> subject line: Removing stars is horrible for consulting: With all those
>> people from biology, medicine and other fields who even ask us questions
>> in term of significance stars that are obviously very common for them.
>> Many of them will certainly ask us for the stars, and ask us to switch
>> to another software product once they do not get it from R. They may not
>> be interested in being taught about the advantages or disadvantages of
>> p-values or stars.
>>
>> There are different use cases of R, and I want to keep stars for
>> consulting tasks where things have to be delivered within minutes. I am
>> happy with or without for teaching, where I have the time and can easily
>> talk about the sense and nonsense of p-values.
>>
>>
>> Best,
>> Uwe
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>>
>>>> What I will likely do is
>>>> make a few changes so that character vectors are automatically changed
>>>> to factors in modelling functions, so that operating with
>>>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>>>>
>>>> Duncan Murdoch
>>>>
>>>
>>>    [apologies for snipping context: "gmane made me do it"]
>>>
>>> ______________________________________________
>>>
>
>> R-devel@
>
>>   mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>
>> R-devel@
>
>>   mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
>
> -----
> Frank Harrell
> Department of Biostatistics, Vanderbilt University
> --
> View this message in context: http://r.789695.n4.nabble.com/Regression-stars-tp4657795p4658268.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From bbolker at gmail.com  Tue Feb 12 16:40:54 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 12 Feb 2013 10:40:54 -0500
Subject: [Rd] Regression stars
In-Reply-To: <511A4F98.50209@statistik.tu-dortmund.de>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
Message-ID: <511A6286.4040704@gmail.com>

On 13-02-12 09:20 AM, Uwe Ligges wrote:
> 
> 
> On 12.02.2013 14:54, Ben Bolker wrote:
>> Duncan Murdoch <murdoch.duncan <at> gmail.com> writes:
>>
>>    [snip]
>>>
>>> Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
>>> I'll let the people who like it defend it.
>>
>>    Would someone (anyone) like to come forward and give us a defense
>> of stringsAsFactors=TRUE -- even someone who doesn't personally like
>> it but would like to play devil's advocate?
> 
> Sure:
> I will have to change all my scripts, my teaching examples, my book, and
> lots of code examples for research and particularly consulting jobs.
> 
> Personally, I think having stringsAsFactors=TRUE is not too bad for
> read.table() but less useful for data.frame().
> 
> And since you ask for the devil's advocate already, related to the
> subject line: Removing stars is horrible for consulting: With all those
> people from biology, medicine and other fields who even ask us questions
> in term of significance stars that are obviously very common for them.
> Many of them will certainly ask us for the stars, and ask us to switch
> to another software product once they do not get it from R. They may not
> be interested in being taught about the advantages or disadvantages of
> p-values or stars.
> 
> There are different use cases of R, and I want to keep stars for
> consulting tasks where things have to be delivered within minutes. I am
> happy with or without for teaching, where I have the time and can easily
> talk about the sense and nonsense of p-values.
> 
> 
> Best,
> Uwe

  Thanks, Uwe.
  Now let me go one step farther.

  Can you (or anyone) give a good argument **other than backward
compatibility** for keeping the stringAsFactors=TRUE argument on
data.frame()?

  I appreciate your distinction between data.frame() and read.table()'s
use of stringAsFactors, and I can see that there is some point for
quick-and-dirty interactive use in setting all non-numeric variables to
factors (arguing that wanting non-numerics as factors is somewhat more
common than wanting them as strings).

  It might be nice to add an optional stringsAsFactors (and check.names)
argument to transform(): I've had to write my own Transform() function
to allow the defaults to be overridden, since transform() calls
data.frame() with the defaults.  (Setting the stringsAsFactors option
globally would work, although not for check.names.)

  Ben BOlker

> 
>>
>>> What I will likely do is
>>> make a few changes so that character vectors are automatically changed
>>> to factors in modelling functions, so that operating with
>>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>>>
>>> Duncan Murdoch
>>>
>>
>>   [apologies for snipping context: "gmane made me do it"]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From ligges at statistik.tu-dortmund.de  Tue Feb 12 16:44:55 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Tue, 12 Feb 2013 16:44:55 +0100
Subject: [Rd] Regression stars
In-Reply-To: <511A6286.4040704@gmail.com>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<511A6286.4040704@gmail.com>
Message-ID: <511A6377.6030004@statistik.tu-dortmund.de>



On 12.02.2013 16:40, Ben Bolker wrote:
> On 13-02-12 09:20 AM, Uwe Ligges wrote:
>>
>>
>> On 12.02.2013 14:54, Ben Bolker wrote:
>>> Duncan Murdoch <murdoch.duncan <at> gmail.com> writes:
>>>
>>>     [snip]
>>>>
>>>> Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
>>>> I'll let the people who like it defend it.
>>>
>>>     Would someone (anyone) like to come forward and give us a defense
>>> of stringsAsFactors=TRUE -- even someone who doesn't personally like
>>> it but would like to play devil's advocate?
>>
>> Sure:
>> I will have to change all my scripts, my teaching examples, my book, and
>> lots of code examples for research and particularly consulting jobs.
>>
>> Personally, I think having stringsAsFactors=TRUE is not too bad for
>> read.table() but less useful for data.frame().
>>
>> And since you ask for the devil's advocate already, related to the
>> subject line: Removing stars is horrible for consulting: With all those
>> people from biology, medicine and other fields who even ask us questions
>> in term of significance stars that are obviously very common for them.
>> Many of them will certainly ask us for the stars, and ask us to switch
>> to another software product once they do not get it from R. They may not
>> be interested in being taught about the advantages or disadvantages of
>> p-values or stars.
>>
>> There are different use cases of R, and I want to keep stars for
>> consulting tasks where things have to be delivered within minutes. I am
>> happy with or without for teaching, where I have the time and can easily
>> talk about the sense and nonsense of p-values.
>>
>>
>> Best,
>> Uwe
>
>    Thanks, Uwe.
>    Now let me go one step farther.
>
>    Can you (or anyone) give a good argument **other than backward
> compatibility** for keeping the stringAsFactors=TRUE argument on
> data.frame()?

No, I cannot,
Uwe


>
>    I appreciate your distinction between data.frame() and read.table()'s
> use of stringAsFactors, and I can see that there is some point for
> quick-and-dirty interactive use in setting all non-numeric variables to
> factors (arguing that wanting non-numerics as factors is somewhat more
> common than wanting them as strings).
>
>    It might be nice to add an optional stringsAsFactors (and check.names)
> argument to transform(): I've had to write my own Transform() function
> to allow the defaults to be overridden, since transform() calls
> data.frame() with the defaults.  (Setting the stringsAsFactors option
> globally would work, although not for check.names.)
>
>    Ben BOlker
>
>>
>>>
>>>> What I will likely do is
>>>> make a few changes so that character vectors are automatically changed
>>>> to factors in modelling functions, so that operating with
>>>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>>>>
>>>> Duncan Murdoch
>>>>
>>>
>>>    [apologies for snipping context: "gmane made me do it"]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>


From murdoch.duncan at gmail.com  Tue Feb 12 17:02:35 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 12 Feb 2013 11:02:35 -0500
Subject: [Rd] Regression stars
In-Reply-To: <511A6286.4040704@gmail.com>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<511A6286.4040704@gmail.com>
Message-ID: <511A679B.4020306@gmail.com>

On 12/02/2013 10:40 AM, Ben Bolker wrote:
> On 13-02-12 09:20 AM, Uwe Ligges wrote:
> >
> >
> > On 12.02.2013 14:54, Ben Bolker wrote:
> >> Duncan Murdoch <murdoch.duncan <at> gmail.com> writes:
> >>
> >>    [snip]
> >>>
> >>> Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
> >>> I'll let the people who like it defend it.
> >>
> >>    Would someone (anyone) like to come forward and give us a defense
> >> of stringsAsFactors=TRUE -- even someone who doesn't personally like
> >> it but would like to play devil's advocate?
> >
> > Sure:
> > I will have to change all my scripts, my teaching examples, my book, and
> > lots of code examples for research and particularly consulting jobs.
> >
> > Personally, I think having stringsAsFactors=TRUE is not too bad for
> > read.table() but less useful for data.frame().
> >
> > And since you ask for the devil's advocate already, related to the
> > subject line: Removing stars is horrible for consulting: With all those
> > people from biology, medicine and other fields who even ask us questions
> > in term of significance stars that are obviously very common for them.
> > Many of them will certainly ask us for the stars, and ask us to switch
> > to another software product once they do not get it from R. They may not
> > be interested in being taught about the advantages or disadvantages of
> > p-values or stars.
> >
> > There are different use cases of R, and I want to keep stars for
> > consulting tasks where things have to be delivered within minutes. I am
> > happy with or without for teaching, where I have the time and can easily
> > talk about the sense and nonsense of p-values.
> >
> >
> > Best,
> > Uwe
>
>    Thanks, Uwe.
>    Now let me go one step farther.
>
>    Can you (or anyone) give a good argument **other than backward
> compatibility** for keeping the stringAsFactors=TRUE argument on
> data.frame()?

I can, under two assumptions:

   1.  We keep stringsAsFactors=TRUE on read.table().
   2.  We keep the stringsAsFactors argument in data.frame().

Under those assumptions, it would just be confusing to have opposite 
defaults.  (Just in case someone hasn't read all of this thread: I'd be 
happier to have the default be FALSE in both cases, but not until 
3.1.x.  For 3.0.x I think I'd just change the default value of 
default.stringsAsFactors() to FALSE, so people could easily get the old 
behaviour.)

Duncan Murdoch

>
>    I appreciate your distinction between data.frame() and read.table()'s
> use of stringAsFactors, and I can see that there is some point for
> quick-and-dirty interactive use in setting all non-numeric variables to
> factors (arguing that wanting non-numerics as factors is somewhat more
> common than wanting them as strings).
>
>    It might be nice to add an optional stringsAsFactors (and check.names)
> argument to transform(): I've had to write my own Transform() function
> to allow the defaults to be overridden, since transform() calls
> data.frame() with the defaults.  (Setting the stringsAsFactors option
> globally would work, although not for check.names.)
>
>    Ben BOlker
>
> >
> >>
> >>> What I will likely do is
> >>> make a few changes so that character vectors are automatically changed
> >>> to factors in modelling functions, so that operating with
> >>> stringsAsFactors=FALSE doesn't trigger silly warnings.
> >>>
> >>> Duncan Murdoch
> >>>
> >>
> >>   [apologies for snipping context: "gmane made me do it"]
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rowe at muxspace.com  Tue Feb 12 17:05:55 2013
From: rowe at muxspace.com (Brian Lee Yung Rowe)
Date: Tue, 12 Feb 2013 11:05:55 -0500
Subject: [Rd] Regression stars
In-Reply-To: <511A6286.4040704@gmail.com>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<511A6286.4040704@gmail.com>
Message-ID: <02F28BE5-04D2-44A8-920D-6E957CCDC4C7@muxspace.com>


I thought that the default was the way it was for performance reasons. For large data.frames or repeated applications, using factors should be faster for non-trivial strings.

> fs <- c('apple','peach','watermelon','spinach','persimmon','potato','kale')
> n <- 1000000
>
> a1 <- data.frame(f=sample(fs,n,replace=TRUE), x1=rnorm(n), x2=rnorm(n), stringsAsFactors=TRUE)
> a2 <- data.frame(f=sample(fs,n,replace=TRUE), x1=rnorm(n), x2=rnorm(n), stringsAsFactors=FALSE)
>
> fn <- function(i,x) x[x$f %in% c('kale','spinach'),]
> system.time(z <- sapply(1:100, fn, a1))
   user  system elapsed 
 19.614   4.037  24.649 
> system.time(z <- sapply(1:100, fn, a2))
   user  system elapsed 
 19.726   7.715  36.761 


On Feb 12, 2013, at 10:40 AM, Ben Bolker <bbolker at gmail.com> wrote:
> 
>  Thanks, Uwe.
>  Now let me go one step farther.
> 
>  Can you (or anyone) give a good argument **other than backward
> compatibility** for keeping the stringAsFactors=TRUE argument on
> data.frame()?
> 
>  I appreciate your distinction between data.frame() and read.table()'s
> use of stringAsFactors, and I can see that there is some point for
> quick-and-dirty interactive use in setting all non-numeric variables to
> factors (arguing that wanting non-numerics as factors is somewhat more
> common than wanting them as strings).
> 
>  It might be nice to add an optional stringsAsFactors (and check.names)
> argument to transform(): I've had to write my own Transform() function
> to allow the defaults to be overridden, since transform() calls
> data.frame() with the defaults.  (Setting the stringsAsFactors option
> globally would work, although not for check.names.)
> 
>  Ben BOlker
> 
>> 
>>> 
>>>> What I will likely do is
>>>> make a few changes so that character vectors are automatically changed
>>>> to factors in modelling functions, so that operating with
>>>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>>>> 
>>>> Duncan Murdoch
>>>> 
>>> 
>>>  [apologies for snipping context: "gmane made me do it"]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Tue Feb 12 17:20:55 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 12 Feb 2013 17:20:55 +0100
Subject: [Rd] Regression stars
In-Reply-To: <02F28BE5-04D2-44A8-920D-6E957CCDC4C7@muxspace.com>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<511A6286.4040704@gmail.com>
	<02F28BE5-04D2-44A8-920D-6E957CCDC4C7@muxspace.com>
Message-ID: <4BDA0169-2C89-488B-B891-50EE1E857DB7@gmail.com>


On Feb 12, 2013, at 17:05 , Brian Lee Yung Rowe wrote:

> 
> I thought that the default was the way it was for performance reasons. For large data.frames or repeated applications, using factors should be faster for non-trivial strings.

I think not. Historically, it's more like "In statistics we have two kinds of variables, numerical and categorical. OK, so we have the occasional truly character-type variables like name and address, let's handle those as a special case". 


-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pburns at pburns.seanet.com  Tue Feb 12 18:48:55 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 12 Feb 2013 17:48:55 +0000
Subject: [Rd] get and exists are not vectorized
Message-ID: <511A8087.10800@pburns.seanet.com>

Here is the current behavior (in 2.15.2 and 3.0.0):

 > exists(c('notLikely', 'exists'))
[1] FALSE
 > exists(c('exists', 'notLikely'))
[1] TRUE
 > get(c('notLikely', 'exists'))
Error in get(c("notLikely", "exists")) : object 'notLikely' not found
 > get(c('exists', 'notLikely'))
function (x, where = -1, envir = if (missing(frame)) 
as.environment(where) else sys.frame(frame),
     frame, mode = "any", inherits = TRUE)
.Internal(exists(x, envir, mode, inherits))
<bytecode: 0x000000000f7f8830>
<environment: namespace:base>


Both 'exists' and 'get' silently ignore all but the
first element.

My view is that 'get' should do what it currently does
except it should warn about ignoring subsequent elements
if there are any.

I don't see a reason why 'exists' shouldn't be vectorized.

Am I missing something?

Pat

-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From ravi.varadhan at jhu.edu  Tue Feb 12 16:03:41 2013
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Tue, 12 Feb 2013 15:03:41 +0000
Subject: [Rd] Regression stars
In-Reply-To: <511A5947.2010002@statistik.tu-dortmund.de>
References: <1360243924659-4657795.post@n4.nabble.com>
	<20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com> <loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<1360680169120-4658268.post@n4.nabble.com>
	<511A5947.2010002@statistik.tu-dortmund.de>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3365277@DOM-EB-MAIL2.win.ad.jhu.edu>

They are "reaching for the stars".  Pardon my jest, but I couldn't resist. 

Ravi

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Uwe Ligges
Sent: Tuesday, February 12, 2013 10:01 AM
To: Frank Harrell
Cc: r-devel at r-project.org
Subject: Re: [Rd] Regression stars



On 12.02.2013 15:42, Frank Harrell wrote:
> Uwe I've been consulting for decades and have never once been asked 
> for such stars.

Honestly: last time I have been asked last week.

And when I answered (in another case few months ago) "OK, I can add you another 5 stars for p values smaller than 0.5" they did not find it too funny.

Best,
Uwe

> And when a clinical researcher puts a sentence in a study protocol 
> that P<0.05 will be considered "significant" I get them to take it out.
>
> Frank
>
> Uwe Ligges-3 wrote
>> On 12.02.2013 14:54, Ben Bolker wrote:
>>> Duncan Murdoch
>> <murdoch.duncan <at>
>>   gmail.com> writes:
>>>
>>>     [snip]
>>>>
>>>> Regarding stringsAsFactors:  I'm not going to defend keeping it as 
>>>> is, I'll let the people who like it defend it.
>>>
>>>     Would someone (anyone) like to come forward and give us a 
>>> defense of stringsAsFactors=TRUE -- even someone who doesn't 
>>> personally like it but would like to play devil's advocate?
>>
>> Sure:
>> I will have to change all my scripts, my teaching examples, my book, 
>> and lots of code examples for research and particularly consulting jobs.
>>
>> Personally, I think having stringsAsFactors=TRUE is not too bad for
>> read.table() but less useful for data.frame().
>>
>> And since you ask for the devil's advocate already, related to the 
>> subject line: Removing stars is horrible for consulting: With all 
>> those people from biology, medicine and other fields who even ask us 
>> questions in term of significance stars that are obviously very common for them.
>> Many of them will certainly ask us for the stars, and ask us to 
>> switch to another software product once they do not get it from R. 
>> They may not be interested in being taught about the advantages or 
>> disadvantages of p-values or stars.
>>
>> There are different use cases of R, and I want to keep stars for 
>> consulting tasks where things have to be delivered within minutes. I 
>> am happy with or without for teaching, where I have the time and can 
>> easily talk about the sense and nonsense of p-values.
>>
>>
>> Best,
>> Uwe
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>
>>>
>>>> What I will likely do is
>>>> make a few changes so that character vectors are automatically 
>>>> changed to factors in modelling functions, so that operating with 
>>>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>>>>
>>>> Duncan Murdoch
>>>>
>>>
>>>    [apologies for snipping context: "gmane made me do it"]
>>>
>>> ______________________________________________
>>>
>
>> R-devel@
>
>>   mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> ______________________________________________
>
>> R-devel@
>
>>   mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>
>
>
> -----
> Frank Harrell
> Department of Biostatistics, Vanderbilt University
> --
> View this message in context: 
> http://r.789695.n4.nabble.com/Regression-stars-tp4657795p4658268.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From tim.triche at gmail.com  Tue Feb 12 19:01:19 2013
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Tue, 12 Feb 2013 10:01:19 -0800
Subject: [Rd] Regression stars
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3365277@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <1360243924659-4657795.post@n4.nabble.com>
	<20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com> <loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<1360680169120-4658268.post@n4.nabble.com>
	<511A5947.2010002@statistik.tu-dortmund.de>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3365277@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <CAC+N9BWwTCTHJsDFA9iJUf2QH50Q=Yb6iqgT5JvxjhQ478Qd+g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130212/ac477ce0/attachment.pl>

From simon.urbanek at r-project.org  Tue Feb 12 19:02:57 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 12 Feb 2013 13:02:57 -0500
Subject: [Rd] Regression stars
In-Reply-To: <02F28BE5-04D2-44A8-920D-6E957CCDC4C7@muxspace.com>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<511A6286.4040704@gmail.com>
	<02F28BE5-04D2-44A8-920D-6E957CCDC4C7@muxspace.com>
Message-ID: <F37729C0-45FD-424B-934C-07DDFCFA62D4@r-project.org>


On Feb 12, 2013, at 11:05 AM, Brian Lee Yung Rowe wrote:

> 
> I thought that the default was the way it was for performance reasons. For large data.frames or repeated applications, using factors should be faster for non-trivial strings.
> 
>> fs <- c('apple','peach','watermelon','spinach','persimmon','potato','kale')
>> n <- 1000000
>> 
>> a1 <- data.frame(f=sample(fs,n,replace=TRUE), x1=rnorm(n), x2=rnorm(n), stringsAsFactors=TRUE)
>> a2 <- data.frame(f=sample(fs,n,replace=TRUE), x1=rnorm(n), x2=rnorm(n), stringsAsFactors=FALSE)
>> 
>> fn <- function(i,x) x[x$f %in% c('kale','spinach'),]
>> system.time(z <- sapply(1:100, fn, a1))
>   user  system elapsed 
> 19.614   4.037  24.649 
>> system.time(z <- sapply(1:100, fn, a2))
>   user  system elapsed 
> 19.726   7.715  36.761 
> 

Not really:

> system.time(z <- sapply(1:100, fn, a1))
   user  system elapsed 
 13.780   0.444  14.229 
> rm(z)
> gc()
          used (Mb) gc trigger   (Mb)  max used   (Mb)
Ncells  182113  9.8     407500   21.8    337655   18.1
Vcells 5789638 44.2  133982285 1022.3 163019778 1243.8
> system.time(z <- sapply(1:100, fn, a2))
   user  system elapsed 
 13.201   0.668  13.873 


But your test is bogus, because %in% uses match() which converts factors to character vectors anyway, so in your case you're just measuring noise in your system, character vectors are always faster in your example.

The reason is that in R strings are hashed so character vectors are technically very similar to factors just with faster access (because they don't need to go through the integer indirection). On 32-bit strings are in theory always faster than factors, on 64-bit they use double the size so they may or may not be faster depending on how you hit the cache etc. Anyway, in modern R versions you're much better off using character vectors than factors for any processing, so stringsAsFactors=FALSE is what I use exclusively.

Cheers,
Simon

> 
> On Feb 12, 2013, at 10:40 AM, Ben Bolker <bbolker at gmail.com> wrote:
>> 
>> Thanks, Uwe.
>> Now let me go one step farther.
>> 
>> Can you (or anyone) give a good argument **other than backward
>> compatibility** for keeping the stringAsFactors=TRUE argument on
>> data.frame()?
>> 
>> I appreciate your distinction between data.frame() and read.table()'s
>> use of stringAsFactors, and I can see that there is some point for
>> quick-and-dirty interactive use in setting all non-numeric variables to
>> factors (arguing that wanting non-numerics as factors is somewhat more
>> common than wanting them as strings).
>> 
>> It might be nice to add an optional stringsAsFactors (and check.names)
>> argument to transform(): I've had to write my own Transform() function
>> to allow the defaults to be overridden, since transform() calls
>> data.frame() with the defaults.  (Setting the stringsAsFactors option
>> globally would work, although not for check.names.)
>> 
>> Ben BOlker
>> 
>>> 
>>>> 
>>>>> What I will likely do is
>>>>> make a few changes so that character vectors are automatically changed
>>>>> to factors in modelling functions, so that operating with
>>>>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>>>>> 
>>>>> Duncan Murdoch
>>>>> 
>>>> 
>>>> [apologies for snipping context: "gmane made me do it"]
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From claudia.beleites at ipht-jena.de  Tue Feb 12 19:30:20 2013
From: claudia.beleites at ipht-jena.de (Claudia Beleites)
Date: Tue, 12 Feb 2013 19:30:20 +0100
Subject: [Rd] Contribution
In-Reply-To: <CAG6ADrSNRm_z9_An+EpaiTtvQbnUpHp07aqGUW8iR0gCAa3yrQ@mail.gmail.com>
References: <CAG6ADrSNRm_z9_An+EpaiTtvQbnUpHp07aqGUW8iR0gCAa3yrQ@mail.gmail.com>
Message-ID: <20130212193020.18d3f540@cbdesktop>

Hi Parthasarathy,

IMHO the easiest way to contribute to R is contributing to an R
package. And one way to do that is to apply for a Google Summer of Code
project. I guess activities about that will start soon, as the program
was just announced, and they will take place at a separate email list:

gsoc-r at groups.google.com

So I suggest you sign up for that list, and maybe explain a bit who you
are, what experience you have in R programming (or other languages) and
what your programming interests are. 

Best, Claudia




> I am Parthasarathy G , from IIT Maras ( India ). I am currently in
> third year of the undergraduate course.
> 
> I would like to contribute to the R project. Can anyone guide me
> regarding this?
> 
> Thanking you,
> Parthasarathy
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Claudia Beleites
Spectroscopy/Imaging
Institute of Photonic Technology 
Albert-Einstein-Str. 9
07745 Jena
Germany

email: claudia.beleites at ipht-jena.de
phone: +49 3641 206-133
fax:   +49 2641 206-399


From hpages at fhcrc.org  Tue Feb 12 19:47:31 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 12 Feb 2013 10:47:31 -0800
Subject: [Rd] Regression stars
In-Reply-To: <4BDA0169-2C89-488B-B891-50EE1E857DB7@gmail.com>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<511A6286.4040704@gmail.com>
	<02F28BE5-04D2-44A8-920D-6E957CCDC4C7@muxspace.com>
	<4BDA0169-2C89-488B-B891-50EE1E857DB7@gmail.com>
Message-ID: <511A8E43.6080302@fhcrc.org>

On 02/12/2013 08:20 AM, peter dalgaard wrote:
>
> On Feb 12, 2013, at 17:05 , Brian Lee Yung Rowe wrote:
>
>>
>> I thought that the default was the way it was for performance reasons. For large data.frames or repeated applications, using factors should be faster for non-trivial strings.
>
> I think not. Historically, it's more like "In statistics we have two kinds of variables, numerical and categorical. OK, so we have the occasional truly character-type variables like name and address, let's handle those as a special case".

<sarcasm>

Since character vectors are sooooo bad and people use them where
they should instead use a factor, I propose to go all the way and
by adding the stringsAsFactors arg to character() too. That way
people are put on the right track from the very start.

</sarcasm>

No seriously, if my variable is categorical, it's already in a factor
and that's how I pass it to data.frame(). But if I have it in a
character vector, it's because that's how I want it. It's my choice.
How could anybody ever think that having data.frame() alter his/her
data is a good thing?

Please *remove* the stringsAsFactors arg of data.frame() in R 3.0.
You'll do a big favor to your user base.

Thanks,
H.

>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From murdoch.duncan at gmail.com  Tue Feb 12 20:19:51 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 12 Feb 2013 14:19:51 -0500
Subject: [Rd] Regression stars
In-Reply-To: <511A8E43.6080302@fhcrc.org>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<511A6286.4040704@gmail.com>
	<02F28BE5-04D2-44A8-920D-6E957CCDC4C7@muxspace.com>
	<4BDA0169-2C89-488B-B891-50EE1E857DB7@gmail.com>
	<511A8E43.6080302@fhcrc.org>
Message-ID: <511A95D7.7060708@gmail.com>

On 12/02/2013 1:47 PM, Herv? Pag?s wrote:
> On 02/12/2013 08:20 AM, peter dalgaard wrote:
> >
> > On Feb 12, 2013, at 17:05 , Brian Lee Yung Rowe wrote:
> >
> >>
> >> I thought that the default was the way it was for performance reasons. For large data.frames or repeated applications, using factors should be faster for non-trivial strings.
> >
> > I think not. Historically, it's more like "In statistics we have two kinds of variables, numerical and categorical. OK, so we have the occasional truly character-type variables like name and address, let's handle those as a special case".
>
> <sarcasm>
>
> Since character vectors are sooooo bad and people use them where
> they should instead use a factor, I propose to go all the way and
> by adding the stringsAsFactors arg to character() too. That way
> people are put on the right track from the very start.
>
> </sarcasm>

I think you are misreading what Peter wrote.  He wasn't defending that 
point of view, he was describing it.
>
> No seriously, if my variable is categorical, it's already in a factor
> and that's how I pass it to data.frame(). But if I have it in a
> character vector, it's because that's how I want it. It's my choice.
> How could anybody ever think that having data.frame() alter his/her
> data is a good thing?
>
> Please *remove* the stringsAsFactors arg of data.frame() in R 3.0.
> You'll do a big favor to your user base.

That's a really bad suggestion -- it would break code for people who set 
stringsAsFactors=FALSE as well as those who rely on the current default 
behaviour.   We certainly won't do that.

Duncan Murdoch


From hpages at fhcrc.org  Tue Feb 12 21:27:13 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 12 Feb 2013 12:27:13 -0800
Subject: [Rd] Regression stars
In-Reply-To: <511A95D7.7060708@gmail.com>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<511A6286.4040704@gmail.com>
	<02F28BE5-04D2-44A8-920D-6E957CCDC4C7@muxspace.com>
	<4BDA0169-2C89-488B-B891-50EE1E857DB7@gmail.com>
	<511A8E43.6080302@fhcrc.org> <511A95D7.7060708@gmail.com>
Message-ID: <511AA5A1.5050008@fhcrc.org>

Hi Duncan,

On 02/12/2013 11:19 AM, Duncan Murdoch wrote:
> On 12/02/2013 1:47 PM, Herv? Pag?s wrote:
>> On 02/12/2013 08:20 AM, peter dalgaard wrote:
>> >
>> > On Feb 12, 2013, at 17:05 , Brian Lee Yung Rowe wrote:
>> >
>> >>
>> >> I thought that the default was the way it was for performance
>> reasons. For large data.frames or repeated applications, using factors
>> should be faster for non-trivial strings.
>> >
>> > I think not. Historically, it's more like "In statistics we have two
>> kinds of variables, numerical and categorical. OK, so we have the
>> occasional truly character-type variables like name and address, let's
>> handle those as a special case".
>>
>> <sarcasm>
>>
>> Since character vectors are sooooo bad and people use them where
>> they should instead use a factor, I propose to go all the way and
>> by adding the stringsAsFactors arg to character() too. That way
>> people are put on the right track from the very start.
>>
>> </sarcasm>
>
> I think you are misreading what Peter wrote.  He wasn't defending that
> point of view, he was describing it.

I was answering to the thread, not to Peter in particular. Sorry if it
sounded otherwise.

>>
>> No seriously, if my variable is categorical, it's already in a factor
>> and that's how I pass it to data.frame(). But if I have it in a
>> character vector, it's because that's how I want it. It's my choice.
>> How could anybody ever think that having data.frame() alter his/her
>> data is a good thing?
>>
>> Please *remove* the stringsAsFactors arg of data.frame() in R 3.0.
>> You'll do a big favor to your user base.
>
> That's a really bad suggestion -- it would break code for people who set
> stringsAsFactors=FALSE as well as those who rely on the current default
> behaviour.   We certainly won't do that.

But since there seems to be a discussion about doing some changes to
the stringsAsFactors "feature", I was hoping you would consider that
one too.  Doing the right thing sometimes requires breaking people's
code, sadly!

Cheers,
H.

>
> Duncan Murdoch
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From tlumley at uw.edu  Wed Feb 13 01:22:20 2013
From: tlumley at uw.edu (Thomas Lumley)
Date: Wed, 13 Feb 2013 13:22:20 +1300
Subject: [Rd] stopping finalizers
Message-ID: <CAJ55+dJogFHu3bXBFSjDGynsH0FKN4A15=5uWg_KS4XTaEOSCA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130213/ed1bc92b/attachment.pl>

From nalimilan at club.fr  Wed Feb 13 10:12:03 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 13 Feb 2013 10:12:03 +0100
Subject: [Rd] Private environments and/or assignInMyNamespace
In-Reply-To: <511A4785.5070504@bht-berlin.de>
References: <511A4785.5070504@bht-berlin.de>
Message-ID: <1360746723.28045.23.camel@milan>

Le mardi 12 f?vrier 2013 ? 14:45 +0100, Ulrike Gr?mping a ?crit :
> Dear DevelopeRs,
> 
> I've been struggling with the new regulations regarding modifications to 
> the search path, regarding my Rcmdr plugin package RcmdrPlugin.DoE. John 
> Fox made Rcmdr comply with the new policy by removing the environment 
> RcmdrEnv from the search path. For the time being, he developed an 
> option that allows users to put the environment from Rcmdr (RcmdrEnv) on 
> the search path, like in earlier versions of Rcmdr (thanks John!), which 
> rescues my package for the immediate future; however, in the long run it 
> would be nice to be able to make it work without that.
> 
> The reason why I currently need the environment on the search path (may 
> be due to my lack of understanding how tcltk widgets are handled): I 
> have quite elaborate notebook widgets on which users can make many 
> entries. Some entries are only checked after clicking OK, and if an 
> error is found at that point, the user receives a small message window 
> that has to be confirmed and is subsequently returned to the notebook 
> widget in the state it was in when pressing OK. These widgets are 
> currently held in the environment RcmdrEnv; they work when RcmdrEnv is 
> on the search path; however, it is not sufficient to retrieve them with 
> John's function getRcmdr, which works fine for objects other than widgets.
I'm not sure I understand exactly how this works, but does that mean you
close the dialog before checking the entries? If it is the case, you
could check them before, and if an error is detected, you would keep the
dialog open: this way, you would not need to restore anything.

Could you point us at the relevant code?


Regards

> Here my question: Would it be an option to place the widgets in a 
> private environment of my plugin package (then I would have to learn how 
> to create one and work with it), or won't they be found that way? 
> Alternatively, I could have unexported objects of all required names in 
> my namespace and modify these via assignInMyNamespace (I don't think 
> that anybody from somewhere else would import that namespace, it's not 
> that kind of package). Would that be a viable alternative, and would the 
> widgets be found that way? Any further ideas?
> 
> Best regards,
> Ulrike
>


From groemping at bht-berlin.de  Wed Feb 13 13:16:46 2013
From: groemping at bht-berlin.de (=?UTF-8?B?VWxyaWtlIEdyw7ZtcGluZw==?=)
Date: Wed, 13 Feb 2013 13:16:46 +0100
Subject: [Rd] Private environments and/or assignInMyNamespace
In-Reply-To: <1360746723.28045.23.camel@milan>
References: <511A4785.5070504@bht-berlin.de> <1360746723.28045.23.camel@milan>
Message-ID: <511B842E.6030408@bht-berlin.de>

Milan,

I am not closing the dialog, but without the dialog in the search space, 
I cannot properly refer to it any more using e.g. the Rcmdr function 
errorCondition.
It has been a long time ago that I wrote this; I don't have a small 
reproducible example right now. Below is an example of what I do in 
function Menu.pb2level:

I am using function justDoItDoE (instead of Rcmdr justDoIt, because 
justDoIt puts the focus in the wrong place for my purpose; have to adapt 
to RStudio here!):
justDoItDoE <- function (command)
{
     Message()
     if (!getRcmdr("suppress.X11.warnings")) {
         messages.connection <- file(open = "w+")
         sink(messages.connection, type = "message")
         on.exit({
             sink(type = "message")
             close(messages.connection)
         })
     }
     else messages.connection <- getRcmdr("messages.connection")
     result <- try(eval(parse(text = command), envir = .GlobalEnv))
     if (!class(result)[1] == "try-error")
         Rcmdr:::checkWarnings(readLines(messages.connection))
     result
}
<environment: namespace:RcmdrPlugin.DoE>

Subsequently, I am using the Rcmdr function errorCondition:
errorCondition <- function (window = top, recall = NULL, message = 
stop("message not supplied"),
     model = FALSE)
{
     tmp <- substitute({
         on.exit(remove(list = objects(pattern = "^\\.\\.", all.names = 
TRUE)))
         if (model) putRcmdr("modelNumber", getRcmdr("modelNumber") -
             1)
         if (!is.null(window)) {
             if (GrabFocus()) tkgrab.release(window)
             tkdestroy(window)
         }
         Message(message = message, type = "error")
         if (!is.null(recall)) recall() else tkfocus(CommanderWindow())
     })
     eval(tmp, parent.frame())
}

Function errorCondition has to find the dialog topdes2, and I have to be 
inside function Menu.pb2level again:
             hilf <- justDoItDoE(command)
             if (class(hilf)[1] == "try-error") {
                 errorCondition(window = topdes2, recall = Menu.pb2level,
                   message = gettextRcmdr(hilf))
                 return()
             }

This code does not work with topdes2 not in the search path, and when I 
tried before, it did also not work with getRcmdr("topdes2") instead of 
topdes2 - but maybe, I just was not following this approach through 
thoroughly enough.

Any thoughts whether the storage of widgets in an environment off the 
search path might work (when properly followed through, which will be a 
lot of work)? Or any suggestion how else I can achieve what I try to do?

Best, Ulrike

Am 13.02.2013 10:12, schrieb Milan Bouchet-Valat:
> Le mardi 12 f?vrier 2013 ? 14:45 +0100, Ulrike Gr?mping a ?crit :
>> Dear DevelopeRs,
>>
>> I've been struggling with the new regulations regarding modifications to
>> the search path, regarding my Rcmdr plugin package RcmdrPlugin.DoE. John
>> Fox made Rcmdr comply with the new policy by removing the environment
>> RcmdrEnv from the search path. For the time being, he developed an
>> option that allows users to put the environment from Rcmdr (RcmdrEnv) on
>> the search path, like in earlier versions of Rcmdr (thanks John!), which
>> rescues my package for the immediate future; however, in the long run it
>> would be nice to be able to make it work without that.
>>
>> The reason why I currently need the environment on the search path (may
>> be due to my lack of understanding how tcltk widgets are handled): I
>> have quite elaborate notebook widgets on which users can make many
>> entries. Some entries are only checked after clicking OK, and if an
>> error is found at that point, the user receives a small message window
>> that has to be confirmed and is subsequently returned to the notebook
>> widget in the state it was in when pressing OK. These widgets are
>> currently held in the environment RcmdrEnv; they work when RcmdrEnv is
>> on the search path; however, it is not sufficient to retrieve them with
>> John's function getRcmdr, which works fine for objects other than widgets.
> I'm not sure I understand exactly how this works, but does that mean you
> close the dialog before checking the entries? If it is the case, you
> could check them before, and if an error is detected, you would keep the
> dialog open: this way, you would not need to restore anything.
>
> Could you point us at the relevant code?
>
>
> Regards
>
>> Here my question: Would it be an option to place the widgets in a
>> private environment of my plugin package (then I would have to learn how
>> to create one and work with it), or won't they be found that way?
>> Alternatively, I could have unexported objects of all required names in
>> my namespace and modify these via assignInMyNamespace (I don't think
>> that anybody from somewhere else would import that namespace, it's not
>> that kind of package). Would that be a viable alternative, and would the
>> widgets be found that way? Any further ideas?
>>
>> Best regards,
>> Ulrike
>>


From pdalgd at gmail.com  Wed Feb 13 13:25:09 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 13 Feb 2013 13:25:09 +0100
Subject: [Rd] Regression stars
In-Reply-To: <511A95D7.7060708@gmail.com>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<511A6286.4040704@gmail.com>
	<02F28BE5-04D2-44A8-920D-6E957CCDC4C7@muxspace.com>
	<4BDA0169-2C89-488B-B891-50EE1E857DB7@gmail.com>
	<511A8E43.6080302@fhcrc.org> <511A95D7.7060708@gmail.com>
Message-ID: <128C73D9-AF83-4878-892F-E1B2A9CD8320@gmail.com>


On Feb 12, 2013, at 20:19 , Duncan Murdoch wrote:

> I think you are misreading what Peter wrote.  He wasn't defending that point of view, he was describing it.
> 

Yes. However, that being said, there is the point that the whole thing has been designed to work within the paradigm that I described, and, for better or worse, things are reasonably coherent and consistent within that framework.

The thing that always worries me, when people get bothered by some aspect of software design, is that, if you change only that aspect, you may find yourself with something that is incoherent and inconsistent. I have quite a few times found myself realizing that "Uncle John was right after all".  

For instance, if you change the paradigm to say that "character variables are character, unless explicitly turned into factors", and then ameliorate the inconvenience by changing code that relies on factors to convert character variables on the fly, then you will lose the otherwise automatic consistency of level sets between subsets of data. (So, the math department not only has zero female professors, the entire female gender ceases to exist for that subgroup.)

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From info at aghmed.fsnet.co.uk  Wed Feb 13 13:33:20 2013
From: info at aghmed.fsnet.co.uk (Michael Dewey)
Date: Wed, 13 Feb 2013 12:33:20 +0000
Subject: [Rd] stringsAsFactors
In-Reply-To: <CA+vqiLH_OzKKcYLxK3jsrQRtpvN=Uj6xoEJpsCAwX3yLQG-vzA@mail.g
	mail.com>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
	<51192F72.4090904@gmail.com>
	<CA+vqiLH_OzKKcYLxK3jsrQRtpvN=Uj6xoEJpsCAwX3yLQG-vzA@mail.gmail.com>
Message-ID: <Zen-1U5bWl-0008SN-65@smarthost02.mail.zen.net.uk>

At 18:01 11/02/2013, Ista Zahn wrote:
>FWIW my view is that for data cleaning and organizing factors just get
>it the way. For modeling I like them because they make it easier to
>understand what is happening. For example I can look at the levels()
>to see what the reference group will be. With characters one has to
>know a) that levels are created in alphabetical order and b) the
>alphabetical order of the the unique values in the character vector.
>Ugh. So my habit is to turn off stringsAsFactors, then explicitly
>convert to factors before modeling (I also use factors to change the
>order in which things are displayed in tables and graphs, another
>place where converting to factors myself is useful but the creating
>them in alphabetical order by default is not)
>
>All this is to say that I would like options(stingsAsFactors=FALSE) to
>be the default, but I like the warning about converting to factors in
>modeling functions because it reminds me that I forgot to covert them,
>which I like to do anyway...

I seem to be one of the few people who find the current default 
helpful. When I read in a dataset I am nearly always going to follow 
it with one or more of the modelling functions and so I do want to 
treat the categorical variables as factors. I cannot off-hand think 
of an example where I have had to convert them to characters.

Incidentally xkcd has, while this discussion has been going on, 
posted something relevant
http://www.xkcd.com/1172/



>Best,
>Ista
>
>On Mon, Feb 11, 2013 at 12:50 PM, Duncan Murdoch
><murdoch.duncan at gmail.com> wrote:
> > On 11/02/2013 12:13 PM, William Dunlap wrote:
> >>
> >> Note that changing this does not just mean getting rid of "silly
> >> warnings".
> >> Currently, predict.lm() can give wrong answers when stringsAsFactors is
> >> FALSE.
> >>
> >>    > d <- data.frame(x=1:10, f=rep(c("A","B","C"), c(4,3,3)), y=c(1:4,
> >> 15:17, 28.1,28.8,30.1))
> >>    > fit_ab <- lm(y ~ x + f, data = d, subset = f!="B")
> >>    Warning message:
> >>    In model.matrix.default(mt, mf, contrasts) :
> >>      variable 'f' converted to a factor
> >>    > predict(fit_ab, newdata=d)
> >>     1 2 3 4 5 6 7 8 9 10
> >>     1  2  3  4 25 26 27  8  9 10
> >>    Warning messages:
> >>    1: In model.matrix.default(Terms, m, contrasts.arg = object$contrasts)
> >> :
> >>      variable 'f' converted to a factor
> >>    2: In predict.lm(fit_ab, newdata = d) :
> >>      prediction from a rank-deficient fit may be misleading
> >>
> >> fit_ab is not rank-deficient and the predict should report
> >>     1 2 3 4 NA NA NA 28 29 30
> >
> >
> > In R-devel, the two warnings about factor conversions are no longer given,
> > but the predictions are the same and the warning about rank 
> deficiency still
> > shows up.  If f is set to be a factor, an error is generated:
> >
> > Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
> > object$xlevels) :
> >   factor f has new levels B
> >
> > I think both the warning and error are somewhat reasonable responses.  The
> > fit is rank deficient relative to the model that includes f == 
> "B",  because
> > the column of the design matrix corresponding to f level B would be
> > completely zero.  In this particular model, we could still do predictions
> > for the other levels, but it also seems reasonable to quit, given that
> > clearly something has gone wrong.
> >
> > I do think that it's unfortunate that we don't get the same result in both
> > cases, and I'd like to have gotten the predictions you suggested, but I
> > don't think that's going to happen.  The reason for the difference is that
> > the subsetting is done before the conversion to a factor, but I think that
> > is unavoidable without really big changes.
> >
> > Duncan Murdoch
> >
> >
> >
> >>
> >> Bill Dunlap
> >> Spotfire, TIBCO Software
> >> wdunlap tibco.com
> >>
> >> > -----Original Message-----
> >> > From: r-devel-bounces at r-project.org
> >> > [mailto:r-devel-bounces at r-project.org] On Behalf
> >> > Of Terry Therneau
> >> > Sent: Monday, February 11, 2013 5:50 AM
> >> > To: r-devel at r-project.org; Duncan Murdoch
> >> > Subject: Re: [Rd] stringsAsFactors
> >> >
> >> > I think your idea to remove the warnings is excellent, and a good
> >> > compromise.
> >> > Characters
> >> > already work fine in modeling functions except for the silly warning.
> >> >
> >> > It is interesting how often the defaults for a program reflect the data
> >> > sets in use at the
> >> > time the defaults were chosen.  There are some such in my own survival
> >> > package whose
> >> > proper value is no longer as "obvious" as it was when I chose them.
> >> > Factors are very
> >> > handy for variables which have only a few levels and will be used in
> >> > modeling.  Every
> >> > character variable of every dataset in "Statistical Models in S", which
> >> > introduced
> >> > factors, is of this type so auto-transformation made a lot of sense.
> >> > The "solder" data
> >> > set there is one for which Helmert contrasts are proper so guess what
> >> > the default
> >> > contrast
> >> > option was?  (I think there are only a few data sets in the world for
> >> > which Helmert makes
> >> > sense, however, and R eventually changed the default.)
> >> >
> >> > For character variables that should not be factors such as a street
> >> > adress
> >> > stringsAsFactors can be a real PITA, and I expect that people's
> >> > preference for the option
> >> > depends almost entirely on how often these arise in their own work.  As
> >> > long as there is
> >> > an option that can be overridden I'm okay.  Yes, I'd prefer FALSE as the
> >> > default, partly
> >> > because the current value is a tripwire in the hallway that eventually
> >> > catches every new
> >> > user.
> >> >
> >> > Terry Therneau
> >> >
> >> > On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
> >> > > Both of these were discussed by R Core.  I think it's unlikely the
> >> > > default for stringsAsFactors will be changed (some R Core members like
> >> > > the current behaviour), but it's fairly likely the show.signif.stars
> >> > > default will change.  (That's if someone gets around to it:  I
> >> > > personally don't care about that one.  P-values are commonly used
> >> > > statistics, and the stars are just a simple graphical display of them.
> >> > > I find some p-values to be useful, and the display to be harmless.)
> >> > >
> >> > > I think it's really unlikely the more extreme changes (i.e. dropping
> >> > > show.signif.stars completely, or dropping p-values) will happen.
> >> > >
> >> > > Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
> >> > > I'll let the people who like it defend it.  What I will likely do is
> >> > > make a few changes so that character vectors are automatically changed
> >> > > to factors in modelling functions, so that operating with
> >> > > stringsAsFactors=FALSE doesn't trigger silly warnings.
> >> >
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel

Michael Dewey
info at aghmed.fsnet.co.uk
http://www.aghmed.fsnet.co.uk/home.html


From istazahn at gmail.com  Wed Feb 13 13:54:03 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 13 Feb 2013 07:54:03 -0500
Subject: [Rd] stringsAsFactors
In-Reply-To: <Zen-1U5bWl-0008SN-65@smarthost02.mail.zen.net.uk>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
	<51192F72.4090904@gmail.com>
	<CA+vqiLH_OzKKcYLxK3jsrQRtpvN=Uj6xoEJpsCAwX3yLQG-vzA@mail.gmail.com>
	<Zen-1U5bWl-0008SN-65@smarthost02.mail.zen.net.uk>
Message-ID: <CA+vqiLGWn+HJBFczdXSrtawXxivEia7pqpOAsFcnoC8OubyNFA@mail.gmail.com>

On Wed, Feb 13, 2013 at 7:33 AM, Michael Dewey <info at aghmed.fsnet.co.uk> wrote:
> At 18:01 11/02/2013, Ista Zahn wrote:
>>
>> FWIW my view is that for data cleaning and organizing factors just get
>> it the way. For modeling I like them because they make it easier to
>> understand what is happening. For example I can look at the levels()
>> to see what the reference group will be. With characters one has to
>> know a) that levels are created in alphabetical order and b) the
>> alphabetical order of the the unique values in the character vector.
>> Ugh. So my habit is to turn off stringsAsFactors, then explicitly
>> convert to factors before modeling (I also use factors to change the
>> order in which things are displayed in tables and graphs, another
>> place where converting to factors myself is useful but the creating
>> them in alphabetical order by default is not)
>>
>> All this is to say that I would like options(stingsAsFactors=FALSE) to
>> be the default, but I like the warning about converting to factors in
>> modeling functions because it reminds me that I forgot to covert them,
>> which I like to do anyway...
>
>
> I seem to be one of the few people who find the current default helpful.
> When I read in a dataset I am nearly always going to follow it with one or
> more of the modelling functions and so I do want to treat the categorical
> variables as factors. I cannot off-hand think of an example where I have had
> to convert them to characters.

Your data must reach you in a much better state than mine reaches me.
I spend most of my time organizing, combining, fixing typos,
reshaping, merging and so on. Then I see the dreaded warning

"In `[<-.factor`(`*tmp*`, 6, value = "z") :
  invalid factor level, NAs generated

which reminds me that I've forgotten to set stringsAsFactors=FALSE.
However, I'm not saying I don't like factors. Once the data is cleaned
up they are very useful. But often I find that when I'm trying to
clean up a messy data set they just get in the way. And since that is
what I spend most of my time doing, factors get in the way most of the
time for me.


>
> Incidentally xkcd has, while this discussion has been going on, posted
> something relevant
> http://www.xkcd.com/1172/
>
>
>
>
>> Best,
>> Ista
>>
>> On Mon, Feb 11, 2013 at 12:50 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>> > On 11/02/2013 12:13 PM, William Dunlap wrote:
>> >>
>> >> Note that changing this does not just mean getting rid of "silly
>> >> warnings".
>> >> Currently, predict.lm() can give wrong answers when stringsAsFactors is
>> >> FALSE.
>> >>
>> >>    > d <- data.frame(x=1:10, f=rep(c("A","B","C"), c(4,3,3)), y=c(1:4,
>> >> 15:17, 28.1,28.8,30.1))
>> >>    > fit_ab <- lm(y ~ x + f, data = d, subset = f!="B")
>> >>    Warning message:
>> >>    In model.matrix.default(mt, mf, contrasts) :
>> >>      variable 'f' converted to a factor
>> >>    > predict(fit_ab, newdata=d)
>> >>     1 2 3 4 5 6 7 8 9 10
>> >>     1  2  3  4 25 26 27  8  9 10
>> >>    Warning messages:
>> >>    1: In model.matrix.default(Terms, m, contrasts.arg =
>> >> object$contrasts)
>> >> :
>> >>      variable 'f' converted to a factor
>> >>    2: In predict.lm(fit_ab, newdata = d) :
>> >>      prediction from a rank-deficient fit may be misleading
>> >>
>> >> fit_ab is not rank-deficient and the predict should report
>> >>     1 2 3 4 NA NA NA 28 29 30
>> >
>> >
>> > In R-devel, the two warnings about factor conversions are no longer
>> > given,
>> > but the predictions are the same and the warning about rank deficiency
>> > still
>> > shows up.  If f is set to be a factor, an error is generated:
>> >
>> > Error in model.frame.default(Terms, newdata, na.action = na.action, xlev
>> > =
>> > object$xlevels) :
>> >   factor f has new levels B
>> >
>> > I think both the warning and error are somewhat reasonable responses.
>> > The
>> > fit is rank deficient relative to the model that includes f == "B",
>> > because
>> > the column of the design matrix corresponding to f level B would be
>> > completely zero.  In this particular model, we could still do
>> > predictions
>> > for the other levels, but it also seems reasonable to quit, given that
>> > clearly something has gone wrong.
>> >
>> > I do think that it's unfortunate that we don't get the same result in
>> > both
>> > cases, and I'd like to have gotten the predictions you suggested, but I
>> > don't think that's going to happen.  The reason for the difference is
>> > that
>> > the subsetting is done before the conversion to a factor, but I think
>> > that
>> > is unavoidable without really big changes.
>> >
>> > Duncan Murdoch
>> >
>> >
>> >
>> >>
>> >> Bill Dunlap
>> >> Spotfire, TIBCO Software
>> >> wdunlap tibco.com
>> >>
>> >> > -----Original Message-----
>> >> > From: r-devel-bounces at r-project.org
>> >> > [mailto:r-devel-bounces at r-project.org] On Behalf
>> >> > Of Terry Therneau
>> >> > Sent: Monday, February 11, 2013 5:50 AM
>> >> > To: r-devel at r-project.org; Duncan Murdoch
>> >> > Subject: Re: [Rd] stringsAsFactors
>> >> >
>> >> > I think your idea to remove the warnings is excellent, and a good
>> >> > compromise.
>> >> > Characters
>> >> > already work fine in modeling functions except for the silly warning.
>> >> >
>> >> > It is interesting how often the defaults for a program reflect the
>> >> > data
>> >> > sets in use at the
>> >> > time the defaults were chosen.  There are some such in my own
>> >> > survival
>> >> > package whose
>> >> > proper value is no longer as "obvious" as it was when I chose them.
>> >> > Factors are very
>> >> > handy for variables which have only a few levels and will be used in
>> >> > modeling.  Every
>> >> > character variable of every dataset in "Statistical Models in S",
>> >> > which
>> >> > introduced
>> >> > factors, is of this type so auto-transformation made a lot of sense.
>> >> > The "solder" data
>> >> > set there is one for which Helmert contrasts are proper so guess what
>> >> > the default
>> >> > contrast
>> >> > option was?  (I think there are only a few data sets in the world for
>> >> > which Helmert makes
>> >> > sense, however, and R eventually changed the default.)
>> >> >
>> >> > For character variables that should not be factors such as a street
>> >> > adress
>> >> > stringsAsFactors can be a real PITA, and I expect that people's
>> >> > preference for the option
>> >> > depends almost entirely on how often these arise in their own work.
>> >> > As
>> >> > long as there is
>> >> > an option that can be overridden I'm okay.  Yes, I'd prefer FALSE as
>> >> > the
>> >> > default, partly
>> >> > because the current value is a tripwire in the hallway that
>> >> > eventually
>> >> > catches every new
>> >> > user.
>> >> >
>> >> > Terry Therneau
>> >> >
>> >> > On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
>> >> > > Both of these were discussed by R Core.  I think it's unlikely the
>> >> > > default for stringsAsFactors will be changed (some R Core members
>> >> > > like
>> >> > > the current behaviour), but it's fairly likely the
>> >> > > show.signif.stars
>> >> > > default will change.  (That's if someone gets around to it:  I
>> >> > > personally don't care about that one.  P-values are commonly used
>> >> > > statistics, and the stars are just a simple graphical display of
>> >> > > them.
>> >> > > I find some p-values to be useful, and the display to be harmless.)
>> >> > >
>> >> > > I think it's really unlikely the more extreme changes (i.e.
>> >> > > dropping
>> >> > > show.signif.stars completely, or dropping p-values) will happen.
>> >> > >
>> >> > > Regarding stringsAsFactors:  I'm not going to defend keeping it as
>> >> > > is,
>> >> > > I'll let the people who like it defend it.  What I will likely do
>> >> > > is
>> >> > > make a few changes so that character vectors are automatically
>> >> > > changed
>> >> > > to factors in modelling functions, so that operating with
>> >> > > stringsAsFactors=FALSE doesn't trigger silly warnings.
>> >> >
>> >> > ______________________________________________
>> >> > R-devel at r-project.org mailing list
>> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> Michael Dewey
> info at aghmed.fsnet.co.uk
> http://www.aghmed.fsnet.co.uk/home.html
>


From murdoch.duncan at gmail.com  Wed Feb 13 14:17:44 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 13 Feb 2013 08:17:44 -0500
Subject: [Rd] Regression stars
In-Reply-To: <128C73D9-AF83-4878-892F-E1B2A9CD8320@gmail.com>
References: <20130209184801.GD14037@laura>
	<CAC+N9BXeaBzBMGidTJbrBT_hjKM0fW5ey6EWBSBbVqk12LZXGQ@mail.gmail.com>
	<CAC+N9BVRxcWLtGwHGbBD=4=uAPSan4jEFYfOWsLLqV4FrSyLGA@mail.gmail.com>
	<51180503.1080605@gmail.com>
	<loom.20130212T145313-215@post.gmane.org>
	<511A4F98.50209@statistik.tu-dortmund.de>
	<511A6286.4040704@gmail.com>
	<02F28BE5-04D2-44A8-920D-6E957CCDC4C7@muxspace.com>
	<4BDA0169-2C89-488B-B891-50EE1E857DB7@gmail.com>
	<511A8E43.6080302@fhcrc.org> <511A95D7.7060708@gmail.com>
	<128C73D9-AF83-4878-892F-E1B2A9CD8320@gmail.com>
Message-ID: <511B9278.7040503@gmail.com>

On 13-02-13 7:25 AM, peter dalgaard wrote:
>
> On Feb 12, 2013, at 20:19 , Duncan Murdoch wrote:
>
>> I think you are misreading what Peter wrote.  He wasn't defending
>> that point of view, he was describing it.
>>
>
> Yes. However, that being said, there is the point that the whole
> thing has been designed to work within the paradigm that I described,
> and, for better or worse, things are reasonably coherent and
> consistent within that framework.
>
> The thing that always worries me, when people get bothered by some
> aspect of software design, is that, if you change only that aspect,
> you may find yourself with something that is incoherent and
> inconsistent. I have quite a few times found myself realizing that
> "Uncle John was right after all".
>
> For instance, if you change the paradigm to say that "character
> variables are character, unless explicitly turned into factors", and
> then ameliorate the inconvenience by changing code that relies on
> factors to convert character variables on the fly, then you will lose
> the otherwise automatic consistency of level sets between subsets of
> data. (So, the math department not only has zero female professors,
> the entire female gender ceases to exist for that subgroup.)
>

Sure, if I have a file that contains a column named Sex and it is all M,
I can't expect R to automatically know that there is another
possibility.  That's always been a problem.  If we automatically convert
the data to factors when we read, then maybe we'll be lucky and some
other part of that file that we're planning to throw away will contain
an F, and we'll automatically construct the right factor.
(Except we don't:  lm and glm will throw away the F level if there are
none in the subset we pass to them, factor or not, because they use
drop.unused.levels=TRUE in their call to model.frame().)

There's also the possibility that there will be m and f in there, and
we'll get it wrong.

In R 2.15.2, we do the automatic conversion with a warning, but we do it
wrong, which leads to the inconsistency that Bill Dunlap reported.
R-devel drops the warning and comes closer to getting it right, but it's
really an impossible problem:  if we never see an F, we'll never set the
levels of the factor properly.  If we see a typo like m or f and don't
realize it's a typo, we'll have more than two Sex values.

The current R-devel implementation delays the conversion as much as it
can, and maybe it delays it too far.  It allows model.frame() to
continue to return character columns, as it does in 2.15.2.  This was to
support xtabs(), which treats character columns differently from
factors, and other unforeseen uses.  Another possibility would be to add
an argument ("stringsAsFactors"?) to model.frame() to let modelling
functions choose whether they want factors or not.  xtabs() would say
no, lm() and glm() would say yes.  I think the current implementation is
preferable because it won't require changes to well written existing
functions.

With the current R-devel implementation, it is easier than in 2.15.2 to
get errors thrown when the auto-conversion goes wrong.  I don't know of
any examples where you get incorrect results.  I think this is an
improvement.

I'd appreciate hearing of any bugs in it.

Duncan Murdoch


From nalimilan at club.fr  Wed Feb 13 14:24:01 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 13 Feb 2013 14:24:01 +0100
Subject: [Rd] Private environments and/or assignInMyNamespace
In-Reply-To: <511B842E.6030408@bht-berlin.de>
References: <511A4785.5070504@bht-berlin.de>
	<1360746723.28045.23.camel@milan> <511B842E.6030408@bht-berlin.de>
Message-ID: <1360761841.28045.45.camel@milan>

Le mercredi 13 f?vrier 2013 ? 13:16 +0100, Ulrike Gr?mping a ?crit :
> Milan,
> 
> I am not closing the dialog, but without the dialog in the search space, 
> I cannot properly refer to it any more using e.g. the Rcmdr function 
> errorCondition.
> It has been a long time ago that I wrote this; I don't have a small 
> reproducible example right now. Below is an example of what I do in 
> function Menu.pb2level:
> 
> I am using function justDoItDoE (instead of Rcmdr justDoIt, because 
> justDoIt puts the focus in the wrong place for my purpose; have to adapt 
> to RStudio here!):
> justDoItDoE <- function (command)
> {
>      Message()
>      if (!getRcmdr("suppress.X11.warnings")) {
>          messages.connection <- file(open = "w+")
>          sink(messages.connection, type = "message")
>          on.exit({
>              sink(type = "message")
>              close(messages.connection)
>          })
>      }
>      else messages.connection <- getRcmdr("messages.connection")
>      result <- try(eval(parse(text = command), envir = .GlobalEnv))
>      if (!class(result)[1] == "try-error")
>          Rcmdr:::checkWarnings(readLines(messages.connection))
>      result
> }
> <environment: namespace:RcmdrPlugin.DoE>
> 
> Subsequently, I am using the Rcmdr function errorCondition:
> errorCondition <- function (window = top, recall = NULL, message = 
> stop("message not supplied"),
>      model = FALSE)
> {
>      tmp <- substitute({
>          on.exit(remove(list = objects(pattern = "^\\.\\.", all.names = 
> TRUE)))
>          if (model) putRcmdr("modelNumber", getRcmdr("modelNumber") -
>              1)
>          if (!is.null(window)) {
>              if (GrabFocus()) tkgrab.release(window)
>              tkdestroy(window)
>          }
>          Message(message = message, type = "error")
>          if (!is.null(recall)) recall() else tkfocus(CommanderWindow())
>      })
>      eval(tmp, parent.frame())
> }
> 
> Function errorCondition has to find the dialog topdes2, and I have to be 
> inside function Menu.pb2level again:
>              hilf <- justDoItDoE(command)
>              if (class(hilf)[1] == "try-error") {
>                  errorCondition(window = topdes2, recall = Menu.pb2level,
>                    message = gettextRcmdr(hilf))
>                  return()
>              }
> 
> This code does not work with topdes2 not in the search path, and when I 
> tried before, it did also not work with getRcmdr("topdes2") instead of 
> topdes2 - but maybe, I just was not following this approach through 
> thoroughly enough.
> 
> Any thoughts whether the storage of widgets in an environment off the 
> search path might work (when properly followed through, which will be a 
> lot of work)? Or any suggestion how else I can achieve what I try to do?
OK, this is what I suspected. John should probably comment this
statement, but I do not really understand the purpose of the
errorCondition() function. I've stopped using it in my own RCommander
plug-in.

What I would do if I had to solve your problem is to call return()
instead of errorCondition(), so that the dialog is left as-is. To tell
the user that something is wrong, you can use Message(), or show an
error dialog or a label in the original dialog right before calling
return(). This is the simplest solution and it does not require any
programming trick. But maybe I'm missing something. ;-)


My two cents

> Best, Ulrike
> 
> Am 13.02.2013 10:12, schrieb Milan Bouchet-Valat:
> > Le mardi 12 f?vrier 2013 ? 14:45 +0100, Ulrike Gr?mping a ?crit :
> >> Dear DevelopeRs,
> >>
> >> I've been struggling with the new regulations regarding modifications to
> >> the search path, regarding my Rcmdr plugin package RcmdrPlugin.DoE. John
> >> Fox made Rcmdr comply with the new policy by removing the environment
> >> RcmdrEnv from the search path. For the time being, he developed an
> >> option that allows users to put the environment from Rcmdr (RcmdrEnv) on
> >> the search path, like in earlier versions of Rcmdr (thanks John!), which
> >> rescues my package for the immediate future; however, in the long run it
> >> would be nice to be able to make it work without that.
> >>
> >> The reason why I currently need the environment on the search path (may
> >> be due to my lack of understanding how tcltk widgets are handled): I
> >> have quite elaborate notebook widgets on which users can make many
> >> entries. Some entries are only checked after clicking OK, and if an
> >> error is found at that point, the user receives a small message window
> >> that has to be confirmed and is subsequently returned to the notebook
> >> widget in the state it was in when pressing OK. These widgets are
> >> currently held in the environment RcmdrEnv; they work when RcmdrEnv is
> >> on the search path; however, it is not sufficient to retrieve them with
> >> John's function getRcmdr, which works fine for objects other than widgets.
> > I'm not sure I understand exactly how this works, but does that mean you
> > close the dialog before checking the entries? If it is the case, you
> > could check them before, and if an error is detected, you would keep the
> > dialog open: this way, you would not need to restore anything.
> >
> > Could you point us at the relevant code?
> >
> >
> > Regards
> >
> >> Here my question: Would it be an option to place the widgets in a
> >> private environment of my plugin package (then I would have to learn how
> >> to create one and work with it), or won't they be found that way?
> >> Alternatively, I could have unexported objects of all required names in
> >> my namespace and modify these via assignInMyNamespace (I don't think
> >> that anybody from somewhere else would import that namespace, it's not
> >> that kind of package). Would that be a viable alternative, and would the
> >> widgets be found that way? Any further ideas?
> >>
> >> Best regards,
> >> Ulrike
> >>


From murdoch.duncan at gmail.com  Wed Feb 13 14:27:30 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 13 Feb 2013 08:27:30 -0500
Subject: [Rd] stringsAsFactors
In-Reply-To: <Zen-1U5bWl-0008SN-65@smarthost02.mail.zen.net.uk>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
	<51192F72.4090904@gmail.com>
	<CA+vqiLH_OzKKcYLxK3jsrQRtpvN=Uj6xoEJpsCAwX3yLQG-vzA@mail.gmail.com>
	<Zen-1U5bWl-0008SN-65@smarthost02.mail.zen.net.uk>
Message-ID: <511B94C2.5000208@gmail.com>

On 13-02-13 7:33 AM, Michael Dewey wrote:
> At 18:01 11/02/2013, Ista Zahn wrote:
>> FWIW my view is that for data cleaning and organizing factors just get
>> it the way. For modeling I like them because they make it easier to
>> understand what is happening. For example I can look at the levels()
>> to see what the reference group will be. With characters one has to
>> know a) that levels are created in alphabetical order and b) the
>> alphabetical order of the the unique values in the character vector.
>> Ugh. So my habit is to turn off stringsAsFactors, then explicitly
>> convert to factors before modeling (I also use factors to change the
>> order in which things are displayed in tables and graphs, another
>> place where converting to factors myself is useful but the creating
>> them in alphabetical order by default is not)
>>
>> All this is to say that I would like options(stingsAsFactors=FALSE) to
>> be the default, but I like the warning about converting to factors in
>> modeling functions because it reminds me that I forgot to covert them,
>> which I like to do anyway...
>
> I seem to be one of the few people who find the current default
> helpful. When I read in a dataset I am nearly always going to follow
> it with one or more of the modelling functions and so I do want to
> treat the categorical variables as factors. I cannot off-hand think
> of an example where I have had to convert them to characters.

Please try out the current R-devel (revision 61928 or newer) and let me 
know if anything in your current workflow gets broken by the recent changes.

Duncan Murdoch

>
> Incidentally xkcd has, while this discussion has been going on,
> posted something relevant
> http://www.xkcd.com/1172/
>
>
>
>> Best,
>> Ista
>>
>> On Mon, Feb 11, 2013 at 12:50 PM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>> On 11/02/2013 12:13 PM, William Dunlap wrote:
>>>>
>>>> Note that changing this does not just mean getting rid of "silly
>>>> warnings".
>>>> Currently, predict.lm() can give wrong answers when stringsAsFactors is
>>>> FALSE.
>>>>
>>>>     > d <- data.frame(x=1:10, f=rep(c("A","B","C"), c(4,3,3)), y=c(1:4,
>>>> 15:17, 28.1,28.8,30.1))
>>>>     > fit_ab <- lm(y ~ x + f, data = d, subset = f!="B")
>>>>     Warning message:
>>>>     In model.matrix.default(mt, mf, contrasts) :
>>>>       variable 'f' converted to a factor
>>>>     > predict(fit_ab, newdata=d)
>>>>      1 2 3 4 5 6 7 8 9 10
>>>>      1  2  3  4 25 26 27  8  9 10
>>>>     Warning messages:
>>>>     1: In model.matrix.default(Terms, m, contrasts.arg = object$contrasts)
>>>> :
>>>>       variable 'f' converted to a factor
>>>>     2: In predict.lm(fit_ab, newdata = d) :
>>>>       prediction from a rank-deficient fit may be misleading
>>>>
>>>> fit_ab is not rank-deficient and the predict should report
>>>>      1 2 3 4 NA NA NA 28 29 30
>>>
>>>
>>> In R-devel, the two warnings about factor conversions are no longer given,
>>> but the predictions are the same and the warning about rank
>> deficiency still
>>> shows up.  If f is set to be a factor, an error is generated:
>>>
>>> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
>>> object$xlevels) :
>>>    factor f has new levels B
>>>
>>> I think both the warning and error are somewhat reasonable responses.  The
>>> fit is rank deficient relative to the model that includes f ==
>> "B",  because
>>> the column of the design matrix corresponding to f level B would be
>>> completely zero.  In this particular model, we could still do predictions
>>> for the other levels, but it also seems reasonable to quit, given that
>>> clearly something has gone wrong.
>>>
>>> I do think that it's unfortunate that we don't get the same result in both
>>> cases, and I'd like to have gotten the predictions you suggested, but I
>>> don't think that's going to happen.  The reason for the difference is that
>>> the subsetting is done before the conversion to a factor, but I think that
>>> is unavoidable without really big changes.
>>>
>>> Duncan Murdoch
>>>
>>>
>>>
>>>>
>>>> Bill Dunlap
>>>> Spotfire, TIBCO Software
>>>> wdunlap tibco.com
>>>>
>>>>> -----Original Message-----
>>>>> From: r-devel-bounces at r-project.org
>>>>> [mailto:r-devel-bounces at r-project.org] On Behalf
>>>>> Of Terry Therneau
>>>>> Sent: Monday, February 11, 2013 5:50 AM
>>>>> To: r-devel at r-project.org; Duncan Murdoch
>>>>> Subject: Re: [Rd] stringsAsFactors
>>>>>
>>>>> I think your idea to remove the warnings is excellent, and a good
>>>>> compromise.
>>>>> Characters
>>>>> already work fine in modeling functions except for the silly warning.
>>>>>
>>>>> It is interesting how often the defaults for a program reflect the data
>>>>> sets in use at the
>>>>> time the defaults were chosen.  There are some such in my own survival
>>>>> package whose
>>>>> proper value is no longer as "obvious" as it was when I chose them.
>>>>> Factors are very
>>>>> handy for variables which have only a few levels and will be used in
>>>>> modeling.  Every
>>>>> character variable of every dataset in "Statistical Models in S", which
>>>>> introduced
>>>>> factors, is of this type so auto-transformation made a lot of sense.
>>>>> The "solder" data
>>>>> set there is one for which Helmert contrasts are proper so guess what
>>>>> the default
>>>>> contrast
>>>>> option was?  (I think there are only a few data sets in the world for
>>>>> which Helmert makes
>>>>> sense, however, and R eventually changed the default.)
>>>>>
>>>>> For character variables that should not be factors such as a street
>>>>> adress
>>>>> stringsAsFactors can be a real PITA, and I expect that people's
>>>>> preference for the option
>>>>> depends almost entirely on how often these arise in their own work.  As
>>>>> long as there is
>>>>> an option that can be overridden I'm okay.  Yes, I'd prefer FALSE as the
>>>>> default, partly
>>>>> because the current value is a tripwire in the hallway that eventually
>>>>> catches every new
>>>>> user.
>>>>>
>>>>> Terry Therneau
>>>>>
>>>>> On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
>>>>>> Both of these were discussed by R Core.  I think it's unlikely the
>>>>>> default for stringsAsFactors will be changed (some R Core members like
>>>>>> the current behaviour), but it's fairly likely the show.signif.stars
>>>>>> default will change.  (That's if someone gets around to it:  I
>>>>>> personally don't care about that one.  P-values are commonly used
>>>>>> statistics, and the stars are just a simple graphical display of them.
>>>>>> I find some p-values to be useful, and the display to be harmless.)
>>>>>>
>>>>>> I think it's really unlikely the more extreme changes (i.e. dropping
>>>>>> show.signif.stars completely, or dropping p-values) will happen.
>>>>>>
>>>>>> Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
>>>>>> I'll let the people who like it defend it.  What I will likely do is
>>>>>> make a few changes so that character vectors are automatically changed
>>>>>> to factors in modelling functions, so that operating with
>>>>>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> Michael Dewey
> info at aghmed.fsnet.co.uk
> http://www.aghmed.fsnet.co.uk/home.html
>


From nalimilan at club.fr  Wed Feb 13 14:30:53 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 13 Feb 2013 14:30:53 +0100
Subject: [Rd] stringsAsFactors
In-Reply-To: <Zen-1U5bWl-0008SN-65@smarthost02.mail.zen.net.uk>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
	<51192F72.4090904@gmail.com>
	<CA+vqiLH_OzKKcYLxK3jsrQRtpvN=Uj6xoEJpsCAwX3yLQG-vzA@mail.gmail.com>
	<Zen-1U5bWl-0008SN-65@smarthost02.mail.zen.net.uk>
Message-ID: <1360762253.28045.50.camel@milan>

Le mercredi 13 f?vrier 2013 ? 12:33 +0000, Michael Dewey a ?crit :
> At 18:01 11/02/2013, Ista Zahn wrote:
> >FWIW my view is that for data cleaning and organizing factors just get
> >it the way. For modeling I like them because they make it easier to
> >understand what is happening. For example I can look at the levels()
> >to see what the reference group will be. With characters one has to
> >know a) that levels are created in alphabetical order and b) the
> >alphabetical order of the the unique values in the character vector.
> >Ugh. So my habit is to turn off stringsAsFactors, then explicitly
> >convert to factors before modeling (I also use factors to change the
> >order in which things are displayed in tables and graphs, another
> >place where converting to factors myself is useful but the creating
> >them in alphabetical order by default is not)
> >
> >All this is to say that I would like options(stingsAsFactors=FALSE) to
> >be the default, but I like the warning about converting to factors in
> >modeling functions because it reminds me that I forgot to covert them,
> >which I like to do anyway...
> 
> I seem to be one of the few people who find the current default 
> helpful. When I read in a dataset I am nearly always going to follow 
> it with one or more of the modelling functions and so I do want to 
> treat the categorical variables as factors. I cannot off-hand think 
> of an example where I have had to convert them to characters.
If the changes to modeling functions that are discussed in this thread
can finally be applied (i.e. a solution is found), characters would be
converted to factors automatically, so you would not notice the
difference. And if you need to change the order of levels of your
factors, calling factor(myVar, levels=c(...)) is the same, be myVar a
character or a factor.

> Incidentally xkcd has, while this discussion has been going on, 
> posted something relevant
> http://www.xkcd.com/1172/
Truly hilarious, indeed. But beware, it sounds like an argument in favor
of the change, while you are lobbying against it. :-p


Regards



> 
> 
> >Best,
> >Ista
> >
> >On Mon, Feb 11, 2013 at 12:50 PM, Duncan Murdoch
> ><murdoch.duncan at gmail.com> wrote:
> > > On 11/02/2013 12:13 PM, William Dunlap wrote:
> > >>
> > >> Note that changing this does not just mean getting rid of "silly
> > >> warnings".
> > >> Currently, predict.lm() can give wrong answers when stringsAsFactors is
> > >> FALSE.
> > >>
> > >>    > d <- data.frame(x=1:10, f=rep(c("A","B","C"), c(4,3,3)), y=c(1:4,
> > >> 15:17, 28.1,28.8,30.1))
> > >>    > fit_ab <- lm(y ~ x + f, data = d, subset = f!="B")
> > >>    Warning message:
> > >>    In model.matrix.default(mt, mf, contrasts) :
> > >>      variable 'f' converted to a factor
> > >>    > predict(fit_ab, newdata=d)
> > >>     1 2 3 4 5 6 7 8 9 10
> > >>     1  2  3  4 25 26 27  8  9 10
> > >>    Warning messages:
> > >>    1: In model.matrix.default(Terms, m, contrasts.arg = object$contrasts)
> > >> :
> > >>      variable 'f' converted to a factor
> > >>    2: In predict.lm(fit_ab, newdata = d) :
> > >>      prediction from a rank-deficient fit may be misleading
> > >>
> > >> fit_ab is not rank-deficient and the predict should report
> > >>     1 2 3 4 NA NA NA 28 29 30
> > >
> > >
> > > In R-devel, the two warnings about factor conversions are no longer given,
> > > but the predictions are the same and the warning about rank 
> > deficiency still
> > > shows up.  If f is set to be a factor, an error is generated:
> > >
> > > Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
> > > object$xlevels) :
> > >   factor f has new levels B
> > >
> > > I think both the warning and error are somewhat reasonable responses.  The
> > > fit is rank deficient relative to the model that includes f == 
> > "B",  because
> > > the column of the design matrix corresponding to f level B would be
> > > completely zero.  In this particular model, we could still do predictions
> > > for the other levels, but it also seems reasonable to quit, given that
> > > clearly something has gone wrong.
> > >
> > > I do think that it's unfortunate that we don't get the same result in both
> > > cases, and I'd like to have gotten the predictions you suggested, but I
> > > don't think that's going to happen.  The reason for the difference is that
> > > the subsetting is done before the conversion to a factor, but I think that
> > > is unavoidable without really big changes.
> > >
> > > Duncan Murdoch
> > >
> > >
> > >
> > >>
> > >> Bill Dunlap
> > >> Spotfire, TIBCO Software
> > >> wdunlap tibco.com
> > >>
> > >> > -----Original Message-----
> > >> > From: r-devel-bounces at r-project.org
> > >> > [mailto:r-devel-bounces at r-project.org] On Behalf
> > >> > Of Terry Therneau
> > >> > Sent: Monday, February 11, 2013 5:50 AM
> > >> > To: r-devel at r-project.org; Duncan Murdoch
> > >> > Subject: Re: [Rd] stringsAsFactors
> > >> >
> > >> > I think your idea to remove the warnings is excellent, and a good
> > >> > compromise.
> > >> > Characters
> > >> > already work fine in modeling functions except for the silly warning.
> > >> >
> > >> > It is interesting how often the defaults for a program reflect the data
> > >> > sets in use at the
> > >> > time the defaults were chosen.  There are some such in my own survival
> > >> > package whose
> > >> > proper value is no longer as "obvious" as it was when I chose them.
> > >> > Factors are very
> > >> > handy for variables which have only a few levels and will be used in
> > >> > modeling.  Every
> > >> > character variable of every dataset in "Statistical Models in S", which
> > >> > introduced
> > >> > factors, is of this type so auto-transformation made a lot of sense.
> > >> > The "solder" data
> > >> > set there is one for which Helmert contrasts are proper so guess what
> > >> > the default
> > >> > contrast
> > >> > option was?  (I think there are only a few data sets in the world for
> > >> > which Helmert makes
> > >> > sense, however, and R eventually changed the default.)
> > >> >
> > >> > For character variables that should not be factors such as a street
> > >> > adress
> > >> > stringsAsFactors can be a real PITA, and I expect that people's
> > >> > preference for the option
> > >> > depends almost entirely on how often these arise in their own work.  As
> > >> > long as there is
> > >> > an option that can be overridden I'm okay.  Yes, I'd prefer FALSE as the
> > >> > default, partly
> > >> > because the current value is a tripwire in the hallway that eventually
> > >> > catches every new
> > >> > user.
> > >> >
> > >> > Terry Therneau
> > >> >
> > >> > On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
> > >> > > Both of these were discussed by R Core.  I think it's unlikely the
> > >> > > default for stringsAsFactors will be changed (some R Core members like
> > >> > > the current behaviour), but it's fairly likely the show.signif.stars
> > >> > > default will change.  (That's if someone gets around to it:  I
> > >> > > personally don't care about that one.  P-values are commonly used
> > >> > > statistics, and the stars are just a simple graphical display of them.
> > >> > > I find some p-values to be useful, and the display to be harmless.)
> > >> > >
> > >> > > I think it's really unlikely the more extreme changes (i.e. dropping
> > >> > > show.signif.stars completely, or dropping p-values) will happen.
> > >> > >
> > >> > > Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
> > >> > > I'll let the people who like it defend it.  What I will likely do is
> > >> > > make a few changes so that character vectors are automatically changed
> > >> > > to factors in modelling functions, so that operating with
> > >> > > stringsAsFactors=FALSE doesn't trigger silly warnings.
> > >> >
> > >> > ______________________________________________
> > >> > R-devel at r-project.org mailing list
> > >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> Michael Dewey
> info at aghmed.fsnet.co.uk
> http://www.aghmed.fsnet.co.uk/home.html
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Wed Feb 13 14:39:23 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 13 Feb 2013 08:39:23 -0500
Subject: [Rd] stringsAsFactors
In-Reply-To: <1360762253.28045.50.camel@milan>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
	<51192F72.4090904@gmail.com>
	<CA+vqiLH_OzKKcYLxK3jsrQRtpvN=Uj6xoEJpsCAwX3yLQG-vzA@mail.gmail.com>
	<Zen-1U5bWl-0008SN-65@smarthost02.mail.zen.net.uk>
	<1360762253.28045.50.camel@milan>
Message-ID: <511B978B.9080000@gmail.com>

On 13-02-13 8:30 AM, Milan Bouchet-Valat wrote:
> Le mercredi 13 f?vrier 2013 ? 12:33 +0000, Michael Dewey a ?crit :
>> At 18:01 11/02/2013, Ista Zahn wrote:
>>> FWIW my view is that for data cleaning and organizing factors just get
>>> it the way. For modeling I like them because they make it easier to
>>> understand what is happening. For example I can look at the levels()
>>> to see what the reference group will be. With characters one has to
>>> know a) that levels are created in alphabetical order and b) the
>>> alphabetical order of the the unique values in the character vector.
>>> Ugh. So my habit is to turn off stringsAsFactors, then explicitly
>>> convert to factors before modeling (I also use factors to change the
>>> order in which things are displayed in tables and graphs, another
>>> place where converting to factors myself is useful but the creating
>>> them in alphabetical order by default is not)
>>>
>>> All this is to say that I would like options(stingsAsFactors=FALSE) to
>>> be the default, but I like the warning about converting to factors in
>>> modeling functions because it reminds me that I forgot to covert them,
>>> which I like to do anyway...
>>
>> I seem to be one of the few people who find the current default
>> helpful. When I read in a dataset I am nearly always going to follow
>> it with one or more of the modelling functions and so I do want to
>> treat the categorical variables as factors. I cannot off-hand think
>> of an example where I have had to convert them to characters.
> If the changes to modeling functions that are discussed in this thread
> can finally be applied (i.e. a solution is found), characters would be
> converted to factors automatically, so you would not notice the
> difference. And if you need to change the order of levels of your
> factors, calling factor(myVar, levels=c(...)) is the same, be myVar a
> character or a factor.

I think most of the changes *have* been applied.  Please try R-devel, 
and point out problems.

The only change that I would like to apply but haven't (and probably 
won't) is to change the default for stringsAsFactors to FALSE.  Users 
who think that is a bad idea can bolster their cases by setting 
options(stringsAsFactors=FALSE), and posting descriptions of all the 
horrors that ensue.

Duncan Murdoch

>
>> Incidentally xkcd has, while this discussion has been going on,
>> posted something relevant
>> http://www.xkcd.com/1172/
> Truly hilarious, indeed. But beware, it sounds like an argument in favor
> of the change, while you are lobbying against it. :-p
>
>
> Regards
>
>
>
>>
>>
>>> Best,
>>> Ista
>>>
>>> On Mon, Feb 11, 2013 at 12:50 PM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com> wrote:
>>>> On 11/02/2013 12:13 PM, William Dunlap wrote:
>>>>>
>>>>> Note that changing this does not just mean getting rid of "silly
>>>>> warnings".
>>>>> Currently, predict.lm() can give wrong answers when stringsAsFactors is
>>>>> FALSE.
>>>>>
>>>>>     > d <- data.frame(x=1:10, f=rep(c("A","B","C"), c(4,3,3)), y=c(1:4,
>>>>> 15:17, 28.1,28.8,30.1))
>>>>>     > fit_ab <- lm(y ~ x + f, data = d, subset = f!="B")
>>>>>     Warning message:
>>>>>     In model.matrix.default(mt, mf, contrasts) :
>>>>>       variable 'f' converted to a factor
>>>>>     > predict(fit_ab, newdata=d)
>>>>>      1 2 3 4 5 6 7 8 9 10
>>>>>      1  2  3  4 25 26 27  8  9 10
>>>>>     Warning messages:
>>>>>     1: In model.matrix.default(Terms, m, contrasts.arg = object$contrasts)
>>>>> :
>>>>>       variable 'f' converted to a factor
>>>>>     2: In predict.lm(fit_ab, newdata = d) :
>>>>>       prediction from a rank-deficient fit may be misleading
>>>>>
>>>>> fit_ab is not rank-deficient and the predict should report
>>>>>      1 2 3 4 NA NA NA 28 29 30
>>>>
>>>>
>>>> In R-devel, the two warnings about factor conversions are no longer given,
>>>> but the predictions are the same and the warning about rank
>>> deficiency still
>>>> shows up.  If f is set to be a factor, an error is generated:
>>>>
>>>> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
>>>> object$xlevels) :
>>>>    factor f has new levels B
>>>>
>>>> I think both the warning and error are somewhat reasonable responses.  The
>>>> fit is rank deficient relative to the model that includes f ==
>>> "B",  because
>>>> the column of the design matrix corresponding to f level B would be
>>>> completely zero.  In this particular model, we could still do predictions
>>>> for the other levels, but it also seems reasonable to quit, given that
>>>> clearly something has gone wrong.
>>>>
>>>> I do think that it's unfortunate that we don't get the same result in both
>>>> cases, and I'd like to have gotten the predictions you suggested, but I
>>>> don't think that's going to happen.  The reason for the difference is that
>>>> the subsetting is done before the conversion to a factor, but I think that
>>>> is unavoidable without really big changes.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>
>>>>
>>>>>
>>>>> Bill Dunlap
>>>>> Spotfire, TIBCO Software
>>>>> wdunlap tibco.com
>>>>>
>>>>>> -----Original Message-----
>>>>>> From: r-devel-bounces at r-project.org
>>>>>> [mailto:r-devel-bounces at r-project.org] On Behalf
>>>>>> Of Terry Therneau
>>>>>> Sent: Monday, February 11, 2013 5:50 AM
>>>>>> To: r-devel at r-project.org; Duncan Murdoch
>>>>>> Subject: Re: [Rd] stringsAsFactors
>>>>>>
>>>>>> I think your idea to remove the warnings is excellent, and a good
>>>>>> compromise.
>>>>>> Characters
>>>>>> already work fine in modeling functions except for the silly warning.
>>>>>>
>>>>>> It is interesting how often the defaults for a program reflect the data
>>>>>> sets in use at the
>>>>>> time the defaults were chosen.  There are some such in my own survival
>>>>>> package whose
>>>>>> proper value is no longer as "obvious" as it was when I chose them.
>>>>>> Factors are very
>>>>>> handy for variables which have only a few levels and will be used in
>>>>>> modeling.  Every
>>>>>> character variable of every dataset in "Statistical Models in S", which
>>>>>> introduced
>>>>>> factors, is of this type so auto-transformation made a lot of sense.
>>>>>> The "solder" data
>>>>>> set there is one for which Helmert contrasts are proper so guess what
>>>>>> the default
>>>>>> contrast
>>>>>> option was?  (I think there are only a few data sets in the world for
>>>>>> which Helmert makes
>>>>>> sense, however, and R eventually changed the default.)
>>>>>>
>>>>>> For character variables that should not be factors such as a street
>>>>>> adress
>>>>>> stringsAsFactors can be a real PITA, and I expect that people's
>>>>>> preference for the option
>>>>>> depends almost entirely on how often these arise in their own work.  As
>>>>>> long as there is
>>>>>> an option that can be overridden I'm okay.  Yes, I'd prefer FALSE as the
>>>>>> default, partly
>>>>>> because the current value is a tripwire in the hallway that eventually
>>>>>> catches every new
>>>>>> user.
>>>>>>
>>>>>> Terry Therneau
>>>>>>
>>>>>> On 02/11/2013 05:00 AM, r-devel-request at r-project.org wrote:
>>>>>>> Both of these were discussed by R Core.  I think it's unlikely the
>>>>>>> default for stringsAsFactors will be changed (some R Core members like
>>>>>>> the current behaviour), but it's fairly likely the show.signif.stars
>>>>>>> default will change.  (That's if someone gets around to it:  I
>>>>>>> personally don't care about that one.  P-values are commonly used
>>>>>>> statistics, and the stars are just a simple graphical display of them.
>>>>>>> I find some p-values to be useful, and the display to be harmless.)
>>>>>>>
>>>>>>> I think it's really unlikely the more extreme changes (i.e. dropping
>>>>>>> show.signif.stars completely, or dropping p-values) will happen.
>>>>>>>
>>>>>>> Regarding stringsAsFactors:  I'm not going to defend keeping it as is,
>>>>>>> I'll let the people who like it defend it.  What I will likely do is
>>>>>>> make a few changes so that character vectors are automatically changed
>>>>>>> to factors in modelling functions, so that operating with
>>>>>>> stringsAsFactors=FALSE doesn't trigger silly warnings.
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> Michael Dewey
>> info at aghmed.fsnet.co.uk
>> http://www.aghmed.fsnet.co.uk/home.html
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From charlie at stat.umn.edu  Wed Feb 13 14:40:54 2013
From: charlie at stat.umn.edu (Charles Geyer)
Date: Wed, 13 Feb 2013 07:40:54 -0600
Subject: [Rd] Regression stars
Message-ID: <CAKctRd0f5aMquq+WoKCe1_rG9boPo=xygx+XRjOnekWBSem+fQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130213/01179f7e/attachment.pl>

From jfox at mcmaster.ca  Wed Feb 13 15:35:09 2013
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 13 Feb 2013 09:35:09 -0500
Subject: [Rd] Private environments and/or assignInMyNamespace
In-Reply-To: <1360761841.28045.45.camel@milan>
References: <511A4785.5070504@bht-berlin.de> <1360746723.28045.23.camel@milan>
	<511B842E.6030408@bht-berlin.de> <1360761841.28045.45.camel@milan>
Message-ID: <web-444617544@cgpsrv2.cis.mcmaster.ca>

Dear Milan and Ulrike,

The purpose of errorCondition() is to put a dialog in the state it was in prior to the erroneous input, reflecting, e.g., prior selections. Like all Rcmdr utility functions, its use isn't mandatory -- it's simply meant to be convenient and to encourage some consistency in behaviour in the Rcmdr and plug-ins. 

If you prefer to have a dialog remain in its erroneous state after an error -- and I can see an argument for that -- then you needn't use errorCondition(). 

Finally, if this is the only thing preventing Ulrike's dialogs from working, then avoiding errorCondition() an attractive solution.

Best,
 John

On Wed, 13 Feb 2013 14:24:01 +0100
 Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Le mercredi 13 f?vrier 2013 ? 13:16 +0100, Ulrike Gr?mping a ?crit :
> > Milan,
> > 
> > I am not closing the dialog, but without the dialog in the search space, 
> > I cannot properly refer to it any more using e.g. the Rcmdr function 
> > errorCondition.
> > It has been a long time ago that I wrote this; I don't have a small 
> > reproducible example right now. Below is an example of what I do in 
> > function Menu.pb2level:
> > 
> > I am using function justDoItDoE (instead of Rcmdr justDoIt, because 
> > justDoIt puts the focus in the wrong place for my purpose; have to adapt 
> > to RStudio here!):
> > justDoItDoE <- function (command)
> > {
> >      Message()
> >      if (!getRcmdr("suppress.X11.warnings")) {
> >          messages.connection <- file(open = "w+")
> >          sink(messages.connection, type = "message")
> >          on.exit({
> >              sink(type = "message")
> >              close(messages.connection)
> >          })
> >      }
> >      else messages.connection <- getRcmdr("messages.connection")
> >      result <- try(eval(parse(text = command), envir = .GlobalEnv))
> >      if (!class(result)[1] == "try-error")
> >          Rcmdr:::checkWarnings(readLines(messages.connection))
> >      result
> > }
> > <environment: namespace:RcmdrPlugin.DoE>
> > 
> > Subsequently, I am using the Rcmdr function errorCondition:
> > errorCondition <- function (window = top, recall = NULL, message = 
> > stop("message not supplied"),
> >      model = FALSE)
> > {
> >      tmp <- substitute({
> >          on.exit(remove(list = objects(pattern = "^\\.\\.", all.names = 
> > TRUE)))
> >          if (model) putRcmdr("modelNumber", getRcmdr("modelNumber") -
> >              1)
> >          if (!is.null(window)) {
> >              if (GrabFocus()) tkgrab.release(window)
> >              tkdestroy(window)
> >          }
> >          Message(message = message, type = "error")
> >          if (!is.null(recall)) recall() else tkfocus(CommanderWindow())
> >      })
> >      eval(tmp, parent.frame())
> > }
> > 
> > Function errorCondition has to find the dialog topdes2, and I have to be 
> > inside function Menu.pb2level again:
> >              hilf <- justDoItDoE(command)
> >              if (class(hilf)[1] == "try-error") {
> >                  errorCondition(window = topdes2, recall = Menu.pb2level,
> >                    message = gettextRcmdr(hilf))
> >                  return()
> >              }
> > 
> > This code does not work with topdes2 not in the search path, and when I 
> > tried before, it did also not work with getRcmdr("topdes2") instead of 
> > topdes2 - but maybe, I just was not following this approach through 
> > thoroughly enough.
> > 
> > Any thoughts whether the storage of widgets in an environment off the 
> > search path might work (when properly followed through, which will be a 
> > lot of work)? Or any suggestion how else I can achieve what I try to do?
> OK, this is what I suspected. John should probably comment this
> statement, but I do not really understand the purpose of the
> errorCondition() function. I've stopped using it in my own RCommander
> plug-in.
> 
> What I would do if I had to solve your problem is to call return()
> instead of errorCondition(), so that the dialog is left as-is. To tell
> the user that something is wrong, you can use Message(), or show an
> error dialog or a label in the original dialog right before calling
> return(). This is the simplest solution and it does not require any
> programming trick. But maybe I'm missing something. ;-)
> 
> 
> My two cents
> 
> > Best, Ulrike
> > 
> > Am 13.02.2013 10:12, schrieb Milan Bouchet-Valat:
> > > Le mardi 12 f?vrier 2013 ? 14:45 +0100, Ulrike Gr?mping a ?crit :
> > >> Dear DevelopeRs,
> > >>
> > >> I've been struggling with the new regulations regarding modifications to
> > >> the search path, regarding my Rcmdr plugin package RcmdrPlugin.DoE. John
> > >> Fox made Rcmdr comply with the new policy by removing the environment
> > >> RcmdrEnv from the search path. For the time being, he developed an
> > >> option that allows users to put the environment from Rcmdr (RcmdrEnv) on
> > >> the search path, like in earlier versions of Rcmdr (thanks John!), which
> > >> rescues my package for the immediate future; however, in the long run it
> > >> would be nice to be able to make it work without that.
> > >>
> > >> The reason why I currently need the environment on the search path (may
> > >> be due to my lack of understanding how tcltk widgets are handled): I
> > >> have quite elaborate notebook widgets on which users can make many
> > >> entries. Some entries are only checked after clicking OK, and if an
> > >> error is found at that point, the user receives a small message window
> > >> that has to be confirmed and is subsequently returned to the notebook
> > >> widget in the state it was in when pressing OK. These widgets are
> > >> currently held in the environment RcmdrEnv; they work when RcmdrEnv is
> > >> on the search path; however, it is not sufficient to retrieve them with
> > >> John's function getRcmdr, which works fine for objects other than widgets.
> > > I'm not sure I understand exactly how this works, but does that mean you
> > > close the dialog before checking the entries? If it is the case, you
> > > could check them before, and if an error is detected, you would keep the
> > > dialog open: this way, you would not need to restore anything.
> > >
> > > Could you point us at the relevant code?
> > >
> > >
> > > Regards
> > >
> > >> Here my question: Would it be an option to place the widgets in a
> > >> private environment of my plugin package (then I would have to learn how
> > >> to create one and work with it), or won't they be found that way?
> > >> Alternatively, I could have unexported objects of all required names in
> > >> my namespace and modify these via assignInMyNamespace (I don't think
> > >> that anybody from somewhere else would import that namespace, it's not
> > >> that kind of package). Would that be a viable alternative, and would the
> > >> widgets be found that way? Any further ideas?
> > >>
> > >> Best regards,
> > >> Ulrike
> > >>
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From groemping at bht-berlin.de  Wed Feb 13 15:42:22 2013
From: groemping at bht-berlin.de (=?ISO-8859-1?Q?Ulrike_Gr=F6mping?=)
Date: Wed, 13 Feb 2013 15:42:22 +0100
Subject: [Rd] Private environments and/or assignInMyNamespace
In-Reply-To: <web-444617544@cgpsrv2.cis.mcmaster.ca>
References: <511A4785.5070504@bht-berlin.de> <1360746723.28045.23.camel@milan>
	<511B842E.6030408@bht-berlin.de> <1360761841.28045.45.camel@milan>
	<web-444617544@cgpsrv2.cis.mcmaster.ca>
Message-ID: <511BA64E.9020000@bht-berlin.de>

Dear John and Milan,

thanks a lot for your input. Unfortunately, this is by far not the only 
think preventing my dialog from working, I am afraid. This was the start 
of the matter, as far as I remember, but I think that buttons like my 
refresh button etc. will also need special attention - as my plugin was 
written, before Rcmdr knew how to make dialogs remember their settings, 
I created constructions for that as well. I suppose that I have to bite 
the bullet at some point and try for one of the dialogs whether I can 
make it work by thoroughly applying putDoE and getDoE (i.e. assigning to 
and retrieving from my own private environment) to all affected widgets.

Best, Ulrike

Am 13.02.2013 15:35, schrieb John Fox:
> Dear Milan and Ulrike,
>
> The purpose of errorCondition() is to put a dialog in the state it was in prior to the erroneous input, reflecting, e.g., prior selections. Like all Rcmdr utility functions, its use isn't mandatory -- it's simply meant to be convenient and to encourage some consistency in behaviour in the Rcmdr and plug-ins.
>
> If you prefer to have a dialog remain in its erroneous state after an error -- and I can see an argument for that -- then you needn't use errorCondition().
>
> Finally, if this is the only thing preventing Ulrike's dialogs from working, then avoiding errorCondition() an attractive solution.
>
> Best,
>   John
>
> On Wed, 13 Feb 2013 14:24:01 +0100
>   Milan Bouchet-Valat <nalimilan at club.fr> wrote:
>> Le mercredi 13 f?vrier 2013 ? 13:16 +0100, Ulrike Gr?mping a ?crit :
>>> Milan,
>>>
>>> I am not closing the dialog, but without the dialog in the search space,
>>> I cannot properly refer to it any more using e.g. the Rcmdr function
>>> errorCondition.
>>> It has been a long time ago that I wrote this; I don't have a small
>>> reproducible example right now. Below is an example of what I do in
>>> function Menu.pb2level:
>>>
>>> I am using function justDoItDoE (instead of Rcmdr justDoIt, because
>>> justDoIt puts the focus in the wrong place for my purpose; have to adapt
>>> to RStudio here!):
>>> justDoItDoE <- function (command)
>>> {
>>>       Message()
>>>       if (!getRcmdr("suppress.X11.warnings")) {
>>>           messages.connection <- file(open = "w+")
>>>           sink(messages.connection, type = "message")
>>>           on.exit({
>>>               sink(type = "message")
>>>               close(messages.connection)
>>>           })
>>>       }
>>>       else messages.connection <- getRcmdr("messages.connection")
>>>       result <- try(eval(parse(text = command), envir = .GlobalEnv))
>>>       if (!class(result)[1] == "try-error")
>>>           Rcmdr:::checkWarnings(readLines(messages.connection))
>>>       result
>>> }
>>> <environment: namespace:RcmdrPlugin.DoE>
>>>
>>> Subsequently, I am using the Rcmdr function errorCondition:
>>> errorCondition <- function (window = top, recall = NULL, message =
>>> stop("message not supplied"),
>>>       model = FALSE)
>>> {
>>>       tmp <- substitute({
>>>           on.exit(remove(list = objects(pattern = "^\\.\\.", all.names =
>>> TRUE)))
>>>           if (model) putRcmdr("modelNumber", getRcmdr("modelNumber") -
>>>               1)
>>>           if (!is.null(window)) {
>>>               if (GrabFocus()) tkgrab.release(window)
>>>               tkdestroy(window)
>>>           }
>>>           Message(message = message, type = "error")
>>>           if (!is.null(recall)) recall() else tkfocus(CommanderWindow())
>>>       })
>>>       eval(tmp, parent.frame())
>>> }
>>>
>>> Function errorCondition has to find the dialog topdes2, and I have to be
>>> inside function Menu.pb2level again:
>>>               hilf <- justDoItDoE(command)
>>>               if (class(hilf)[1] == "try-error") {
>>>                   errorCondition(window = topdes2, recall = Menu.pb2level,
>>>                     message = gettextRcmdr(hilf))
>>>                   return()
>>>               }
>>>
>>> This code does not work with topdes2 not in the search path, and when I
>>> tried before, it did also not work with getRcmdr("topdes2") instead of
>>> topdes2 - but maybe, I just was not following this approach through
>>> thoroughly enough.
>>>
>>> Any thoughts whether the storage of widgets in an environment off the
>>> search path might work (when properly followed through, which will be a
>>> lot of work)? Or any suggestion how else I can achieve what I try to do?
>> OK, this is what I suspected. John should probably comment this
>> statement, but I do not really understand the purpose of the
>> errorCondition() function. I've stopped using it in my own RCommander
>> plug-in.
>>
>> What I would do if I had to solve your problem is to call return()
>> instead of errorCondition(), so that the dialog is left as-is. To tell
>> the user that something is wrong, you can use Message(), or show an
>> error dialog or a label in the original dialog right before calling
>> return(). This is the simplest solution and it does not require any
>> programming trick. But maybe I'm missing something. ;-)
>>
>>
>> My two cents
>>
>>> Best, Ulrike
>>>
>>> Am 13.02.2013 10:12, schrieb Milan Bouchet-Valat:
>>>> Le mardi 12 f?vrier 2013 ? 14:45 +0100, Ulrike Gr?mping a ?crit :
>>>>> Dear DevelopeRs,
>>>>>
>>>>> I've been struggling with the new regulations regarding modifications to
>>>>> the search path, regarding my Rcmdr plugin package RcmdrPlugin.DoE. John
>>>>> Fox made Rcmdr comply with the new policy by removing the environment
>>>>> RcmdrEnv from the search path. For the time being, he developed an
>>>>> option that allows users to put the environment from Rcmdr (RcmdrEnv) on
>>>>> the search path, like in earlier versions of Rcmdr (thanks John!), which
>>>>> rescues my package for the immediate future; however, in the long run it
>>>>> would be nice to be able to make it work without that.
>>>>>
>>>>> The reason why I currently need the environment on the search path (may
>>>>> be due to my lack of understanding how tcltk widgets are handled): I
>>>>> have quite elaborate notebook widgets on which users can make many
>>>>> entries. Some entries are only checked after clicking OK, and if an
>>>>> error is found at that point, the user receives a small message window
>>>>> that has to be confirmed and is subsequently returned to the notebook
>>>>> widget in the state it was in when pressing OK. These widgets are
>>>>> currently held in the environment RcmdrEnv; they work when RcmdrEnv is
>>>>> on the search path; however, it is not sufficient to retrieve them with
>>>>> John's function getRcmdr, which works fine for objects other than widgets.
>>>> I'm not sure I understand exactly how this works, but does that mean you
>>>> close the dialog before checking the entries? If it is the case, you
>>>> could check them before, and if an error is detected, you would keep the
>>>> dialog open: this way, you would not need to restore anything.
>>>>
>>>> Could you point us at the relevant code?
>>>>
>>>>
>>>> Regards
>>>>
>>>>> Here my question: Would it be an option to place the widgets in a
>>>>> private environment of my plugin package (then I would have to learn how
>>>>> to create one and work with it), or won't they be found that way?
>>>>> Alternatively, I could have unexported objects of all required names in
>>>>> my namespace and modify these via assignInMyNamespace (I don't think
>>>>> that anybody from somewhere else would import that namespace, it's not
>>>>> that kind of package). Would that be a viable alternative, and would the
>>>>> widgets be found that way? Any further ideas?
>>>>>
>>>>> Best regards,
>>>>> Ulrike
>>>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Wed Feb 13 16:12:52 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 13 Feb 2013 10:12:52 -0500
Subject: [Rd] Regression stars
In-Reply-To: <CAKctRd0f5aMquq+WoKCe1_rG9boPo=xygx+XRjOnekWBSem+fQ@mail.gmail.com>
References: <CAKctRd0f5aMquq+WoKCe1_rG9boPo=xygx+XRjOnekWBSem+fQ@mail.gmail.com>
Message-ID: <511BAD74.7080501@gmail.com>

On 13/02/2013 8:40 AM, Charles Geyer wrote:
> Please do not change the defaults for the show.signif.stars option or for
> the default.stringsAsFactors option.  Backward compatibility is more
> important than your convenience.  The same sort of argument could be made
> for changing the default of the "[" function from drop = TRUE to drop =
> FALSE.  It would lead to less gotchas when coding and make R a saner
> programming language (less infernoish), but would annoy and confuse
> ordinary users and is not "the R way".

That is something that might improve the language, but it would be far 
more disruptive than either of the other two changes.  It's a matter of 
balance.  In my judgment its cost would greatly exceed its benefit.  In 
the case of stringsAsFactors, I think the benefits would exceed the 
costs.    In the case of the stars, I think both costs and benefits are 
negligible.  I think "the R way" is this kind of balance, with a fairly 
strong conservative tilt.  Due to the conservatism, I'm not planning to 
make the stringsAsFactors change for everybody, but I have made an 
effort to make it easier to make the change individually via the 
option() setting.

Duncan Murdoch

>   In any case your philosophical
> arguments about signif stars are bogus.  Non-simultaneous have exactly the
> same problem as these "regression stars".  As I once said in a paper, they
> are something "users think they can interpret" with the unstated
> implication that they really cannot.  Charlie's law of users says ordinary
> users of statistics actually ignore confidence levels and treat all
> confidence intervals as if they cover (i. e., take the true confidence
> level to be 100%).  You cannot fix lack of user understanding of statistics
> by any such simplistic idea.  Yes R is a prime example of "worse is
> better", but it is the way it is.  Don't try to turn it into C++.  Thank
> you.


From ncrookston.fs at gmail.com  Wed Feb 13 16:45:30 2013
From: ncrookston.fs at gmail.com (Nicholas Crookston)
Date: Wed, 13 Feb 2013 07:45:30 -0800
Subject: [Rd] stringsAsFactors
In-Reply-To: <511B978B.9080000@gmail.com>
References: <mailman.19.1360580413.23621.r-devel@r-project.org>
	<5118F70A.6060100@mayo.edu>
	<E66794E69CFDE04D9A70842786030B931B900B58@PA-MBX04.na.tibco.com>
	<51192F72.4090904@gmail.com>
	<CA+vqiLH_OzKKcYLxK3jsrQRtpvN=Uj6xoEJpsCAwX3yLQG-vzA@mail.gmail.com>
	<Zen-1U5bWl-0008SN-65@smarthost02.mail.zen.net.uk>
	<1360762253.28045.50.camel@milan> <511B978B.9080000@gmail.com>
Message-ID: <CAAk+MXwnje8R1--X8xbifbFcBrzAzYmoqWuojs+kuD3QToW6ZA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130213/11d46b78/attachment.pl>

From hb at biostat.ucsf.edu  Thu Feb 14 00:43:06 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 13 Feb 2013 15:43:06 -0800
Subject: [Rd] VignetteBuilder: Unlike other package fields,
 it does not support version specifiers
Message-ID: <CAFDcVCQjxLS_nW5Jw=L_4hQjHn-ZycgmwymJtgRpicJKWr+zvg@mail.gmail.com>

Just an observation/FYI on the new DESCRIPTION field 'VignetteBuilder'
available in R devel:

Unlike other package fields (Depends, Imports and Suggests),
VignetteBuilder does not support version specifiers, e.g.

VignetteBuilder: R.rsp (>= 0.8.2)

but only

VignetteBuilder: R.rsp

If adding a version specifier, 'R CMD build' complaints with an:

** installing vignettes
Error in loadNamespace(pkg) : there is no package called 'R.rsp(>=0.8.2)'
ERROR: installing vignettes failed

> sessionInfo()
R Under development (unstable) (2013-02-12 r61929)
Platform: x86_64-w64-mingw32/x64 (64-bit)

As I said, just an FYI.

Henrik

PS. Also, thanks for adding support for non-Sweave vignettes!


From r.hijmans at gmail.com  Thu Feb 14 01:35:21 2013
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 13 Feb 2013 16:35:21 -0800
Subject: [Rd] mapply error with Math (S4 group generic)
Message-ID: <CANtt_hxJsqHjVmocZX00=Vup=jHxX64M=L9_BM-M7uYOfya7sg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130213/a9de58e8/attachment.pl>

From murdoch.duncan at gmail.com  Thu Feb 14 03:40:30 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 13 Feb 2013 21:40:30 -0500
Subject: [Rd] VignetteBuilder: Unlike other package fields,
 it does not support version specifiers
In-Reply-To: <CAFDcVCQjxLS_nW5Jw=L_4hQjHn-ZycgmwymJtgRpicJKWr+zvg@mail.gmail.com>
References: <CAFDcVCQjxLS_nW5Jw=L_4hQjHn-ZycgmwymJtgRpicJKWr+zvg@mail.gmail.com>
Message-ID: <511C4E9E.6060500@gmail.com>

On 13-02-13 6:43 PM, Henrik Bengtsson wrote:
> Just an observation/FYI on the new DESCRIPTION field 'VignetteBuilder'
> available in R devel:
>
> Unlike other package fields (Depends, Imports and Suggests),
> VignetteBuilder does not support version specifiers, e.g.
>
> VignetteBuilder: R.rsp (>= 0.8.2)

Yes, that's by design.  It doesn't indicate how the package depends on 
R.rsp, only that the R.rsp package needs to be loaded before vignettes 
are built.  You have to choose Depends, Imports or Suggests as well, and 
that's where the version dependency goes.

Duncan Murdoch

>
> but only
>
> VignetteBuilder: R.rsp
>
> If adding a version specifier, 'R CMD build' complaints with an:
>
> ** installing vignettes
> Error in loadNamespace(pkg) : there is no package called 'R.rsp(>=0.8.2)'
> ERROR: installing vignettes failed
>
>> sessionInfo()
> R Under development (unstable) (2013-02-12 r61929)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> As I said, just an FYI.
>
> Henrik
>
> PS. Also, thanks for adding support for non-Sweave vignettes!
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From r.hijmans at gmail.com  Thu Feb 14 06:50:31 2013
From: r.hijmans at gmail.com (Robert J. Hijmans)
Date: Wed, 13 Feb 2013 21:50:31 -0800
Subject: [Rd] mapply error with Math (S4 group generic)
In-Reply-To: <CANtt_hxJsqHjVmocZX00=Vup=jHxX64M=L9_BM-M7uYOfya7sg@mail.gmail.com>
References: <CANtt_hxJsqHjVmocZX00=Vup=jHxX64M=L9_BM-M7uYOfya7sg@mail.gmail.com>
Message-ID: <CANtt_hwwDFGV27r1WcFxkfr+RYAKeXN+TXXQ8FfsZ4EpCb+RCQ@mail.gmail.com>

Problem solved. Martin Morgan pointed out to me that the error occurs
because in the method in raster I used, to get the function name which
I need for branching, the naive approach:

funname <- as.character(sys.call(sys.parent())[[1]])

from the code of callGeneric Martin deduced that I should instead use

funname <- .Generic

That indeed made the problem go away.
Best, Robert


On Wed, Feb 13, 2013 at 4:35 PM, Robert J. Hijmans <r.hijmans at gmail.com> wrote:
>
> I get an error when using self-defined (not standard) functions with mapply
> with S4 objects from the raster package that I develop: "Error in
> as.character(sys.call(sys.parent())[[1]]) :   cannot coerce type 'closure'
> to vector of type 'character'".  Does anyone understand why? The problem is
> illustrated below. Thanks, Robert
>
>
>> # First a general example that works
>> setClass('Foo',representation (value = 'numeric'))
>> setMethod("Math", signature(x='Foo'),function(x){ x at value <-
>> callGeneric(x at value); x } )
> [1] "Math"
>> f <- new('Foo')
>> f at value = 1
>> ff <- list(f,f)
>> e1 <- exp(f)
>> e2 <- mapply(exp, ff)
>> e3 <- mapply(function(x)exp(x), ff)
>>
>
>
> # Now for the raster package that also has the Math group generic
> implemented
>> library(raster)
> Loading required package: sp
> raster 2.0-41 (21-December-2012)
>> r <- raster(ncol=3, nrow=3)
>> r[] <- 1:9
>> rr <- list(r,r)
>> g1 <- exp(r)
>> g2 <- mapply(exp, rr)
>> g3 <- mapply(function(x)exp(x), rr)
> Error in as.character(sys.call(sys.parent())[[1]]) :
>   cannot coerce type 'closure' to vector of type 'character'
>>
> # For this simple example we could use lapply, and that works fine:
>> gl <- lapply(rr, function(x)exp(x))
>
>
> # but the below works fine (log is defined as a single method, overriding
> its definition in the group generic)
>> g4 <- mapply(function(x)log(x), rr)
> # or when combining with methods from group generic Arith:
>> g5 <- mapply(function(x)log(x*3), rr)
>
>
> # Yet, I also fond problems with the Summary group generic; similar but
> different error message.
>> m1 <- max(rr[[1]], rr[[1]])
>> m2 <- mapply(max, rr, rr)
> Error in as.character(sys.call()[[1L]]) :
>   cannot coerce type 'builtin' to vector of type 'character'
>
>
>
>
>
>> sessionInfo()
> R version 2.15.2 (2012-10-26)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252  LC_CTYPE=English_United
> States.1252    LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C                           LC_TIME=English_United
> States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] raster_2.0-41 sp_0.9-99
>
> loaded via a namespace (and not attached):
> [1] grid_2.15.2     lattice_0.20-10 tools_2.15.2
>>
>


From luke-tierney at uiowa.edu  Thu Feb 14 12:53:10 2013
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 14 Feb 2013 05:53:10 -0600
Subject: [Rd] stopping finalizers
In-Reply-To: <CAJ55+dJogFHu3bXBFSjDGynsH0FKN4A15=5uWg_KS4XTaEOSCA@mail.gmail.com>
References: <CAJ55+dJogFHu3bXBFSjDGynsH0FKN4A15=5uWg_KS4XTaEOSCA@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1302140544570.17940@luke-Latitude>

It might help if you could be more specific about what the issue is --
if they are out of scope why does it matter whether the finalizers
run?

Generically two approaches I can think of:

     you keep track of whenit is safe to fully run your finalizers and have
     your finalizers put the objects on a linked list if it isn't safe to
     run the finalizer now and clear the list each time you make a new one

     keep track of your objects with a weak list andturn them into strong
     references before your calls, then drop the list after.

I'm pretty sure we don't have a mechanism for temporarily suspending
running the finalizers but it is probably fairly easy to add if that
is the only option.

I might be able to think of other options with more details on the
issue.

Best,

luke

On Tue, 12 Feb 2013, Thomas Lumley wrote:

> Is there some way to prevent finalizers running during a section of code?
>
> I have a package that includes R objects linked to database tables.  To
> maintain the call-by-value semantics, tables are copied rather than
> modified, and the extra tables are removed by finalizers during garbage
> collection.
>
> However, if the garbage collection occurs in the middle of processing
> another SQL query (which is relatively likely, since that's where the
> memory allocations are) there are problems with the database interface.
>
> Since the guarantees for the finalizer are "at most once, not before the
> object is out of scope" it seems harmless to be able to prevent finalizers
> from running during a particular code block, but I can't see any way to do
> it.
>
> Suggestions?
>
>    -thomas
>
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From antonio.fabio at gmail.com  Thu Feb 14 20:22:45 2013
From: antonio.fabio at gmail.com (Antonio, Fabio Di Narzo)
Date: Thu, 14 Feb 2013 14:22:45 -0500
Subject: [Rd] stopping finalizers
In-Reply-To: <CAJ55+dJogFHu3bXBFSjDGynsH0FKN4A15=5uWg_KS4XTaEOSCA@mail.gmail.com>
References: <CAJ55+dJogFHu3bXBFSjDGynsH0FKN4A15=5uWg_KS4XTaEOSCA@mail.gmail.com>
Message-ID: <CANyxDDcrU4VDE6hZCxmcPQm0UkVDVMEscyCzGvRgsNhAQqWPTg@mail.gmail.com>

I'm not sure I got your problem right, but you can keep a named copy
of your not-to-be-finalized object as long as it needs to be around,
so it doesn't go out of scope too early.

Something like:
local({
   dontFinalizeMe <- obj
   ##
   ## code which creates copies, overwrites, and indirectly uses 'obj'
   ##
})

hth,
--
Antonio, Fabio Di Narzo,
Biostatistician
Mount Sinai School of Medicine, NY.

2013/2/12 Thomas Lumley <tlumley at uw.edu>:
> Is there some way to prevent finalizers running during a section of code?
>
> I have a package that includes R objects linked to database tables.  To
> maintain the call-by-value semantics, tables are copied rather than
> modified, and the extra tables are removed by finalizers during garbage
> collection.
>
> However, if the garbage collection occurs in the middle of processing
> another SQL query (which is relatively likely, since that's where the
> memory allocations are) there are problems with the database interface.
>
> Since the guarantees for the finalizer are "at most once, not before the
> object is out of scope" it seems harmless to be able to prevent finalizers
> from running during a particular code block, but I can't see any way to do
> it.
>
> Suggestions?
>
>     -thomas
>
>
> --
> Thomas Lumley
> Professor of Biostatistics
> University of Auckland
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tlumley at uw.edu  Thu Feb 14 21:12:18 2013
From: tlumley at uw.edu (Thomas Lumley)
Date: Fri, 15 Feb 2013 09:12:18 +1300
Subject: [Rd] stopping finalizers
In-Reply-To: <alpine.DEB.2.02.1302140544570.17940@luke-Latitude>
References: <CAJ55+dJogFHu3bXBFSjDGynsH0FKN4A15=5uWg_KS4XTaEOSCA@mail.gmail.com>
	<alpine.DEB.2.02.1302140544570.17940@luke-Latitude>
Message-ID: <CAJ55+dJVjg9tN9RZB7Fk2twg-vO6zehXKFj2RU+HAhugVm9bsg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130215/f4d9be90/attachment.pl>

From simon.urbanek at r-project.org  Thu Feb 14 21:57:48 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Thu, 14 Feb 2013 15:57:48 -0500
Subject: [Rd] stopping finalizers
In-Reply-To: <CAJ55+dJVjg9tN9RZB7Fk2twg-vO6zehXKFj2RU+HAhugVm9bsg@mail.gmail.com>
References: <CAJ55+dJogFHu3bXBFSjDGynsH0FKN4A15=5uWg_KS4XTaEOSCA@mail.gmail.com>
	<alpine.DEB.2.02.1302140544570.17940@luke-Latitude>
	<CAJ55+dJVjg9tN9RZB7Fk2twg-vO6zehXKFj2RU+HAhugVm9bsg@mail.gmail.com>
Message-ID: <2F2447A2-CBDB-41E0-8D18-5F90CB61C730@r-project.org>

I would argue that addressing this at a generic R level is the wrong place (almost, see below) -- because this is about *specific* finalizers. You don't mind running other people 's finalizers because they don't mess up your connection. Therefore, I'd argue that primarily the approach should be in your DB driver to synchronize the calls - which is what you did by queueing.

In a sense a more general approach won't be any different - you will need at least a list of *specific* objects that should be deferred - it's either in your driver or in R. I'd argue that the design is much easier in the driver because you know which finalizers to register, whereas R has no concept of finalizer "classes" to group them. You can also do this much more easily in the driver since you know whether they need to be deferred and if they do, you can easily process the deferred once when you get out of your critical section.

Because of this difference between specific finalizers and all GC any R-side solution that doesn't register such finalizers in a special way will be inherently wasteful - as you pointed out in the discussion below - and thus I'd say it's more dangerous than helpful, because R can then lock itself out of memory even if not necessary.

So IMHO the necessary practical way to solve this at R level (if someone wanted to spend the time) would be to create "bags" of finalizers and use those when defining critical regions, something like (pseudocode)

add_fin_bag("myDB", obj1)
// ...
add_fin_bag("myDB", obj2)

critical_fin_section_begin("myDB")
// ... here no finalizers for objects in the bag can be fired
critical_fin_section_end("myDB")

Technically, the simple solution would be to simply preserve the bag in the critical region. However, this would not guarantee that the finalizers get fired at the end of the section even if gc occurred. I suspect it would be harder to guarantee that (other than running gc explicitly or performing explicit de-allocation after the finalizer was detected to be scheduled but not fired).

Cheers,
Simon


On Feb 14, 2013, at 3:12 PM, Thomas Lumley wrote:

> Luke,
> 
> We're actually adopting the first of your generic approaches.
> 
> As a more concrete description:
> 
> There are R objects representing survey data sets, with the data stored in
> a database table.  The subset() method, when applied to these objects,
> creates a new table indicating which rows of the data table are in the
> subset -- we don't modify the original table, because that breaks the
> call-by-value semantics. When the subset object in R goes out of scope, we
> need to delete the extra database table.
> 
> I have been doing this with a finalizer on an environment that's part of
> the subset object in R.   This all worked fine with JDBC, but the native
> database interface requires that all communications with the database come
> in send/receive pairs. Since R is single-threaded, this would normally not
> be any issue. However, since garbage collection can happen at any time, it
> is possible that the send part of the finalizer query "drop table
> _sbs_whatever" comes between the send and receive of some other query, and
> the database connection then falls over.   So, I'm happy for the finalizer
> to run at any time except during a small critical section of R code.
> 
> In this particular case the finalizer only issues "drop table" queries, and
> it doesn't need to know if they succeed, so we can keep a lock in the
> database connection and just store any "drop table" queries that arrive
> during a database operation for later execution.   More generally, though,
> the fact that no R operation is atomic with respect to garbage collection
> seems to make it a bit difficult to use finalizers -- if you need a
> finalizer, it will often be in order to access and free some external
> resource, which is when the race conditions can matter.
> 
> What I was envisaging was something like
> 
> without_gc(expr)
> 
> to evaluate expr with the memory manager set to allocate memory (or attempt
> to do so) without garbage collection.  Even better would be if gc could
> run, but weak references were temporarily treated as strong so that garbage
> without finalizers would be collected but finalizers didn't get triggered.
> Using this facility would be inefficient, because it would allocate more
> memory than necessary and would also mess with the tuning of the garbage
> collector,  but when communicating with other programs it seems it would be
> very useful to have some way of running an R code block and knowing that no
> other R code block would run during it (user interrupts are another issue,
> but they can be caught, and in any case I'm happy to fail when the user
> presses CTRL-C).
> 
>     -thomas
> 
> 
> 
> 
> On Fri, Feb 15, 2013 at 12:53 AM, <luke-tierney at uiowa.edu> wrote:
> 
>> It might help if you could be more specific about what the issue is --
>> if they are out of scope why does it matter whether the finalizers
>> run?
>> 
>> Generically two approaches I can think of:
>> 
>>    you keep track of whenit is safe to fully run your finalizers and have
>>    your finalizers put the objects on a linked list if it isn't safe to
>>    run the finalizer now and clear the list each time you make a new one
>> 
>>    keep track of your objects with a weak list andturn them into strong
>>    references before your calls, then drop the list after.
>> 
>> I'm pretty sure we don't have a mechanism for temporarily suspending
>> running the finalizers but it is probably fairly easy to add if that
>> is the only option.
>> 
>> I might be able to think of other options with more details on the
>> issue.
>> 
>> Best,
>> 
>> luke
>> 
>> 
>> On Tue, 12 Feb 2013, Thomas Lumley wrote:
>> 
>> Is there some way to prevent finalizers running during a section of code?
>>> 
>>> I have a package that includes R objects linked to database tables.  To
>>> maintain the call-by-value semantics, tables are copied rather than
>>> modified, and the extra tables are removed by finalizers during garbage
>>> collection.
>>> 
>>> However, if the garbage collection occurs in the middle of processing
>>> another SQL query (which is relatively likely, since that's where the
>>> memory allocations are) there are problems with the database interface.
>>> 
>>> Since the guarantees for the finalizer are "at most once, not before the
>>> object is out of scope" it seems harmless to be able to prevent finalizers
>>> from running during a particular code block, but I can't see any way to do
>>> it.
>>> 
>>> Suggestions?
>>> 
>>>   -thomas
>>> 
>>> 
>>> 
>>> 
>> --
>> Luke Tierney
>> Chair, Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>   Actuarial Science
>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>> 
> 
> 
> 
> -- 
> Thomas Lumley
> Professor of Biostatistics
> University of Auckland
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From MEC at stowers.org  Thu Feb 14 23:06:51 2013
From: MEC at stowers.org (Cook, Malcolm)
Date: Thu, 14 Feb 2013 22:06:51 +0000
Subject: [Rd] Error: 'mcMap' is not an exported object from
	'namespace:parallel'
Message-ID: <D4772401B9D976478C0895769BE3E79202C100@MBSRV02.sgc.loc>

> library(parallel)
> mcMap(identity,1:5)
Error: could not find function "mcMap"
> parallel:::mcMap(identity,1:5)
[[1]]
[1] 1

[[2]]
[1] 2

[[3]]
[1] 3

[[4]]
[1] 4

[[5]]
[1] 5

> parallel::mcMap(identity,1:5)
Error: 'mcMap' is not an exported object from 'namespace:parallel'

> sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8    LC_PAPER=C                 LC_NAME=C                  LC_ADDRESS=C               LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] parallel  stats     graphics  grDevices utils     datasets  methods   base     


Nuff Said?

Thanks for parallel!

~ malcolm_cook at stowers.org


From h.wickham at gmail.com  Fri Feb 15 03:35:37 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 14 Feb 2013 20:35:37 -0600
Subject: [Rd] stopping finalizers
In-Reply-To: <CAJ55+dJVjg9tN9RZB7Fk2twg-vO6zehXKFj2RU+HAhugVm9bsg@mail.gmail.com>
References: <CAJ55+dJogFHu3bXBFSjDGynsH0FKN4A15=5uWg_KS4XTaEOSCA@mail.gmail.com>
	<alpine.DEB.2.02.1302140544570.17940@luke-Latitude>
	<CAJ55+dJVjg9tN9RZB7Fk2twg-vO6zehXKFj2RU+HAhugVm9bsg@mail.gmail.com>
Message-ID: <CABdHhvG+2mdXCpGdHn9DfzQpUsU3dAndPCZ+2eoof+gvShAUig@mail.gmail.com>

> There are R objects representing survey data sets, with the data stored in
> a database table.  The subset() method, when applied to these objects,
> creates a new table indicating which rows of the data table are in the
> subset -- we don't modify the original table, because that breaks the
> call-by-value semantics. When the subset object in R goes out of scope, we
> need to delete the extra database table.

Isn't subset slightly too early to do this?  It would be slightly more
efficient for subset to return an object that creates the table when
you first attempt to modify it.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From hb at biostat.ucsf.edu  Fri Feb 15 04:29:24 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 14 Feb 2013 19:29:24 -0800
Subject: [Rd] Suggestion: Custom filename patterns for non-Sweave vignettes
Message-ID: <CAFDcVCQs4GEYznPmqkz=gRuq2=KEWMnOqsSq3fGU92mUN0hbUA@mail.gmail.com>

Hi,

as far as I understand it, the new R devel feature of processing
non-Sweave vignettes will (a) locate any "[.][RrSs](nw|tex)$" or
".Rmd" files, (b) check for a registered vignette engine, (c) process
the file using the registered "weave" function, (d) and possibly post
process the generated weave artifact (e.g. a *.tex file).

I'd like to propose to extend this non-Sweave mechanism to allow for
any filename patterns still using a very similar setup.  Here is how
I'd like it to see it work with RSP vignettes (cf. the R.rsp package):

  tools::vignetteEngine("rsp", weave=rspWeave, tangle=rspTangle,
patterns="[.]rsp$")

Argument 'patterns' could default to patterns=c("[.][RrSs](nw|tex)$",
"[.]Rmd$").

This is just a sketch/mock up and it may be that there are better
solutions.  However, the idea is that when specify 'VignetteBuilder:
R.rsp' in DESCRIPTION of a package, R locates all engines registered
by the builder package.  In this case it finds 'rsp'.  (An alternative
to this lookup would be to use a DESCRIPTION field 'VignetteEngines:
R.rsp:rsp, knitr:knitr'.)  It next looks for custom filename patterns
and use those to scan for vignette source files.  With this approach,
the '%\VignetteEngine{knitr}' specifier would become optional.  (I can
see how R now scans for Rnw and Rmd files, checks them for a
\VignetteEngine{} markup, and then looks up the corresponding engine).

Continuing, the above would make it possible to process RSP vignettes
that have filenames:

  reportA.tex.rsp
  reportB.html.rsp
  reportC.md.rsp
  reportD.Rnw.rsp

where rspWeave() will produce the following files:

  reportA.tex
  reportB.html
  reportC.html
  reportD.tex

I included the latter case just to illustrate a special case where
rspWeave() first generates a reportC.Rnw (Sweave or knitr) which is
the processed using the corresponding weaver to generate reportC.tex.

My point is that restricting vignette filenames to ".[RrSs](nw|tex)$"
or ".Rmd" is unnecessary and conceptually it would not be too hard to
extend it to handle any filename patterns.

I am aware that implementing this would require updates in several
place.  If R core would approve on the above extended functionality, I
would be happy to dig into the source code and provide minimal and
backward compatible patches.

Finally, without knowing the details of all the other report
generating packages, my guess is that this extended feature would be
useful also for some of those packages, which in the long run
hopefully results in more packages having more vignettes (regardless
of the vignette format).

All the best,

Henrik


From djsamperi at gmail.com  Fri Feb 15 09:13:51 2013
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 15 Feb 2013 03:13:51 -0500
Subject: [Rd] Building R from source under Mac OS X 10.8.2?
Message-ID: <CADUbQ5iR1KHRx5vcCZmgWCN_zJ2MRDD250_p0RLOz+iE+07DoA@mail.gmail.com>

Hello,

I'm trying to build R from source under Mac OS X 10.8.2 (Mountain Lion)
by following the FAQ and I run into a problem with the Fortran
compiler (downloaded from http://cran.r-project.org/bin/macosx/tools/),
specifically, gfortran-4.2.3. I have Xcode 4.6 installed along with
the latest command-line tools (dated Feb. 9, 2013).

When I try to run configure with or without the --enable-R-framework
options I get this diagnostic:
checking for dummy main to link with Fortran 77 libraries... none
checking for Fortran 77 name-mangling scheme... unknown
configure: WARNING: unknown Fortran name-mangling scheme
checking whether gfortran appends underscores to external names... unknown
configure: error: cannot use Fortran

I'm working with the source for R 2.15.2.

Any tips would be appreciated.

Thanks,
Dominick


From murdoch.duncan at gmail.com  Fri Feb 15 10:15:11 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 15 Feb 2013 04:15:11 -0500
Subject: [Rd] Suggestion: Custom filename patterns for non-Sweave
	vignettes
In-Reply-To: <CAFDcVCQs4GEYznPmqkz=gRuq2=KEWMnOqsSq3fGU92mUN0hbUA@mail.gmail.com>
References: <CAFDcVCQs4GEYznPmqkz=gRuq2=KEWMnOqsSq3fGU92mUN0hbUA@mail.gmail.com>
Message-ID: <511DFC9F.4020209@gmail.com>

There are several reasons I decided against that:

   - two packages may request overlapping patterns, making it much 
messier to do the matching, checking etc, since the matching would have 
to depend on the package being processed.

   - one package may request a pattern that another package uses for 
auxiliary files, e.g. .bib.  If a user has both types of vignette it 
would just be a mess.

   - the extension is also used to determine the output format.  We only 
support LaTeX (which will be converted to PDF) and HTML output.  It 
would be reasonable to support direct PDF output, but I don't think any 
other output formats should be supported.

I understand that forcing you to use .Rmd instead of .html.rsp may look 
unsightly, but I think the extensions need to be fixed, not customizable.

Duncan Murdoch

On 13-02-14 10:29 PM, Henrik Bengtsson wrote:
> Hi,
>
> as far as I understand it, the new R devel feature of processing
> non-Sweave vignettes will (a) locate any "[.][RrSs](nw|tex)$" or
> ".Rmd" files, (b) check for a registered vignette engine, (c) process
> the file using the registered "weave" function, (d) and possibly post
> process the generated weave artifact (e.g. a *.tex file).
>
> I'd like to propose to extend this non-Sweave mechanism to allow for
> any filename patterns still using a very similar setup.  Here is how
> I'd like it to see it work with RSP vignettes (cf. the R.rsp package):
>
>    tools::vignetteEngine("rsp", weave=rspWeave, tangle=rspTangle,
> patterns="[.]rsp$")
>
> Argument 'patterns' could default to patterns=c("[.][RrSs](nw|tex)$",
> "[.]Rmd$").
>
> This is just a sketch/mock up and it may be that there are better
> solutions.  However, the idea is that when specify 'VignetteBuilder:
> R.rsp' in DESCRIPTION of a package, R locates all engines registered
> by the builder package.  In this case it finds 'rsp'.  (An alternative
> to this lookup would be to use a DESCRIPTION field 'VignetteEngines:
> R.rsp:rsp, knitr:knitr'.)  It next looks for custom filename patterns
> and use those to scan for vignette source files.  With this approach,
> the '%\VignetteEngine{knitr}' specifier would become optional.  (I can
> see how R now scans for Rnw and Rmd files, checks them for a
> \VignetteEngine{} markup, and then looks up the corresponding engine).
>
> Continuing, the above would make it possible to process RSP vignettes
> that have filenames:
>
>    reportA.tex.rsp
>    reportB.html.rsp
>    reportC.md.rsp
>    reportD.Rnw.rsp
>
> where rspWeave() will produce the following files:
>
>    reportA.tex
>    reportB.html
>    reportC.html
>    reportD.tex
>
> I included the latter case just to illustrate a special case where
> rspWeave() first generates a reportC.Rnw (Sweave or knitr) which is
> the processed using the corresponding weaver to generate reportC.tex.
>
> My point is that restricting vignette filenames to ".[RrSs](nw|tex)$"
> or ".Rmd" is unnecessary and conceptually it would not be too hard to
> extend it to handle any filename patterns.
>
> I am aware that implementing this would require updates in several
> place.  If R core would approve on the above extended functionality, I
> would be happy to dig into the source code and provide minimal and
> backward compatible patches.
>
> Finally, without knowing the details of all the other report
> generating packages, my guess is that this extended feature would be
> useful also for some of those packages, which in the long run
> hopefully results in more packages having more vignettes (regardless
> of the vignette format).
>
> All the best,
>
> Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Fri Feb 15 15:04:37 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 15 Feb 2013 09:04:37 -0500
Subject: [Rd] Building R from source under Mac OS X 10.8.2?
In-Reply-To: <CADUbQ5iR1KHRx5vcCZmgWCN_zJ2MRDD250_p0RLOz+iE+07DoA@mail.gmail.com>
References: <CADUbQ5iR1KHRx5vcCZmgWCN_zJ2MRDD250_p0RLOz+iE+07DoA@mail.gmail.com>
Message-ID: <331672A8-5865-4041-BD9E-D5E0E5DFDCA2@r-project.org>

Dominick,

On Feb 15, 2013, at 3:13 AM, Dominick Samperi wrote:

> Hello,
> 
> I'm trying to build R from source under Mac OS X 10.8.2 (Mountain Lion)
> by following the FAQ and I run into a problem with the Fortran
> compiler (downloaded from http://cran.r-project.org/bin/macosx/tools/),
> specifically, gfortran-4.2.3. I have Xcode 4.6 installed along with
> the latest command-line tools (dated Feb. 9, 2013).
> 
> When I try to run configure with or without the --enable-R-framework
> options I get this diagnostic:
> checking for dummy main to link with Fortran 77 libraries... none
> checking for Fortran 77 name-mangling scheme... unknown
> configure: WARNING: unknown Fortran name-mangling scheme
> checking whether gfortran appends underscores to external names... unknown
> configure: error: cannot use Fortran
> 
> I'm working with the source for R 2.15.2.
> 
> Any tips would be appreciated.
> 

Have you setup flags so that the architectures match? The default in Xcode for ML is 64-bit while the default for the Fortran is 32-bit (because that was the default for Xcode at the time), so depending on which architecture you want to compile you'll have to use either -arch x86_64 or -arch i386 (see the FAQ for a quickstart guide to compiling R).

Cheers,
Simon



> Thanks,
> Dominick
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From htl10 at users.sourceforge.net  Fri Feb 15 15:11:01 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Fri, 15 Feb 2013 14:11:01 +0000 (GMT)
Subject: [Rd] Matrix does not build with R trunk since Oct.
Message-ID: <1360937461.70374.BPMail_high_noncarrier@web172305.mail.ir2.yahoo.com>


Somebody else had written separately about this before, and so have I a couple of months ago. I assumed this will be fixed before the next R. Since R 3.0 is supposedly only 6 weeks away, even if it is fixed now it doesn't leave much room for testing. 

Anyway neither Matrix 1.0-11 (current) nor 1.0-9 (sept 2012) build with current R trunk.  The  last time it did was 1. 0-9 on 3rd october over 4 months ago. So it appears to be due to change inside r trunk in sept or early oct. 


----------------
Loading required package: Matrix
Error in namespaceExport(ns, exports) : undefined exports: .M.classEnv
Error : require(Matrix) is not TRUE
ERROR: installing package indices failed
* removing ?/svn-loc/R/library/Matrix?
* restoring previous ?/svn-loc/R/library/Matrix?
make[2]: *** [Matrix.ts] Error 1
make[2]: Leaving directory `/svn-loc/R/src/library/Recommended'
make[1]: *** [recommended-packages] Error 2
make[1]: Leaving directory `/svn-loc/R/src/library/Recommended'
make: *** [stamp-recommended] Error 2
----------------

If it matters, here is what r trunk built with:
 ./configure --enable-memory-profiling --enable-strict-barrier --enable-byte-compiled-packages --with-valgrind-instrumentation=2 --enable-lto


From simon.urbanek at r-project.org  Fri Feb 15 15:37:34 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 15 Feb 2013 09:37:34 -0500
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <1360937461.70374.BPMail_high_noncarrier@web172305.mail.ir2.yahoo.com>
References: <1360937461.70374.BPMail_high_noncarrier@web172305.mail.ir2.yahoo.com>
Message-ID: <76A856B2-3735-4D5E-AD86-5541BB52C93A@r-project.org>

On Feb 15, 2013, at 9:11 AM, Hin-Tak Leung wrote:

> Somebody else had written separately about this before, and so have I a couple of months ago. I assumed this will be fixed before the next R. Since R 3.0 is supposedly only 6 weeks away, even if it is fixed now it doesn't leave much room for testing. 
> 
> Anyway neither Matrix 1.0-11 (current) nor 1.0-9 (sept 2012) build with current R trunk.  The  last time it did was 1. 0-9 on 3rd october over 4 months ago. So it appears to be due to change inside r trunk in sept or early oct. 
> 

No problem here - Matrix 1.0-11 and R-devel build just fine with your flags (tested on Ubuntu 12.10, x86_64).

If in doubt, please remove R-devel and checkout a fresh copy. Also FWIW it's a bad practice to build inside the sources - it often causes all sorts of problems when you try to track the sources and stale files are probably what's hitting you.

FWIW: This is likely not the problem you're mentioning, but some recent gcc versions break and LTO is also known to cause issues depending on the compiler version, so tread lightly on the cutting edge.

Cheers,
Simon


> 
> ----------------
> Loading required package: Matrix
> Error in namespaceExport(ns, exports) : undefined exports: .M.classEnv
> Error : require(Matrix) is not TRUE
> ERROR: installing package indices failed
> * removing ?/svn-loc/R/library/Matrix?
> * restoring previous ?/svn-loc/R/library/Matrix?
> make[2]: *** [Matrix.ts] Error 1
> make[2]: Leaving directory `/svn-loc/R/src/library/Recommended'
> make[1]: *** [recommended-packages] Error 2
> make[1]: Leaving directory `/svn-loc/R/src/library/Recommended'
> make: *** [stamp-recommended] Error 2
> ----------------
> 
> If it matters, here is what r trunk built with:
> ./configure --enable-memory-profiling --enable-strict-barrier --enable-byte-compiled-packages --with-valgrind-instrumentation=2 --enable-lto
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Fri Feb 15 16:33:38 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 15 Feb 2013 09:33:38 -0600
Subject: [Rd] match.call() and missing arguments in ...
Message-ID: <CABdHhvHmLXUmYfX54Q6QRn57dEUzGTFBdgv2qQ9jfqRu-MQmsQ@mail.gmail.com>

Hi all,

Is this expected behaviour or a bug in match.call?

f <- function(x, ...) {
  g <- function(...) match.call()

  g(x = x, ...)
}
f(x = 1, y = )
# g(x = x, y = ..1)

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From h.wickham at gmail.com  Fri Feb 15 16:45:18 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 15 Feb 2013 09:45:18 -0600
Subject: [Rd] Printing of anonymous functions in calls is sub-optimal
Message-ID: <CABdHhvEgK1g4gYhmovu_EbvSN185g9LnLAacC5ojWup3_aG07w@mail.gmail.com>

e.g.

substitute(f(x), list(f = function(x) x + 1))
# function (x)
# x + 1(x)

An extra pair of parentheses would really help:

(function(x)
x + 1)(x)

(Better indenting etc would be nice, but not necessary for correct
understand of the code)

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From djsamperi at gmail.com  Fri Feb 15 17:35:32 2013
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 15 Feb 2013 11:35:32 -0500
Subject: [Rd] Building R from source under Mac OS X 10.8.2?
In-Reply-To: <331672A8-5865-4041-BD9E-D5E0E5DFDCA2@r-project.org>
References: <CADUbQ5iR1KHRx5vcCZmgWCN_zJ2MRDD250_p0RLOz+iE+07DoA@mail.gmail.com>
	<331672A8-5865-4041-BD9E-D5E0E5DFDCA2@r-project.org>
Message-ID: <CADUbQ5h6bnwdb_XdxmWmXBAYBPXp03Z+o=XDGnTbSPmBzK3i4w@mail.gmail.com>

Thanks Simon,

I tried the FAQ first, specifically, the
bit about setting arch=x86_64, changing directory
to R-$arch, and running:

../R-2.15.2/configure r_arch=$arch  CC="gcc-4.2 -arch $arch" \
          CXX="g++-4.2 -arch $arch" F77="gfortran-4.2 -arch $arch" \
          FC="gfortran-4.2 -arch $arch" OBJC="gcc-4.2 -arch $arch" \
          --x-includes=/usr/X11/include --x-libraries=/usr/X11/lib

This leads to:
checking whether the C compiler works... no
configure: error: in `/Users/dsamperi/Downloads/R-x86_64':
configure: error: C compiler cannot create executables
See `config.log' for more details

config.log shows that gcc-4.2 was not found, so I edited
the command line by replacing gcc-4.2 with gcc. configure
then failed because g++-4.2 was not found, so I removed
the "-4.2" part here as well.

Now configure finishes.

Thanks again,
Dominick

On Fri, Feb 15, 2013 at 9:04 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> Dominick,
>
> On Feb 15, 2013, at 3:13 AM, Dominick Samperi wrote:
>
>> Hello,
>>
>> I'm trying to build R from source under Mac OS X 10.8.2 (Mountain Lion)
>> by following the FAQ and I run into a problem with the Fortran
>> compiler (downloaded from http://cran.r-project.org/bin/macosx/tools/),
>> specifically, gfortran-4.2.3. I have Xcode 4.6 installed along with
>> the latest command-line tools (dated Feb. 9, 2013).
>>
>> When I try to run configure with or without the --enable-R-framework
>> options I get this diagnostic:
>> checking for dummy main to link with Fortran 77 libraries... none
>> checking for Fortran 77 name-mangling scheme... unknown
>> configure: WARNING: unknown Fortran name-mangling scheme
>> checking whether gfortran appends underscores to external names... unknown
>> configure: error: cannot use Fortran
>>
>> I'm working with the source for R 2.15.2.
>>
>> Any tips would be appreciated.
>>
>
> Have you setup flags so that the architectures match? The default in Xcode for ML is 64-bit while the default for the Fortran is 32-bit (because that was the default for Xcode at the time), so depending on which architecture you want to compile you'll have to use either -arch x86_64 or -arch i386 (see the FAQ for a quickstart guide to compiling R).
>
> Cheers,
> Simon
>
>
>
>> Thanks,
>> Dominick
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>


From htl10 at users.sourceforge.net  Fri Feb 15 17:36:26 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Fri, 15 Feb 2013 16:36:26 +0000 (GMT)
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <76A856B2-3735-4D5E-AD86-5541BB52C93A@r-project.org>
Message-ID: <1360946186.76087.YahooMailClassic@web172301.mail.ir2.yahoo.com>

--- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> On Feb 15, 2013, at 9:11 AM, Hin-Tak
> Leung wrote:
> 
> > Somebody else had written separately about this before,
> and so have I a couple of months ago. I assumed this will be
> fixed before the next R. Since R 3.0 is supposedly only 6
> weeks away, even if it is fixed now it doesn't leave much
> room for testing. 
> > 
> > Anyway neither Matrix 1.0-11 (current) nor 1.0-9 (sept
> 2012) build with current R trunk.? The? last time
> it did was 1. 0-9 on 3rd october over 4 months ago. So it
> appears to be due to change inside r trunk in sept or early
> oct. 
> > 
> 
> No problem here - Matrix 1.0-11 and R-devel build just fine
> with your flags (tested on Ubuntu 12.10, x86_64).
> 
> If in doubt, please remove R-devel and checkout a fresh
> copy. Also FWIW it's a bad practice to build inside the
> sources - it often causes all sorts of problems when you try
> to track the sources and stale files are probably what's
> hitting you.
> 
> FWIW: This is likely not the problem you're mentioning, but
> some recent gcc versions break and LTO is also known to
> cause issues depending on the compiler version, so tread
> lightly on the cutting edge.


Here is a fairly similar post:
http://r.789695.n4.nabble.com/Build-from-Source-fails-on-Loading-required-package-Matrix-td4640371.html

The eventual "solution" of that thread seems to be building from tar ball, which is quite beside the whole point of building from svn trunk.

FWIW, it is very unproductive to talk about "bad practice" - in a hand-waving undocumented/unsubstantiated manner - and options that might or might not work. If "--enable-lto" (or any other options, or build within the dev directory) does not work reliably, it should be either disabled/removed, or documented, or both. Anyway, it has not been working for over 4 months.

You have about 6 weeks before this becomes a big problem - "big" as in "wide-spread".

> Cheers,
> Simon
> 
> 
> > 
> > ----------------
> > Loading required package: Matrix
> > Error in namespaceExport(ns, exports) : undefined
> exports: .M.classEnv
> > Error : require(Matrix) is not TRUE
> > ERROR: installing package indices failed
> > * removing ?/svn-loc/R/library/Matrix?
> > * restoring previous ?/svn-loc/R/library/Matrix?
> > make[2]: *** [Matrix.ts] Error 1
> > make[2]: Leaving directory
> `/svn-loc/R/src/library/Recommended'
> > make[1]: *** [recommended-packages] Error 2
> > make[1]: Leaving directory
> `/svn-loc/R/src/library/Recommended'
> > make: *** [stamp-recommended] Error 2
> > ----------------
> > 
> > If it matters, here is what r trunk built with:
> > ./configure --enable-memory-profiling
> --enable-strict-barrier --enable-byte-compiled-packages
> --with-valgrind-instrumentation=2 --enable-lto
> > 
> > ______________________________________________
> > R-devel at r-project.org
> mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From simon.urbanek at r-project.org  Fri Feb 15 19:08:20 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 15 Feb 2013 13:08:20 -0500
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <1360946186.76087.YahooMailClassic@web172301.mail.ir2.yahoo.com>
References: <1360946186.76087.YahooMailClassic@web172301.mail.ir2.yahoo.com>
Message-ID: <7AA3622A-9144-40A6-9A9B-A499A3ACFBB2@r-project.org>

On Feb 15, 2013, at 11:36 AM, Hin-Tak Leung wrote:

> --- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
>> On Feb 15, 2013, at 9:11 AM, Hin-Tak
>> Leung wrote:
>> 
>>> Somebody else had written separately about this before,
>> and so have I a couple of months ago. I assumed this will be
>> fixed before the next R. Since R 3.0 is supposedly only 6
>> weeks away, even if it is fixed now it doesn't leave much
>> room for testing. 
>>> 
>>> Anyway neither Matrix 1.0-11 (current) nor 1.0-9 (sept
>> 2012) build with current R trunk.  The  last time
>> it did was 1. 0-9 on 3rd october over 4 months ago. So it
>> appears to be due to change inside r trunk in sept or early
>> oct. 
>>> 
>> 
>> No problem here - Matrix 1.0-11 and R-devel build just fine
>> with your flags (tested on Ubuntu 12.10, x86_64).
>> 
>> If in doubt, please remove R-devel and checkout a fresh
>> copy. Also FWIW it's a bad practice to build inside the
>> sources - it often causes all sorts of problems when you try
>> to track the sources and stale files are probably what's
>> hitting you.
>> 
>> FWIW: This is likely not the problem you're mentioning, but
>> some recent gcc versions break and LTO is also known to
>> cause issues depending on the compiler version, so tread
>> lightly on the cutting edge.
> 
> 
> Here is a fairly similar post:
> http://r.789695.n4.nabble.com/Build-from-Source-fails-on-Loading-required-package-Matrix-td4640371.html
> 
> The eventual "solution" of that thread seems to be building from tar ball, which is quite beside the whole point of building from svn trunk.
> 

And how is that relevant to what I said? Did you follow the advice I sent? If you did and still have an issue, post *exact* details on what you did, what system and tools you are using. 


> FWIW, it is very unproductive to talk about "bad practice" - in a hand-waving undocumented/unsubstantiated manner

Building in sources has two problems: a) the content of the source tree can change so subsequent builds can be different from the clean one - you cannot undo that and b) if you update the sources stale files from previous builds can break the build. 

If solving your problems is "unproductive" then I'm not surprised you have them for 4 moths now.


> - and options that might or might not work. If "--enable-lto" (or any other options, or build within the dev directory) does not work reliably, it should be either disabled/removed, or documented, or both.

R cannot test all aspects of a compiler and detect all its bugs. It is *your* responsibility to provide a working compiler - if you are unwilling to do that, R cannot do anything about that.


> Anyway, it has not been working for over 4 months.
> 

That is not true, obviously, and I have presented a counter-example. It may not have been working for *you* and it's likely a problem in your setup (given your lack of cooperation there is no way to tell for sure). We cannot prevent user errors. We can try to point people in the right direction, but if they refuse to listen it's on their head.


> You have about 6 weeks before this becomes a big problem - "big" as in "wide-spread".
> 

You are yet to show that this is a problem in R at all. You failed to follow the basic instructions in the FAQ.

Cheers,
Simon



>> Cheers,
>> Simon
>> 
>> 
>>> 
>>> ----------------
>>> Loading required package: Matrix
>>> Error in namespaceExport(ns, exports) : undefined
>> exports: .M.classEnv
>>> Error : require(Matrix) is not TRUE
>>> ERROR: installing package indices failed
>>> * removing ?/svn-loc/R/library/Matrix?
>>> * restoring previous ?/svn-loc/R/library/Matrix?
>>> make[2]: *** [Matrix.ts] Error 1
>>> make[2]: Leaving directory
>> `/svn-loc/R/src/library/Recommended'
>>> make[1]: *** [recommended-packages] Error 2
>>> make[1]: Leaving directory
>> `/svn-loc/R/src/library/Recommended'
>>> make: *** [stamp-recommended] Error 2
>>> ----------------
>>> 
>>> If it matters, here is what r trunk built with:
>>> ./configure --enable-memory-profiling
>> --enable-strict-barrier --enable-byte-compiled-packages
>> --with-valgrind-instrumentation=2 --enable-lto
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org
>> mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> 


From kasperdanielhansen at gmail.com  Fri Feb 15 19:19:37 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Fri, 15 Feb 2013 13:19:37 -0500
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <7AA3622A-9144-40A6-9A9B-A499A3ACFBB2@r-project.org>
References: <1360946186.76087.YahooMailClassic@web172301.mail.ir2.yahoo.com>
	<7AA3622A-9144-40A6-9A9B-A499A3ACFBB2@r-project.org>
Message-ID: <CAC2h7uv_EHwcZOqdVh7-WM1K-8C+ARTR0EoDM-un4iuas8hFaw@mail.gmail.com>

I build from svn daily and I have not had this problem.  I build in a
tree separate from the source tree.

I do think Hin-Tak has a point about clearly specifying that this is
how you should do it, in the manual (if that has not already
happened).  As a casual user, I would expect make clean to clean out
any stale files, but perhaps that is not happening.  Anyway, seems
more to be a possible documentation problem.

Kasper

On Fri, Feb 15, 2013 at 1:08 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> On Feb 15, 2013, at 11:36 AM, Hin-Tak Leung wrote:
>
>> --- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>>
>>> On Feb 15, 2013, at 9:11 AM, Hin-Tak
>>> Leung wrote:
>>>
>>>> Somebody else had written separately about this before,
>>> and so have I a couple of months ago. I assumed this will be
>>> fixed before the next R. Since R 3.0 is supposedly only 6
>>> weeks away, even if it is fixed now it doesn't leave much
>>> room for testing.
>>>>
>>>> Anyway neither Matrix 1.0-11 (current) nor 1.0-9 (sept
>>> 2012) build with current R trunk.  The  last time
>>> it did was 1. 0-9 on 3rd october over 4 months ago. So it
>>> appears to be due to change inside r trunk in sept or early
>>> oct.
>>>>
>>>
>>> No problem here - Matrix 1.0-11 and R-devel build just fine
>>> with your flags (tested on Ubuntu 12.10, x86_64).
>>>
>>> If in doubt, please remove R-devel and checkout a fresh
>>> copy. Also FWIW it's a bad practice to build inside the
>>> sources - it often causes all sorts of problems when you try
>>> to track the sources and stale files are probably what's
>>> hitting you.
>>>
>>> FWIW: This is likely not the problem you're mentioning, but
>>> some recent gcc versions break and LTO is also known to
>>> cause issues depending on the compiler version, so tread
>>> lightly on the cutting edge.
>>
>>
>> Here is a fairly similar post:
>> http://r.789695.n4.nabble.com/Build-from-Source-fails-on-Loading-required-package-Matrix-td4640371.html
>>
>> The eventual "solution" of that thread seems to be building from tar ball, which is quite beside the whole point of building from svn trunk.
>>
>
> And how is that relevant to what I said? Did you follow the advice I sent? If you did and still have an issue, post *exact* details on what you did, what system and tools you are using.
>
>
>> FWIW, it is very unproductive to talk about "bad practice" - in a hand-waving undocumented/unsubstantiated manner
>
> Building in sources has two problems: a) the content of the source tree can change so subsequent builds can be different from the clean one - you cannot undo that and b) if you update the sources stale files from previous builds can break the build.
>
> If solving your problems is "unproductive" then I'm not surprised you have them for 4 moths now.
>
>
>> - and options that might or might not work. If "--enable-lto" (or any other options, or build within the dev directory) does not work reliably, it should be either disabled/removed, or documented, or both.
>
> R cannot test all aspects of a compiler and detect all its bugs. It is *your* responsibility to provide a working compiler - if you are unwilling to do that, R cannot do anything about that.
>
>
>> Anyway, it has not been working for over 4 months.
>>
>
> That is not true, obviously, and I have presented a counter-example. It may not have been working for *you* and it's likely a problem in your setup (given your lack of cooperation there is no way to tell for sure). We cannot prevent user errors. We can try to point people in the right direction, but if they refuse to listen it's on their head.
>
>
>> You have about 6 weeks before this becomes a big problem - "big" as in "wide-spread".
>>
>
> You are yet to show that this is a problem in R at all. You failed to follow the basic instructions in the FAQ.
>
> Cheers,
> Simon
>
>
>
>>> Cheers,
>>> Simon
>>>
>>>
>>>>
>>>> ----------------
>>>> Loading required package: Matrix
>>>> Error in namespaceExport(ns, exports) : undefined
>>> exports: .M.classEnv
>>>> Error : require(Matrix) is not TRUE
>>>> ERROR: installing package indices failed
>>>> * removing ?/svn-loc/R/library/Matrix?
>>>> * restoring previous ?/svn-loc/R/library/Matrix?
>>>> make[2]: *** [Matrix.ts] Error 1
>>>> make[2]: Leaving directory
>>> `/svn-loc/R/src/library/Recommended'
>>>> make[1]: *** [recommended-packages] Error 2
>>>> make[1]: Leaving directory
>>> `/svn-loc/R/src/library/Recommended'
>>>> make: *** [stamp-recommended] Error 2
>>>> ----------------
>>>>
>>>> If it matters, here is what r trunk built with:
>>>> ./configure --enable-memory-profiling
>>> --enable-strict-barrier --enable-byte-compiled-packages
>>> --with-valgrind-instrumentation=2 --enable-lto
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org
>>> mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Fri Feb 15 19:53:08 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 15 Feb 2013 10:53:08 -0800
Subject: [Rd] Suggestion: Custom filename patterns for non-Sweave
	vignettes
In-Reply-To: <511DFC9F.4020209@gmail.com>
References: <CAFDcVCQs4GEYznPmqkz=gRuq2=KEWMnOqsSq3fGU92mUN0hbUA@mail.gmail.com>
	<511DFC9F.4020209@gmail.com>
Message-ID: <CAFDcVCQjsAWbf7WbJrar_Z0XJqTe8EwywOvOUq=-o7wAxOkE8Q@mail.gmail.com>

Hi Duncan,

thanks you for your prompt reply.


On Fri, Feb 15, 2013 at 1:15 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> There are several reasons I decided against that:
>
>   - two packages may request overlapping patterns, making it much messier to
> do the matching, checking etc, since the matching would have to depend on
> the package being processed.

So, isn't that somewhat already taken care of by the 'VignetteBuilder'
field in DESCRIPTION?  It specifies additional builders in addition to
the default/builtin Sweave builder.  Conflicts would only happen if a
package developer (e.g. PkgA) includes a pattern that either (A)
overrides the builtin in "[.][RrSs](nw|tex)$" / "[.]Rmd$" patterns, or
(B) specifies to builders with the same patterns.  First of all, there
are not that many builder packages, so this is something that could be
negotiated among those to minimize conflicts.  Second, case (A) can be
protected against by not allowing builder packages (e.g. knitr, rsp,
...) to add/register those patterns (tricky but possible to test for)
(but only default to them if that is what they wish to use).  For case
(B), the developer of package PkgA has the power to avoid conflicts.
One could also imagine the ordering of packages listed in
'VignetteBuilder' would provide a prioritization.

BTW, case (A) is basically what the new design is already providing;
all builder packages use the same patterns.

So, from a package building point of view, I don't see how this would
make it messier.  I can see that when checking a package it is harder
to validate matches between input and output formats (is that done?).
Let me know if I simplifying things too much - then I'll read up on
the 'R CMD *' source code.

>
>   - one package may request a pattern that another package uses for
> auxiliary files, e.g. .bib.  If a user has both types of vignette it would
> just be a mess.

I see your concern, but is there really a significant risk for this?
And if it would occur, (i) it would be contained to PkgA, (ii) the
developer of package PkgA would quickly detect it, and (iii) the
"badly behaving" builder package would rather soon flagged as doing
something bad (and its developer would be informed and so on).

>
>   - the extension is also used to determine the output format.  We only
> support LaTeX (which will be converted to PDF) and HTML output.  It would be
> reasonable to support direct PDF output, but I don't think any other output
> formats should be supported.

Yes, supporting PDF output makes sense.  One may also consider
generation of plain *.txt files (think README.txt and similar).  As I
see it, the restriction on supported *output* formats are given by
what the R help system wish to support (which is basically *.pdf and
*.html documents).  It's clear that the decision on what to support is
up to the maintainer of the R system (i.e. R core).

When it comes to input/source files for generating those output files,
it's harder to argue for restrictions.  As I understand it, the new
support for non-Sweave vignettes is moving away from such restriction,
which is great.  Despite the restrictions on file extension, it is
possible to "hijack" (my words) any of the supported extension for
whatever reason you want, as long as you produce a *.pdf or *.html
document in the end.  More below...

>
> I understand that forcing you to use .Rmd instead of .html.rsp may look
> unsightly, but I think the extensions need to be fixed, not customizable.

I still find it unfortunate that the R system opens up for processing
any type of input files but enforces those to have certain filename
extensions.

As a real example, today Sweave and knitr both use *.Rnw.  This means
that if I send someone a standalone *.Rnw file, they will not be able
to tell how to compile it without further instructions from me or by
inspecting the content type, or by trial and error.  I believe that
makes reproducible research a bit more tedious.  With unique filename
extensions, life is easier.  It's easy to imagine that if other
builder packages (e.g. R.rsp, brew, ...) also start using *.Rnw,
things are not going to become better.  The current "rules" are
pushing things in that direction.  To take an extreme stand, it's a
little bit like using *.txt for all your C, C++, Erlang, Fortran,
Simula, ... code, because it in the end of the day they all compile to
binaries anyway.

One may argue that the Rnw/Rtex/Rmd extensions only apply to the R
package vignettes and you can still use other extensions when you work
with standalone vignette source files.  That's of course also
unfortunate, because that will add additional confusion, e.g "You can
find the vignette in my package, but by the way you should really
rename it because ...".  The exact same source file will have
different extensions depending on context.  (In my own case, I found
*.tex.rsp, *.html.rsp, *.md.rsp, *.Rnw.rsp, ... to be much less
ambiguous and I prefer not to introduce ambiguity in mapping those to
*.Rnw/*.Rtex/*.Rmd.)

Finally, the supported extensions are basically *.Rnw, *.Rtex and
*.Rmd.  To break those down, "*nw" originates from 'Noweb'
[http://wikipedia.org/wiki/Noweb], "*tex" from TeX
[http://wikipedia.org/wiki/latex] and "*md" from Markdown
[wikipedia.org/wiki/Markdown].  The "R*" part indicates that there is
some additional markup format to those file formats.  But in the end
of the day, they indicate that the source files should be
markup-embedded files containing some flavor of Noweb, TeX or
Markdown.  I find it weird to use those also for, say, formats such as
HTML, reStructuredText, AsciiDoc, MediaWiki, Org-Mode etc.


To summarize, I really appreciate the move to a built-in support for
non-Sweave vignettes (without using custom Makefiles), but I find that
the supported filename extensions has not been brought along in this
move.


Thanks again,

Henrik

>
> Duncan Murdoch
>
>
> On 13-02-14 10:29 PM, Henrik Bengtsson wrote:
>>
>> Hi,
>>
>> as far as I understand it, the new R devel feature of processing
>> non-Sweave vignettes will (a) locate any "[.][RrSs](nw|tex)$" or
>> ".Rmd" files, (b) check for a registered vignette engine, (c) process
>> the file using the registered "weave" function, (d) and possibly post
>> process the generated weave artifact (e.g. a *.tex file).
>>
>> I'd like to propose to extend this non-Sweave mechanism to allow for
>> any filename patterns still using a very similar setup.  Here is how
>> I'd like it to see it work with RSP vignettes (cf. the R.rsp package):
>>
>>    tools::vignetteEngine("rsp", weave=rspWeave, tangle=rspTangle,
>> patterns="[.]rsp$")
>>
>> Argument 'patterns' could default to patterns=c("[.][RrSs](nw|tex)$",
>> "[.]Rmd$").
>>
>> This is just a sketch/mock up and it may be that there are better
>> solutions.  However, the idea is that when specify 'VignetteBuilder:
>> R.rsp' in DESCRIPTION of a package, R locates all engines registered
>> by the builder package.  In this case it finds 'rsp'.  (An alternative
>> to this lookup would be to use a DESCRIPTION field 'VignetteEngines:
>> R.rsp:rsp, knitr:knitr'.)  It next looks for custom filename patterns
>> and use those to scan for vignette source files.  With this approach,
>> the '%\VignetteEngine{knitr}' specifier would become optional.  (I can
>> see how R now scans for Rnw and Rmd files, checks them for a
>> \VignetteEngine{} markup, and then looks up the corresponding engine).
>>
>> Continuing, the above would make it possible to process RSP vignettes
>> that have filenames:
>>
>>    reportA.tex.rsp
>>    reportB.html.rsp
>>    reportC.md.rsp
>>    reportD.Rnw.rsp
>>
>> where rspWeave() will produce the following files:
>>
>>    reportA.tex
>>    reportB.html
>>    reportC.html
>>    reportD.tex
>>
>> I included the latter case just to illustrate a special case where
>> rspWeave() first generates a reportC.Rnw (Sweave or knitr) which is
>> the processed using the corresponding weaver to generate reportC.tex.
>>
>> My point is that restricting vignette filenames to ".[RrSs](nw|tex)$"
>> or ".Rmd" is unnecessary and conceptually it would not be too hard to
>> extend it to handle any filename patterns.
>>
>> I am aware that implementing this would require updates in several
>> place.  If R core would approve on the above extended functionality, I
>> would be happy to dig into the source code and provide minimal and
>> backward compatible patches.
>>
>> Finally, without knowing the details of all the other report
>> generating packages, my guess is that this extended feature would be
>> useful also for some of those packages, which in the long run
>> hopefully results in more packages having more vignettes (regardless
>> of the vignette format).
>>
>> All the best,
>>
>> Henrik
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From htl10 at users.sourceforge.net  Fri Feb 15 19:55:28 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Fri, 15 Feb 2013 18:55:28 +0000 (GMT)
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <7AA3622A-9144-40A6-9A9B-A499A3ACFBB2@r-project.org>
Message-ID: <1360954528.30906.YahooMailClassic@web172303.mail.ir2.yahoo.com>

Look. I don't see this as "my" problem - as far as I am concerned, I have donated my time - and over and over - to testing pre-released code. I am not using pre-released code for production work. If the released code in 3.0 does not work correctly in 6 weeks' time, I just don't upgrade. No loss for me there.

I don't know why it is degenerating into another distraction about some people's egos.

--- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> On Feb 15, 2013, at 11:36 AM, Hin-Tak
> Leung wrote:
> 
> > --- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org>
> wrote:
> > 
> >> On Feb 15, 2013, at 9:11 AM, Hin-Tak
> >> Leung wrote:
> >> 
> >>> Somebody else had written separately about this
> before,
> >> and so have I a couple of months ago. I assumed
> this will be
> >> fixed before the next R. Since R 3.0 is supposedly
> only 6
> >> weeks away, even if it is fixed now it doesn't
> leave much
> >> room for testing. 
> >>> 
> >>> Anyway neither Matrix 1.0-11 (current) nor
> 1.0-9 (sept
> >> 2012) build with current R trunk.? The?
> last time
> >> it did was 1. 0-9 on 3rd october over 4 months ago.
> So it
> >> appears to be due to change inside r trunk in sept
> or early
> >> oct. 
> >>> 
> >> 
> >> No problem here - Matrix 1.0-11 and R-devel build
> just fine
> >> with your flags (tested on Ubuntu 12.10, x86_64).
> >> 
> >> If in doubt, please remove R-devel and checkout a
> fresh
> >> copy. Also FWIW it's a bad practice to build inside
> the
> >> sources - it often causes all sorts of problems
> when you try
> >> to track the sources and stale files are probably
> what's
> >> hitting you.
> >> 
> >> FWIW: This is likely not the problem you're
> mentioning, but
> >> some recent gcc versions break and LTO is also
> known to
> >> cause issues depending on the compiler version, so
> tread
> >> lightly on the cutting edge.
> > 
> > 
> > Here is a fairly similar post:
> > http://r.789695.n4.nabble.com/Build-from-Source-fails-on-Loading-required-package-Matrix-td4640371.html
> > 
> > The eventual "solution" of that thread seems to be
> building from tar ball, which is quite beside the whole
> point of building from svn trunk.
> > 
> 
> And how is that relevant to what I said? Did you follow the
> advice I sent? If you did and still have an issue, post
> *exact* details on what you did, what system and tools you
> are using. 
> 
> 
> > FWIW, it is very unproductive to talk about "bad
> practice" - in a hand-waving undocumented/unsubstantiated
> manner
> 
> Building in sources has two problems: a) the content of the
> source tree can change so subsequent builds can be different
> from the clean one - you cannot undo that and b) if you
> update the sources stale files from previous builds can
> break the build. 
> 
> If solving your problems is "unproductive" then I'm not
> surprised you have them for 4 moths now.
> 
> 
> > - and options that might or might not work. If
> "--enable-lto" (or any other options, or build within the
> dev directory) does not work reliably, it should be either
> disabled/removed, or documented, or both.
> 
> R cannot test all aspects of a compiler and detect all its
> bugs. It is *your* responsibility to provide a working
> compiler - if you are unwilling to do that, R cannot do
> anything about that.
> 
> 
> > Anyway, it has not been working for over 4 months.
> > 
> 
> That is not true, obviously, and I have presented a
> counter-example. It may not have been working for *you* and
> it's likely a problem in your setup (given your lack of
> cooperation there is no way to tell for sure). We cannot
> prevent user errors. We can try to point people in the right
> direction, but if they refuse to listen it's on their head.
> 
> 
> > You have about 6 weeks before this becomes a big
> problem - "big" as in "wide-spread".
> > 
> 
> You are yet to show that this is a problem in R at all. You
> failed to follow the basic instructions in the FAQ.
> 
> Cheers,
> Simon
> 
> 
> 
> >> Cheers,
> >> Simon
> >> 
> >> 
> >>> 
> >>> ----------------
> >>> Loading required package: Matrix
> >>> Error in namespaceExport(ns, exports) :
> undefined
> >> exports: .M.classEnv
> >>> Error : require(Matrix) is not TRUE
> >>> ERROR: installing package indices failed
> >>> * removing ?/svn-loc/R/library/Matrix?
> >>> * restoring previous
> ?/svn-loc/R/library/Matrix?
> >>> make[2]: *** [Matrix.ts] Error 1
> >>> make[2]: Leaving directory
> >> `/svn-loc/R/src/library/Recommended'
> >>> make[1]: *** [recommended-packages] Error 2
> >>> make[1]: Leaving directory
> >> `/svn-loc/R/src/library/Recommended'
> >>> make: *** [stamp-recommended] Error 2
> >>> ----------------
> >>> 
> >>> If it matters, here is what r trunk built
> with:
> >>> ./configure --enable-memory-profiling
> >> --enable-strict-barrier
> --enable-byte-compiled-packages
> >> --with-valgrind-instrumentation=2 --enable-lto
> >>> 
> >>> ______________________________________________
> >>> R-devel at r-project.org
> >> mailing list
> >>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >> 
> >> 
> > 
> > 
> 
>


From simon.urbanek at r-project.org  Fri Feb 15 20:03:46 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 15 Feb 2013 14:03:46 -0500
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <1360954528.30906.YahooMailClassic@web172303.mail.ir2.yahoo.com>
References: <1360954528.30906.YahooMailClassic@web172303.mail.ir2.yahoo.com>
Message-ID: <2B97A288-1898-4EF8-9351-3CA84F878C69@r-project.org>


On Feb 15, 2013, at 1:55 PM, Hin-Tak Leung wrote:

> Look. I don't see this as "my" problem - as far as I am concerned, I have donated my time - and over and over - to testing pre-released code. I am not using pre-released code for production work. If the released code in 3.0 does not work correctly in 6 weeks' time, I just don't upgrade. No loss for me there.
> 

It works - confirmed by several people. You have a problem, but you didn't tell us the specifics of the problem so there's nothing we can do.


> I don't know why it is degenerating into another distraction about some people's egos.
> 

I don't either - it's not productive.

Cheers,
Simon


> --- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> 
>> On Feb 15, 2013, at 11:36 AM, Hin-Tak
>> Leung wrote:
>> 
>>> --- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org>
>> wrote:
>>> 
>>>> On Feb 15, 2013, at 9:11 AM, Hin-Tak
>>>> Leung wrote:
>>>> 
>>>>> Somebody else had written separately about this
>> before,
>>>> and so have I a couple of months ago. I assumed
>> this will be
>>>> fixed before the next R. Since R 3.0 is supposedly
>> only 6
>>>> weeks away, even if it is fixed now it doesn't
>> leave much
>>>> room for testing. 
>>>>> 
>>>>> Anyway neither Matrix 1.0-11 (current) nor
>> 1.0-9 (sept
>>>> 2012) build with current R trunk.  The 
>> last time
>>>> it did was 1. 0-9 on 3rd october over 4 months ago.
>> So it
>>>> appears to be due to change inside r trunk in sept
>> or early
>>>> oct. 
>>>>> 
>>>> 
>>>> No problem here - Matrix 1.0-11 and R-devel build
>> just fine
>>>> with your flags (tested on Ubuntu 12.10, x86_64).
>>>> 
>>>> If in doubt, please remove R-devel and checkout a
>> fresh
>>>> copy. Also FWIW it's a bad practice to build inside
>> the
>>>> sources - it often causes all sorts of problems
>> when you try
>>>> to track the sources and stale files are probably
>> what's
>>>> hitting you.
>>>> 
>>>> FWIW: This is likely not the problem you're
>> mentioning, but
>>>> some recent gcc versions break and LTO is also
>> known to
>>>> cause issues depending on the compiler version, so
>> tread
>>>> lightly on the cutting edge.
>>> 
>>> 
>>> Here is a fairly similar post:
>>> http://r.789695.n4.nabble.com/Build-from-Source-fails-on-Loading-required-package-Matrix-td4640371.html
>>> 
>>> The eventual "solution" of that thread seems to be
>> building from tar ball, which is quite beside the whole
>> point of building from svn trunk.
>>> 
>> 
>> And how is that relevant to what I said? Did you follow the
>> advice I sent? If you did and still have an issue, post
>> *exact* details on what you did, what system and tools you
>> are using. 
>> 
>> 
>>> FWIW, it is very unproductive to talk about "bad
>> practice" - in a hand-waving undocumented/unsubstantiated
>> manner
>> 
>> Building in sources has two problems: a) the content of the
>> source tree can change so subsequent builds can be different
>> from the clean one - you cannot undo that and b) if you
>> update the sources stale files from previous builds can
>> break the build. 
>> 
>> If solving your problems is "unproductive" then I'm not
>> surprised you have them for 4 moths now.
>> 
>> 
>>> - and options that might or might not work. If
>> "--enable-lto" (or any other options, or build within the
>> dev directory) does not work reliably, it should be either
>> disabled/removed, or documented, or both.
>> 
>> R cannot test all aspects of a compiler and detect all its
>> bugs. It is *your* responsibility to provide a working
>> compiler - if you are unwilling to do that, R cannot do
>> anything about that.
>> 
>> 
>>> Anyway, it has not been working for over 4 months.
>>> 
>> 
>> That is not true, obviously, and I have presented a
>> counter-example. It may not have been working for *you* and
>> it's likely a problem in your setup (given your lack of
>> cooperation there is no way to tell for sure). We cannot
>> prevent user errors. We can try to point people in the right
>> direction, but if they refuse to listen it's on their head.
>> 
>> 
>>> You have about 6 weeks before this becomes a big
>> problem - "big" as in "wide-spread".
>>> 
>> 
>> You are yet to show that this is a problem in R at all. You
>> failed to follow the basic instructions in the FAQ.
>> 
>> Cheers,
>> Simon
>> 
>> 
>> 
>>>> Cheers,
>>>> Simon
>>>> 
>>>> 
>>>>> 
>>>>> ----------------
>>>>> Loading required package: Matrix
>>>>> Error in namespaceExport(ns, exports) :
>> undefined
>>>> exports: .M.classEnv
>>>>> Error : require(Matrix) is not TRUE
>>>>> ERROR: installing package indices failed
>>>>> * removing ?/svn-loc/R/library/Matrix?
>>>>> * restoring previous
>> ?/svn-loc/R/library/Matrix?
>>>>> make[2]: *** [Matrix.ts] Error 1
>>>>> make[2]: Leaving directory
>>>> `/svn-loc/R/src/library/Recommended'
>>>>> make[1]: *** [recommended-packages] Error 2
>>>>> make[1]: Leaving directory
>>>> `/svn-loc/R/src/library/Recommended'
>>>>> make: *** [stamp-recommended] Error 2
>>>>> ----------------
>>>>> 
>>>>> If it matters, here is what r trunk built
>> with:
>>>>> ./configure --enable-memory-profiling
>>>> --enable-strict-barrier
>> --enable-byte-compiled-packages
>>>> --with-valgrind-instrumentation=2 --enable-lto
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org
>>>> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>>> 
>>> 
>>> 
>> 
>> 
> 
> 


From htl10 at users.sourceforge.net  Fri Feb 15 20:13:16 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Fri, 15 Feb 2013 19:13:16 +0000 (GMT)
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <2B97A288-1898-4EF8-9351-3CA84F878C69@r-project.org>
Message-ID: <1360955596.66622.YahooMailClassic@web172302.mail.ir2.yahoo.com>

--- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> On Feb 15, 2013, at 1:55 PM, Hin-Tak Leung wrote:
> 
> > Look. I don't see this as "my" problem - as far as I am
> concerned, I have donated my time - and over and over - to
> testing pre-released code. I am not using pre-released code
> for production work. If the released code in 3.0 does not
> work correctly in 6 weeks' time, I just don't upgrade. No
> loss for me there.
> > 
> 
> It works - confirmed by several people. You have a problem,
> but you didn't tell us the specifics of the problem so
> there's nothing we can do.

I do not have a problem. I do not need to spend time regularly testing pre-release code, and I think I should stop.
 
> > I don't know why it is degenerating into another
> distraction about some people's egos.
> > 
> 
> I don't either - it's not productive.
> 
> Cheers,
> Simon
> 
> 
> > --- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org>
> wrote:
> > 
> >> On Feb 15, 2013, at 11:36 AM, Hin-Tak
> >> Leung wrote:
> >> 
> >>> --- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org>
> >> wrote:
> >>> 
> >>>> On Feb 15, 2013, at 9:11 AM, Hin-Tak
> >>>> Leung wrote:
> >>>> 
> >>>>> Somebody else had written separately
> about this
> >> before,
> >>>> and so have I a couple of months ago. I
> assumed
> >> this will be
> >>>> fixed before the next R. Since R 3.0 is
> supposedly
> >> only 6
> >>>> weeks away, even if it is fixed now it
> doesn't
> >> leave much
> >>>> room for testing. 
> >>>>> 
> >>>>> Anyway neither Matrix 1.0-11 (current)
> nor
> >> 1.0-9 (sept
> >>>> 2012) build with current R trunk.? The
> 
> >> last time
> >>>> it did was 1. 0-9 on 3rd october over 4
> months ago.
> >> So it
> >>>> appears to be due to change inside r trunk
> in sept
> >> or early
> >>>> oct. 
> >>>>> 
> >>>> 
> >>>> No problem here - Matrix 1.0-11 and R-devel
> build
> >> just fine
> >>>> with your flags (tested on Ubuntu 12.10,
> x86_64).
> >>>> 
> >>>> If in doubt, please remove R-devel and
> checkout a
> >> fresh
> >>>> copy. Also FWIW it's a bad practice to
> build inside
> >> the
> >>>> sources - it often causes all sorts of
> problems
> >> when you try
> >>>> to track the sources and stale files are
> probably
> >> what's
> >>>> hitting you.
> >>>> 
> >>>> FWIW: This is likely not the problem
> you're
> >> mentioning, but
> >>>> some recent gcc versions break and LTO is
> also
> >> known to
> >>>> cause issues depending on the compiler
> version, so
> >> tread
> >>>> lightly on the cutting edge.
> >>> 
> >>> 
> >>> Here is a fairly similar post:
> >>> http://r.789695.n4.nabble.com/Build-from-Source-fails-on-Loading-required-package-Matrix-td4640371.html
> >>> 
> >>> The eventual "solution" of that thread seems to
> be
> >> building from tar ball, which is quite beside the
> whole
> >> point of building from svn trunk.
> >>> 
> >> 
> >> And how is that relevant to what I said? Did you
> follow the
> >> advice I sent? If you did and still have an issue,
> post
> >> *exact* details on what you did, what system and
> tools you
> >> are using. 
> >> 
> >> 
> >>> FWIW, it is very unproductive to talk about
> "bad
> >> practice" - in a hand-waving
> undocumented/unsubstantiated
> >> manner
> >> 
> >> Building in sources has two problems: a) the
> content of the
> >> source tree can change so subsequent builds can be
> different
> >> from the clean one - you cannot undo that and b) if
> you
> >> update the sources stale files from previous builds
> can
> >> break the build. 
> >> 
> >> If solving your problems is "unproductive" then I'm
> not
> >> surprised you have them for 4 moths now.
> >> 
> >> 
> >>> - and options that might or might not work. If
> >> "--enable-lto" (or any other options, or build
> within the
> >> dev directory) does not work reliably, it should be
> either
> >> disabled/removed, or documented, or both.
> >> 
> >> R cannot test all aspects of a compiler and detect
> all its
> >> bugs. It is *your* responsibility to provide a
> working
> >> compiler - if you are unwilling to do that, R
> cannot do
> >> anything about that.
> >> 
> >> 
> >>> Anyway, it has not been working for over 4
> months.
> >>> 
> >> 
> >> That is not true, obviously, and I have presented
> a
> >> counter-example. It may not have been working for
> *you* and
> >> it's likely a problem in your setup (given your
> lack of
> >> cooperation there is no way to tell for sure). We
> cannot
> >> prevent user errors. We can try to point people in
> the right
> >> direction, but if they refuse to listen it's on
> their head.
> >> 
> >> 
> >>> You have about 6 weeks before this becomes a
> big
> >> problem - "big" as in "wide-spread".
> >>> 
> >> 
> >> You are yet to show that this is a problem in R at
> all. You
> >> failed to follow the basic instructions in the
> FAQ.
> >> 
> >> Cheers,
> >> Simon
> >> 
> >> 
> >> 
> >>>> Cheers,
> >>>> Simon
> >>>> 
> >>>> 
> >>>>> 
> >>>>> ----------------
> >>>>> Loading required package: Matrix
> >>>>> Error in namespaceExport(ns, exports)
> :
> >> undefined
> >>>> exports: .M.classEnv
> >>>>> Error : require(Matrix) is not TRUE
> >>>>> ERROR: installing package indices
> failed
> >>>>> * removing
> ?/svn-loc/R/library/Matrix?
> >>>>> * restoring previous
> >> ?/svn-loc/R/library/Matrix?
> >>>>> make[2]: *** [Matrix.ts] Error 1
> >>>>> make[2]: Leaving directory
> >>>> `/svn-loc/R/src/library/Recommended'
> >>>>> make[1]: *** [recommended-packages]
> Error 2
> >>>>> make[1]: Leaving directory
> >>>> `/svn-loc/R/src/library/Recommended'
> >>>>> make: *** [stamp-recommended] Error 2
> >>>>> ----------------
> >>>>> 
> >>>>> If it matters, here is what r trunk
> built
> >> with:
> >>>>> ./configure --enable-memory-profiling
> >>>> --enable-strict-barrier
> >> --enable-byte-compiled-packages
> >>>> --with-valgrind-instrumentation=2
> --enable-lto
> >>>>> 
> >>>>>
> ______________________________________________
> >>>>> R-devel at r-project.org
> >>>> mailing list
> >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> >>>> 
> >>>> 
> >>> 
> >>> 
> >> 
> >> 
> > 
> > 
> 
>


From murdoch.duncan at gmail.com  Fri Feb 15 20:30:40 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 15 Feb 2013 14:30:40 -0500
Subject: [Rd] Suggestion: Custom filename patterns for non-Sweave
	vignettes
In-Reply-To: <CAFDcVCQjsAWbf7WbJrar_Z0XJqTe8EwywOvOUq=-o7wAxOkE8Q@mail.gmail.com>
References: <CAFDcVCQs4GEYznPmqkz=gRuq2=KEWMnOqsSq3fGU92mUN0hbUA@mail.gmail.com>
	<511DFC9F.4020209@gmail.com>
	<CAFDcVCQjsAWbf7WbJrar_Z0XJqTe8EwywOvOUq=-o7wAxOkE8Q@mail.gmail.com>
Message-ID: <511E8CE0.5070403@gmail.com>

On 13-02-15 1:53 PM, Henrik Bengtsson wrote:
> Hi Duncan,
>
> thanks you for your prompt reply.
>
>
> On Fri, Feb 15, 2013 at 1:15 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> There are several reasons I decided against that:
>>
>>    - two packages may request overlapping patterns, making it much messier to
>> do the matching, checking etc, since the matching would have to depend on
>> the package being processed.
>
> So, isn't that somewhat already taken care of by the 'VignetteBuilder'
> field in DESCRIPTION?  It specifies additional builders in addition to
> the default/builtin Sweave builder.

No, it specifies additional packages besides utils.  Packages may 
specify multiple engines.  For example, knitr can handle Sweave-like 
knitr vignettes, and markdown-based vignettes.  Yihui chose to use the 
same engine for both, but it might make more sense to specify different 
engines.

So a user might say they want a knitr vignette and a .html.rsp vignette. 
  But perhaps in the meantime, Yihui added an engine that can handle 
.rsp files.  So the user would have to list both packages, and there 
would be an ambiguity as to which one should be run.  You might say 
that's the user's problem, but they wouldn't complain to themselves, 
they'd complain to me, so it's my problem.

It would be possible to design all of this to work:  the engine could 
check the file and say "oops, that's not my kind of .rsp file, try the 
next engine".  I just don't think it's worth it.  I certainly don't have 
time to design and program it or even to check your offered patch before 
feature freeze.  I can make small tweaks, but big changes that need lots 
of testing aren't going to happen.


  Conflicts would only happen if a
> package developer (e.g. PkgA) includes a pattern that either (A)
> overrides the builtin in "[.][RrSs](nw|tex)$" / "[.]Rmd$" patterns, or
> (B) specifies to builders with the same patterns.  First of all, there
> are not that many builder packages, so this is something that could be
> negotiated among those to minimize conflicts.  Second, case (A) can be
> protected against by not allowing builder packages (e.g. knitr, rsp,
> ...) to add/register those patterns (tricky but possible to test for)

I don't think it's feasible to check for overlap in regular expression 
patterns.

> (but only default to them if that is what they wish to use).  For case
> (B), the developer of package PkgA has the power to avoid conflicts.
> One could also imagine the ordering of packages listed in
> 'VignetteBuilder' would provide a prioritization.

Sure, but it would be confusing to get an error from knitr when you 
didn't know knitr was handling .rsp.

> BTW, case (A) is basically what the new design is already providing;
> all builder packages use the same patterns.
>
> So, from a package building point of view, I don't see how this would
> make it messier.  I can see that when checking a package it is harder
> to validate matches between input and output formats (is that done?).
> Let me know if I simplifying things too much - then I'll read up on
> the 'R CMD *' source code.
>
>>
>>    - one package may request a pattern that another package uses for
>> auxiliary files, e.g. .bib.  If a user has both types of vignette it would
>> just be a mess.
>
> I see your concern, but is there really a significant risk for this?

If you look through CRAN, you'll see packages that do very weird things. 
  If it's legal, someone will try it.


> And if it would occur, (i) it would be contained to PkgA, (ii) the
> developer of package PkgA would quickly detect it, and (iii) the
> "badly behaving" builder package would rather soon flagged as doing
> something bad (and its developer would be informed and so on).
>
>>
>>    - the extension is also used to determine the output format.  We only
>> support LaTeX (which will be converted to PDF) and HTML output.  It would be
>> reasonable to support direct PDF output, but I don't think any other output
>> formats should be supported.
>
> Yes, supporting PDF output makes sense.  One may also consider
> generation of plain *.txt files (think README.txt and similar).  As I
> see it, the restriction on supported *output* formats are given by
> what the R help system wish to support (which is basically *.pdf and
> *.html documents).  It's clear that the decision on what to support is
> up to the maintainer of the R system (i.e. R core).
>
> When it comes to input/source files for generating those output files,
> it's harder to argue for restrictions.  As I understand it, the new
> support for non-Sweave vignettes is moving away from such restriction,
> which is great.  Despite the restrictions on file extension, it is
> possible to "hijack" (my words) any of the supported extension for
> whatever reason you want, as long as you produce a *.pdf or *.html
> document in the end.  More below...

The issue is that the supplier of a custom input extension would also 
need to specify what kind of output it produced, so R knows how to 
handle it.  That makes it more complicated, harder to test, etc.
>
>>
>> I understand that forcing you to use .Rmd instead of .html.rsp may look
>> unsightly, but I think the extensions need to be fixed, not customizable.
>
> I still find it unfortunate that the R system opens up for processing
> any type of input files but enforces those to have certain filename
> extensions.
>
> As a real example, today Sweave and knitr both use *.Rnw.  This means
> that if I send someone a standalone *.Rnw file, they will not be able
> to tell how to compile it without further instructions from me or by
> inspecting the content type, or by trial and error.  I believe that
> makes reproducible research a bit more tedious.  With unique filename
> extensions, life is easier.  It's easy to imagine that if other
> builder packages (e.g. R.rsp, brew, ...) also start using *.Rnw,
> things are not going to become better.  The current "rules" are
> pushing things in that direction.  To take an extreme stand, it's a
> little bit like using *.txt for all your C, C++, Erlang, Fortran,
> Simula, ... code, because it in the end of the day they all compile to
> binaries anyway.

I agree to some extent, but if sending someone an Rnw causes problems, 
then don't do that.  Rename it before you send it.  Or rename it to Rnw 
when you put it in the vignettes directory.

>
> One may argue that the Rnw/Rtex/Rmd extensions only apply to the R
> package vignettes and you can still use other extensions when you work
> with standalone vignette source files.  That's of course also
> unfortunate, because that will add additional confusion, e.g "You can
> find the vignette in my package, but by the way you should really
> rename it because ...".  The exact same source file will have
> different extensions depending on context.  (In my own case, I found
> *.tex.rsp, *.html.rsp, *.md.rsp, *.Rnw.rsp, ... to be much less
> ambiguous and I prefer not to introduce ambiguity in mapping those to
> *.Rnw/*.Rtex/*.Rmd.)

You could map them to .tex.Rnw, .html.Rmd, .Rnw.Rnw, and your engine 
could do what it does now with *.rsp files.
>
> Finally, the supported extensions are basically *.Rnw, *.Rtex and
> *.Rmd.  To break those down, "*nw" originates from 'Noweb'
> [http://wikipedia.org/wiki/Noweb], "*tex" from TeX
> [http://wikipedia.org/wiki/latex] and "*md" from Markdown
> [wikipedia.org/wiki/Markdown].  The "R*" part indicates that there is
> some additional markup format to those file formats.  But in the end
> of the day, they indicate that the source files should be
> markup-embedded files containing some flavor of Noweb, TeX or
> Markdown.  I find it weird to use those also for, say, formats such as
> HTML, reStructuredText, AsciiDoc, MediaWiki, Org-Mode etc.

That's the etymology, not the meaning.
>
>
> To summarize, I really appreciate the move to a built-in support for
> non-Sweave vignettes (without using custom Makefiles), but I find that
> the supported filename extensions has not been brought along in this
> move.
>

There's always time to argue for R 3.1.0.

Duncan Murdoch


From htl10 at users.sourceforge.net  Sat Feb 16 00:13:50 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Fri, 15 Feb 2013 23:13:50 +0000 (GMT)
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <1360937461.70374.BPMail_high_noncarrier@web172305.mail.ir2.yahoo.com>
Message-ID: <1360970030.67507.YahooMailClassic@web172304.mail.ir2.yahoo.com>

FWIW, extracting snapshot source elsewhere outside svn, run "tools/rsync-recommended" then just plain "./configure && make" doesn't work either. Nothing to do with building inside checkout nor extra configure options.

This is fedora 18, x86_64.

--- On Fri, 15/2/13, Hin-Tak Leung <htl10 at users.sourceforge.net> wrote:

> Somebody else had written separately about this before, and
> so have I a couple of months ago. I assumed this will be
> fixed before the next R. Since R 3.0 is supposedly only 6
> weeks away, even if it is fixed now it doesn't leave much
> room for testing. 
> 
> Anyway neither Matrix 1.0-11 (current) nor 1.0-9 (sept 2012)
> build with current R trunk.? The? last time it did
> was 1. 0-9 on 3rd october over 4 months ago. So it appears
> to be due to change inside r trunk in sept or early oct. 
> 
> 
> ----------------
> Loading required package: Matrix
> Error in namespaceExport(ns, exports) : undefined exports:
> .M.classEnv
> Error : require(Matrix) is not TRUE
> ERROR: installing package indices failed
> * removing ?/svn-loc/R/library/Matrix?
> * restoring previous ?/svn-loc/R/library/Matrix?
> make[2]: *** [Matrix.ts] Error 1
> make[2]: Leaving directory
> `/svn-loc/R/src/library/Recommended'
> make[1]: *** [recommended-packages] Error 2
> make[1]: Leaving directory
> `/svn-loc/R/src/library/Recommended'
> make: *** [stamp-recommended] Error 2
> ----------------
> 
> If it matters, here is what r trunk built with:
>  ./configure --enable-memory-profiling
> --enable-strict-barrier --enable-byte-compiled-packages
> --with-valgrind-instrumentation=2 --enable-lto
> 
> 
>


From tlumley at uw.edu  Sat Feb 16 02:24:44 2013
From: tlumley at uw.edu (Thomas Lumley)
Date: Sat, 16 Feb 2013 14:24:44 +1300
Subject: [Rd] stopping finalizers
In-Reply-To: <CABdHhvG+2mdXCpGdHn9DfzQpUsU3dAndPCZ+2eoof+gvShAUig@mail.gmail.com>
References: <CAJ55+dJogFHu3bXBFSjDGynsH0FKN4A15=5uWg_KS4XTaEOSCA@mail.gmail.com>
	<alpine.DEB.2.02.1302140544570.17940@luke-Latitude>
	<CAJ55+dJVjg9tN9RZB7Fk2twg-vO6zehXKFj2RU+HAhugVm9bsg@mail.gmail.com>
	<CABdHhvG+2mdXCpGdHn9DfzQpUsU3dAndPCZ+2eoof+gvShAUig@mail.gmail.com>
Message-ID: <CAJ55+dJdQ7tA9T2CHumhPWhqHm8dR76Aw_3A_fA4qnSV+wcLyg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130216/ef4ef424/attachment.pl>

From h.wickham at gmail.com  Sat Feb 16 02:32:41 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 15 Feb 2013 19:32:41 -0600
Subject: [Rd] stopping finalizers
In-Reply-To: <CAJ55+dJdQ7tA9T2CHumhPWhqHm8dR76Aw_3A_fA4qnSV+wcLyg@mail.gmail.com>
References: <CAJ55+dJogFHu3bXBFSjDGynsH0FKN4A15=5uWg_KS4XTaEOSCA@mail.gmail.com>
	<alpine.DEB.2.02.1302140544570.17940@luke-Latitude>
	<CAJ55+dJVjg9tN9RZB7Fk2twg-vO6zehXKFj2RU+HAhugVm9bsg@mail.gmail.com>
	<CABdHhvG+2mdXCpGdHn9DfzQpUsU3dAndPCZ+2eoof+gvShAUig@mail.gmail.com>
	<CAJ55+dJdQ7tA9T2CHumhPWhqHm8dR76Aw_3A_fA4qnSV+wcLyg@mail.gmail.com>
Message-ID: <CABdHhvFhboLO4Y5T9QLUhuEjRNtrd5yx2prEu90_qKoHFCdYRg@mail.gmail.com>

> The subset table isn't a copy of the subset, it contains the unique key and
> an indicator column showing whether the element is in the subset.  I need
> this even if the subset is never modified, so that I can join it to the main
> table and use it in SQL 'where' conditions to get computations for the right
> subset of the data.

Cool - Is that faster than storing a column that just contains the
include indices?

>  The whole point of this new sqlsurvey package is that most of the
> aggregation operations happen in the database rather than in R, which is
> faster for very large data tables.  The use case is things like the American
> Community Survey and the Nationwide Emergency Department Subsample, with
> millions or tens of millions of records and quite a lot of variables.  At
> this scale, loading stuff into memory isn't feasible on commodity desktops
> and laptops, and even on computers with enough memory, the database
> (MonetDB) is faster.

Have you done any comparisons of monetdb vs sqlite - I'm interested to
know how much faster it is. I'm working on a package
(https://github.com/hadley/dplyr) that compiles R data manipulation
expressions into (e.g. SQL), and have been wondering if it's worth
considering a column-store like monetdb.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From tlumley at uw.edu  Sat Feb 16 03:03:24 2013
From: tlumley at uw.edu (Thomas Lumley)
Date: Sat, 16 Feb 2013 15:03:24 +1300
Subject: [Rd] stopping finalizers
In-Reply-To: <CABdHhvFhboLO4Y5T9QLUhuEjRNtrd5yx2prEu90_qKoHFCdYRg@mail.gmail.com>
References: <CAJ55+dJogFHu3bXBFSjDGynsH0FKN4A15=5uWg_KS4XTaEOSCA@mail.gmail.com>
	<alpine.DEB.2.02.1302140544570.17940@luke-Latitude>
	<CAJ55+dJVjg9tN9RZB7Fk2twg-vO6zehXKFj2RU+HAhugVm9bsg@mail.gmail.com>
	<CABdHhvG+2mdXCpGdHn9DfzQpUsU3dAndPCZ+2eoof+gvShAUig@mail.gmail.com>
	<CAJ55+dJdQ7tA9T2CHumhPWhqHm8dR76Aw_3A_fA4qnSV+wcLyg@mail.gmail.com>
	<CABdHhvFhboLO4Y5T9QLUhuEjRNtrd5yx2prEu90_qKoHFCdYRg@mail.gmail.com>
Message-ID: <CAJ55+dKwNeVFiMSy8g0CzheYDkJKPNtau+pjdyj26nCEd+8Qfg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130216/6d54926b/attachment.pl>

From josh.m.ulrich at gmail.com  Fri Feb 15 19:25:52 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 15 Feb 2013 12:25:52 -0600
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <CAC2h7uv_EHwcZOqdVh7-WM1K-8C+ARTR0EoDM-un4iuas8hFaw@mail.gmail.com>
References: <1360946186.76087.YahooMailClassic@web172301.mail.ir2.yahoo.com>
	<7AA3622A-9144-40A6-9A9B-A499A3ACFBB2@r-project.org>
	<CAC2h7uv_EHwcZOqdVh7-WM1K-8C+ARTR0EoDM-un4iuas8hFaw@mail.gmail.com>
Message-ID: <CAPPM_gTnFFoF5tA8V5xUoHq9gxKfo94D3vowUpk_qo_CJf1bsA@mail.gmail.com>

On Fri, Feb 15, 2013 at 12:19 PM, Kasper Daniel Hansen
<kasperdanielhansen at gmail.com> wrote:
> I build from svn daily and I have not had this problem.  I build in a
> tree separate from the source tree.
>
> I do think Hin-Tak has a point about clearly specifying that this is
> how you should do it, in the manual (if that has not already
> happened).  As a casual user, I would expect make clean to clean out
> any stale files, but perhaps that is not happening.  Anyway, seems
> more to be a possible documentation problem.
>
It's already in the R Installation and Administration Manual:
http://cran.r-project.org/doc/manuals/R-admin.html#Simple-compilation

See the second-to-last paragraph.  It recommends you do not build in
the top-level source directory, particularly when you work with a
version of R from Subversion.

Best,
Josh

> Kasper
>
> On Fri, Feb 15, 2013 at 1:08 PM, Simon Urbanek
> <simon.urbanek at r-project.org> wrote:
>> On Feb 15, 2013, at 11:36 AM, Hin-Tak Leung wrote:
>>
>>> --- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>>>
>>>> On Feb 15, 2013, at 9:11 AM, Hin-Tak
>>>> Leung wrote:
>>>>
>>>>> Somebody else had written separately about this before,
>>>> and so have I a couple of months ago. I assumed this will be
>>>> fixed before the next R. Since R 3.0 is supposedly only 6
>>>> weeks away, even if it is fixed now it doesn't leave much
>>>> room for testing.
>>>>>
>>>>> Anyway neither Matrix 1.0-11 (current) nor 1.0-9 (sept
>>>> 2012) build with current R trunk.  The  last time
>>>> it did was 1. 0-9 on 3rd october over 4 months ago. So it
>>>> appears to be due to change inside r trunk in sept or early
>>>> oct.
>>>>>
>>>>
>>>> No problem here - Matrix 1.0-11 and R-devel build just fine
>>>> with your flags (tested on Ubuntu 12.10, x86_64).
>>>>
>>>> If in doubt, please remove R-devel and checkout a fresh
>>>> copy. Also FWIW it's a bad practice to build inside the
>>>> sources - it often causes all sorts of problems when you try
>>>> to track the sources and stale files are probably what's
>>>> hitting you.
>>>>
>>>> FWIW: This is likely not the problem you're mentioning, but
>>>> some recent gcc versions break and LTO is also known to
>>>> cause issues depending on the compiler version, so tread
>>>> lightly on the cutting edge.
>>>
>>>
>>> Here is a fairly similar post:
>>> http://r.789695.n4.nabble.com/Build-from-Source-fails-on-Loading-required-package-Matrix-td4640371.html
>>>
>>> The eventual "solution" of that thread seems to be building from tar ball, which is quite beside the whole point of building from svn trunk.
>>>
>>
>> And how is that relevant to what I said? Did you follow the advice I sent? If you did and still have an issue, post *exact* details on what you did, what system and tools you are using.
>>
>>
>>> FWIW, it is very unproductive to talk about "bad practice" - in a hand-waving undocumented/unsubstantiated manner
>>
>> Building in sources has two problems: a) the content of the source tree can change so subsequent builds can be different from the clean one - you cannot undo that and b) if you update the sources stale files from previous builds can break the build.
>>
>> If solving your problems is "unproductive" then I'm not surprised you have them for 4 moths now.
>>
>>
>>> - and options that might or might not work. If "--enable-lto" (or any other options, or build within the dev directory) does not work reliably, it should be either disabled/removed, or documented, or both.
>>
>> R cannot test all aspects of a compiler and detect all its bugs. It is *your* responsibility to provide a working compiler - if you are unwilling to do that, R cannot do anything about that.
>>
>>
>>> Anyway, it has not been working for over 4 months.
>>>
>>
>> That is not true, obviously, and I have presented a counter-example. It may not have been working for *you* and it's likely a problem in your setup (given your lack of cooperation there is no way to tell for sure). We cannot prevent user errors. We can try to point people in the right direction, but if they refuse to listen it's on their head.
>>
>>
>>> You have about 6 weeks before this becomes a big problem - "big" as in "wide-spread".
>>>
>>
>> You are yet to show that this is a problem in R at all. You failed to follow the basic instructions in the FAQ.
>>
>> Cheers,
>> Simon
>>
>>
>>
>>>> Cheers,
>>>> Simon
>>>>
>>>>
>>>>>
>>>>> ----------------
>>>>> Loading required package: Matrix
>>>>> Error in namespaceExport(ns, exports) : undefined
>>>> exports: .M.classEnv
>>>>> Error : require(Matrix) is not TRUE
>>>>> ERROR: installing package indices failed
>>>>> * removing ?/svn-loc/R/library/Matrix?
>>>>> * restoring previous ?/svn-loc/R/library/Matrix?
>>>>> make[2]: *** [Matrix.ts] Error 1
>>>>> make[2]: Leaving directory
>>>> `/svn-loc/R/src/library/Recommended'
>>>>> make[1]: *** [recommended-packages] Error 2
>>>>> make[1]: Leaving directory
>>>> `/svn-loc/R/src/library/Recommended'
>>>>> make: *** [stamp-recommended] Error 2
>>>>> ----------------
>>>>>
>>>>> If it matters, here is what r trunk built with:
>>>>> ./configure --enable-memory-profiling
>>>> --enable-strict-barrier --enable-byte-compiled-packages
>>>> --with-valgrind-instrumentation=2 --enable-lto
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org
>>>> mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com

R/Finance 2013: Applied Finance with R  | www.RinFinance.com


From kasperdanielhansen at gmail.com  Fri Feb 15 19:32:25 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Fri, 15 Feb 2013 13:32:25 -0500
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <CAPPM_gTnFFoF5tA8V5xUoHq9gxKfo94D3vowUpk_qo_CJf1bsA@mail.gmail.com>
References: <1360946186.76087.YahooMailClassic@web172301.mail.ir2.yahoo.com>
	<7AA3622A-9144-40A6-9A9B-A499A3ACFBB2@r-project.org>
	<CAC2h7uv_EHwcZOqdVh7-WM1K-8C+ARTR0EoDM-un4iuas8hFaw@mail.gmail.com>
	<CAPPM_gTnFFoF5tA8V5xUoHq9gxKfo94D3vowUpk_qo_CJf1bsA@mail.gmail.com>
Message-ID: <CAC2h7utD1tmtAE-GjzfinHW9_-3AHoeVAsTN1-akdxZfOks0hg@mail.gmail.com>

On Fri, Feb 15, 2013 at 1:25 PM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> On Fri, Feb 15, 2013 at 12:19 PM, Kasper Daniel Hansen
> <kasperdanielhansen at gmail.com> wrote:
>> I build from svn daily and I have not had this problem.  I build in a
>> tree separate from the source tree.
>>
>> I do think Hin-Tak has a point about clearly specifying that this is
>> how you should do it, in the manual (if that has not already
>> happened).  As a casual user, I would expect make clean to clean out
>> any stale files, but perhaps that is not happening.  Anyway, seems
>> more to be a possible documentation problem.
>>
> It's already in the R Installation and Administration Manual:
> http://cran.r-project.org/doc/manuals/R-admin.html#Simple-compilation
>
> See the second-to-last paragraph.  It recommends you do not build in
> the top-level source directory, particularly when you work with a
> version of R from Subversion.

Ok, this certainly recommends doing it in another build tree, so I
think it is quite clearly documented.

Kasper

> Best,
> Josh
>
>> Kasper
>>
>> On Fri, Feb 15, 2013 at 1:08 PM, Simon Urbanek
>> <simon.urbanek at r-project.org> wrote:
>>> On Feb 15, 2013, at 11:36 AM, Hin-Tak Leung wrote:
>>>
>>>> --- On Fri, 15/2/13, Simon Urbanek <simon.urbanek at r-project.org> wrote:
>>>>
>>>>> On Feb 15, 2013, at 9:11 AM, Hin-Tak
>>>>> Leung wrote:
>>>>>
>>>>>> Somebody else had written separately about this before,
>>>>> and so have I a couple of months ago. I assumed this will be
>>>>> fixed before the next R. Since R 3.0 is supposedly only 6
>>>>> weeks away, even if it is fixed now it doesn't leave much
>>>>> room for testing.
>>>>>>
>>>>>> Anyway neither Matrix 1.0-11 (current) nor 1.0-9 (sept
>>>>> 2012) build with current R trunk.  The  last time
>>>>> it did was 1. 0-9 on 3rd october over 4 months ago. So it
>>>>> appears to be due to change inside r trunk in sept or early
>>>>> oct.
>>>>>>
>>>>>
>>>>> No problem here - Matrix 1.0-11 and R-devel build just fine
>>>>> with your flags (tested on Ubuntu 12.10, x86_64).
>>>>>
>>>>> If in doubt, please remove R-devel and checkout a fresh
>>>>> copy. Also FWIW it's a bad practice to build inside the
>>>>> sources - it often causes all sorts of problems when you try
>>>>> to track the sources and stale files are probably what's
>>>>> hitting you.
>>>>>
>>>>> FWIW: This is likely not the problem you're mentioning, but
>>>>> some recent gcc versions break and LTO is also known to
>>>>> cause issues depending on the compiler version, so tread
>>>>> lightly on the cutting edge.
>>>>
>>>>
>>>> Here is a fairly similar post:
>>>> http://r.789695.n4.nabble.com/Build-from-Source-fails-on-Loading-required-package-Matrix-td4640371.html
>>>>
>>>> The eventual "solution" of that thread seems to be building from tar ball, which is quite beside the whole point of building from svn trunk.
>>>>
>>>
>>> And how is that relevant to what I said? Did you follow the advice I sent? If you did and still have an issue, post *exact* details on what you did, what system and tools you are using.
>>>
>>>
>>>> FWIW, it is very unproductive to talk about "bad practice" - in a hand-waving undocumented/unsubstantiated manner
>>>
>>> Building in sources has two problems: a) the content of the source tree can change so subsequent builds can be different from the clean one - you cannot undo that and b) if you update the sources stale files from previous builds can break the build.
>>>
>>> If solving your problems is "unproductive" then I'm not surprised you have them for 4 moths now.
>>>
>>>
>>>> - and options that might or might not work. If "--enable-lto" (or any other options, or build within the dev directory) does not work reliably, it should be either disabled/removed, or documented, or both.
>>>
>>> R cannot test all aspects of a compiler and detect all its bugs. It is *your* responsibility to provide a working compiler - if you are unwilling to do that, R cannot do anything about that.
>>>
>>>
>>>> Anyway, it has not been working for over 4 months.
>>>>
>>>
>>> That is not true, obviously, and I have presented a counter-example. It may not have been working for *you* and it's likely a problem in your setup (given your lack of cooperation there is no way to tell for sure). We cannot prevent user errors. We can try to point people in the right direction, but if they refuse to listen it's on their head.
>>>
>>>
>>>> You have about 6 weeks before this becomes a big problem - "big" as in "wide-spread".
>>>>
>>>
>>> You are yet to show that this is a problem in R at all. You failed to follow the basic instructions in the FAQ.
>>>
>>> Cheers,
>>> Simon
>>>
>>>
>>>
>>>>> Cheers,
>>>>> Simon
>>>>>
>>>>>
>>>>>>
>>>>>> ----------------
>>>>>> Loading required package: Matrix
>>>>>> Error in namespaceExport(ns, exports) : undefined
>>>>> exports: .M.classEnv
>>>>>> Error : require(Matrix) is not TRUE
>>>>>> ERROR: installing package indices failed
>>>>>> * removing ?/svn-loc/R/library/Matrix?
>>>>>> * restoring previous ?/svn-loc/R/library/Matrix?
>>>>>> make[2]: *** [Matrix.ts] Error 1
>>>>>> make[2]: Leaving directory
>>>>> `/svn-loc/R/src/library/Recommended'
>>>>>> make[1]: *** [recommended-packages] Error 2
>>>>>> make[1]: Leaving directory
>>>>> `/svn-loc/R/src/library/Recommended'
>>>>>> make: *** [stamp-recommended] Error 2
>>>>>> ----------------
>>>>>>
>>>>>> If it matters, here is what r trunk built with:
>>>>>> ./configure --enable-memory-profiling
>>>>> --enable-strict-barrier --enable-byte-compiled-packages
>>>>> --with-valgrind-instrumentation=2 --enable-lto
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org
>>>>> mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
>
> R/Finance 2013: Applied Finance with R  | www.RinFinance.com


From gunter.berton at gene.com  Sat Feb 16 07:24:19 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 15 Feb 2013 22:24:19 -0800
Subject: [Rd] Printing of anonymous functions in calls is sub-optimal
In-Reply-To: <CABdHhvEgK1g4gYhmovu_EbvSN185g9LnLAacC5ojWup3_aG07w@mail.gmail.com>
References: <CABdHhvEgK1g4gYhmovu_EbvSN185g9LnLAacC5ojWup3_aG07w@mail.gmail.com>
Message-ID: <CACk-te153qhWuzN4MwcozknhM38kNVv6MtJKKg-r1eVx9ODs0w@mail.gmail.com>

As there has been no response to this ...

Why not simply:

> g <- substitute(f(x),list(f=function(x){x+1})) ## with curly braces
> g
function (x)
{
    x + 1
}(x)
> x <- 2
> eval(g)
[1] 3


Cheers,
Bert

On Fri, Feb 15, 2013 at 7:45 AM, Hadley Wickham <h.wickham at gmail.com> wrote:
> e.g.
>
> substitute(f(x), list(f = function(x) x + 1))
> # function (x)
> # x + 1(x)
>
> An extra pair of parentheses would really help:
>
> (function(x)
> x + 1)(x)
>
> (Better indenting etc would be nice, but not necessary for correct
> understand of the code)
>
> Hadley
>
> --
> Chief Scientist, RStudio
> http://had.co.nz/
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From Roger.bivand at nhh.no  Sat Feb 16 14:03:47 2013
From: Roger.bivand at nhh.no (Roger Bivand)
Date: Sat, 16 Feb 2013 13:03:47 +0000
Subject: [Rd] Matrix does not build with R trunk since Oct.
References: <2B97A288-1898-4EF8-9351-3CA84F878C69@r-project.org>
	<1360955596.66622.YahooMailClassic@web172302.mail.ir2.yahoo.com>
Message-ID: <loom.20130216T135153-208@post.gmane.org>

Hin-Tak Leung <htl10 <at> users.sourceforge.net> writes:

> 
> --- On Fri, 15/2/13, Simon Urbanek <simon.urbanek <at> r-project.org> wrote:
> 
> > On Feb 15, 2013, at 1:55 PM, Hin-Tak Leung wrote:
> > 
> > > Look. I don't see this as "my" problem - as far as I am
> > concerned, I have donated my time - and over and over - to
> > testing pre-released code. I am not using pre-released code
> > for production work. If the released code in 3.0 does not
> > work correctly in 6 weeks' time, I just don't upgrade. No
> > loss for me there.
> > > 
> > 
> > It works - confirmed by several people. You have a problem,
> > but you didn't tell us the specifics of the problem so
> > there's nothing we can do.
> 
> I do not have a problem. I do not need to spend time regularly testing
pre-release code, and I think I should stop.


The probably unknown now, for today's comfortable people, simple procedure has
always been:

svn up
tools/rsync-recommended # R only
./configure ...
make distclean
./configure ...
make
make check # R or relevant software only
make install

which always works even when building in the source tree. This whole thread is
unnecessary if you remember to run make distclean, as all files that might
appear to be fresh (but are not because of indirect dependencies, such as
changes in the methods package), are rebuilt. When in doubt, use make distclean.
It's as easy as that, nothing to get excited about. Section 7.2.6 of
http://www.gnu.org/prep/standards/html_node/index.html.

Roger


> 
> > > I don't know why it is degenerating into another
> > distraction about some people's egos.
> > > 
> > 
> > I don't either - it's not productive.
> > 
> > Cheers,
> > Simon
> > 
> >


From simon.urbanek at r-project.org  Sat Feb 16 15:56:46 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 16 Feb 2013 09:56:46 -0500
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <loom.20130216T135153-208@post.gmane.org>
References: <2B97A288-1898-4EF8-9351-3CA84F878C69@r-project.org>
	<1360955596.66622.YahooMailClassic@web172302.mail.ir2.yahoo.com>
	<loom.20130216T135153-208@post.gmane.org>
Message-ID: <B6FADE68-B6A7-409D-B824-CA6C9EE4BB08@r-project.org>


On Feb 16, 2013, at 8:03 AM, Roger Bivand wrote:

> Hin-Tak Leung <htl10 <at> users.sourceforge.net> writes:
> 
>> 
>> --- On Fri, 15/2/13, Simon Urbanek <simon.urbanek <at> r-project.org> wrote:
>> 
>>> On Feb 15, 2013, at 1:55 PM, Hin-Tak Leung wrote:
>>> 
>>>> Look. I don't see this as "my" problem - as far as I am
>>> concerned, I have donated my time - and over and over - to
>>> testing pre-released code. I am not using pre-released code
>>> for production work. If the released code in 3.0 does not
>>> work correctly in 6 weeks' time, I just don't upgrade. No
>>> loss for me there.
>>>> 
>>> 
>>> It works - confirmed by several people. You have a problem,
>>> but you didn't tell us the specifics of the problem so
>>> there's nothing we can do.
>> 
>> I do not have a problem. I do not need to spend time regularly testing
> pre-release code, and I think I should stop.
> 
> 
> The probably unknown now, for today's comfortable people, simple procedure has
> always been:
> 
> svn up
> tools/rsync-recommended # R only
> ./configure ...
> make distclean
> ./configure ...
> make
> make check # R or relevant software only
> make install
> 
> which always works even when building in the source tree.

Although it goes a long way, it doesn't always work -- it assumes that the directory structure did not change in the project between the revisions - distclean may not clean things that have changed since you updated the SVN (note that to address that you should run distclean *before* the update). Also note that R-devel is unstable for a reason -- as you are tracking it you may encounter bugs in the build which will make your in-source build (including distclean) break -- even if that bug is then fixed in next update the damage has been done already so you cannot recover. This has happened before, so in such cases you have to blow away everything and start from scratch (from svn co ..). That's why we are suggesting building outside sources, because it's easier to blow away just the build (there are still cases where even that won't work - e.g. when sources files are accidentally modified by the build). Before claiming that something doesn't work, you have to do a clean build. In a majority of cases you will get away with in-sources build, but if you don't, you have to know what to do.


> This whole thread is unnecessary

Period. It is indeed. The thread was about alleged issue with Matrix in R-devel which could not be confirmed (I even checked on Fedora 18 now and it builds just fine). We were not able to reproduce it and the reporter was unwilling to follow any suggestions hence we have no way to follow it up as it's not reproducible so I see the case as closed.

Cheers,
Simon


> if you remember to run make distclean, as all files that might
> appear to be fresh (but are not because of indirect dependencies, such as
> changes in the methods package), are rebuilt. When in doubt, use make distclean.
> It's as easy as that, nothing to get excited about. Section 7.2.6 of
> http://www.gnu.org/prep/standards/html_node/index.html.
> 
> Roger
> 
> 
>> 
>>>> I don't know why it is degenerating into another
>>> distraction about some people's egos.
>>>> 
>>> 
>>> I don't either - it's not productive.
>>> 
>>> Cheers,
>>> Simon
>>> 
>>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From murdoch.duncan at gmail.com  Sat Feb 16 16:18:58 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 16 Feb 2013 10:18:58 -0500
Subject: [Rd] Printing of anonymous functions in calls is sub-optimal
In-Reply-To: <CABdHhvEgK1g4gYhmovu_EbvSN185g9LnLAacC5ojWup3_aG07w@mail.gmail.com>
References: <CABdHhvEgK1g4gYhmovu_EbvSN185g9LnLAacC5ojWup3_aG07w@mail.gmail.com>
Message-ID: <511FA362.9060305@gmail.com>

On 13-02-15 10:45 AM, Hadley Wickham wrote:
> e.g.
>
> substitute(f(x), list(f = function(x) x + 1))
> # function (x)
> # x + 1(x)
>
> An extra pair of parentheses would really help:
>
> (function(x)
> x + 1)(x)
>
> (Better indenting etc would be nice, but not necessary for correct
> understand of the code)

This is a little tricky for the deparser.  It sees a call to a function 
which was determined by an expression.  Sometimes you want parens, 
sometimes you don't.  For example, if getfun(y) returns a function, it's 
clearer to display a call as getfun(y)(x) than (getfun(y))(x).

I'll see if I can work out which kinds of expressions need to be 
parenthesized and implement it in the deparser.

Duncan


From h.wickham at gmail.com  Sat Feb 16 16:19:29 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 16 Feb 2013 09:19:29 -0600
Subject: [Rd] Printing of anonymous functions in calls is sub-optimal
In-Reply-To: <CACk-te153qhWuzN4MwcozknhM38kNVv6MtJKKg-r1eVx9ODs0w@mail.gmail.com>
References: <CABdHhvEgK1g4gYhmovu_EbvSN185g9LnLAacC5ojWup3_aG07w@mail.gmail.com>
	<CACk-te153qhWuzN4MwcozknhM38kNVv6MtJKKg-r1eVx9ODs0w@mail.gmail.com>
Message-ID: <CABdHhvH4+sm++-wN6mRm9uWY6XTjO5uf7ktWyOFKcB81APeM4g@mail.gmail.com>

On Sat, Feb 16, 2013 at 12:24 AM, Bert Gunter <gunter.berton at gene.com> wrote:
> As there has been no response to this ...
>
> Why not simply:
>
>> g <- substitute(f(x),list(f=function(x){x+1})) ## with curly braces
>> g
> function (x)
> {
>     x + 1
> }(x)
>> x <- 2
>> eval(g)
> [1] 3

Thomas Lumley sent me a similar suggestion off-list; but I'm not
complaining about how it works; my example executed fine. I'm
complaining that the rendering of the call object is misleading.

Hadley


-- 
Chief Scientist, RStudio
http://had.co.nz/


From h.wickham at gmail.com  Sat Feb 16 16:22:28 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 16 Feb 2013 09:22:28 -0600
Subject: [Rd] Printing of anonymous functions in calls is sub-optimal
In-Reply-To: <511FA362.9060305@gmail.com>
References: <CABdHhvEgK1g4gYhmovu_EbvSN185g9LnLAacC5ojWup3_aG07w@mail.gmail.com>
	<511FA362.9060305@gmail.com>
Message-ID: <CABdHhvGsqp76OZYLm12R9AvrekY5KnL3tOwPHpSnc0c2=DPyvQ@mail.gmail.com>

> This is a little tricky for the deparser.  It sees a call to a function
> which was determined by an expression.  Sometimes you want parens, sometimes
> you don't.  For example, if getfun(y) returns a function, it's clearer to
> display a call as getfun(y)(x) than (getfun(y))(x).
>
> I'll see if I can work out which kinds of expressions need to be
> parenthesized and implement it in the deparser.

I suspect it's only when you have a function in the quoted call, not a symbol:

# Don't add parens
q1 <- quote(g(f)(x))
is.symbol(q1[[1]])

# Add parents
q2 <- substitute(f(x), list(f = function(x) {x + 1}))
is.function(q2[[1]])

Thanks for thinking about it!

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From h.wickham at gmail.com  Sat Feb 16 16:41:37 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Sat, 16 Feb 2013 09:41:37 -0600
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <B6FADE68-B6A7-409D-B824-CA6C9EE4BB08@r-project.org>
References: <2B97A288-1898-4EF8-9351-3CA84F878C69@r-project.org>
	<1360955596.66622.YahooMailClassic@web172302.mail.ir2.yahoo.com>
	<loom.20130216T135153-208@post.gmane.org>
	<B6FADE68-B6A7-409D-B824-CA6C9EE4BB08@r-project.org>
Message-ID: <CABdHhvHFDvtubO+88A1ujmodV0ktNE_ZoVqP=XyV7NunZ7vfKg@mail.gmail.com>

> Although it goes a long way, it doesn't always work -- it assumes that the directory structure did not change in the project between the revisions - distclean may not clean things that have changed since you updated the SVN (note that to address that you should run distclean *before* the update). Also note that R-devel is unstable for a reason -- as you are tracking it you may encounter bugs in the build which will make your in-source build (including distclean) break -- even if that bug is then fixed in next update the damage has been done already so you cannot recover. This has happened before, so in such cases you have to blow away everything and start from scratch (from svn co ..).

One of the cool things about git is git clean - that allows you to
remove all non-git files from the repo without having to do checkout
from scratch.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From ggrothendieck at gmail.com  Sat Feb 16 16:54:26 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 16 Feb 2013 10:54:26 -0500
Subject: [Rd] RSetReg.exe
Message-ID: <CAP01uRnLce9MaibXXGxckpakn09LcmX4vQH0O4eL+pKDpencXA@mail.gmail.com>

R.exe, Rgui.exe, Rcmd.exe and Rscript.exe all support the --help
argument but RSetReg.exe --help ignores the argument and attempts to
set the registry key.  Since one might try this as a first attempt to
figure out what the command is all about this seems a bit dangerous.
It would be nice if it responded to --help as the other R*.exe
commands do.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From murdoch.duncan at gmail.com  Sat Feb 16 17:39:39 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 16 Feb 2013 11:39:39 -0500
Subject: [Rd] Printing of anonymous functions in calls is sub-optimal
In-Reply-To: <CABdHhvH4+sm++-wN6mRm9uWY6XTjO5uf7ktWyOFKcB81APeM4g@mail.gmail.com>
References: <CABdHhvEgK1g4gYhmovu_EbvSN185g9LnLAacC5ojWup3_aG07w@mail.gmail.com>
	<CACk-te153qhWuzN4MwcozknhM38kNVv6MtJKKg-r1eVx9ODs0w@mail.gmail.com>
	<CABdHhvH4+sm++-wN6mRm9uWY6XTjO5uf7ktWyOFKcB81APeM4g@mail.gmail.com>
Message-ID: <511FB64B.3060808@gmail.com>

On 13-02-16 10:19 AM, Hadley Wickham wrote:
> On Sat, Feb 16, 2013 at 12:24 AM, Bert Gunter <gunter.berton at gene.com> wrote:
>> As there has been no response to this ...
>>
>> Why not simply:
>>
>>> g <- substitute(f(x),list(f=function(x){x+1})) ## with curly braces
>>> g
>> function (x)
>> {
>>      x + 1
>> }(x)
>>> x <- 2
>>> eval(g)
>> [1] 3
>
> Thomas Lumley sent me a similar suggestion off-list; but I'm not
> complaining about how it works; my example executed fine. I'm
> complaining that the rendering of the call object is misleading.

Even with the braces it's misleading, in that

y <- function (x)
{
     x + 1
}(x)

is evaluated to define y to be a function with body

{
     x + 1
}(x)

which is syntactically valid, but not the same as the thing being deparsed.

Duncan Murdoch


From simon.urbanek at r-project.org  Sat Feb 16 21:15:03 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 16 Feb 2013 15:15:03 -0500
Subject: [Rd] Matrix does not build with R trunk since Oct.
In-Reply-To: <1360970030.67507.YahooMailClassic@web172304.mail.ir2.yahoo.com>
References: <1360970030.67507.YahooMailClassic@web172304.mail.ir2.yahoo.com>
Message-ID: <7355FBAE-0044-4807-8F08-BA927B42D3B1@r-project.org>

On Feb 15, 2013, at 6:13 PM, Hin-Tak Leung wrote:

> FWIW, extracting snapshot source elsewhere outside svn, run "tools/rsync-recommended" then just plain "./configure && make" doesn't work either. Nothing to do with building inside checkout nor extra configure options.
> 

Can you define "extracting snapshot source elsewhere outside svn"? That is likely the crucial point. If you mean that you used "svn checkout" on one machine, copied the content to another machine which does *not* have svn and then built there -- then this is unsupported and it has never been supported (depending on the R version it would either break or report invalid svn rev in R.version). You can *only* build from the svn sources if you have svn installed on the machine (equally, you cannot use svn export - see R-admin 1.2.1). You can only proceed on a machine without svn if you first create a distribution tar ball (e.g., via make dist) on the machine with svn and then use that tar ball on another machine (this is how R snapshots work).


> This is fedora 18, x86_64.
> 

I checked on Fedora 18 and it works just fine using

svn co https://svn.r-project.org/R/trunk R-devel
cd R-devel/
tools/rsync-recommended 
./configure 
make

Cheers,
Simon



> --- On Fri, 15/2/13, Hin-Tak Leung <htl10 at users.sourceforge.net> wrote:
> 
>> Somebody else had written separately about this before, and
>> so have I a couple of months ago. I assumed this will be
>> fixed before the next R. Since R 3.0 is supposedly only 6
>> weeks away, even if it is fixed now it doesn't leave much
>> room for testing. 
>> 
>> Anyway neither Matrix 1.0-11 (current) nor 1.0-9 (sept 2012)
>> build with current R trunk.  The  last time it did
>> was 1. 0-9 on 3rd october over 4 months ago. So it appears
>> to be due to change inside r trunk in sept or early oct. 
>> 
>> 
>> ----------------
>> Loading required package: Matrix
>> Error in namespaceExport(ns, exports) : undefined exports:
>> .M.classEnv
>> Error : require(Matrix) is not TRUE
>> ERROR: installing package indices failed
>> * removing ?/svn-loc/R/library/Matrix?
>> * restoring previous ?/svn-loc/R/library/Matrix?
>> make[2]: *** [Matrix.ts] Error 1
>> make[2]: Leaving directory
>> `/svn-loc/R/src/library/Recommended'
>> make[1]: *** [recommended-packages] Error 2
>> make[1]: Leaving directory
>> `/svn-loc/R/src/library/Recommended'
>> make: *** [stamp-recommended] Error 2
>> ----------------
>> 
>> If it matters, here is what r trunk built with:
>> ./configure --enable-memory-profiling
>> --enable-strict-barrier --enable-byte-compiled-packages
>> --with-valgrind-instrumentation=2 --enable-lto
>> 
>> 
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Sat Feb 16 22:55:09 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sat, 16 Feb 2013 13:55:09 -0800
Subject: [Rd] Suggestion: Custom filename patterns for non-Sweave
	vignettes
In-Reply-To: <511E8CE0.5070403@gmail.com>
References: <CAFDcVCQs4GEYznPmqkz=gRuq2=KEWMnOqsSq3fGU92mUN0hbUA@mail.gmail.com>
	<511DFC9F.4020209@gmail.com>
	<CAFDcVCQjsAWbf7WbJrar_Z0XJqTe8EwywOvOUq=-o7wAxOkE8Q@mail.gmail.com>
	<511E8CE0.5070403@gmail.com>
Message-ID: <CAFDcVCRYRXu-0pwCwXkKnD-T8GY9ZOQqioeaQE8_8Pfdhn+2aQ@mail.gmail.com>

Hi,

as said at the end, all comments are now in the light of R 3.x.0 (x > 0).


On Fri, Feb 15, 2013 at 11:30 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-02-15 1:53 PM, Henrik Bengtsson wrote:
>>
>> Hi Duncan,
>>
>> thanks you for your prompt reply.
>>
>>
>> On Fri, Feb 15, 2013 at 1:15 AM, Duncan Murdoch
>> <murdoch.duncan at gmail.com> wrote:
>>>
>>> There are several reasons I decided against that:
>>>
>>>    - two packages may request overlapping patterns, making it much
>>> messier to
>>> do the matching, checking etc, since the matching would have to depend on
>>> the package being processed.
>>
>>
>> So, isn't that somewhat already taken care of by the 'VignetteBuilder'
>> field in DESCRIPTION?  It specifies additional builders in addition to
>> the default/builtin Sweave builder.
>
>
> No, it specifies additional packages besides utils. Packages may specify
> multiple engines.

I think we're on the same page here - by "builders" I meant "packages
that provide engine for building vignettes".

> For example, knitr can handle Sweave-like knitr
> vignettes, and markdown-based vignettes.  Yihui chose to use the same engine
> for both, but it might make more sense to specify different engines.

Just to add a tiny FYI related to this comment; RSP markup is
independent of the output format, so in that case it makes sense to
have a single engine regardless of output format.

>
> So a user might say they want a knitr vignette and a .html.rsp vignette.
> But perhaps in the meantime, Yihui added an engine that can handle .rsp
> files.  So the user would have to list both packages, and there would be an
> ambiguity as to which one should be run.  You might say that's the user's
> problem, but they wouldn't complain to themselves, they'd complain to me, so
> it's my problem.

As I understand it, currently the rule is that R will take a .Rnw, /
Rmd file, scan its content for \VignetteEngine{<engine>} to infer the
vignette engine, and then apply that vignette engine to the source
file.  If no \VignetteEngine{} is found, the default is to use Sweave
(as before).  The exact same strategy can be applied with support
custom filename patterns, with the default to give an error (or
alternatively silently skip it) if no \VignetteEngine{} is found (*).
This would remove any ambiguities between an R.rsp and knitr 'rsp'
engine, just as it does for *.Rnw currently.

(*) Ideally, I'd like the default to be inferred from the file's
content type, which in turn could be guessed from the filename
extension and possibly some content-type markup (e.g.
\VignetteContentType{...}), but I'm willing to step back from that.


>
> It would be possible to design all of this to work:  the engine could check
> the file and say "oops, that's not my kind of .rsp file, try the next
> engine".  I just don't think it's worth it.  I certainly don't have time to
> design and program it or even to check your offered patch before feature
> freeze.  I can make small tweaks, but big changes that need lots of testing
> aren't going to happen.

I definitely hear you and I fully understand.


>
>
>
>  Conflicts would only happen if a
>>
>> package developer (e.g. PkgA) includes a pattern that either (A)
>> overrides the builtin in "[.][RrSs](nw|tex)$" / "[.]Rmd$" patterns, or
>> (B) specifies to builders with the same patterns.  First of all, there
>> are not that many builder packages, so this is something that could be
>> negotiated among those to minimize conflicts.  Second, case (A) can be
>> protected against by not allowing builder packages (e.g. knitr, rsp,
>> ...) to add/register those patterns (tricky but possible to test for)
>
>
> I don't think it's feasible to check for overlap in regular expression
> patterns.

Here I was only thinking of testing for overlaps with
"[.][RrSs](nw|tex)$" / "[.]Rmd$", which can be done as:

illegalPattern <- function(pattern) {
  files <- c(outer(c("R", "r", "S", "s"), c("nw", "tex"), FUN=paste,
sep=""), "Rmd")
  files <- paste(".", files, sep="")
  any(regexpr(pattern, files) != -1L)
}

But yes, checking for overlapping patterns in general would be very hard.


>
>
>> (but only default to them if that is what they wish to use).  For case
>> (B), the developer of package PkgA has the power to avoid conflicts.
>> One could also imagine the ordering of packages listed in
>> 'VignetteBuilder' would provide a prioritization.
>
>
> Sure, but it would be confusing to get an error from knitr when you didn't
> know knitr was handling .rsp.

See above reply on \VignetteEngine{}.

>
>
>> BTW, case (A) is basically what the new design is already providing;
>> all builder packages use the same patterns.
>>
>> So, from a package building point of view, I don't see how this would
>> make it messier.  I can see that when checking a package it is harder
>> to validate matches between input and output formats (is that done?).
>> Let me know if I simplifying things too much - then I'll read up on
>> the 'R CMD *' source code.
>>
>>>
>>>    - one package may request a pattern that another package uses for
>>> auxiliary files, e.g. .bib.  If a user has both types of vignette it
>>> would
>>> just be a mess.

Again, see the \VignetteEngine{} markup comment above.  That would
work as a protection and it can be completely ignored outside the R
vignette building mechanism.  If the *.bib file does not have a
\VignetteEngine{}, then it could be skipped.


>>
>>
>> I see your concern, but is there really a significant risk for this?
>
>
> If you look through CRAN, you'll see packages that do very weird things.  If
> it's legal, someone will try it.
>
>
>
>> And if it would occur, (i) it would be contained to PkgA, (ii) the
>> developer of package PkgA would quickly detect it, and (iii) the
>> "badly behaving" builder package would rather soon flagged as doing
>> something bad (and its developer would be informed and so on).
>>
>>>
>>>    - the extension is also used to determine the output format.  We only
>>> support LaTeX (which will be converted to PDF) and HTML output.  It would
>>> be
>>> reasonable to support direct PDF output, but I don't think any other
>>> output
>>> formats should be supported.
>>
>>
>> Yes, supporting PDF output makes sense.  One may also consider
>> generation of plain *.txt files (think README.txt and similar).  As I
>> see it, the restriction on supported *output* formats are given by
>> what the R help system wish to support (which is basically *.pdf and
>> *.html documents).  It's clear that the decision on what to support is
>> up to the maintainer of the R system (i.e. R core).
>>
>> When it comes to input/source files for generating those output files,
>> it's harder to argue for restrictions.  As I understand it, the new
>> support for non-Sweave vignettes is moving away from such restriction,
>> which is great.  Despite the restrictions on file extension, it is
>> possible to "hijack" (my words) any of the supported extension for
>> whatever reason you want, as long as you produce a *.pdf or *.html
>> document in the end.  More below...
>
>
> The issue is that the supplier of a custom input extension would also need
> to specify what kind of output it produced, so R knows how to handle it.
> That makes it more complicated, harder to test, etc.

This led me to dig into the tools/R/Vignettes.R source code.  Couldn't
R instead check the extension of the output file, which could be
returned by the weave function (not sure if a weave function is
required to return anything, but it could be part of the design)?
This would be a more generic solution and also support the case where
an engine takes an *.Rnw file and either outputs a *.tex file or
decides to go all the way and generate a *.pdf.

I understand that this would require passing these output files
"dynamically" to tools:::.build_vignette_index().  See also comment
below.


>
>>
>>>
>>> I understand that forcing you to use .Rmd instead of .html.rsp may look
>>> unsightly, but I think the extensions need to be fixed, not customizable.
>>
>>
>> I still find it unfortunate that the R system opens up for processing
>> any type of input files but enforces those to have certain filename
>> extensions.
>>
>> As a real example, today Sweave and knitr both use *.Rnw.  This means
>> that if I send someone a standalone *.Rnw file, they will not be able
>> to tell how to compile it without further instructions from me or by
>> inspecting the content type, or by trial and error.  I believe that
>> makes reproducible research a bit more tedious.  With unique filename
>> extensions, life is easier.  It's easy to imagine that if other
>> builder packages (e.g. R.rsp, brew, ...) also start using *.Rnw,
>> things are not going to become better.  The current "rules" are
>> pushing things in that direction.  To take an extreme stand, it's a
>> little bit like using *.txt for all your C, C++, Erlang, Fortran,
>> Simula, ... code, because it in the end of the day they all compile to
>> binaries anyway.
>
>
> I agree to some extent, but if sending someone an Rnw causes problems, then
> don't do that.  Rename it before you send it.  Or rename it to Rnw when you
> put it in the vignettes directory.

I'm not worry about my own behavior, I'm worrying about third parties
that I don't know of.  The only way for me (the R.rsp maintainer) to
protect against this (and avoid getting support emails), is to
silently/secretly have the RSP engine support *.Rnw/*.Rmd extensions
as well.  Not ideal, but I can live with it.


>
>
>>
>> One may argue that the Rnw/Rtex/Rmd extensions only apply to the R
>> package vignettes and you can still use other extensions when you work
>> with standalone vignette source files.  That's of course also
>> unfortunate, because that will add additional confusion, e.g "You can
>> find the vignette in my package, but by the way you should really
>> rename it because ...".  The exact same source file will have
>> different extensions depending on context.  (In my own case, I found
>> *.tex.rsp, *.html.rsp, *.md.rsp, *.Rnw.rsp, ... to be much less
>> ambiguous and I prefer not to introduce ambiguity in mapping those to
>> *.Rnw/*.Rtex/*.Rmd.)
>
>
> You could map them to .tex.Rnw, .html.Rmd, .Rnw.Rnw, and your engine could
> do what it does now with *.rsp files.

When looking into this idea of basically using *.Rnw and *.Rmd (or
possibly .tex.rsp.Rnw, .html.rsp.Rmd, .Rnw.rsp.Rnw) as "triggers", I
had a look at the tools/R/Vignettes.R source code and discovered:

vignette_output <- function(filenames) {
   outfiles <- sub("\\.[RrSs](nw|tex)$", ".pdf", filenames)
   sub("\\.Rmd$", ".html", outfiles)
}

which gives:

> files <- c(".tex.Rnw", ".html.Rmd", ".Rnw.Rnw")
> vignette_output(files)
[1] ".tex.pdf"   ".html.html" ".Rnw.pdf"

> files <- c(".tex.rsp.Rnw", ".html.rsp.Rmd", ".Rnw.rsp.Rnw")
> vignette_output(files)
[1] ".tex.rsp.pdf"   ".html.rsp.html" ".Rnw.rsp.pdf"

Next, looking at tools:::.build_vignette_index() these are also the
filenames (iff existing otherwise empty), that will be listed as PDFs
(or HTMLs) output in the vignette index.

Unfortunately, R.rsp operates by taking an *.<ext>.rsp file and
dropping the filename extension to arrive at a *.<ext> file.  (This
can actually be done recursively and there are options to run
postprocessors that would continue processing the output file if their
file content/ext is recognize, e.g. *.tex.rsp will generate *.tex
which will be compile to a PDF or *.Rnw.rsp will generate *.Rnw which
will be passed to Sweave/knitr to generate *.tex which will be compile
to a PDF).  This means that the RSP engine would need to preserve
those "intermediate" filename extensions to fit the R vignette setup.
Again, I could probably find ad hoc workarounds for this too.


BTW, I don't think the requirement that the input and output files for
vignettes should have matching filenames after dropping the filename
extension is explicitly documented.  ?tools::vignetteEngine could be
interpreted as it is, but only if you know.  (Also, deep down
?RweaveLatex mention a default behavior but that's not the same as the
requirement).  If this requirement is intended, then I would suggest
to clarify ?tools::vignetteEngine from:

<quote>If the filename being processed has one of the Sweave
extensions (i.e. matching the regular expression ".[RrSs](nw|tex)$"),
the weave function should produce a ?.tex? file in the same
directory."</quote>

to:

<update>If the filename being processed has one of the Sweave
extensions (i.e. matching the regular expression ".[RrSs](nw|tex)$"),
the weave function should produce a file in the same directory with
the filename extension replaced by ".tex".</update>


While speaking about ?tools::vignetteEngine.  Its 'Description' is not
clear on whether it packages with vignettes (e.g. PkgA) or the builder
packages (e.g. knitr, R.rsp, ...) that should call this function;

<quote>Vignettes are normally processed by Sweave, but package writers
may choose to use a different engine (e.g. knitr or noweb). This
function is used by those packages to register their engines, and
internally by R to retrieve them.</quote>

The problematic word is "those".  Maybe the following is better:

<update>Vignettes are normally processed by Sweave, but package
writers may choose to use a different engine (e.g. knitr or noweb).
Packages (e.g. knitr) that provide vignette engines should register
those engines in their .onLoad() function so that R can retrieve them
internally.  [See Section 'Non-Sweave vignettes' in 'Writing R
Extensions' for further details.]</update>



>
>>
>> Finally, the supported extensions are basically *.Rnw, *.Rtex and
>> *.Rmd.  To break those down, "*nw" originates from 'Noweb'
>> [http://wikipedia.org/wiki/Noweb], "*tex" from TeX
>> [http://wikipedia.org/wiki/latex] and "*md" from Markdown
>> [wikipedia.org/wiki/Markdown].  The "R*" part indicates that there is
>> some additional markup format to those file formats.  But in the end
>> of the day, they indicate that the source files should be
>> markup-embedded files containing some flavor of Noweb, TeX or
>> Markdown.  I find it weird to use those also for, say, formats such as
>> HTML, reStructuredText, AsciiDoc, MediaWiki, Org-Mode etc.
>
>
> That's the etymology, not the meaning.

Mmmkay... if so, then the following passage should be corrected in WRE
Section 'Non-Sweave vignettes':

<quote>R recognizes non-Sweave vignettes using the same extensions as
for Sweave vignettes; in addition, the extension .Rmd (standing for ?R
markdown?) is supported.</quote>


>
>>
>>
>> To summarize, I really appreciate the move to a built-in support for
>> non-Sweave vignettes (without using custom Makefiles), but I find that
>> the supported filename extensions has not been brought along in this
>> move.
>>
>
> There's always time to argue for R 3.1.0.

I'm glad to see those words.  I understand the R 3.0.0 deadline, so
consider what I have said this far as arguments for R 3.x.0 (x > 0).


Thanks again for your replies.  They do clarifies your design
strategies and constraints, which help me going forward.

Henrik


>
> Duncan Murdoch
>


From murdoch.duncan at gmail.com  Sun Feb 17 00:29:58 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 16 Feb 2013 18:29:58 -0500
Subject: [Rd] Printing of anonymous functions in calls is sub-optimal
In-Reply-To: <CABdHhvGsqp76OZYLm12R9AvrekY5KnL3tOwPHpSnc0c2=DPyvQ@mail.gmail.com>
References: <CABdHhvEgK1g4gYhmovu_EbvSN185g9LnLAacC5ojWup3_aG07w@mail.gmail.com>
	<511FA362.9060305@gmail.com>
	<CABdHhvGsqp76OZYLm12R9AvrekY5KnL3tOwPHpSnc0c2=DPyvQ@mail.gmail.com>
Message-ID: <51201676.2000208@gmail.com>

On 13-02-16 10:22 AM, Hadley Wickham wrote:
>> This is a little tricky for the deparser.  It sees a call to a function
>> which was determined by an expression.  Sometimes you want parens, sometimes
>> you don't.  For example, if getfun(y) returns a function, it's clearer to
>> display a call as getfun(y)(x) than (getfun(y))(x).
>>
>> I'll see if I can work out which kinds of expressions need to be
>> parenthesized and implement it in the deparser.
>
> I suspect it's only when you have a function in the quoted call, not a symbol:
>
> # Don't add parens
> q1 <- quote(g(f)(x))
> is.symbol(q1[[1]])
>
> # Add parents
> q2 <- substitute(f(x), list(f = function(x) {x + 1}))
> is.function(q2[[1]])
>
> Thanks for thinking about it!

It's in place now.  There are two kinds of cases it handles:

Unevaluated expressions are the hardest.  For those, parens are used 
when the function is an infix operator other than ::, :::, $, [ or [[.
They're also used for special syntax, like if, while, etc.

For evaluated things, only your example (a closure object) get parens.

I'm sure you can construct things that deparse improperly, but it does a 
better job now.  For example, from the new test script:

 > ## Anonymous function calls were not deparsed properly
 > substitute(f(x), list(f = function(x) x + 1))
(function (x)
x + 1)(x)
 > substitute(f(x), list(f = quote(function(x) x + 1)))
(function(x) x + 1)(x)
 > substitute(f(x), list(f = quote(f+g)))
(f + g)(x)
 > substitute(f(x), list(f = quote(base::mean)))
base::mean(x)
 > substitute(f(x), list(f = quote(a[n])))
a[n](x)
 > substitute(f(x), list(f = quote(g(y))))
g(y)(x)
 > ## The first three need parens, the last three don't.
 >

This is in R-devel and R-patched.

Duncan Murdoch


From wdunlap at tibco.com  Sun Feb 17 06:47:45 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Sun, 17 Feb 2013 05:47:45 +0000
Subject: [Rd] Printing of anonymous functions in calls is sub-optimal
In-Reply-To: <CABdHhvGsqp76OZYLm12R9AvrekY5KnL3tOwPHpSnc0c2=DPyvQ@mail.gmail.com>
References: <CABdHhvEgK1g4gYhmovu_EbvSN185g9LnLAacC5ojWup3_aG07w@mail.gmail.com>
	<511FA362.9060305@gmail.com>
	<CABdHhvGsqp76OZYLm12R9AvrekY5KnL3tOwPHpSnc0c2=DPyvQ@mail.gmail.com>
Message-ID: <E66794E69CFDE04D9A70842786030B931B90370C@PA-MBX04.na.tibco.com>

> I suspect it's only when you have a function in the quoted call, not a symbol:

Add a call to 'function' (as opposed to the function made by evaluating that call)
to your test suite:

  > Q <- list(
         q1 = quote(getFunction("-")(x)),
         q2 = substitute(f(x), list(f = function(x) {-x})),
         q3 = substitute(f(x), list(f = quote(function(x) {-x}))))
  > sapply(Q, function(x)class(x[[1]]))
          q1         q2         q3 
      "call" "function"     "call" 
  > Q
  $q1
  getFunction("-")(x)
  
  $q2
  function (x) 
  {
      -x
  }(x)

  $q3
  function(x) {
      -x
  }(x)

  > sapply(Q, eval, list(x=137))
    q1   q2   q3 
  -137 -137 -137

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Hadley Wickham
> Sent: Saturday, February 16, 2013 7:22 AM
> To: Duncan Murdoch
> Cc: r-devel at r-project.org
> Subject: Re: [Rd] Printing of anonymous functions in calls is sub-optimal
> 
> > This is a little tricky for the deparser.  It sees a call to a function
> > which was determined by an expression.  Sometimes you want parens, sometimes
> > you don't.  For example, if getfun(y) returns a function, it's clearer to
> > display a call as getfun(y)(x) than (getfun(y))(x).
> >
> > I'll see if I can work out which kinds of expressions need to be
> > parenthesized and implement it in the deparser.
> 
> I suspect it's only when you have a function in the quoted call, not a symbol:
> 
> # Don't add parens
> q1 <- quote(g(f)(x))
> is.symbol(q1[[1]])
> 
> # Add parents
> q2 <- substitute(f(x), list(f = function(x) {x + 1}))
> is.function(q2[[1]])
> 
> Thanks for thinking about it!
> 
> Hadley
> 
> --
> Chief Scientist, RStudio
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From matevzpavlic at gmail.com  Sun Feb 17 00:48:14 2013
From: matevzpavlic at gmail.com (Matevz Pavlic)
Date: Sat, 16 Feb 2013 15:48:14 -0800 (PST)
Subject: [Rd] Passing R code from webpage
Message-ID: <1361058494221-4658800.post@n4.nabble.com>

Hi all, 

Is there a way to pass R code from web page (html file) to do some
statistics and than plot the output in web browser. 

I am looking forever at this, and cant find a way.

Regards,m



--
View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800.html
Sent from the R devel mailing list archive at Nabble.com.


From pchausse at uwaterloo.ca  Sun Feb 17 14:55:29 2013
From: pchausse at uwaterloo.ca (Pierre Chausse)
Date: Sun, 17 Feb 2013 08:55:29 -0500
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361058494221-4658800.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>
Message-ID: <5120E151.6020009@uwaterloo.ca>

If R and ghostcript are installed on the server that hosts you webpage, 
it is easy. All you need is a minimum of php. I started with doR (which 
I think does not exist anymore) and modified it. Even better, some 
people offers a solution for you. Here is a GPL licenced solution.

http://steve-chen.net/document/r/r_php



Le 2013-02-16 18:48, Matevz Pavlic a ?crit :
> Hi all,
>
> Is there a way to pass R code from web page (html file) to do some
> statistics and than plot the output in web browser.
>
> I am looking forever at this, and cant find a way.
>
> Regards,m
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From marc_schwartz at me.com  Sun Feb 17 15:06:46 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sun, 17 Feb 2013 08:06:46 -0600
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361058494221-4658800.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>
Message-ID: <EB5CAC08-6CB9-48E2-B40B-2DD863AA7702@me.com>

On Feb 16, 2013, at 5:48 PM, Matevz Pavlic <matevzpavlic at gmail.com> wrote:

> Hi all, 
> 
> Is there a way to pass R code from web page (html file) to do some
> statistics and than plot the output in web browser. 
> 
> I am looking forever at this, and cant find a way.
> 
> Regards,m



You might have wanted to start by looking at the R FAQ, which contains the following:

  http://cran.r-project.org/doc/FAQ/R-FAQ.html#R-Web-Interfaces

More recently, there is Shiny, which I did not see listed in the above:

  http://www.rstudio.com/shiny/

Regards,

Marc Schwartz


From simon.urbanek at r-project.org  Sun Feb 17 15:16:57 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 17 Feb 2013 09:16:57 -0500
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361058494221-4658800.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>
Message-ID: <BB2254CE-CB16-4960-8D69-1064A0762BD2@r-project.org>

On Feb 16, 2013, at 6:48 PM, Matevz Pavlic wrote:

> Hi all, 
> 
> Is there a way to pass R code from web page (html file) to do some
> statistics and than plot the output in web browser. 
> 
> I am looking forever at this, and cant find a way.
> 

Typically this is done by sending an AJAX request to R and display the result (or simple forms if you want to). I use FastRWeb for this - it even has an example on how you create plots and other output. There is also rApache if you are using apache web server.

Cheers,
Simon


> Regards,m
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From marchywka at hotmail.com  Sun Feb 17 15:29:16 2013
From: marchywka at hotmail.com (Mike Marchywka)
Date: Sun, 17 Feb 2013 09:29:16 -0500
Subject: [Rd] Passing R code from webpage
In-Reply-To: <BB2254CE-CB16-4960-8D69-1064A0762BD2@r-project.org>
References: <1361058494221-4658800.post@n4.nabble.com>,
	<BB2254CE-CB16-4960-8D69-1064A0762BD2@r-project.org>
Message-ID: <BLU166-W43C98BB734A61880F46C4ABE0C0@phx.gbl>






----------------------------------------
> From: simon.urbanek at r-project.org
> Date: Sun, 17 Feb 2013 09:16:57 -0500
> To: matevzpavlic at gmail.com
> CC: r-devel at r-project.org
> Subject: Re: [Rd] Passing R code from webpage
>
> On Feb 16, 2013, at 6:48 PM, Matevz Pavlic wrote:
>
> > Hi all,
> >
> > Is there a way to pass R code from web page (html file) to do some
> > statistics and than plot the output in web browser.
> >
> > I am looking forever at this, and cant find a way.
> >
>
> Typically this is done by sending an AJAX request to R and display the result (or simple forms if you want to). I use FastRWeb for this - it even has an example on how you create plots and other output. There is also rApache if you are using apache web server.

Depending on how you want to use it, as others have suggested, there are a lot of approaches. Invoking an "R" process is a bit expensive and
having a single R server available is much more efficient however for what we were doing the bigger gain was from caching results. That is,
we have maps by area, say state or zip code, where we can tolerate results a few minutes old. So, we used a custom java server to
invoke R as part of a general ability to execute bash scripts and then buffer the resulting images in memory. This approach worked well
but did potentially require starting a new Rprocess for each request. I had always wanted to make use of shared R instances but never
got around to doing this as the scaling never became relevant.?

Our interface was something simple, like "http://host/Rscriptname?zip=00000&otherkeys=value"

which would return an result with appropriate mime type to keep browser happy and have it fit on page ok etc.

The point is that ?anything that can invoke a bash script can invoke R and if ?you are concerned about doing this efficiently it is not hard to write a simple java app that listens on a port and can invoke
R and then do caching to meet your needs if apache etc does not do this easily.?







>
> Cheers,
> Simon
>
>
> > Regards,m
> >
> >
> >
> > --
> > View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800.html
> > Sent from the R devel mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
 		 	   		  

From simon.urbanek at r-project.org  Sun Feb 17 15:39:11 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 17 Feb 2013 09:39:11 -0500
Subject: [Rd] Passing R code from webpage
In-Reply-To: <BLU166-W43C98BB734A61880F46C4ABE0C0@phx.gbl>
References: <1361058494221-4658800.post@n4.nabble.com>,
	<BB2254CE-CB16-4960-8D69-1064A0762BD2@r-project.org>
	<BLU166-W43C98BB734A61880F46C4ABE0C0@phx.gbl>
Message-ID: <18E32626-BA32-4AF4-BDBC-52289F370FEC@r-project.org>


On Feb 17, 2013, at 9:29 AM, Mike Marchywka wrote:

>> From: simon.urbanek at r-project.org
>> Date: Sun, 17 Feb 2013 09:16:57 -0500
>> To: matevzpavlic at gmail.com
>> CC: r-devel at r-project.org
>> Subject: Re: [Rd] Passing R code from webpage
>> 
>> On Feb 16, 2013, at 6:48 PM, Matevz Pavlic wrote:
>> 
>>> Hi all,
>>> 
>>> Is there a way to pass R code from web page (html file) to do some
>>> statistics and than plot the output in web browser.
>>> 
>>> I am looking forever at this, and cant find a way.
>>> 
>> 
>> Typically this is done by sending an AJAX request to R and display the result (or simple forms if you want to). I use FastRWeb for this - it even has an example on how you create plots and other output. There is also rApache if you are using apache web server.
> 
> Depending on how you want to use it, as others have suggested, there are a lot of approaches. Invoking an "R" process is a bit expensive and
> having a single R server available is much more efficient however for what we were doing the bigger gain was from caching results. That is,
> we have maps by area, say state or zip code, where we can tolerate results a few minutes old. So, we used a custom java server to
> invoke R as part of a general ability to execute bash scripts and then buffer the resulting images in memory. This approach worked well
> but did potentially require starting a new Rprocess for each request. I had always wanted to make use of shared R instances but never
> got around to doing this as the scaling never became relevant. 
> 
> Our interface was something simple, like "http://host/Rscriptname?zip=00000&otherkeys=value"
> 
> which would return an result with appropriate mime type to keep browser happy and have it fit on page ok etc.
> 
> The point is that  anything that can invoke a bash script can invoke R and if  you are concerned about doing this efficiently it is not hard to write a simple java app that listens on a port and can invoke
> R and then do caching to meet your needs if apache etc does not do this easily. 
> 

That's why FastRWeb gives you all the flexibility without the need to write anything: you can use any webserver you want (with CGI or PHP) or you can use the built-in webserver in Rserve if you don't want any dependencies other than R and it still scales fairly well as it supports parallel connections. You don't need to write anything at all as FastRWeb does all the transformation of URL query parameters, forms etc into R function arguments so you just write scripts with one R function - that simple.

Cheers,
Simon


> 
> 
>> 
>> Cheers,
>> Simon
>> 
>> 
>>> Regards,m
>>> 
>>> 
>>> 
>>> --
>>> View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800.html
>>> Sent from the R devel mailing list archive at Nabble.com.
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 		 	   		  
> 


From matevzpavlic at gmail.com  Sun Feb 17 17:30:37 2013
From: matevzpavlic at gmail.com (Matevz Pavlic)
Date: Sun, 17 Feb 2013 08:30:37 -0800 (PST)
Subject: [Rd] Passing R code from webpage
In-Reply-To: <18E32626-BA32-4AF4-BDBC-52289F370FEC@r-project.org>
References: <1361058494221-4658800.post@n4.nabble.com>
	<BB2254CE-CB16-4960-8D69-1064A0762BD2@r-project.org>
	<BLU166-W43C98BB734A61880F46C4ABE0C0@phx.gbl>
	<18E32626-BA32-4AF4-BDBC-52289F370FEC@r-project.org>
Message-ID: <1361118637555-4658839.post@n4.nabble.com>

Hi , 

thanks for all the replies. 
I'll have a good look at this FastRWeb.  Just one thing. My pages are done
with Razor *.CSTHML. Could this be a problem for FastRWeb (and me) ;)?

regards, m



--
View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658839.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Sun Feb 17 17:57:37 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 17 Feb 2013 11:57:37 -0500
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361118637555-4658839.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>
	<BB2254CE-CB16-4960-8D69-1064A0762BD2@r-project.org>
	<BLU166-W43C98BB734A61880F46C4ABE0C0@phx.gbl>
	<18E32626-BA32-4AF4-BDBC-52289F370FEC@r-project.org>
	<1361118637555-4658839.post@n4.nabble.com>
Message-ID: <149DD500-EA7F-488F-855A-A9078F5646E3@r-project.org>

On Feb 17, 2013, at 11:30 AM, Matevz Pavlic wrote:

> Hi , 
> 
> thanks for all the replies. 
> I'll have a good look at this FastRWeb.  Just one thing. My pages are done
> with Razor *.CSTHML. Could this be a problem for FastRWeb (and me) ;)?
> 

R doesn't care how you generate the pages - it will be just processing requests that you define on such pages. Think of it as serving R scripts by a web server - it doesn't matter how you construct the URLs/requests that reference it.

BTW: since you mentioned CSHTML  --- you'll lose a lot of benefits on Windows, so if you think of using Windows as a server, think twice ;). Pretty much all scalable solutions assume you are using unix. On Windows you'll need a pool of R instances if you want to have some illusion of scalability so it's a lot more involved and wasteful.

Cheers,
Simon



> regards, m
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658839.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From matevzpavlic at gmail.com  Sun Feb 17 18:09:51 2013
From: matevzpavlic at gmail.com (Matevz Pavlic)
Date: Sun, 17 Feb 2013 09:09:51 -0800 (PST)
Subject: [Rd] Passing R code from webpage
In-Reply-To: <149DD500-EA7F-488F-855A-A9078F5646E3@r-project.org>
References: <1361058494221-4658800.post@n4.nabble.com>
	<BB2254CE-CB16-4960-8D69-1064A0762BD2@r-project.org>
	<BLU166-W43C98BB734A61880F46C4ABE0C0@phx.gbl>
	<18E32626-BA32-4AF4-BDBC-52289F370FEC@r-project.org>
	<1361118637555-4658839.post@n4.nabble.com>
	<149DD500-EA7F-488F-855A-A9078F5646E3@r-project.org>
Message-ID: <1361120991625-4658848.post@n4.nabble.com>

Hi, 

yes, i saw that about Cshtml...but it's done already, can't change it now. 

Are there any samples of web pages or some samples to download for FastRWeb?
I am having troubles understanding how to install this and get it to work...

tnx, m



--
View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658848.html
Sent from the R devel mailing list archive at Nabble.com.


From simon.urbanek at r-project.org  Sun Feb 17 19:10:33 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 17 Feb 2013 13:10:33 -0500
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361120991625-4658848.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>
	<BB2254CE-CB16-4960-8D69-1064A0762BD2@r-project.org>
	<BLU166-W43C98BB734A61880F46C4ABE0C0@phx.gbl>
	<18E32626-BA32-4AF4-BDBC-52289F370FEC@r-project.org>
	<1361118637555-4658839.post@n4.nabble.com>
	<149DD500-EA7F-488F-855A-A9078F5646E3@r-project.org>
	<1361120991625-4658848.post@n4.nabble.com>
Message-ID: <DB6DB319-8FD4-48A4-B4F5-113C3E46C447@r-project.org>


On Feb 17, 2013, at 12:09 PM, Matevz Pavlic wrote:

> Hi, 
> 
> yes, i saw that about Cshtml...but it's done already, can't change it now. 
> 
> Are there any samples of web pages or some samples to download for FastRWeb?
> I am having troubles understanding how to install this and get it to work...
> 

There is the INSTALL file in the package with all the details. Sample scripts (example*) will be installed as part of the installation process -- if you want to look at them first, they are in the inst/web.R directory of the package sources. An example HTML page with JS to use AJAX is in the web/index.html file. Jay Emerson also has a blog entry about installing FastRWeb
http://jayemerson.blogspot.com/2011/10/setting-up-fastrwebrserve-on-ubuntu.html
You can ask questions about FastRWeb or Rserve on the stats-rosuda-devel mailing list.

Cheers,
Simon


From jeff.a.ryan at gmail.com  Sun Feb 17 19:23:22 2013
From: jeff.a.ryan at gmail.com (Jeff Ryan)
Date: Sun, 17 Feb 2013 12:23:22 -0600
Subject: [Rd] Passing R code from webpage
In-Reply-To: <DB6DB319-8FD4-48A4-B4F5-113C3E46C447@r-project.org>
References: <1361058494221-4658800.post@n4.nabble.com>
	<BB2254CE-CB16-4960-8D69-1064A0762BD2@r-project.org>
	<BLU166-W43C98BB734A61880F46C4ABE0C0@phx.gbl>
	<18E32626-BA32-4AF4-BDBC-52289F370FEC@r-project.org>
	<1361118637555-4658839.post@n4.nabble.com>
	<149DD500-EA7F-488F-855A-A9078F5646E3@r-project.org>
	<1361120991625-4658848.post@n4.nabble.com>
	<DB6DB319-8FD4-48A4-B4F5-113C3E46C447@r-project.org>
Message-ID: <CABDUZc-d7KWm4F4k8s1EJEDTg4pnLCuAW=tHiLk6QD1Ym2Bq7w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130217/07b755be/attachment.pl>

From murdoch.duncan at gmail.com  Sun Feb 17 19:54:34 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 17 Feb 2013 13:54:34 -0500
Subject: [Rd] Printing of anonymous functions in calls is sub-optimal
In-Reply-To: <51201676.2000208@gmail.com>
References: <CABdHhvEgK1g4gYhmovu_EbvSN185g9LnLAacC5ojWup3_aG07w@mail.gmail.com>
	<511FA362.9060305@gmail.com>
	<CABdHhvGsqp76OZYLm12R9AvrekY5KnL3tOwPHpSnc0c2=DPyvQ@mail.gmail.com>
	<51201676.2000208@gmail.com>
Message-ID: <5121276A.30206@gmail.com>

On 13-02-16 6:29 PM, Duncan Murdoch wrote:
> On 13-02-16 10:22 AM, Hadley Wickham wrote:
>>> This is a little tricky for the deparser.  It sees a call to a function
>>> which was determined by an expression.  Sometimes you want parens, sometimes
>>> you don't.  For example, if getfun(y) returns a function, it's clearer to
>>> display a call as getfun(y)(x) than (getfun(y))(x).
>>>
>>> I'll see if I can work out which kinds of expressions need to be
>>> parenthesized and implement it in the deparser.
>>
>> I suspect it's only when you have a function in the quoted call, not a symbol:
>>
>> # Don't add parens
>> q1 <- quote(g(f)(x))
>> is.symbol(q1[[1]])
>>
>> # Add parents
>> q2 <- substitute(f(x), list(f = function(x) {x + 1}))
>> is.function(q2[[1]])
>>
>> Thanks for thinking about it!
>
> It's in place now.  There are two kinds of cases it handles:
>
> Unevaluated expressions are the hardest.  For those, parens are used
> when the function is an infix operator other than ::, :::, $, [ or [[.
> They're also used for special syntax, like if, while, etc.
>
> For evaluated things, only your example (a closure object) get parens.
>
> I'm sure you can construct things that deparse improperly, but it does a
> better job now.  For example, from the new test script:
>
>   > ## Anonymous function calls were not deparsed properly
>   > substitute(f(x), list(f = function(x) x + 1))
> (function (x)
> x + 1)(x)
>   > substitute(f(x), list(f = quote(function(x) x + 1)))
> (function(x) x + 1)(x)
>   > substitute(f(x), list(f = quote(f+g)))
> (f + g)(x)
>   > substitute(f(x), list(f = quote(base::mean)))
> base::mean(x)
>   > substitute(f(x), list(f = quote(a[n])))
> a[n](x)
>   > substitute(f(x), list(f = quote(g(y))))
> g(y)(x)
>   > ## The first three need parens, the last three don't.
>   >
>
> This is in R-devel and R-patched.

This broke a number of packages, which depended on the particular text 
of deparsed expressions, so we're going to revert the R-patched fix. 
R-devel (to become 3.0.0) will get it, but not 2.15.3.

Duncan Murdoch


From matevzpavlic at gmail.com  Sun Feb 17 20:20:52 2013
From: matevzpavlic at gmail.com (Matevz Pavlic)
Date: Sun, 17 Feb 2013 11:20:52 -0800 (PST)
Subject: [Rd] Passing R code from webpage
In-Reply-To: <DB6DB319-8FD4-48A4-B4F5-113C3E46C447@r-project.org>
References: <1361058494221-4658800.post@n4.nabble.com>
	<BB2254CE-CB16-4960-8D69-1064A0762BD2@r-project.org>
	<BLU166-W43C98BB734A61880F46C4ABE0C0@phx.gbl>
	<18E32626-BA32-4AF4-BDBC-52289F370FEC@r-project.org>
	<1361118637555-4658839.post@n4.nabble.com>
	<149DD500-EA7F-488F-855A-A9078F5646E3@r-project.org>
	<1361120991625-4658848.post@n4.nabble.com>
	<DB6DB319-8FD4-48A4-B4F5-113C3E46C447@r-project.org>
Message-ID: <1361128852088-4658871.post@n4.nabble.com>

Hi again, 

i am very sorry, but i can't install this from the details in INSTALL file.
As I understand these are instructions for Unix server, but i'd like to
install it on window... 





--
View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658871.html
Sent from the R devel mailing list archive at Nabble.com.


From matevzpavlic at gmail.com  Sun Feb 17 20:48:53 2013
From: matevzpavlic at gmail.com (Matevz Pavlic)
Date: Sun, 17 Feb 2013 11:48:53 -0800 (PST)
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361128852088-4658871.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>
	<BB2254CE-CB16-4960-8D69-1064A0762BD2@r-project.org>
	<BLU166-W43C98BB734A61880F46C4ABE0C0@phx.gbl>
	<18E32626-BA32-4AF4-BDBC-52289F370FEC@r-project.org>
	<1361118637555-4658839.post@n4.nabble.com>
	<149DD500-EA7F-488F-855A-A9078F5646E3@r-project.org>
	<1361120991625-4658848.post@n4.nabble.com>
	<DB6DB319-8FD4-48A4-B4F5-113C3E46C447@r-project.org>
	<1361128852088-4658871.post@n4.nabble.com>
Message-ID: <1361130533746-4658875.post@n4.nabble.com>

Here's what i did (Windows) :

1.)  install.packages("FastRWeb")  
2.) system(paste("cd",system.file(package="FastRWeb"),"&& install.sh")
3.) code{system.file("cgi-bin", package="FastRWeb")

I ran all this from Rstudio.

But i don't understand what "var" means. I suspect it's a folder, probably
in unix...because i don't have it anywhere in FastRWeb.

Any help?





--
View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658875.html
Sent from the R devel mailing list archive at Nabble.com.


From mehrotra.pulkit at gmail.com  Sun Feb 17 13:27:38 2013
From: mehrotra.pulkit at gmail.com (Pulkit Mehrotra)
Date: Sun, 17 Feb 2013 04:27:38 -0800
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361058494221-4658800.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>
Message-ID: <CAANJ-wek4j+ab=1_0quUGgrnBrf+kRMocFpTodRNCqAFrJEXHQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130217/8e333f27/attachment.pl>

From marchywka at hotmail.com  Mon Feb 18 12:01:42 2013
From: marchywka at hotmail.com (Mike Marchywka)
Date: Mon, 18 Feb 2013 06:01:42 -0500
Subject: [Rd] Passing R code from webpage
In-Reply-To: <CAANJ-wek4j+ab=1_0quUGgrnBrf+kRMocFpTodRNCqAFrJEXHQ@mail.gmail.com>
References: <1361058494221-4658800.post@n4.nabble.com>,
	<CAANJ-wek4j+ab=1_0quUGgrnBrf+kRMocFpTodRNCqAFrJEXHQ@mail.gmail.com>
Message-ID: <BLU166-W35CDC0CE9CC52759F67450BEF40@phx.gbl>




----------------------------------------
> Date: Sun, 17 Feb 2013 04:27:38 -0800
> From: mehrotra.pulkit at gmail.com
> To: matevzpavlic at gmail.com
> CC: r-devel at r-project.org
> Subject: Re: [Rd] Passing R code from webpage
>
> hi ,
>
> First of all you should as this question on r-help rather than on r-devel
> as this group deals with development related issues with R.

Well, personally this potentially a rather substantial issue and while methods
may exist to interface R to webservers, it may be worth discussing if there are
any things you could do to R to make it run more easily as an "R" server
so that you need not make a bunch of instance to run in this setting.
If 10 people on the same machine use R, what duplication is there?
Can I launch a background task within R and still work in foreground?
Is there anything anyone could should or wants to change in R to make this
work better here??


>
> As for the package you can use the shiny package from Rstudio. I have
> provided the links below.
>
> http://shiny.rstudio.org/
> http://www.rstudio.com/shiny/
>
> regards,
> Pulkit
>
> On Sat, Feb 16, 2013 at 3:48 PM, Matevz Pavlic <matevzpavlic at gmail.com>wrote:
>
> > Hi all,
> >
> > Is there a way to pass R code from web page (html file) to do some
> > statistics and than plot the output in web browser.
> >
> > I am looking forever at this, and cant find a way.
> >
> > Regards,m
> >
> >
> >
> > --
> > View this message in context:
> > http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800.html
> > Sent from the R devel mailing list archive at Nabble.com.
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
 		 	   		  

From nalimilan at club.fr  Mon Feb 18 12:22:23 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Mon, 18 Feb 2013 12:22:23 +0100
Subject: [Rd] nobs() with glm(family="poisson")
Message-ID: <1361186543.2067.24.camel@milan.ined.fr>

Hi!

The nobs() method for glm objects always returns the number of cases
with non-null weights in the data, which does not correspond to the
number of observations for Poisson regression/log-linear models, i.e.
when family="poisson" or family="quasipoisson".

This sounds dangerous since nobs() is, as the documentation states,
primarily aimed at computing the Bayesian information criterion. Raftery
(1995:20) warned against this:
> What should n be? Once again, it is best to use the actual number of
> individuals, i.e. the sum of the cell counts, and not the number of
> cells (Raftery, 1986a).

Is there a reason why this should not/cannot be done that way?

This behavior can be reproduced with with R 3.0.0 from SVN, using the
example from ?glm:
counts <- c(18,17,15,20,10,20,25,13,12)
outcome <- gl(3,1,9)
treatment <- gl(3,3)
glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
nobs(glm.D93)
# 9 == length(counts)
# Should be 150 == sum(counts)

FWIW, stats:::nobs.glm is currently defined as:
nobs.glm <- function (object, ...) 
    if (!is.null(w <- object$prior.weights)) sum(w != 0) else length(object$residuals)


Thanks!


Raftery, Adrian E. 1995. ?Bayesian Model Selection in Social Research.?
Sociological methodology 25:111?96.


From matevzpavlic at gmail.com  Mon Feb 18 12:24:43 2013
From: matevzpavlic at gmail.com (Matevz Pavlic)
Date: Mon, 18 Feb 2013 03:24:43 -0800 (PST)
Subject: [Rd] Passing R code from webpage
In-Reply-To: <BLU166-W35CDC0CE9CC52759F67450BEF40@phx.gbl>
References: <1361058494221-4658800.post@n4.nabble.com>
	<CAANJ-wek4j+ab=1_0quUGgrnBrf+kRMocFpTodRNCqAFrJEXHQ@mail.gmail.com>
	<BLU166-W35CDC0CE9CC52759F67450BEF40@phx.gbl>
Message-ID: <1361186683328-4658909.post@n4.nabble.com>

Hi, 

i think all of this i kinda complicated, even though in all the packages
authors  are saying that "minimum code is required". 
I mean, i am not an IT engineer , but i have created quite some webpages, so
i have some knowledge of HTML5, CSS, C# (limited), and also work quite a lot
with R and still installing R to run as a webserver seems to be too
complicated. 
I have look in all packages i can imaggine, Rook, ggoleVis, Shiny....but in
all i get the problem when i want to connect to a MS SQL database.


This is the workflow that i'd like to achieve : 
1.) in webrowser connect to MS SQL database
2.) do some R statistics and plots
3.) show that in web browser.


I am pretty sure it can be very complicated, but it just seems so.

any help (still) greatly appreciated.

BTW: I HAVE posted in R-help, but no responses were given.
m

regards, m



--
View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658909.html
Sent from the R devel mailing list archive at Nabble.com.


From marchywka at hotmail.com  Mon Feb 18 12:59:55 2013
From: marchywka at hotmail.com (Mike Marchywka)
Date: Mon, 18 Feb 2013 06:59:55 -0500
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361186683328-4658909.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>,
	<CAANJ-wek4j+ab=1_0quUGgrnBrf+kRMocFpTodRNCqAFrJEXHQ@mail.gmail.com>,
	<BLU166-W35CDC0CE9CC52759F67450BEF40@phx.gbl>,
	<1361186683328-4658909.post@n4.nabble.com>
Message-ID: <BLU166-W39D87CA6ADB3BC4A98A959BEF40@phx.gbl>





----------------------------------------
> Date: Mon, 18 Feb 2013 03:24:43 -0800
> From: matevzpavlic at gmail.com
> To: r-devel at r-project.org
> Subject: Re: [Rd] Passing R code from webpage
>
> Hi,
>
> i think all of this i kinda complicated, even though in all the packages
> authors are saying that "minimum code is required".
> I mean, i am not an IT engineer , but i have created quite some webpages, so
> i have some knowledge of HTML5, CSS, C# (limited), and also work quite a lot
> with R and still installing R to run as a webserver seems to be too
> complicated.
> I have look in all packages i can imaggine, Rook, ggoleVis, Shiny....but in
> all i get the problem when i want to connect to a MS SQL database.
>
>
> This is the workflow that i'd like to achieve :
> 1.) in webrowser connect to MS SQL database
> 2.) do some R statistics and plots
> 3.) show that in web browser.

Well, if you want a version of R that is a webserver that is one thing,
if you want a webserver that can call R and don't care how it scales then any server
that can execute arbitrary executables would work and you could ask on an apache list
for example. The problem is getting scaling. In the case we had, results were easily cached
and we had a facility for invoking bash scripts and so t the time the R instances were not a big
deal. There are several ways, like Rserve, to make R more server like. The case we had was mostly loaded
with short requests so we needed to fix the server threading model and used netty and java.
You may be happy with apache, no idea. This becomes an issue of R devel if anyone things?
there are ways to make multiple R tasks work together better.

Accessing DB from R is probably a help question however :) Although here too scaling can be a matter
of caching facilities and a custom server may help there.?




>
>
> I am pretty sure it can be very complicated, but it just seems so.
>
> any help (still) greatly appreciated.
>
> BTW: I HAVE posted in R-help, but no responses were given.
> m
>
> regards, m
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658909.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
 		 	   		  

From matevzpavlic at gmail.com  Mon Feb 18 13:13:25 2013
From: matevzpavlic at gmail.com (Matevz Pavlic)
Date: Mon, 18 Feb 2013 04:13:25 -0800 (PST)
Subject: [Rd] Passing R code from webpage
In-Reply-To: <BLU166-W39D87CA6ADB3BC4A98A959BEF40@phx.gbl>
References: <1361058494221-4658800.post@n4.nabble.com>
	<CAANJ-wek4j+ab=1_0quUGgrnBrf+kRMocFpTodRNCqAFrJEXHQ@mail.gmail.com>
	<BLU166-W35CDC0CE9CC52759F67450BEF40@phx.gbl>
	<1361186683328-4658909.post@n4.nabble.com>
	<BLU166-W39D87CA6ADB3BC4A98A959BEF40@phx.gbl>
Message-ID: <1361189605060-4658915.post@n4.nabble.com>

Yes, 

i have looked at apache, but  there is no Windows version (at least to my
knowledge).

I know how to connect to MS SQL from R, i just dont know how to do that from
web browser.

thanks, m



--
View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658915.html
Sent from the R devel mailing list archive at Nabble.com.


From marchywka at hotmail.com  Mon Feb 18 13:41:06 2013
From: marchywka at hotmail.com (Mike Marchywka)
Date: Mon, 18 Feb 2013 07:41:06 -0500
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361189605060-4658915.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>,
	<CAANJ-wek4j+ab=1_0quUGgrnBrf+kRMocFpTodRNCqAFrJEXHQ@mail.gmail.com>,
	<BLU166-W35CDC0CE9CC52759F67450BEF40@phx.gbl>,
	<1361186683328-4658909.post@n4.nabble.com>,
	<BLU166-W39D87CA6ADB3BC4A98A959BEF40@phx.gbl>,
	<1361189605060-4658915.post@n4.nabble.com>
Message-ID: <BLU166-W130749FF53B0851D2AA94CBEF40@phx.gbl>





----------------------------------------
> Date: Mon, 18 Feb 2013 04:13:25 -0800
> From: matevzpavlic at gmail.com
> To: r-devel at r-project.org
> Subject: Re: [Rd] Passing R code from webpage
>
> Yes,
>

y
> knowledge).

well, this getting off topic but I could suggest you go get cygwin and learn to use linux
while still on 'dohs LOL I think there is a 'dohs apache version but yes it is unlikely
that IIS would interface to stuff like this easily although i have no idea.?


>
> I know how to connect to MS SQL from R, i just dont know how to do that from
> web browser.

If you can do this it is likely a security flaw. You should do all of this on the server.
This has nothing to do with R...



>
> thanks, m
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658915.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
 		 	   		  

From simon.urbanek at r-project.org  Mon Feb 18 14:57:45 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 18 Feb 2013 08:57:45 -0500
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361186683328-4658909.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>
	<CAANJ-wek4j+ab=1_0quUGgrnBrf+kRMocFpTodRNCqAFrJEXHQ@mail.gmail.com>
	<BLU166-W35CDC0CE9CC52759F67450BEF40@phx.gbl>
	<1361186683328-4658909.post@n4.nabble.com>
Message-ID: <676B15E0-CD6B-4E9C-8A29-D2A8EA1699A3@r-project.org>

On Feb 18, 2013, at 6:24 AM, Matevz Pavlic wrote:

> Hi, 
> 
> i think all of this i kinda complicated, even though in all the packages
> authors  are saying that "minimum code is required". 
> I mean, i am not an IT engineer , but i have created quite some webpages, so
> i have some knowledge of HTML5, CSS, C# (limited), and also work quite a lot
> with R and still installing R to run as a webserver seems to be too
> complicated. 

Not at all - R has a built-in webserver (it's used for the help pages), so if you install R, you're done with that part. Rook gives you a wrapper for that.

The problem is it doesn't scale, so if you're happy with one-user solution then you can use R without anything. If you need something that scales, then you need something else -- and for Windows you're a bit out of luck, because the lack of fork+COW on Windows (BTW cygwin doesn't help there, either) paired with the fact that R is not thread-safe means it's quite hard to get scalability on Windows involving R. The best bet on Windows are server solutions that keep a pool of individual R instances as workers but I'm not aware of any off the top of my head (I recall some Java solutions way back when Java was hip and I have it on my ToDo list for Rserve but it's not there yet).


> I have look in all packages i can imaggine, Rook, ggoleVis, Shiny....but in
> all i get the problem when i want to connect to a MS SQL database.
> 

That shouldn't really matter - as long as you can connect from any R session, you will be able to connect through R from the webserver.


> This is the workflow that i'd like to achieve : 
> 1.) in webrowser connect to MS SQL database

I assume you mean from the R script? Otherwise you'll have to shove the data across (not impossible but why not connect from R?).


> 2.) do some R statistics and plots
> 3.) show that in web browser.
> 
> 
> I am pretty sure it can be very complicated, but it just seems so.
> 
> any help (still) greatly appreciated.
> 
> BTW: I HAVE posted in R-help, but no responses were given.
> m
> 
> regards, m
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658909.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From therneau at mayo.edu  Mon Feb 18 15:25:36 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 18 Feb 2013 08:25:36 -0600
Subject: [Rd] Small suggestion for termplot
Message-ID: <512239E0.7090303@mayo.edu>

Brian,
   I used termplot(..., plot=FALSE) recently in R-devel: works like a charm.  Thanks much 
for the update.

   Our in-house "gamterms" function, which this obviates, would also return the "constant" 
attribute from the underlying predict(..., type="terms") call.  I have occasionally found 
this useful, and so it would be a worthwhile addition to termplot.  Currently
       fit <- coxph(Surv(time, status) ~ pspline(age) + sex + ns(wt.loss), data=lung)
       zed <- termplot(fit, se=TRUE, plot=FALSE)

returns a list with components zed$age, zed$sex, zed$wt.loss.  The constant could be added 
as another element of the list or as an attribute, I don't have an opinion either way so 
have not suggested a patch.  You may have a reason for preferring one or the other.  
Clearly this is not critical for version 3.0 release.

   I sent this to you since you impliemented the plot=FALSE change, cc to the list in case 
someone else is appropriate.

   For those on the list, the recent change has three nice features:
      a. Use of predict(.., type='terms') is a nuisance because the result is in data set 
order rather than x order, a lines() call becomes a scribble.  This has reduced each term 
to the set of unique x values, in order, just what you need for a plot.
      b. In the coxph example above I use plot(zed$age$x, exp(zed$age$y), log='y') to get 
a better y-axis label.  For all the developers, this is a nice way to deflect requests for 
yet-another-plotting-option addition to termplot.
     c. Easy to overlay results from two separate fits.

Terry T.


From h.wickham at gmail.com  Mon Feb 18 16:17:19 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 18 Feb 2013 09:17:19 -0600
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361058494221-4658800.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>
Message-ID: <CABdHhvGxWRrMtuXfNdTcK_dFrWqT6oe48QT17BJAoovQ5EJSTQ@mail.gmail.com>

No one yet has mentioned shiny (http://www.rstudio.com/shiny/); it
allows you to get up and prototyping quickly, and we're working on
ways to make it just as easy to scale to multiple users (currently
it's possible, but you have to be willing to get your hands dirty
configuring servers etc).

Hadley

On Sat, Feb 16, 2013 at 5:48 PM, Matevz Pavlic <matevzpavlic at gmail.com> wrote:
> Hi all,
>
> Is there a way to pass R code from web page (html file) to do some
> statistics and than plot the output in web browser.
>
> I am looking forever at this, and cant find a way.
>
> Regards,m
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800.html
> Sent from the R devel mailing list archive at Nabble.com.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Chief Scientist, RStudio
http://had.co.nz/


From matevzpavlic at gmail.com  Mon Feb 18 16:20:01 2013
From: matevzpavlic at gmail.com (Matevz Pavlic)
Date: Mon, 18 Feb 2013 07:20:01 -0800 (PST)
Subject: [Rd] Passing R code from webpage
In-Reply-To: <676B15E0-CD6B-4E9C-8A29-D2A8EA1699A3@r-project.org>
References: <1361058494221-4658800.post@n4.nabble.com>
	<CAANJ-wek4j+ab=1_0quUGgrnBrf+kRMocFpTodRNCqAFrJEXHQ@mail.gmail.com>
	<BLU166-W35CDC0CE9CC52759F67450BEF40@phx.gbl>
	<1361186683328-4658909.post@n4.nabble.com>
	<676B15E0-CD6B-4E9C-8A29-D2A8EA1699A3@r-project.org>
Message-ID: <1361200801464-4658944.post@n4.nabble.com>

Hi, 


>Not at all - R has a built-in webserver (it's used for the help pages), so
if you install R, you're done with that part. Rook >gives you a wrapper for
that. 

What do you mean by wrapper? 


> The problem is it doesn't scale, so if you're happy with one-user solution
> then you can use R without anything. If you 
> need something that scales, then you need something else -- and for
> Windows you're a bit out of luck, because the lack > of fork+COW on
> Windows (BTW cygwin doesn't help there, either) paired with the fact that
> R is not thread-safe means i
> quite hard to get scalability on Windows involving R. The best bet on
> Windows are server solutions that keep a pool of 
> individual R instances as workers but I'm not aware of any off the top of
> my head (I recall some Java solutions way back
> when Java was hip and I have it on my ToDo list for Rserve but it's not
> there yet). 

What do you mean by scale/scaling? (not an IT engineer). Mainly this would
be used for one-user-at-the-time. So if by scaling you mean multiple user at
the same time, this would not be a problem....

> I have look in all packages i can imaggine, Rook, ggoleVis, Shiny....but
> in 
> all i get the problem when i want to connect to a MS SQL database. 
> 

> That shouldn't really matter - as long as you can connect from any R
> session, you will be able to connect through R from 
> the webserver. 

The problem is that i don't even know how to start getting data from SQL and
put it to R and get plot back ;)

> This is the workflow that i'd like to achieve : 
> 1.) in webrowser connect to MS SQL database 

> I assume you mean from the R script? Otherwise you'll have to shove the
> data across (not impossible but why not 
> connect from R?).  

Yes, i know how to do it from R script. Don't know how to do this in HTML.

I just need some pointers (or even better example of code) on how to use R
script in HTML.


Thanks, m



--
View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658944.html
Sent from the R devel mailing list archive at Nabble.com.


From h.wickham at gmail.com  Mon Feb 18 16:20:51 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 18 Feb 2013 09:20:51 -0600
Subject: [Rd] quote() vs quote(expr=)
Message-ID: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>

Hi all,

I think there's a small buglet in quote:

str(quote())
# Error in quote() : 0 arguments passed to 'quote' which requires 1
str(quote(expr = ))
# symbol

I bring this up because this seems like the most natural way of
capturing the "missing" symbol with pure R code, compared to
substitute() or bquote() or formals(plot)$x

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From matevzpavlic at gmail.com  Mon Feb 18 16:33:15 2013
From: matevzpavlic at gmail.com (Matevz Pavlic)
Date: Mon, 18 Feb 2013 07:33:15 -0800 (PST)
Subject: [Rd] Passing R code from webpage
In-Reply-To: <CABdHhvGxWRrMtuXfNdTcK_dFrWqT6oe48QT17BJAoovQ5EJSTQ@mail.gmail.com>
References: <1361058494221-4658800.post@n4.nabble.com>
	<CABdHhvGxWRrMtuXfNdTcK_dFrWqT6oe48QT17BJAoovQ5EJSTQ@mail.gmail.com>
Message-ID: <1361201595142-4658946.post@n4.nabble.com>

Hi, 


> No one yet has mentioned shiny (http://www.rstudio.com/shiny/); it 
> allows you to get up and prototyping quickly, and we're working on 
> ways to make it just as easy to scale to multiple users (currently 
> it's possible, but you have to be willing to get your hands dirty 
> configuring servers etc). 

They did mention it....and i took a look. But as always could set it up. Can
find any useful manual for connection to MS SQL server and getting data from
SQL, doing statistics and showing plots in Browser.

Any pointers are welcome...

regards, m




--
View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658946.html
Sent from the R devel mailing list archive at Nabble.com.


From pdalgd at gmail.com  Mon Feb 18 16:53:50 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 18 Feb 2013 16:53:50 +0100
Subject: [Rd] quote() vs quote(expr=)
In-Reply-To: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
References: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
Message-ID: <01CE77E8-6F40-4050-A365-A21DFF933585@gmail.com>


On Feb 18, 2013, at 16:20 , Hadley Wickham wrote:

> Hi all,
> 
> I think there's a small buglet in quote:
> 
> str(quote())
> # Error in quote() : 0 arguments passed to 'quote' which requires 1
> str(quote(expr = ))
> # symbol
> 

If there is a bug here, I'd say that it is in str(), revealing the implementation of the missing value as the symbol ``, which we otherwise try not to disclose to R code, e.g.

> as.symbol("")
Error in as.symbol("") : attempt to use zero-length variable name

There's a difference between passing 0 arguments and passing a missing argument and I see nothing particularly wrong with quote(expr=) returning missing. It is, for instance, reasonably consistent that

> eval(quote(expr=))
Error in eval(expr, envir, enclos) : argument is missing, with no default

> I bring this up because this seems like the most natural way of
> capturing the "missing" symbol with pure R code, compared to
> substitute() or bquote() or formals(plot)$x

Are you sure you want to do that? I tend to think that it belongs in the "if it breaks, you get to keep both pieces" category.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From simon.urbanek at r-project.org  Mon Feb 18 17:02:18 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 18 Feb 2013 11:02:18 -0500
Subject: [Rd] Passing R code from webpage
In-Reply-To: <1361200801464-4658944.post@n4.nabble.com>
References: <1361058494221-4658800.post@n4.nabble.com>
	<CAANJ-wek4j+ab=1_0quUGgrnBrf+kRMocFpTodRNCqAFrJEXHQ@mail.gmail.com>
	<BLU166-W35CDC0CE9CC52759F67450BEF40@phx.gbl>
	<1361186683328-4658909.post@n4.nabble.com>
	<676B15E0-CD6B-4E9C-8A29-D2A8EA1699A3@r-project.org>
	<1361200801464-4658944.post@n4.nabble.com>
Message-ID: <70DFF251-F763-40E1-8AC3-443D3291453E@r-project.org>


On Feb 18, 2013, at 10:20 AM, Matevz Pavlic wrote:

> Hi, 
> 
> 
>> Not at all - R has a built-in webserver (it's used for the help pages), so
> if you install R, you're done with that part. Rook >gives you a wrapper for
> that. 
> 
> What do you mean by wrapper? 
> 

It defines an API that is easier to use that writing the httpd function (which is called by the build-in HTTP server) yourself.


>> The problem is it doesn't scale, so if you're happy with one-user solution
>> then you can use R without anything. If you 
>> need something that scales, then you need something else -- and for
>> Windows you're a bit out of luck, because the lack > of fork+COW on
>> Windows (BTW cygwin doesn't help there, either) paired with the fact that
>> R is not thread-safe means i
>> quite hard to get scalability on Windows involving R. The best bet on
>> Windows are server solutions that keep a pool of 
>> individual R instances as workers but I'm not aware of any off the top of
>> my head (I recall some Java solutions way back
>> when Java was hip and I have it on my ToDo list for Rserve but it's not
>> there yet). 
> 
> What do you mean by scale/scaling? (not an IT engineer). Mainly this would
> be used for one-user-at-the-time. So if by scaling you mean multiple user at
> the same time,

Yes

> this would not be a problem....
> 

Ok, you're fine then.


>> I have look in all packages i can imaggine, Rook, ggoleVis, Shiny....but
>> in 
>> all i get the problem when i want to connect to a MS SQL database. 
>> 
> 
>> That shouldn't really matter - as long as you can connect from any R
>> session, you will be able to connect through R from 
>> the webserver. 
> 
> The problem is that i don't even know how to start getting data from SQL and
> put it to R and get plot back ;)
> 

Why would you want to pull the data client-side? That is quite cumbersome since you have to rely on the client (browser) to be able to connect to the database -- I don't think that's easy. It's much easier to just tell R what to query for and let R pull the data, plot it and return the plots and results.


>> This is the workflow that i'd like to achieve : 
>> 1.) in webrowser connect to MS SQL database 
> 
>> I assume you mean from the R script? Otherwise you'll have to shove the
>> data across (not impossible but why not 
>> connect from R?).  
> 
> Yes, i know how to do it from R script. Don't know how to do this in HTML.
> 
> I just need some pointers (or even better example of code) on how to use R
> script in HTML.
> 

I'm not sure what you really mean ;) - using R from HTML simply means sending R code from the client (browser) to the server and have the server run that code. That's easy - you simply issue a request, for example
http://myserver/R?eval=print(1:10)
It is inherently unsafe (anyone can do anything on your server), but in principle possible. In the real world you probably don't want to do that (unless you don't care about security) - you want to have the R script on the server to define what to do and just accept input, which could be a SQL query for example (still some security implications but not as bad) or even better just arguments that define what to look up.

For example (this is using FastRWeb API but it should illustrate the idea):

foo.R:

run <- function(city, ...) {
  if (missing(city)) return("Sorry, you have to specify a city!")
  db <- dbConnect("myDatabase:...")
  q <- dbSendQuery(db, "SELECT age FROM user WHERE city=?", city)
  age <- fetch(q, n = -1)[[1]]
  dbClearResult(q)
  dbDisconnect(db)
  p <- WebPlot(400, 400)
  hist(age)
  p
}
 
In HTML you can either use a form

<form action=R/foo>
City: <input type=text name=city>
<input type=submit>
</form>

or AJAX into a div
 
<a href=# onclick='javascript:req('foo?city=Paris', 'result');'>Paris</a><p>
<div id=result></div>

where the req() JS function could look like this (a more complete one is in the FastRWeb examples):

function req(what, where) {
  if (!window.ajax) {
   if (window.XMLHttpRequest)
    window.ajax = new XMLHttpRequest();
  else if (window.ActiveXObject)
    window.ajax = new ActiveXObject("Microsoft.XMLHTTP");
  }
  var ajax= window.ajax;
  ajax.open("GET",what);
  ajax.onreadystatechange = function() {
  if (ajax.readyState == 4) {
    if (ajax.status == 200)
      document.getElementById(where).innerHTML = ajax.responseText;
    else
      document.getElementById(where).innerHTML = "<b>Sorry, cannot load this page</b> ("+ajax.status+" "+window.ajax.statusText+")";
    }
  }
  ajax.send(null);
  return false;
}

Either way, you get the idea - you could pass a SQL query instead or use eval() in the argument if you want (as I said, that's too insecure for my taste). But in all cases you are really running everything server-side.


That said, there is potentially another solution -- I don't know anything about CSHTML, but if it can really hook into C# from HTML then you make be able to use the C# part to connect to R - there is a C# Rserve client (assuming that CSHTML is server-side interpretation). This is theoretical, I don't use Windows so I don't know if that is meant to work.

Cheers,
Simon


> 
> Thanks, m
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658944.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From h.wickham at gmail.com  Mon Feb 18 17:04:04 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 18 Feb 2013 10:04:04 -0600
Subject: [Rd] quote() vs quote(expr=)
In-Reply-To: <01CE77E8-6F40-4050-A365-A21DFF933585@gmail.com>
References: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
	<01CE77E8-6F40-4050-A365-A21DFF933585@gmail.com>
Message-ID: <CABdHhvHQ8uEqZ7AEhhY131=BRaUXByspdoQuc2+c3=gcBfPARw@mail.gmail.com>

> If there is a bug here, I'd say that it is in str(), revealing the implementation of the missing value as the symbol ``,

Yes, a fix to str would be nice too :)

> which we otherwise try not to disclose to R code, e.g.
>
>> as.symbol("")
> Error in as.symbol("") : attempt to use zero-length variable name


> There's a difference between passing 0 arguments and passing a missing argument and I see nothing particularly wrong with quote(expr=) returning missing. It is, for instance, reasonably consistent that
>
>> eval(quote(expr=))
> Error in eval(expr, envir, enclos) : argument is missing, with no default

quote(expr =) returning missing seems like the right thing to me,
quote() throwing an error does not, because it violates the usual
semantics where f(x = ) is equivalent to f().

>> I bring this up because this seems like the most natural way of
>> capturing the "missing" symbol with pure R code, compared to
>> substitute() or bquote() or formals(plot)$x
>
> Are you sure you want to do that? I tend to think that it belongs in the "if it breaks, you get to keep both pieces" category.

You do occasionally need the missing symbol when computing on the
language (see e.g.
https://github.com/hadley/pryr/blob/master/R/partial.r for an example
of where I use it).  You do have to handle it with care, but you are
limited without it.

I think it's better to have one canonical way of getting the missing
symbol when you need it, so that it's easier to recognise in code, and
to clearly illustrates that you do want the missing symbol.  I'd
certainly accept an argument that there should be a dedicated function
to do this, rather than relying on an implementation side-effect of
quote, bquote etc.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From pdalgd at gmail.com  Mon Feb 18 17:35:21 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 18 Feb 2013 17:35:21 +0100
Subject: [Rd] quote() vs quote(expr=)
In-Reply-To: <CABdHhvHQ8uEqZ7AEhhY131=BRaUXByspdoQuc2+c3=gcBfPARw@mail.gmail.com>
References: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
	<01CE77E8-6F40-4050-A365-A21DFF933585@gmail.com>
	<CABdHhvHQ8uEqZ7AEhhY131=BRaUXByspdoQuc2+c3=gcBfPARw@mail.gmail.com>
Message-ID: <6860B4BC-FCA9-4A93-8817-8BB99AEA1A0D@gmail.com>


On Feb 18, 2013, at 17:04 , Hadley Wickham wrote:

> quote(expr =) returning missing seems like the right thing to me,
> quote() throwing an error does not, because it violates the usual
> semantics where f(x = ) is equivalent to f().

Except that it isn't:

> (function(...)nargs())()
[1] 0
> (function(...)nargs())(x=)
[1] 1


-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From luke-tierney at uiowa.edu  Mon Feb 18 19:31:10 2013
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 18 Feb 2013 12:31:10 -0600
Subject: [Rd] quote() vs quote(expr=)
In-Reply-To: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
References: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
Message-ID: <alpine.LFD.2.03.1302181227030.10691@uiowa.edu>

I wouldn't count on any way of capturing this thing being reliable in
the long term.  As I recall what I do in codetools and the compiler is
use features of missing() to test for it, but try to abstract those
uses into one or two places only so I can easily change them if
missing()'s behavior changes. Basically this internal thing
_shouldn't_ be visible at R level, and if we ever figure out how to
make that happen it will.

Best,

luke

On Mon, 18 Feb 2013, Hadley Wickham wrote:

> Hi all,
>
> I think there's a small buglet in quote:
>
> str(quote())
> # Error in quote() : 0 arguments passed to 'quote' which requires 1
> str(quote(expr = ))
> # symbol
>
> I bring this up because this seems like the most natural way of
> capturing the "missing" symbol with pure R code, compared to
> substitute() or bquote() or formals(plot)$x
>
> Hadley
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From h.wickham at gmail.com  Mon Feb 18 19:31:59 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 18 Feb 2013 12:31:59 -0600
Subject: [Rd] quote() vs quote(expr=)
In-Reply-To: <6860B4BC-FCA9-4A93-8817-8BB99AEA1A0D@gmail.com>
References: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
	<01CE77E8-6F40-4050-A365-A21DFF933585@gmail.com>
	<CABdHhvHQ8uEqZ7AEhhY131=BRaUXByspdoQuc2+c3=gcBfPARw@mail.gmail.com>
	<6860B4BC-FCA9-4A93-8817-8BB99AEA1A0D@gmail.com>
Message-ID: <CABdHhvG3Z957-JnuiEkFw6D=o=LuAts2oEvXGE2HZ0kWmYvbAw@mail.gmail.com>

On Mon, Feb 18, 2013 at 10:35 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On Feb 18, 2013, at 17:04 , Hadley Wickham wrote:
>
>> quote(expr =) returning missing seems like the right thing to me,
>> quote() throwing an error does not, because it violates the usual
>> semantics where f(x = ) is equivalent to f().
>
> Except that it isn't:
>
>> (function(...)nargs())()
> [1] 0
>> (function(...)nargs())(x=)
> [1] 1

But hardly any functions use nargs:

> find_funs("package:base", fun_calls, fixed("nargs"))
Using environment package:base
 [1] "-.Date"               "-.POSIXt"             "[.data.frame"
 [4] "[[.data.frame"        "[[<-.data.frame"      "[[<-.numeric_version"
 [7] "[<-.data.frame"       "+.Date"               "+.POSIXt"
[10] "diag"                 "message"              "Ops.data.frame"
[13] "Ops.Date"             "Ops.difftime"         "Ops.numeric_version"
[16] "Ops.POSIXt"           "seq.default"          "stop"
[19] "system.file"          "trace"                "warning"
> find_funs("package:stats", fun_calls, fixed("nargs"))
Using environment package:stats
[1] "model.frame.default"

The majority is used to switch between cases like -x vs x - y or to
detect extra arguments if something weird is being done with ...

So I think it's reasonable to expect that f() and f(x = ) do the same thing.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From h.wickham at gmail.com  Mon Feb 18 19:33:14 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 18 Feb 2013 12:33:14 -0600
Subject: [Rd] quote() vs quote(expr=)
In-Reply-To: <alpine.LFD.2.03.1302181227030.10691@uiowa.edu>
References: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
	<alpine.LFD.2.03.1302181227030.10691@uiowa.edu>
Message-ID: <CABdHhvFs3voJjhQ7oCMMxXSTkDvAQje_Nr2dnkWJsMwJf9z0qA@mail.gmail.com>

In general, should we expect that the ability to compute on the
language within R will decrease over time? Otherwise, I presume if you
do change the behaviour of missing then you'll still provide some way
to create/call functions with missing arguments.

Hadley

On Mon, Feb 18, 2013 at 12:31 PM,  <luke-tierney at uiowa.edu> wrote:
> I wouldn't count on any way of capturing this thing being reliable in
> the long term.  As I recall what I do in codetools and the compiler is
> use features of missing() to test for it, but try to abstract those
> uses into one or two places only so I can easily change them if
> missing()'s behavior changes. Basically this internal thing
> _shouldn't_ be visible at R level, and if we ever figure out how to
> make that happen it will.
>
> Best,
>
> luke
>
>
> On Mon, 18 Feb 2013, Hadley Wickham wrote:
>
>> Hi all,
>>
>> I think there's a small buglet in quote:
>>
>> str(quote())
>> # Error in quote() : 0 arguments passed to 'quote' which requires 1
>> str(quote(expr = ))
>> # symbol
>>
>> I bring this up because this seems like the most natural way of
>> capturing the "missing" symbol with pure R code, compared to
>> substitute() or bquote() or formals(plot)$x
>>
>> Hadley
>>
>>
>
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



-- 
Chief Scientist, RStudio
http://had.co.nz/


From luke-tierney at uiowa.edu  Mon Feb 18 19:43:01 2013
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 18 Feb 2013 12:43:01 -0600
Subject: [Rd] quote() vs quote(expr=)
In-Reply-To: <CABdHhvFs3voJjhQ7oCMMxXSTkDvAQje_Nr2dnkWJsMwJf9z0qA@mail.gmail.com>
References: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
	<alpine.LFD.2.03.1302181227030.10691@uiowa.edu>
	<CABdHhvFs3voJjhQ7oCMMxXSTkDvAQje_Nr2dnkWJsMwJf9z0qA@mail.gmail.com>
Message-ID: <alpine.LFD.2.03.1302181238210.10691@uiowa.edu>

Of course not. What I hope can happpen is that we can reduce the
degree to which internal implementation quirks leak out into the user
level. The fact that there is an internal "missing token" (that
happens to be used for a couple of different things) is a quirk; if
you look at the code I use you can see why it is a quirk. Cleaning
this up will help computing on the language (at least that is the
hope).

luke

On Mon, 18 Feb 2013, Hadley Wickham wrote:

> In general, should we expect that the ability to compute on the
> language within R will decrease over time? Otherwise, I presume if you
> do change the behaviour of missing then you'll still provide some way
> to create/call functions with missing arguments.
>
> Hadley
>
> On Mon, Feb 18, 2013 at 12:31 PM,  <luke-tierney at uiowa.edu> wrote:
>> I wouldn't count on any way of capturing this thing being reliable in
>> the long term.  As I recall what I do in codetools and the compiler is
>> use features of missing() to test for it, but try to abstract those
>> uses into one or two places only so I can easily change them if
>> missing()'s behavior changes. Basically this internal thing
>> _shouldn't_ be visible at R level, and if we ever figure out how to
>> make that happen it will.
>>
>> Best,
>>
>> luke
>>
>>
>> On Mon, 18 Feb 2013, Hadley Wickham wrote:
>>
>>> Hi all,
>>>
>>> I think there's a small buglet in quote:
>>>
>>> str(quote())
>>> # Error in quote() : 0 arguments passed to 'quote' which requires 1
>>> str(quote(expr = ))
>>> # symbol
>>>
>>> I bring this up because this seems like the most natural way of
>>> capturing the "missing" symbol with pure R code, compared to
>>> substitute() or bquote() or formals(plot)$x
>>>
>>> Hadley
>>>
>>>
>>
>> --
>> Luke Tierney
>> Chair, Statistics and Actuarial Science
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>    Actuarial Science
>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>
>
>
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From h.wickham at gmail.com  Mon Feb 18 19:59:44 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 18 Feb 2013 12:59:44 -0600
Subject: [Rd] quote() vs quote(expr=)
In-Reply-To: <alpine.LFD.2.03.1302181238210.10691@uiowa.edu>
References: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
	<alpine.LFD.2.03.1302181227030.10691@uiowa.edu>
	<CABdHhvFs3voJjhQ7oCMMxXSTkDvAQje_Nr2dnkWJsMwJf9z0qA@mail.gmail.com>
	<alpine.LFD.2.03.1302181238210.10691@uiowa.edu>
Message-ID: <CABdHhvHcAG77QVXu0o5x1AHORgv_fKGggFYPU4njk+jFkGcA-Q@mail.gmail.com>

Ok, that's what I thought.  Thanks!
Hadley

On Mon, Feb 18, 2013 at 12:43 PM,  <luke-tierney at uiowa.edu> wrote:
> Of course not. What I hope can happpen is that we can reduce the
> degree to which internal implementation quirks leak out into the user
> level. The fact that there is an internal "missing token" (that
> happens to be used for a couple of different things) is a quirk; if
> you look at the code I use you can see why it is a quirk. Cleaning
> this up will help computing on the language (at least that is the
> hope).
>
>
> luke
>
> On Mon, 18 Feb 2013, Hadley Wickham wrote:
>
>> In general, should we expect that the ability to compute on the
>> language within R will decrease over time? Otherwise, I presume if you
>> do change the behaviour of missing then you'll still provide some way
>> to create/call functions with missing arguments.
>>
>> Hadley
>>
>> On Mon, Feb 18, 2013 at 12:31 PM,  <luke-tierney at uiowa.edu> wrote:
>>>
>>> I wouldn't count on any way of capturing this thing being reliable in
>>> the long term.  As I recall what I do in codetools and the compiler is
>>> use features of missing() to test for it, but try to abstract those
>>> uses into one or two places only so I can easily change them if
>>> missing()'s behavior changes. Basically this internal thing
>>> _shouldn't_ be visible at R level, and if we ever figure out how to
>>> make that happen it will.
>>>
>>> Best,
>>>
>>> luke
>>>
>>>
>>> On Mon, 18 Feb 2013, Hadley Wickham wrote:
>>>
>>>> Hi all,
>>>>
>>>> I think there's a small buglet in quote:
>>>>
>>>> str(quote())
>>>> # Error in quote() : 0 arguments passed to 'quote' which requires 1
>>>> str(quote(expr = ))
>>>> # symbol
>>>>
>>>> I bring this up because this seems like the most natural way of
>>>> capturing the "missing" symbol with pure R code, compared to
>>>> substitute() or bquote() or formals(plot)$x
>>>>
>>>> Hadley
>>>>
>>>>
>>>
>>> --
>>> Luke Tierney
>>> Chair, Statistics and Actuarial Science
>>> Ralph E. Wareham Professor of Mathematical Sciences
>>> University of Iowa                  Phone:             319-335-3386
>>> Department of Statistics and        Fax:               319-335-3017
>>>    Actuarial Science
>>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
>>
>>
>>
>>
>
> --
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu



-- 
Chief Scientist, RStudio
http://had.co.nz/


From matevzpavlic at gmail.com  Mon Feb 18 21:44:20 2013
From: matevzpavlic at gmail.com (Matevz Pavlic)
Date: Mon, 18 Feb 2013 12:44:20 -0800 (PST)
Subject: [Rd] Passing R code from webpage
In-Reply-To: <70DFF251-F763-40E1-8AC3-443D3291453E@r-project.org>
References: <1361058494221-4658800.post@n4.nabble.com>
	<CAANJ-wek4j+ab=1_0quUGgrnBrf+kRMocFpTodRNCqAFrJEXHQ@mail.gmail.com>
	<BLU166-W35CDC0CE9CC52759F67450BEF40@phx.gbl>
	<1361186683328-4658909.post@n4.nabble.com>
	<676B15E0-CD6B-4E9C-8A29-D2A8EA1699A3@r-project.org>
	<1361200801464-4658944.post@n4.nabble.com>
	<70DFF251-F763-40E1-8AC3-443D3291453E@r-project.org>
Message-ID: <1361220260531-4658988.post@n4.nabble.com>

*Hi, 

first of all-thank you for your extensive answer.*




> Hi, 
> 
> 
>> Not at all - R has a built-in webserver (it's used for the help pages),
>> so
> if you install R, you're done with that part. Rook >gives you a wrapper
> for
> that. 
> 
> What do you mean by wrapper? 
> 

>It defines an API that is easier to use that writing the httpd function
(which is called by the build-in HTTP server) yourself.

*OK. Thanks for the clarification.*

> What do you mean by scale/scaling? (not an IT engineer). Mainly this would
> be used for one-user-at-the-time. So if by scaling you mean multiple user
> at
> the same time,



I'm not sure what you really mean ;) - using R from HTML simply means
sending R code from the client (browser) to the server and have the server
run that code. That's easy - you simply issue a request, for example
http://myserver/R?eval=print(1:10)

* I don't know if it should work, but he link with example doesn't work on
my machine.... )*

> For example (this is using FastRWeb API but it should illustrate the
> idea):

*Ok, here's where i lose it.*
/
foo.R:

run <- function(city, ...) {
  if (missing(city)) return("Sorry, you have to specify a city!")
  db <- dbConnect("myDatabase:...")
  q <- dbSendQuery(db, "SELECT age FROM user WHERE city=?", city)
  age <- fetch(q, n = -1)[[1]]
  dbClearResult(q)
  dbDisconnect(db)
  p <- WebPlot(400, 400)
  hist(age)
  p
}/

*Ok, creating a foo.R is easy. But where do i put this file? Do i have to
start the server before or open  R ? *

 
I/n HTML you can either use a form/

/<form action=R/foo>
City: <input type=text name=city>
<input type=submit>
</form>/

*How does HTML know where to "look" for the file foo.R. This is what i can
't see written anywhere in manuals?
*
/
Either way, you get the idea - you could pass a SQL query instead or use
eval() in the argument if you want (as I said, that's too insecure for my
taste). But in all cases you are really running everything server-side.
/

*Ok, this is even better. *

/That said, there is potentially another solution -- I don't know anything
about CSHTML, but if it can really hook into C# from HTML then you make be
able to use the C# part to connect to R - there is a C# Rserve client
(assuming that CSHTML is server-side interpretation). This is theoretical, I
don't use Windows so I don't know if that is meant to work./

*Ok, i'll look at it. *

Thank again, 

matevz
>



--
View this message in context: http://r.789695.n4.nabble.com/Passing-R-code-from-webpage-tp4658800p4658988.html
Sent from the R devel mailing list archive at Nabble.com.


From h.wickham at gmail.com  Mon Feb 18 22:33:16 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 18 Feb 2013 15:33:16 -0600
Subject: [Rd] Including modified R source code in a package
Message-ID: <CABdHhvEqROBjGsgRYEHGG=SXnjHBsb60sWKwOc01TBh9EZ3LWg@mail.gmail.com>

Hi all,

I would like to include a function that I have made by modifying an
existing R function (bw.SJ and corresponding code in bandwidths.c).
The header of bandwidths.c states:

/*
 *  R : A Computer Language for Statistical Data Analysis
 *  bandwidth.c by W. N. Venables and B. D. Ripley  Copyright (C) 1994-2001
 *  Copyright (C) 2012  The R Core Team
 *
 *  This program is free software; you can redistribute it and/or modify
 *  it under the terms of the GNU General Public License as published by
 *  the Free Software Foundation; either version 2 of the License, or
 *  (at your option) any later version.
 ...
*/

so it was originally written by Bill Venables and Brian Ripley, who in
2012 passed the copyrights to the R core team.

What do I need to do to ensure meet my obligations under the GPL and
to adequately acknowledge the work of the original authors.
Currently:

* my package has a compatible license (also GPL >= 2), and

* I have acknowledged the authors in the documentation for my function

* In the code, I have retained the copyrights of the original authors

Do I also need to include Brian, Bill or the R core team in the
authors at R field in my DESCRIPTION (as contributors)?

Is there anything else I should do?

Thanks!

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From rasmussen.bryan at gmail.com  Tue Feb 19 01:19:19 2013
From: rasmussen.bryan at gmail.com (bryan rasmussen)
Date: Tue, 19 Feb 2013 01:19:19 +0100
Subject: [Rd] best way to extract this meaningful data from a table
Message-ID: <CAHKsR688gB80+BHk1N8oLXwGNW_f=yCDW9H0KWMCujJ5CP2WiQ@mail.gmail.com>

I have a table with a structure like the following:

lang | basic id | doc id | topics|
se  | 447157 | MD_2002_0014 |12 |

loaded topics <- read.table("path to file",header=TRUE, sep="|",
fileEncoding="utf-8")

In that table the actual meaningful data (in this context) is the text
before the first underscore in doc id which is the document type ( for
example MD as above), and topics.
However topics can have more than one value in it, multiple values are
comma separated, if there is no actual topic I have a 0 although I can
also have an empty column if I want.

So what I want is the best way to extract the meaningful data - the
comma separated values of each topics column and the actual document
type so that I can start to do reports of how many documents of type X
have no topics, median number of topics per document type etc.

Do I have to loop through the table and build a new table up with the
info I want, or is there a smarter way to do it?
If a smarter way, what is that smarter way.

Thanks,
Bryan Rasmussen


From kasperdanielhansen at gmail.com  Tue Feb 19 03:57:54 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Mon, 18 Feb 2013 21:57:54 -0500
Subject: [Rd] best way to extract this meaningful data from a table
In-Reply-To: <CAHKsR688gB80+BHk1N8oLXwGNW_f=yCDW9H0KWMCujJ5CP2WiQ@mail.gmail.com>
References: <CAHKsR688gB80+BHk1N8oLXwGNW_f=yCDW9H0KWMCujJ5CP2WiQ@mail.gmail.com>
Message-ID: <CAC2h7uvT=ADLONqea2L5GqVuTL6Q_LgXhVw1bpp3B8=WRMGtMg@mail.gmail.com>

This is not an R-devel question, so please do not reply to this list.

I would try
  sapply(strsplit(loaded.topics$doc.id, "_"), function(xx) xx[1])
to get the MD part.

Kasper

On Mon, Feb 18, 2013 at 7:19 PM, bryan rasmussen
<rasmussen.bryan at gmail.com> wrote:
> I have a table with a structure like the following:
>
> lang | basic id | doc id | topics|
> se  | 447157 | MD_2002_0014 |12 |
>
> loaded topics <- read.table("path to file",header=TRUE, sep="|",
> fileEncoding="utf-8")
>
> In that table the actual meaningful data (in this context) is the text
> before the first underscore in doc id which is the document type ( for
> example MD as above), and topics.
> However topics can have more than one value in it, multiple values are
> comma separated, if there is no actual topic I have a 0 although I can
> also have an empty column if I want.
>
> So what I want is the best way to extract the meaningful data - the
> comma separated values of each topics column and the actual document
> type so that I can start to do reports of how many documents of type X
> have no topics, median number of topics per document type etc.
>
> Do I have to loop through the table and build a new table up with the
> info I want, or is there a smarter way to do it?
> If a smarter way, what is that smarter way.
>
> Thanks,
> Bryan Rasmussen
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Tue Feb 19 11:25:37 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 19 Feb 2013 05:25:37 -0500
Subject: [Rd] Including modified R source code in a package
In-Reply-To: <CABdHhvEqROBjGsgRYEHGG=SXnjHBsb60sWKwOc01TBh9EZ3LWg@mail.gmail.com>
References: <CABdHhvEqROBjGsgRYEHGG=SXnjHBsb60sWKwOc01TBh9EZ3LWg@mail.gmail.com>
Message-ID: <51235321.3040007@gmail.com>

On 13-02-18 4:33 PM, Hadley Wickham wrote:
> Hi all,
>
> I would like to include a function that I have made by modifying an
> existing R function (bw.SJ and corresponding code in bandwidths.c).
> The header of bandwidths.c states:
>
> /*
>   *  R : A Computer Language for Statistical Data Analysis
>   *  bandwidth.c by W. N. Venables and B. D. Ripley  Copyright (C) 1994-2001
>   *  Copyright (C) 2012  The R Core Team
>   *
>   *  This program is free software; you can redistribute it and/or modify
>   *  it under the terms of the GNU General Public License as published by
>   *  the Free Software Foundation; either version 2 of the License, or
>   *  (at your option) any later version.
>   ...
> */
>
> so it was originally written by Bill Venables and Brian Ripley, who in
> 2012 passed the copyrights to the R core team.

I would not assume that:  I would assume that the R Core Team licensed 
the source from Venables and Ripley (maybe under the GPL, but not 
necessarily), and both them and R Core Team now hold copyright, and are 
willing to license it to you under the GPL.

>
> What do I need to do to ensure meet my obligations under the GPL and

I won't give legal advice.

> to adequately acknowledge the work of the original authors.
> Currently:
>
> * my package has a compatible license (also GPL >= 2), and
>
> * I have acknowledged the authors in the documentation for my function
>
> * In the code, I have retained the copyrights of the original authors
>
> Do I also need to include Brian, Bill or the R core team in the
> authors at R field in my DESCRIPTION (as contributors)?

That seems reasonable.

Duncan Murdoch


From pdalgd at gmail.com  Tue Feb 19 14:03:03 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 19 Feb 2013 14:03:03 +0100
Subject: [Rd] quote() vs quote(expr=)
In-Reply-To: <alpine.LFD.2.03.1302181227030.10691@uiowa.edu>
References: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
	<alpine.LFD.2.03.1302181227030.10691@uiowa.edu>
Message-ID: <4DC52965-C9CD-446E-BAE0-58765D3B8324@gmail.com>


On Feb 18, 2013, at 19:31 , <luke-tierney at uiowa.edu> <luke-tierney at uiowa.edu> wrote:

> I wouldn't count on any way of capturing this thing being reliable in
> the long term.  As I recall what I do in codetools and the compiler is
> use features of missing() to test for it, but try to abstract those
> uses into one or two places only so I can easily change them if
> missing()'s behavior changes. Basically this internal thing
> _shouldn't_ be visible at R level, and if we ever figure out how to
> make that happen it will.
> 
> Best,
> 
> luke
> 

Yes. I think we at some point played around with the idea of making the missing object a genuine first class object. However, the semantics are too irregular, as in

> a <- alist(x=)
> a$x

> b <- a$x
> c <- b
Error: argument "b" is missing, with no default

An R object than can be referenced, but (sometimes) not dereferenced is just weird.

On the other hand, if we want to be able to compute on things like argument lists, there needs to be a way of representing an absent default. Also, a functions evaluation frame will contain objects representing arguments, even if they are missing, as in

> (function(x)ls())()
[1] "x"

So it seems that there is no way around letting lists and environments have missing components. It is a quirk that it happens to be implemented as as.name(""), though.

Come to think of it, there are a few oddities in the current design: 

- why can't we check for a missing list component with missing(a$x)?

- why does a$x above not throw an error? (I can see that it is necessary to be able to shuffle argument lists around, and probably also to subset them, but direct dereference could be avoided, I think.)


> On Mon, 18 Feb 2013, Hadley Wickham wrote:
> 
>> Hi all,
>> 
>> I think there's a small buglet in quote:
>> 
>> str(quote())
>> # Error in quote() : 0 arguments passed to 'quote' which requires 1
>> str(quote(expr = ))
>> # symbol
>> 
>> I bring this up because this seems like the most natural way of
>> capturing the "missing" symbol with pure R code, compared to
>> substitute() or bquote() or formals(plot)$x
>> 
>> Hadley
>> 
>> 
> 
> -- 
> Luke Tierney
> Chair, Statistics and Actuarial Science
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>   Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From peter.meilstrup at gmail.com  Tue Feb 19 14:20:04 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Tue, 19 Feb 2013 05:20:04 -0800
Subject: [Rd] quote() vs quote(expr=)
In-Reply-To: <4DC52965-C9CD-446E-BAE0-58765D3B8324@gmail.com>
References: <CABdHhvGwS1xuOqYLqtJAGjJrm5gGvLW7XJs+4bg3LY_R3Z7oNQ@mail.gmail.com>
	<alpine.LFD.2.03.1302181227030.10691@uiowa.edu>
	<4DC52965-C9CD-446E-BAE0-58765D3B8324@gmail.com>
Message-ID: <CAJoaRhbtQo3JRT+4iPmNQg8_rdkYLWNvhiDecS1CPnkVeRmiHw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130219/5da9cfbb/attachment.pl>

From nalimilan at club.fr  Tue Feb 19 17:32:05 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Tue, 19 Feb 2013 17:32:05 +0100
Subject: [Rd] Small quirks in summary.(g)lm docs
Message-ID: <1361291525.2067.109.camel@milan.ined.fr>

Hi!

In R 3.0.0 from current SVN, ?summary.lm says:
> Value [...]
> df degrees of freedom, a 3-vector (p, n-p, p*), the last
>    being the number of non-aliased coefficients.

?summary.glm says:
> df a 3-vector of the rank of the model and the number of residual 
>    degrees of freedom, plus number of non-aliased coefficients.

It seems to me that the description is reversed: p is the number of
non-aliased coefficients, and p* the total number of coefficients. I do
not have reference books off-hand to check how it is intended to work,
but see this example:

ctl <- c(4.17,5.58,5.18,6.11,4.50,4.61,5.17,4.53,5.33,5.14)
trt <- c(4.81,4.17,4.41,3.59,5.87,3.83,6.03,4.89,4.32,4.69)
group <- gl(2,10,20, labels=c("Ctl","Trt"))
weight <- c(ctl, trt)
lm.D9 <- lm(weight ~ group + I(group != "Ctl"))
lm.D9

Call:
lm(formula = weight ~ group + I(group != "Ctl"))

Coefficients:
          (Intercept)               groupTrt  I(group != "Ctl")TRUE  
                5.032                 -0.371                     NA  

summary(lm.D9)$df
[1]  2 18  3

sum(!summary(lm.D9)$aliased)
[1] 2


The same is true with glm().


Also, ?summary.lm seems to miss a mention that is present
in ?summary.glm:
> Aliased coefficients are omitted in the returned object but (as from
> R 1.8.0) restored by the print method.

This is apparently true of summary.lm too:

summary(lm.D9)

Call:
lm(formula = weight ~ group + I(group != "Ctl"))

Residuals:
    Min      1Q  Median      3Q     Max 
-1.0710 -0.4938  0.0685  0.2462  1.3690 

Coefficients: (1 not defined because of singularities)
                      Estimate Std. Error t value Pr(>|t|)    
(Intercept)             5.0320     0.2202  22.850 9.55e-15 ***
groupTrt               -0.3710     0.3114  -1.191    0.249    
I(group != "Ctl")TRUE       NA         NA      NA       NA    
---
Signif. codes:  0 ?***? 0.001 ?**? 0.01 ?*? 0.05 ?.? 0.1 ? ? 1 

Residual standard error: 0.6964 on 18 degrees of freedom
Multiple R-squared: 0.07308,	Adjusted R-squared: 0.02158 
F-statistic: 1.419 on 1 and 18 DF,  p-value: 0.249 

summary(lm.D9)$coefficients
            Estimate Std. Error  t value     Pr(>|t|)
(Intercept)    5.032  0.2202177 22.85012 9.547128e-15
groupTrt      -0.371  0.3114349 -1.19126 2.490232e-01


Attached is a patch that applies these changes, if I'm not mistaken (and
my English can be improved...).


Regards
-------------- next part --------------
A non-text attachment was scrubbed...
Name: summary.patch
Type: text/x-patch
Size: 2117 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130219/3842ca4c/attachment.bin>

From htl10 at users.sourceforge.net  Tue Feb 19 20:52:51 2013
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Tue, 19 Feb 2013 19:52:51 +0000 (GMT)
Subject: [Rd] bug fix Re: Matrix does not build with R trunk since Oct.
In-Reply-To: <1360970030.67507.YahooMailClassic@web172304.mail.ir2.yahoo.com>
Message-ID: <1361303571.14266.YahooMailClassic@web172302.mail.ir2.yahoo.com>

Here is what make Matrix builds. I guess this means a new Matrix 1.0-12 will be released. r57849 is dec 2011, and in any case, a conditional based on precise svn version seems a bad idea. I haven't pinned point why it broke in Oct 2012, probably co-incide with the switch of R_SVN_VERSION's data type in around that time. Just grep'ed for ".M.classEnv" to see where it comes from.

--- Matrix/NAMESPACE~	2013-01-30 11:14:48.000000000 +0000
+++ Matrix/NAMESPACE	2013-02-19 18:50:19.372867331 +0000
@@ -75,7 +75,7 @@
 #        "writeHB",
        , "writeMM"
        )
-if(getRversion() < "2.15.0" || R.version$`svn rev` < 57849)
+if(getRversion() < "2.15.0")
     export(".M.classEnv")
 
 ## substitute for using  cbind() / rbind()


--- On Fri, 15/2/13, Hin-Tak Leung <htl10 at users.sourceforge.net> wrote:

> FWIW, extracting snapshot source
> elsewhere outside svn, run "tools/rsync-recommended" then
> just plain "./configure && make" doesn't work
> either. Nothing to do with building inside checkout nor
> extra configure options.
> 
> This is fedora 18, x86_64.
> 
> --- On Fri, 15/2/13, Hin-Tak Leung <htl10 at users.sourceforge.net>
> wrote:
> 
> > Somebody else had written separately about this before,
> and
> > so have I a couple of months ago. I assumed this will
> be
> > fixed before the next R. Since R 3.0 is supposedly only
> 6
> > weeks away, even if it is fixed now it doesn't leave
> much
> > room for testing. 
> > 
> > Anyway neither Matrix 1.0-11 (current) nor 1.0-9 (sept
> 2012)
> > build with current R trunk.? The? last time it did
> > was 1. 0-9 on 3rd october over 4 months ago. So it
> appears
> > to be due to change inside r trunk in sept or early
> oct. 
> > 
> > 
> > ----------------
> > Loading required package: Matrix
> > Error in namespaceExport(ns, exports) : undefined
> exports:
> > .M.classEnv
> > Error : require(Matrix) is not TRUE
> > ERROR: installing package indices failed
> > * removing ?/svn-loc/R/library/Matrix?
> > * restoring previous ?/svn-loc/R/library/Matrix?
> > make[2]: *** [Matrix.ts] Error 1
> > make[2]: Leaving directory
> > `/svn-loc/R/src/library/Recommended'
> > make[1]: *** [recommended-packages] Error 2
> > make[1]: Leaving directory
> > `/svn-loc/R/src/library/Recommended'
> > make: *** [stamp-recommended] Error 2
> > ----------------
> > 
> > If it matters, here is what r trunk built with:
> >? ./configure --enable-memory-profiling
> > --enable-strict-barrier
> --enable-byte-compiled-packages
> > --with-valgrind-instrumentation=2 --enable-lto
> > 
> > 
> >
>


From suharto_anggono at yahoo.com  Wed Feb 20 11:42:37 2013
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Wed, 20 Feb 2013 02:42:37 -0800 (PST)
Subject: [Rd] Simultaneously adding rows and columns by '[<-.data.frame' may
	fail
Message-ID: <1361356957.702.YahooMailClassic@web125105.mail.ne1.yahoo.com>

I saw the following in R help page "Extract.data.frame".

     The replacement methods can be used to add whole column(s) by
     specifying non-existent column(s), in which case the column(s) are
     added at the right-hand edge of the data frame and numerical
     indices must be contiguous to existing indices.  On the other
     hand, rows can be added at any row after the current last row, and
     the columns will be in-filled with missing values.


So, I tried something like this.

> x <- data.frame(a=1, s=1)
> y <- data.frame(a=1, r=8, e=9)
> z <- x
> z[2, c("a","r","e")] <- y
Error in `*tmp*`[[j]] : recursive indexing failed at level 2


Using debug("[<-.data.frame") revealed that execution stopped at this line.

                  length(x[[j]]) <- nrows


From stepping by debug("[<-.data.frame"), I saw that '[<-.data.frame' actually did well before the failing line. In the failing line, it looks like 'jj' is meant instead of 'j'.


In the code of function '[<-.data.frame', near the end, it looks like 'j' needs to be replaced with 'jj' in the lines marked by # below.

    if (has.i) 
        for (jjj in seq_len(p)) {
            jj <- jseq[jjj]
            vjj <- value[[jvseq[[jjj]]]]
            if (jj <= nvars) {
                ...
            }
            else {
                x[[jj]] <- vjj[FALSE]
                if (length(dim(vjj)) == 2L) {
                  length(x[[j]]) <- nrows * ncol(vjj)  #
                  dim(x[[j]]) <- c(nrows, ncol(vjj))  #
                  x[[jj]][iseq, ] <- vjj
                }
                else {
                  length(x[[j]]) <- nrows  #
                  x[[jj]][iseq] <- vjj
                }
            }
        }
    else ... 


After doing fix("[<-.data.frame") by replacing appropriate 'j' with 'jj', it works.

> fix("[<-.data.frame")
> x <- data.frame(a=1, s=1)
> y <- data.frame(a=1, r=8, e=9)
> z <- x
> z[2, c("a","r","e")] <- y
> z
  a  s  r  e
1 1  1 NA NA
2 1 NA  8  9


> sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_2.15.2


From prlw1 at cam.ac.uk  Wed Feb 20 18:46:54 2013
From: prlw1 at cam.ac.uk (Patrick Welche)
Date: Wed, 20 Feb 2013 17:46:54 +0000
Subject: [Rd] R_CHECK_FUNCS
Message-ID: <20130220174654.GD1659@quark.inf.phy.private.cam.ac.uk>

I was compiling R on a system which admittedly was in the odd situation
that it declared a function in math.h, but didn't have the associated
implementation in libm, and the R 2.15.1 compilation failed.

It turns out that R_CHECK_FUNCS is rather less robust than the standard
AC_CHECK_FUNCS which actually attempts to link. On my temporarily broken
system, AC_CHECK_FUNCS would not have been fooled, and R would have
compiled successfully.

Thoughts on making R_CHECK_FUNCS simply an alias for AC_CHECK_FUNCS?

Cheers,

Patrick


From alireza.s.mahani at gmail.com  Wed Feb 20 22:39:36 2013
From: alireza.s.mahani at gmail.com (Alireza Mahani)
Date: Wed, 20 Feb 2013 13:39:36 -0800 (PST)
Subject: [Rd] Using SQLBulkOperations in RODBC
Message-ID: <1361396376518-4659205.post@n4.nabble.com>

I have a question for the R core development team:

Are there any near-term plans to incorporate the ODBC API function
SQLBulkOperations into the RODBC package? As you are probably well aware,
the sqlSave() function uses a row-by-row insert (even in the 'fast' version)
that imposes heavy DB transaction overheads as well as unnecessary network
transmission overheads. Replacing the current version of the code with a
call to SQLBulkOperations could speed up sqlSave function for moderate to
large data sets up to 10x.

I am asking so I can decide whether it is worthwhile for me to implement a
home-grown version of the code or I can look forward to a new release of
RODBC within the next couple of weeks or months.

Thank you,
Ali



--
View this message in context: http://r.789695.n4.nabble.com/Using-SQLBulkOperations-in-RODBC-tp4659205.html
Sent from the R devel mailing list archive at Nabble.com.


From rkoenker at illinois.edu  Thu Feb 21 00:20:39 2013
From: rkoenker at illinois.edu (Roger Koenker)
Date: Wed, 20 Feb 2013 17:20:39 -0600
Subject: [Rd] =?windows-1252?q?GC_encountered_a_node_=28=85=29_with_an_unk?=
 =?windows-1252?q?nown_SEXP_type?=
Message-ID: <89285C28-C05C-4941-863D-96A02D36D108@illinois.edu>

Dear All,

I'm trying to track down a very erratic bug in some fortran;  I have an example that
quite consistently segfaults on windoz, and more sporadically on mac, all in the 
course of doing some bootstrap calculations, varying the set.seed call,  but I'm now
trying to see what is going on on our  redhat system:

R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows"
Copyright (C) 2012 The R Foundation for Statistical Computing
ISBN 3-900051-07-0
Platform: x86_64-unknown-linux-gnu (64-bit)

I now have an example, i.e. a seed, that produces the error:

Error in crq.fit.por(xb, yb, cb, weights = w, ctype = ctype, ...) : 
  GC encountered a node (0xb488bc0) with an unknown SEXP type: SPECIALSXP at memory.c:927

I've tried capturing the data for this call and running it from the terminal
window, but annoyingly it fails to complain when I do that.  I thought someone
might have a better idea.  My experience with gdb is very limited, I tried running
R -d gdb  
which reproduces the error, but this gets me back to the R prompt and I can't
see any more than what was available without gdb.  Any advice would be most
welcome.

Roger



url:    www.econ.uiuc.edu/~roger            Roger Koenker
email    rkoenker at uiuc.edu            Department of Economics
vox:     217-333-4558                University of Illinois
fax:       217-244-6678                Urbana, IL 61801


From simon.urbanek at r-project.org  Thu Feb 21 02:21:11 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 20 Feb 2013 20:21:11 -0500
Subject: [Rd]
 =?windows-1252?q?GC_encountered_a_node_=28=85=29_with_an_unk?=
 =?windows-1252?q?nown_SEXP_type?=
In-Reply-To: <89285C28-C05C-4941-863D-96A02D36D108@illinois.edu>
References: <89285C28-C05C-4941-863D-96A02D36D108@illinois.edu>
Message-ID: <82AB3529-3A65-4051-A5C7-A529303AD58D@r-project.org>

Roger,

please try tracking it with valgrind - that will typically trigger at the cause whereas what you see is just the fall-out much later when the memory got already corrupted.

Cheers,
Simon


On Feb 20, 2013, at 6:20 PM, Roger Koenker wrote:

> Dear All,
> 
> I'm trying to track down a very erratic bug in some fortran;  I have an example that
> quite consistently segfaults on windoz, and more sporadically on mac, all in the 
> course of doing some bootstrap calculations, varying the set.seed call,  but I'm now
> trying to see what is going on on our  redhat system:
> 
> R version 2.15.1 (2012-06-22) -- "Roasted Marshmallows"
> Copyright (C) 2012 The R Foundation for Statistical Computing
> ISBN 3-900051-07-0
> Platform: x86_64-unknown-linux-gnu (64-bit)
> 
> I now have an example, i.e. a seed, that produces the error:
> 
> Error in crq.fit.por(xb, yb, cb, weights = w, ctype = ctype, ...) : 
>  GC encountered a node (0xb488bc0) with an unknown SEXP type: SPECIALSXP at memory.c:927
> 
> I've tried capturing the data for this call and running it from the terminal
> window, but annoyingly it fails to complain when I do that.  I thought someone
> might have a better idea.  My experience with gdb is very limited, I tried running
> R -d gdb  
> which reproduces the error, but this gets me back to the R prompt and I can't
> see any more than what was available without gdb.  Any advice would be most
> welcome.
> 
> Roger
> 
> 
> 
> url:    www.econ.uiuc.edu/~roger            Roger Koenker
> email    rkoenker at uiuc.edu            Department of Economics
> vox:     217-333-4558                University of Illinois
> fax:       217-244-6678                Urbana, IL 61801
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From jinghuazhao at hotmail.com  Thu Feb 21 11:37:16 2013
From: jinghuazhao at hotmail.com (jing hua zhao)
Date: Thu, 21 Feb 2013 10:37:16 +0000
Subject: [Rd] Query over .Fortran call
In-Reply-To: <82AB3529-3A65-4051-A5C7-A529303AD58D@r-project.org>
References: <89285C28-C05C-4941-863D-96A02D36D108@illinois.edu>,
	<82AB3529-3A65-4051-A5C7-A529303AD58D@r-project.org>
Message-ID: <DUB119-W328D250E85937AE3668228A5F70@phx.gbl>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130221/251655dc/attachment.pl>

From mauricio.zambrano at jrc.ec.europa.eu  Thu Feb 21 14:20:40 2013
From: mauricio.zambrano at jrc.ec.europa.eu (Mauricio Zambrano-Bigiarini)
Date: Thu, 21 Feb 2013 14:20:40 +0100
Subject: [Rd] limitations to random number generator in 64-bits machines
Message-ID: <51261F28.1060604@jrc.ec.europa.eu>

Dear List,

Recently I got the comment that the implementation of the random number 
generator used by default in R (Mersenne-Twister) could not be "safe" 
for 64-bits machines, so I decided to put the question here because I do 
not have expertise in that topic, and because this question could be 
"too technical for R-help's audience". I apologise if this is not the case.

The period 2^19937 - 1 mentioned in the help page of 'RNG' for the 
Mersenne-Twister generator, is it the same for 32-bits machines and 
64-bits ones ?

In addition:

-) If I want to generate two consecutive sequences s_1 and s_2 of n 
pseudo-random numbers each, and knowing how the Random number generator 
is coded, can we estimate in advance the correlation coefficient rho 
between s1 and s2?

-) Let us say that we compute the correlation coefficient rho between 
s_1 and s_2 and find it is not null. How small should it be so that we 
can reasonably use  a statistical analysis that does suppose that the 
sequences are independent ?


Thank in advance for any help you can provide,

Mauricio Zambrano-Bigiarini

-- 
=================================================
Water Resources Unit
Institute for Environment and Sustainability (IES)
Joint Research Centre (JRC), European Commission
TP 261, Via Enrico Fermi 2749, 21027 Ispra (VA), IT
webinfo    : http://floods.jrc.ec.europa.eu/
=================================================
DISCLAIMER:\ "The views expressed are purely those of th...{{dropped:10}}


From gunter.berton at gene.com  Fri Feb 22 12:02:14 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Fri, 22 Feb 2013 03:02:14 -0800
Subject: [Rd] limitations to random number generator in 64-bits machines
In-Reply-To: <51261F28.1060604@jrc.ec.europa.eu>
References: <51261F28.1060604@jrc.ec.europa.eu>
Message-ID: <CACk-te27QhEcEN_B7CPXL3Y3j8kNcZ7HPGdtbYfrdVzHJRWU2w@mail.gmail.com>

AFAICS, these are statistics, not R, issues, and are completely off
topic here. You should post on a statistics list, such as
stats.stackexchange.com, instead.

Cheers,
Bert

On Thu, Feb 21, 2013 at 5:20 AM, Mauricio Zambrano-Bigiarini
<mauricio.zambrano at jrc.ec.europa.eu> wrote:
> Dear List,
>
> Recently I got the comment that the implementation of the random number
> generator used by default in R (Mersenne-Twister) could not be "safe" for
> 64-bits machines, so I decided to put the question here because I do not
> have expertise in that topic, and because this question could be "too
> technical for R-help's audience". I apologise if this is not the case.
>
> The period 2^19937 - 1 mentioned in the help page of 'RNG' for the
> Mersenne-Twister generator, is it the same for 32-bits machines and 64-bits
> ones ?
>
> In addition:
>
> -) If I want to generate two consecutive sequences s_1 and s_2 of n
> pseudo-random numbers each, and knowing how the Random number generator is
> coded, can we estimate in advance the correlation coefficient rho between s1
> and s2?
>
> -) Let us say that we compute the correlation coefficient rho between s_1
> and s_2 and find it is not null. How small should it be so that we can
> reasonably use  a statistical analysis that does suppose that the sequences
> are independent ?
>
>
> Thank in advance for any help you can provide,
>
> Mauricio Zambrano-Bigiarini
>
> --
> =================================================
> Water Resources Unit
> Institute for Environment and Sustainability (IES)
> Joint Research Centre (JRC), European Commission
> TP 261, Via Enrico Fermi 2749, 21027 Ispra (VA), IT
> webinfo    : http://floods.jrc.ec.europa.eu/
> =================================================
> DISCLAIMER:\ "The views expressed are purely those of th...{{dropped:10}}
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

Internal Contact Info:
Phone: 467-7374
Website:
http://pharmadevelopment.roche.com/index/pdb/pdb-functional-groups/pdb-biostatistics/pdb-ncb-home.htm


From ripley at stats.ox.ac.uk  Fri Feb 22 12:54:45 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 22 Feb 2013 11:54:45 +0000
Subject: [Rd] limitations to random number generator in 64-bits machines
In-Reply-To: <CACk-te27QhEcEN_B7CPXL3Y3j8kNcZ7HPGdtbYfrdVzHJRWU2w@mail.gmail.com>
References: <51261F28.1060604@jrc.ec.europa.eu>
	<CACk-te27QhEcEN_B7CPXL3Y3j8kNcZ7HPGdtbYfrdVzHJRWU2w@mail.gmail.com>
Message-ID: <51275C85.9010304@stats.ox.ac.uk>

On 22/02/2013 11:02, Bert Gunter wrote:
> AFAICS, these are statistics, not R, issues, and are completely off
> topic here. You should post on a statistics list, such as
> stats.stackexchange.com, instead.

Except for the unattributed vague comment about 64-bit (sic) machines. 
The RNG is the same (and gives the same results) on both 32- and 64-bit 
machines.  The size of the pointer has nothing to do with random-number 
generation.


>
> Cheers,
> Bert
>
> On Thu, Feb 21, 2013 at 5:20 AM, Mauricio Zambrano-Bigiarini
> <mauricio.zambrano at jrc.ec.europa.eu> wrote:
>> Dear List,
>>
>> Recently I got the comment that the implementation of the random number
>> generator used by default in R (Mersenne-Twister) could not be "safe" for
>> 64-bits machines, so I decided to put the question here because I do not
>> have expertise in that topic, and because this question could be "too
>> technical for R-help's audience". I apologise if this is not the case.
>>
>> The period 2^19937 - 1 mentioned in the help page of 'RNG' for the
>> Mersenne-Twister generator, is it the same for 32-bits machines and 64-bits
>> ones ?
>>
>> In addition:
>>
>> -) If I want to generate two consecutive sequences s_1 and s_2 of n
>> pseudo-random numbers each, and knowing how the Random number generator is
>> coded, can we estimate in advance the correlation coefficient rho between s1
>> and s2?
>>
>> -) Let us say that we compute the correlation coefficient rho between s_1
>> and s_2 and find it is not null. How small should it be so that we can
>> reasonably use  a statistical analysis that does suppose that the sequences
>> are independent ?
>>
>>
>> Thank in advance for any help you can provide,
>>
>> Mauricio Zambrano-Bigiarini
>>
>> --
>> =================================================
>> Water Resources Unit
>> Institute for Environment and Sustainability (IES)
>> Joint Research Centre (JRC), European Commission
>> TP 261, Via Enrico Fermi 2749, 21027 Ispra (VA), IT
>> webinfo    : http://floods.jrc.ec.europa.eu/
>> =================================================
>> DISCLAIMER:\ "The views expressed are purely those of th...{{dropped:10}}
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From mauricio.zambrano at jrc.ec.europa.eu  Fri Feb 22 13:41:38 2013
From: mauricio.zambrano at jrc.ec.europa.eu (Mauricio Zambrano-Bigiarini)
Date: Fri, 22 Feb 2013 13:41:38 +0100
Subject: [Rd] limitations to random number generator in 64-bits machines
In-Reply-To: <51275C85.9010304@stats.ox.ac.uk>
References: <51261F28.1060604@jrc.ec.europa.eu>
	<CACk-te27QhEcEN_B7CPXL3Y3j8kNcZ7HPGdtbYfrdVzHJRWU2w@mail.gmail.com>
	<51275C85.9010304@stats.ox.ac.uk>
Message-ID: <51276782.20702@jrc.ec.europa.eu>

On 22/02/13 12:54, Prof Brian Ripley wrote:
> On 22/02/2013 11:02, Bert Gunter wrote:
>> AFAICS, these are statistics, not R, issues, and are completely off
>> topic here. You should post on a statistics list, such as
>> stats.stackexchange.com, instead.
>
> Except for the unattributed vague comment about 64-bit (sic) machines.
> The RNG is the same (and gives the same results) on both 32- and 64-bit
> machines.  The size of the pointer has nothing to do with random-number
> generation.

Thank you very much for making this clear for me.

Kind regards,

Mauricio

-- 
=================================================
Linux user #454569 -- Ubuntu user #17469
=================================================
"Where ambition ends happiness begins"
(Source Unknown)


From therneau at mayo.edu  Fri Feb 22 20:59:50 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Fri, 22 Feb 2013 13:59:50 -0600
Subject: [Rd] Registering native routines
Message-ID: <5127CE36.6070109@mayo.edu>

I'm working on registering all the routines in the survival package, per a request from 
R-core.  Two questions:

1. In the coxph routine I have this type of structure:
      if (survival has 2 columns) routines <- c("coxfit5_a", "coxfit5_b", "coxfit5_c")
         else                     routines <- c("agfit5_a",  "agfit5_b",  "agfit5_c")

.....

     .C(routines[1], arg1, etc

I tried replacing "routines" with a vector of native symbol references, but it doesn't work

Error in .C(routines[1], as.integer(n), as.integer(nvar), as.double(y),  :
   first argument must be a string (of length 1) or native symbol reference

I had fixed up all the other .C and .Call statements first (28 of them) and that worked, 
so the problem is not with finding the set of symbol references.

2. In the R-exts manual it mentions another argument "style" for C calls to specify if an 
argument is for input, output, or both.  However, I can find no details on how to use it.

3. A few of my routines still had a COPY argument.  I assume that is simply ignored?

Terry T.

R Under development (unstable) (2013-02-11 r61902)
Platform: i686-pc-linux-gnu (32-bit)


From cubranic at stat.ubc.ca  Sat Feb 23 01:26:06 2013
From: cubranic at stat.ubc.ca (Davor Cubranic)
Date: Fri, 22 Feb 2013 16:26:06 -0800
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
Message-ID: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130222/b7f80993/attachment.pl>

From h.wickham at gmail.com  Sat Feb 23 03:13:33 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 22 Feb 2013 20:13:33 -0600
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
Message-ID: <CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>

Hi Davor,

To the best of my knowledge, there's only one way to use functions
from a suggested package: with require:

if (require("suggested_package")) {
  function_from_suggested_package()
} else {
  stop("suggested package not installed")
}

Unfortunately I don't think there's any way to use a suggested package
without polluting the search path.

Hadley

On Fri, Feb 22, 2013 at 6:26 PM, Davor Cubranic <cubranic at stat.ubc.ca> wrote:
> If in my package "Foo" I call a function from another package "Bar" if it's available, according to R-exts, this sounds like I should include "Suggests: Bar" in package Foo's description. But the manual is silent on how to treat Bar's namespace. Should I import it? If so, should this be conditional or unconditional? There is a thread from 2008 in which Duncan Murdoch suggests trying conditionally importing a package if it's installed, with the caveat "If this is allowed" (http://tolstoy.newcastle.edu.au/R/e5/devel/08/10/0488.html). This appears to work in current release of R, 2.15.2, but I'm still not clear if it's officially allowed, much less recommended.
>
> The manual also says:
>
>> If a package only needs a few objects from another package it can use a fully qualified variable reference in the code instead of a formal import. A fully qualified reference to the function f in package foo is of the form foo::f. This is slightly less efficient than a formal import and also loses the advantage of recording all dependencies in the NAMESPACE file, so this approach is usually not recommended. Evaluating foo::f will cause package foo to be loaded, but not attached, if it was not loaded already?this can be an advantage in delaying the loading of a rarely used package.
>>
>
>
> Would this be a better solution than importing when calling into a suggested package?
>
> Davor
>
>
>         [[alternative HTML version deleted]]
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Chief Scientist, RStudio
http://had.co.nz/


From dwinsemius at comcast.net  Sat Feb 23 03:39:55 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 Feb 2013 18:39:55 -0800
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
Message-ID: <AD286524-32D5-4808-B984-E6AF521FB6E5@comcast.net>


On Feb 22, 2013, at 6:13 PM, Hadley Wickham wrote:

> Hi Davor,
> 
> To the best of my knowledge, there's only one way to use functions
> from a suggested package: with require:
> 
> if (require("suggested_package")) {
>  function_from_suggested_package()
> } else {
>  stop("suggested package not installed")
> }
> 
> Unfortunately I don't think there's any way to use a suggested package
> without polluting the search path.

I've always wondered: How does lattice manage to use grid functions without putting them on the search path?

-- 
David
> 
> Hadley
> 
> On Fri, Feb 22, 2013 at 6:26 PM, Davor Cubranic <cubranic at stat.ubc.ca> wrote:
>> If in my package "Foo" I call a function from another package "Bar" if it's available, according to R-exts, this sounds like I should include "Suggests: Bar" in package Foo's description. But the manual is silent on how to treat Bar's namespace. Should I import it? If so, should this be conditional or unconditional? There is a thread from 2008 in which Duncan Murdoch suggests trying conditionally importing a package if it's installed, with the caveat "If this is allowed" (http://tolstoy.newcastle.edu.au/R/e5/devel/08/10/0488.html). This appears to work in current release of R, 2.15.2, but I'm still not clear if it's officially allowed, much less recommended.
>> 
>> The manual also says:
>> 
>>> If a package only needs a few objects from another package it can use a fully qualified variable reference in the code instead of a formal import. A fully qualified reference to the function f in package foo is of the form foo::f. This is slightly less efficient than a formal import and also loses the advantage of recording all dependencies in the NAMESPACE file, so this approach is usually not recommended. Evaluating foo::f will cause package foo to be loaded, but not attached, if it was not loaded already?this can be an advantage in delaying the loading of a rarely used package.
>>> 
>> 
>> 
>> Would this be a better solution than importing when calling into a suggested package?
>> 
>> Davor
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 
> 
> -- 
> Chief Scientist, RStudio
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

David Winsemius
Alameda, CA, USA


From dwinsemius at comcast.net  Sat Feb 23 03:50:07 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Fri, 22 Feb 2013 18:50:07 -0800
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <AD286524-32D5-4808-B984-E6AF521FB6E5@comcast.net>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<AD286524-32D5-4808-B984-E6AF521FB6E5@comcast.net>
Message-ID: <3134DCA3-4BFA-4D0F-8BDD-A7A185FDF8C8@comcast.net>


On Feb 22, 2013, at 6:39 PM, David Winsemius wrote:

> 
> On Feb 22, 2013, at 6:13 PM, Hadley Wickham wrote:
> 
>> Hi Davor,
>> 
>> To the best of my knowledge, there's only one way to use functions
>> from a suggested package: with require:
>> 
>> if (require("suggested_package")) {
>> function_from_suggested_package()
>> } else {
>> stop("suggested package not installed")
>> }
>> 
>> Unfortunately I don't think there's any way to use a suggested package
>> without polluting the search path.
> 
> I've always wondered: How does lattice manage to use grid functions without putting them on the search path?

Maybe I am using the wrong terminology, so here is the behavior I'm referring to:

> sessionInfo()
snipped version an locale ino

attached base packages:
[1] grDevices datasets  splines   graphics  utils     stats     methods   base     

other attached packages:
[1] rms_3.6-2       Hmisc_3.10-1    survival_2.37-2 sos_1.3-5       brew_1.0-6     
[6] lattice_0.20-10

loaded via a namespace (and not attached):
[1] cluster_1.14.3 grid_2.15.2   

Notice that lattice is loaded from my profile

> require(ggplot2)
Loading required package: ggplot2
> sessionInfo()
.... snipped version an locale ino
attached base packages:
[1] grDevices datasets  splines   graphics  utils     stats     methods   base     

other attached packages:
[1] ggplot2_0.9.3   rms_3.6-2       Hmisc_3.10-1    survival_2.37-2 sos_1.3-5      
[6] brew_1.0-6      lattice_0.20-10

loaded via a namespace (and not attached):
 [1] cluster_1.14.3     colorspace_1.2-1   dichromat_2.0-0    digest_0.6.0      
 [5] grid_2.15.2        gtable_0.1.2       labeling_0.1       MASS_7.3-22       
 [9] munsell_0.4        plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
[13] reshape2_1.2.2     scales_0.2.3       stringr_0.6.2     
> ?grid.text
No documentation for ?grid.text? in specified packages and libraries:
you could try ???grid.text?

So at least the help system cannot find a grid function.


> ?grid::grid.text
starting httpd help server ... done
> grid.text
Error: object 'grid.text' not found

Neither can the R interpreter find it. But it's clearly available if you ask nicely:

> grid::grid.text
function (label, x = unit(0.5, "npc"), y = unit(0.5, "npc"), 
    just = "centre", hjust = NULL, vjust = NULL, rot = 0, check.overlap = FALSE, 
    default.units = "npc", name = NULL, gp = gpar(), draw = TRUE, 
    vp = NULL) 
{
    tg <- textGrob(label = label, x = x, y = y, just = just, 
        hjust = hjust, vjust = vjust, rot = rot, check.overlap = check.overlap, 
        default.units = default.units, name = name, gp = gp, 
        vp = vp)
    if (draw) 
        grid.draw(tg)
    invisible(tg)
}
<bytecode: 0x11617dd50>
<environment: namespace:grid>

-- 
David/

> 
> -- 
> David
>> 
>> Hadley
>> 
>> On Fri, Feb 22, 2013 at 6:26 PM, Davor Cubranic <cubranic at stat.ubc.ca> wrote:
>>> If in my package "Foo" I call a function from another package "Bar" if it's available, according to R-exts, this sounds like I should include "Suggests: Bar" in package Foo's description. But the manual is silent on how to treat Bar's namespace. Should I import it? If so, should this be conditional or unconditional? There is a thread from 2008 in which Duncan Murdoch suggests trying conditionally importing a package if it's installed, with the caveat "If this is allowed" (http://tolstoy.newcastle.edu.au/R/e5/devel/08/10/0488.html). This appears to work in current release of R, 2.15.2, but I'm still not clear if it's officially allowed, much less recommended.
>>> 
>>> The manual also says:
>>> 
>>>> If a package only needs a few objects from another package it can use a fully qualified variable reference in the code instead of a formal import. A fully qualified reference to the function f in package foo is of the form foo::f. This is slightly less efficient than a formal import and also loses the advantage of recording all dependencies in the NAMESPACE file, so this approach is usually not recommended. Evaluating foo::f will cause package foo to be loaded, but not attached, if it was not loaded already?this can be an advantage in delaying the loading of a rarely used package.
>>>> 
>>> 
>>> 
>>> Would this be a better solution than importing when calling into a suggested package?
>>> 
>>> Davor
>>> 
>>> 
>>>       [[alternative HTML version deleted]]
>>> 
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> 
>> 
>> -- 
>> Chief Scientist, RStudio
>> http://had.co.nz/
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> David Winsemius
> Alameda, CA, USA
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

David Winsemius
Alameda, CA, USA


From markleeds2 at gmail.com  Sat Feb 23 04:07:12 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Fri, 22 Feb 2013 22:07:12 -0500
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <3134DCA3-4BFA-4D0F-8BDD-A7A185FDF8C8@comcast.net>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<AD286524-32D5-4808-B984-E6AF521FB6E5@comcast.net>
	<3134DCA3-4BFA-4D0F-8BDD-A7A185FDF8C8@comcast.net>
Message-ID: <CAHz+bWaVmSM83FX0aATyUixCyAoGo6KMq9Jd8LFLa6xhprzDtA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130222/dfcd016f/attachment.pl>

From markleeds2 at gmail.com  Sat Feb 23 04:50:56 2013
From: markleeds2 at gmail.com (Mark Leeds)
Date: Fri, 22 Feb 2013 22:50:56 -0500
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <CAHz+bWaVmSM83FX0aATyUixCyAoGo6KMq9Jd8LFLa6xhprzDtA@mail.gmail.com>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<AD286524-32D5-4808-B984-E6AF521FB6E5@comcast.net>
	<3134DCA3-4BFA-4D0F-8BDD-A7A185FDF8C8@comcast.net>
	<CAHz+bWaVmSM83FX0aATyUixCyAoGo6KMq9Jd8LFLa6xhprzDtA@mail.gmail.com>
Message-ID: <CAHz+bWZHgtWenWgVZ_Vaa-KF4HA_LNOeYBEVHhVi68-u7nO_uw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130222/6e97d3ed/attachment.pl>

From simon.urbanek at r-project.org  Sat Feb 23 05:12:43 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 22 Feb 2013 23:12:43 -0500
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
Message-ID: <FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>


On Feb 22, 2013, at 9:13 PM, Hadley Wickham wrote:

> Hi Davor,
> 
> To the best of my knowledge, there's only one way to use functions
> from a suggested package: with require:
> 
> if (require("suggested_package")) {
>  function_from_suggested_package()
> } else {
>  stop("suggested package not installed")
> }
> 
> Unfortunately I don't think there's any way to use a suggested package
> without polluting the search path.
> 

Why -- wouldn't

if (is.function(try(foo::bar, silent=TRUE))) {
  foo::bar(...)
}

do the job?



> Hadley
> 
> On Fri, Feb 22, 2013 at 6:26 PM, Davor Cubranic <cubranic at stat.ubc.ca> wrote:
>> If in my package "Foo" I call a function from another package "Bar" if it's available, according to R-exts, this sounds like I should include "Suggests: Bar" in package Foo's description. But the manual is silent on how to treat Bar's namespace. Should I import it? If so, should this be conditional or unconditional? There is a thread from 2008 in which Duncan Murdoch suggests trying conditionally importing a package if it's installed, with the caveat "If this is allowed" (http://tolstoy.newcastle.edu.au/R/e5/devel/08/10/0488.html). This appears to work in current release of R, 2.15.2, but I'm still not clear if it's officially allowed, much less recommended.
>> 
>> The manual also says:
>> 
>>> If a package only needs a few objects from another package it can use a fully qualified variable reference in the code instead of a formal import. A fully qualified reference to the function f in package foo is of the form foo::f. This is slightly less efficient than a formal import and also loses the advantage of recording all dependencies in the NAMESPACE file, so this approach is usually not recommended. Evaluating foo::f will cause package foo to be loaded, but not attached, if it was not loaded already?this can be an advantage in delaying the loading of a rarely used package.
>>> 
>> 
>> 
>> Would this be a better solution than importing when calling into a suggested package?
>> 
>> Davor
>> 
>> 
>>        [[alternative HTML version deleted]]
>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> 
> 
> -- 
> Chief Scientist, RStudio
> http://had.co.nz/
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From h.wickham at gmail.com  Sat Feb 23 05:40:19 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 22 Feb 2013 22:40:19 -0600
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
Message-ID: <CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130222/20c9fdbe/attachment.pl>

From Berwin.Turlach at gmail.com  Sat Feb 23 07:23:12 2013
From: Berwin.Turlach at gmail.com (Berwin A Turlach)
Date: Sat, 23 Feb 2013 14:23:12 +0800
Subject: [Rd] Recommended way to call/import functions from a Suggested
 package
In-Reply-To: <3134DCA3-4BFA-4D0F-8BDD-A7A185FDF8C8@comcast.net>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<AD286524-32D5-4808-B984-E6AF521FB6E5@comcast.net>
	<3134DCA3-4BFA-4D0F-8BDD-A7A185FDF8C8@comcast.net>
Message-ID: <20130223142312.55a0a311@bossiaea>

G'day David,

On Fri, 22 Feb 2013 18:50:07 -0800
David Winsemius <dwinsemius at comcast.net> wrote:

> On Feb 22, 2013, at 6:39 PM, David Winsemius wrote:
[...]
> > I've always wondered: How does lattice manage to use grid functions
> > without putting them on the search path?

Because lattice imports the grid package and has a NAMESPACE (as have
all packages nowadays):

R> packageDescription("lattice")
Package: lattice
Version: 0.20-10
Date: 2012/08/21
[...]
Suggests: grid, KernSmooth, MASS
Imports: grid, grDevices, graphics, stats, utils, methods
[...]

And the relevant information is not in the "Writing R Extensions"
manual but in section 3.5.4 of the "R Language Definition" manual:

	Packages which have a @emph{namespace} have a different search
	path. When a search for an @R{} object is started from an
	object in such a package, the package itself is searched first,
	then its imports, then the base namespace and finally the
	global environment and the rest of the regular search path.
	The effect is that references to other objects in the same
	package will be resolved to the package, and objects cannot be
	masked by objects of the same name in the global environment or
	in other packages.

Thus, as grid is imported by lattice, it is loaded but not attached
(i.e. does not appear in the search path).  However, function in the
lattice package will find functions in the grid package as the imports
are searched.

> Neither can the R interpreter find it. But it's clearly available if
> you ask nicely:
> 
> > grid::grid.text

This will always work, whether the grid package is loaded/attached or
not:

R> sessionInfo()
R version 2.15.2 (2012-10-26)
Platform: x86_64-unknown-linux-gnu/64 (64-bit)

locale:
[1] C

attached base packages:
[1] stats     graphics  grDevices utils     dataset  methods base     

loaded via a namespace (and not attached):
[1] tools_2.15.2
R> grid::grid.text
function (label, x = unit(0.5, "npc"), y = unit(0.5, "npc"), 
    just = "centre", hjust = NULL, vjust = NULL, rot = 0, check.overlap = FALSE, 
    default.units = "npc", name = NULL, gp = gpar(), draw = TRUE, 
    vp = NULL) 
{
    tg <- textGrob(label = label, x = x, y = y, just = just, 
        hjust = hjust, vjust = vjust, rot = rot, check.overlap = check.overlap, 
        default.units = default.units, name = name, gp = gp, 
        vp = vp)
    if (draw) 
        grid.draw(tg)
    invisible(tg)
}
<bytecode: 0x2507c80>
<environment: namespace:grid>


You specifically asked R to get object grid.text from the grid
package, so R obliges to do so.  For the help system to find the help
pages on an object, the package that contains the help pages has to be
on the search path AFAIK.

Cheers,

	Berwin


From murdoch.duncan at gmail.com  Sat Feb 23 10:09:14 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 23 Feb 2013 04:09:14 -0500
Subject: [Rd] Registering native routines
In-Reply-To: <5127CE36.6070109@mayo.edu>
References: <5127CE36.6070109@mayo.edu>
Message-ID: <5128873A.1030603@gmail.com>

On 13-02-22 2:59 PM, Terry Therneau wrote:
> I'm working on registering all the routines in the survival package, per a request from
> R-core.  Two questions:
>
> 1. In the coxph routine I have this type of structure:
>        if (survival has 2 columns) routines <- c("coxfit5_a", "coxfit5_b", "coxfit5_c")
>           else                     routines <- c("agfit5_a",  "agfit5_b",  "agfit5_c")
>
> .....
>
>       .C(routines[1], arg1, etc
>
> I tried replacing "routines" with a vector of native symbol references, but it doesn't work
>
> Error in .C(routines[1], as.integer(n), as.integer(nvar), as.double(y),  :
>     first argument must be a string (of length 1) or native symbol reference

I imagine routines is a list in this case, so you should be using 
routines[[1]] to extract the element, rather than subsetting the list.

Duncan Murdoch

>
> I had fixed up all the other .C and .Call statements first (28 of them) and that worked,
> so the problem is not with finding the set of symbol references.
>
> 2. In the R-exts manual it mentions another argument "style" for C calls to specify if an
> argument is for input, output, or both.  However, I can find no details on how to use it.
>
> 3. A few of my routines still had a COPY argument.  I assume that is simply ignored?
>
> Terry T.
>
> R Under development (unstable) (2013-02-11 r61902)
> Platform: i686-pc-linux-gnu (32-bit)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From mtyler.jason at gmail.com  Fri Feb 22 23:26:44 2013
From: mtyler.jason at gmail.com (jason tyler)
Date: Fri, 22 Feb 2013 17:26:44 -0500
Subject: [Rd] Issues with installing RBGL package
Message-ID: <CAPCKr9VAiGiPxpoNZRROCJcDOA2kxpga5qGhwjxYi8U9bwFmvQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130222/975cb127/attachment.pl>

From skostysh at princeton.edu  Sat Feb 23 08:11:54 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sat, 23 Feb 2013 02:11:54 -0500
Subject: [Rd] two typos in NEWS.Rd
Message-ID: <CAE3=dmdp_SzYVQbBnz4WRog70ex=W_BkeU2PgacEbyNSV8SNmg@mail.gmail.com>

Regarding:
"\pkg{parallle} (as in e.g. \code{mclapply()}."

Two typos:
"parallle" -> "parallel"
"\code{mclapply()}." -> "\code{mclapply()})"

Patch is attached.

Scott
-------------- next part --------------
diff --git a/doc/NEWS.Rd b/doc/NEWS.Rd
index c642432..012fd8f 100644
--- a/doc/NEWS.Rd
+++ b/doc/NEWS.Rd
@@ -928,7 +928,7 @@
       unloading.
 
       The Tcl/Tk event loop is inhibited in a forked child from package
-      \pkg{parallle} (as in e.g. \code{mclapply()}.
+      \pkg{parallel} (as in e.g. \code{mclapply()}).
 
       \item \code{parallel::makeCluster()} recognizes the value
       \samp{random} for the environment variable \env{R_PARALLEL_PORT}:

From simon.urbanek at r-project.org  Sat Feb 23 14:50:49 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 23 Feb 2013 08:50:49 -0500
Subject: [Rd] Issues with installing RBGL package
In-Reply-To: <CAPCKr9VAiGiPxpoNZRROCJcDOA2kxpga5qGhwjxYi8U9bwFmvQ@mail.gmail.com>
References: <CAPCKr9VAiGiPxpoNZRROCJcDOA2kxpga5qGhwjxYi8U9bwFmvQ@mail.gmail.com>
Message-ID: <45F12E90-2B27-4C71-9CFE-F54DEAAFC4FC@r-project.org>

Jason,

that looks like an interaction of clang with the Boost version inside RBGL - as the error shows it re-defines "p" as an enum type which means anything named p will be broken. Try using g++ instead of clang, I would hope that should be more successful.

Cheers,
S


On Feb 22, 2013, at 5:26 PM, jason tyler wrote:

> Hi all,
> 
> I was installing a package *RBGL* of bioconductor. However, I had some
> issues while installing it. I asked the devel group of bioconductor and
> they told me to consult this group. Here is my conversation with the
> bioconductor group related to the problem
> 
> 
> *Me->*
> I was trying to install the RBGL package using the following command
> 
> biocLite("RBGL")
> 
> However, I got the following error
> *
> installing *source* package ?RBGL? ...
> untarring boost include tree...
> ** libs
> /usr/bin/clang++ -I/usr/local/Cellar/r/2.15.1/R.framework/Resources/include
> -DNDEBUG  -I/usr/local/Cellar/readline/6.2.4/include -isystem
> /usr/local/include -I/usr/X11/include   -Irbgl_trimmed_boost_1_49_0 -fPIC
> -Os -w -pipe -march=native -Qunused-arguments -mmacosx-version-min=10.7  -c
> bbc.cpp -o bbc.o
> /usr/bin/clang++ -I/usr/local/Cellar/r/2.15.1/R.framework/Resources/include
> -DNDEBUG  -I/usr/local/Cellar/readline/6.2.4/include -isystem
> /usr/local/include -I/usr/X11/include   -Irbgl_trimmed_boost_1_49_0 -fPIC
> -Os -w -pipe -march=native -Qunused-arguments -mmacosx-version-min=10.7  -c
> cliques.cpp -o cliques.o
> cliques.cpp:26:31: error: redefinition of 'p' as different kind of symbol
>        std::pair<Edge, bool> p;
>                              ^
> rbgl_trimmed_boost_1_49_0/boost/mpl/assert.hpp:149:42: note: previous
> definition is here
>    BOOST_MPL_AUX_ASSERT_CONSTANT( bool, p = !p_type::value );
>                                         ^
> rbgl_trimmed_boost_1_49_0/boost/mpl/assert.hpp:56:58: note: expanded from
> macro 'BOOST_MPL_AUX_ASSERT_CONSTANT'
> #   define BOOST_MPL_AUX_ASSERT_CONSTANT(T, expr) enum { expr }
>                                                         ^
> cliques.cpp:53:19: error: expression is not assignable
>                p = edge(*va1, *va2, g);
>                ~ ^
> cliques.cpp:54:25: error: member reference base type
> 'mpl_::assert_arg_pred_not<boost::detail::is_iterator_traversal<boost::random_access_traversal_tag>>::<anonymous
> enum at
>      rbgl_trimmed_boost_1_49_0/boost/mpl/assert.hpp:149:5>' is not a
> structure or union
>                if ( !p.second ) return FALSE;*
> 
> 
> Any suggestions how to overcome this or what is causing this issue?
> 
> *Vincent Gray(of bioconductor group) -> *
> please provide sessionInfo() and result of gcc -v
> 
> *Me->*
> gcc -v
> Using built-in specs.
> Target: i686-apple-darwin11
> Configured with:
> /private/var/tmp/llvmgcc42/llvmgcc42-2336.11~28/src/configure
> --disable-checking --enable-werror
> --prefix=/Applications/Xcode.app/Contents/Developer/usr/llvm-gcc-4.2
> --mandir=/share/man --enable-languages=c,objc,c++,obj-c++
> --program-prefix=llvm- --program-transform-name=/^[cg][^.-]*$/s/$/-4.2/
> --with-slibdir=/usr/lib --build=i686-apple-darwin11
> --enable-llvm=/private/var/tmp/llvmgcc42/llvmgcc42-2336.11~28/dst-llvmCore/Developer/usr/local
> --program-prefix=i686-apple-darwin11- --host=x86_64-apple-darwin11
> --target=i686-apple-darwin11 --with-gxx-include-dir=/usr/include/c++/4.2.1
> Thread model: posix
> gcc version 4.2.1 (Based on Apple Inc. build 5658) (LLVM build 2336.11.00)
> 
> 
> *sessionInfo() Results*
> 
> R version 2.15.1 (2012-06-22)
> Platform: x86_64-apple-darwin11.4.0 (64-bit)
> 
> locale:
> [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> other attached packages:
> [1] BiocInstaller_1.8.3
> 
> loaded via a namespace (and not attached):
> [1] tools_2.15.1
> 
> Thanks
> 
> Regards,
> Jason
> 
> *Vincent Gray -> *
> OK, I didn't read your log too well, so I missed that you are using
> clang++.  Theoretically it will work
> 
> http://blog.llvm.org/2010/05/clang-builds-boost.html
> 
> I am using the gcc supplied in Xcode 4.0.2, with
> 
> bash-3.2$ gcc -v
> Using built-in specs.
> Target: i686-apple-darwin10
> Configured with: /var/tmp/gcc/gcc-5666.3~123/src/configure
> --disable-checking --enable-werror --prefix=/usr --mandir=/share/man
> --enable-languages=c,objc,c++,obj-c++
> --program-transform-name=/^[cg][^.-]*$/s/$/-4.2/ --with-slibdir=/usr/lib
> --build=i686-apple-darwin10 --program-prefix=i686-apple-darwin10-
> --host=x86_64-apple-darwin10 --target=i686-apple-darwin10
> --with-gxx-include-dir=/include/c++/4.2.1
> Thread model: posix
> gcc version 4.2.1 (Apple Inc. build 5666) (dot 3)
> 
> this has no problem installing RBGL from source.  your R is a little out of
> date but I don't think that's an issue.
> 
> I have minimal experience with clang++ and you may have to take this to
> R-help or R-devel if you are not going to use Xcode- based compilation, as
> that's what we are basing our builds/tests on.  I did try
> 
> bash-3.2$ clang++ -v
> clang version 3.2 (tags/RELEASE_32/final)
> Target: x86_64-apple-darwin10.8.0
> Thread model: posix
> bash-3.2$ clang++ -arch x86_64 -dynamiclib -Wl,-headerpad_max_install_names
> -undefined dynamic_lookup -single_module -multiply_defined suppress
> -L/Users/stvjc/ExternalSoft/READLINE-62-DIST/lib -lreadline
> -L//Users/stvjc/ExternalSoft/LIBICONV-64/lib -liconv
> -L/Users/stvjc/ExternalSoft/jpeg-6b -ljpeg -o cliques.so cliques.o
> -F/Users/stvjc/ExternalSoft/R-devel-dist/R.framework/.. -framework R
> -Wl,-framework -Wl,CoreFoundation
> 
> and this aping of the R CMD SHLIB command with clang++ quietly produced a
> .so.  Upon linking this in, example(maxClique) worked.  I am not too
> confident that this proves anything.  But perhaps you need to update
> clang++?
> 
>> sessionInfo()
> R version 2.15.2 Patched (2012-12-18 r61368)
> Platform: x86_64-apple-darwin10.8.0/x86_64 (64-bit)
> 
> locale:
> [1]
> en_US.US-ASCII/en_US.US-ASCII/en_US.US-ASCII/C/en_US.US-ASCII/en_US.US-ASCII
> 
> attached base packages:
> [1] stats     graphics  grDevices datasets  utils     tools     methods
> [8] base
> 
> other attached packages:
> [1] BiocInstaller_1.8.3 weaver_1.24.0       codetools_0.2-8
> [4] digest_0.6.0
> 
> 
> *It's been weeks and I haven't been able to install it. Any suggestions
> will be highly appreciated. Thanks group*
> 
> Regards,
> Jason
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ligges at statistik.tu-dortmund.de  Sat Feb 23 16:46:21 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 23 Feb 2013 16:46:21 +0100
Subject: [Rd] two typos in NEWS.Rd
In-Reply-To: <CAE3=dmdp_SzYVQbBnz4WRog70ex=W_BkeU2PgacEbyNSV8SNmg@mail.gmail.com>
References: <CAE3=dmdp_SzYVQbBnz4WRog70ex=W_BkeU2PgacEbyNSV8SNmg@mail.gmail.com>
Message-ID: <5128E44D.5050901@statistik.tu-dortmund.de>



On 23.02.2013 08:11, Scott Kostyshak wrote:
> Regarding:
> "\pkg{parallle} (as in e.g. \code{mclapply()}."
>
> Two typos:
> "parallle" -> "parallel"
> "\code{mclapply()}." -> "\code{mclapply()})"
>
> Patch is attached.


Thanks, fixed,
Uwe Ligges


> Scott
>
>
> typoNEWS.Rd.patch.txt
>
>
> diff --git a/doc/NEWS.Rd b/doc/NEWS.Rd
> index c642432..012fd8f 100644
> --- a/doc/NEWS.Rd
> +++ b/doc/NEWS.Rd
> @@ -928,7 +928,7 @@
>         unloading.
>
>         The Tcl/Tk event loop is inhibited in a forked child from package
> -      \pkg{parallle} (as in e.g. \code{mclapply()}.
> +      \pkg{parallel} (as in e.g. \code{mclapply()}).
>
>         \item \code{parallel::makeCluster()} recognizes the value
>         \samp{random} for the environment variable \env{R_PARALLEL_PORT}:
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From therneau at mayo.edu  Mon Feb 25 15:02:01 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 25 Feb 2013 08:02:01 -0600
Subject: [Rd] Registering native routines
In-Reply-To: <5128873A.1030603@gmail.com>
References: <5127CE36.6070109@mayo.edu> <5128873A.1030603@gmail.com>
Message-ID: <512B6ED9.6010603@mayo.edu>

That was the correct direction: I changed the earler line to "routines <- list(Ccoxfit5a, 
..." and the the later to  .C(routnines[[1]]) and now it works as desired.

Terry T.

On 02/23/2013 03:09 AM, Duncan Murdoch wrote:
> On 13-02-22 2:59 PM, Terry Therneau wrote:
>> I'm working on registering all the routines in the survival package, per a request from
>> R-core.  Two questions:
>>
>> 1. In the coxph routine I have this type of structure:
>>        if (survival has 2 columns) routines <- c("coxfit5_a", "coxfit5_b", "coxfit5_c")
>>           else                     routines <- c("agfit5_a",  "agfit5_b",  "agfit5_c")
>>
>> .....
>>
>>       .C(routines[1], arg1, etc
>>
>> I tried replacing "routines" with a vector of native symbol references, but it doesn't 
>> work
>>
>> Error in .C(routines[1], as.integer(n), as.integer(nvar), as.double(y),  :
>>     first argument must be a string (of length 1) or native symbol reference
>
> I imagine routines is a list in this case, so you should be using routines[[1]] to 
> extract the element, rather than subsetting the list.
>
> Duncan Murdoch


From dtenenba at fhcrc.org  Mon Feb 25 18:25:04 2013
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 25 Feb 2013 09:25:04 -0800
Subject: [Rd] png() problem with R-devel on Mac
Message-ID: <CAF42j22i2-BujG+LYkcN2-vsLJ_hdpt1UtESXxRy=Z+24wcHVA@mail.gmail.com>

> png(tempfile())
Error in .External(C_Quartz, "png", path.expand(filename), width, height,  :
  Incorrect number of arguments (12), expecting 11 for 'Quartz'
> sessionInfo()
R Under development (unstable) (2013-02-24 r62054)
Platform: x86_64-apple-darwin9.8.0/x86_64 (64-bit)

locale:
[1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

> capabilities()
    jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets
    TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
  libxml     fifo   cledit    iconv      NLS  profmem    cairo
    TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE

Thanks,
Dan


From cubranic at stat.ubc.ca  Mon Feb 25 21:20:06 2013
From: cubranic at stat.ubc.ca (Davor Cubranic)
Date: Mon, 25 Feb 2013 12:20:06 -0800
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <20130223142312.55a0a311@bossiaea>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<AD286524-32D5-4808-B984-E6AF521FB6E5@comcast.net>
	<3134DCA3-4BFA-4D0F-8BDD-A7A185FDF8C8@comcast.net>
	<20130223142312.55a0a311@bossiaea>
Message-ID: <FEBE9972-3EB0-4C0F-A4DD-67C41734641E@stat.ubc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130225/89b46db4/attachment.pl>

From cubranic at stat.ubc.ca  Mon Feb 25 21:59:56 2013
From: cubranic at stat.ubc.ca (Davor Cubranic)
Date: Mon, 25 Feb 2013 12:59:56 -0800
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
Message-ID: <4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130225/0786b825/attachment.pl>

From h.wickham at gmail.com  Mon Feb 25 22:28:05 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 25 Feb 2013 15:28:05 -0600
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
	<4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
Message-ID: <CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>

> To summarize, it appears that the only way to call functions from a
> suggested package is by using either 'require' (which will dynamically
> attach it) or the double colon method. Is this something that should be
> mentioned in R-exts?

Except the double colon method doesn't work (i.e. does not pass R CMD
check) unless you also import the package, which means it's no longer
just a suggestion - it must always be installed.

A simple test case (attached DESCRIPTION and R/test.r) yields this
warning on R CMD check:

* checking for unstated dependencies in R code ... WARNING
'::' or ':::' import not declared from: 'MASS'
See the information on DESCRIPTION files in the chapter 'Creating R
packages' of the 'Writing R Extensions' manual.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/

From mtmorgan at fhcrc.org  Mon Feb 25 23:36:29 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Mon, 25 Feb 2013 14:36:29 -0800
Subject: [Rd] Recommended way to call/import functions from a Suggested
 package
In-Reply-To: <CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
	<4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
	<CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>
Message-ID: <512BE76D.8090107@fhcrc.org>

On 02/25/2013 01:28 PM, Hadley Wickham wrote:
>> To summarize, it appears that the only way to call functions from a
>> suggested package is by using either 'require' (which will dynamically
>> attach it) or the double colon method. Is this something that should be
>> mentioned in R-exts?
>
> Except the double colon method doesn't work (i.e. does not pass R CMD
> check) unless you also import the package, which means it's no longer
> just a suggestion - it must always be installed.
>
> A simple test case (attached DESCRIPTION and R/test.r) yields this
> warning on R CMD check:
>
> * checking for unstated dependencies in R code ... WARNING
> '::' or ':::' import not declared from: 'MASS'
> See the information on DESCRIPTION files in the chapter 'Creating R
> packages' of the 'Writing R Extensions' manual.

haven't been following fully, but loadNamespace rather than require, with 
Suggests: MASS in DESCRIPTION ?

f = function() {
     ok <- tryCatch({
         loadNamespace("MASS")
         TRUE
     }, error=function(...) FALSE)

     if (ok) {
         MASS::huber(1:10)
         cat("OK\n")
     }
}

loadNamespaces loads but does not attach the package. Suggests: is enough to 
quieten the warning with

~/tmp$ R --version
R Under development (unstable) (2013-02-21 r62017) -- "Unsuffered Consequences"

This is consistent with RShowDoc("R-exts") section 1.1.1

   Namespaces accessed by the ?::? and ?:::? operators must be listed here, or 
in ?Suggests? or ?Enhances? (see below).

Martin

>
> Hadley
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From h.wickham at gmail.com  Mon Feb 25 23:56:04 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 25 Feb 2013 16:56:04 -0600
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <512BE76D.8090107@fhcrc.org>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
	<4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
	<CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>
	<512BE76D.8090107@fhcrc.org>
Message-ID: <CABdHhvGp93siXObHgCiFAi7zyee=REy22XM5O05X75=fUaf0VQ@mail.gmail.com>

> loadNamespaces loads but does not attach the package. Suggests: is enough to
> quieten the warning with
>
> ~/tmp$ R --version
> R Under development (unstable) (2013-02-21 r62017) -- "Unsuffered
> Consequences"
>
> This is consistent with RShowDoc("R-exts") section 1.1.1
>
>   Namespaces accessed by the ?::? and ?:::? operators must be listed here,
> or in ?Suggests? or ?Enhances? (see below).

I guess that's changed since I last tried it.  (My reproducible
example forgot to include MASS in the Suggests :/ )

Thanks!

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From cubranic at stat.ubc.ca  Tue Feb 26 00:25:22 2013
From: cubranic at stat.ubc.ca (Davor Cubranic)
Date: Mon, 25 Feb 2013 15:25:22 -0800
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
	<4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
	<CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>
Message-ID: <2ED56844-0DBF-4E2B-96BE-46243438F218@stat.ubc.ca>

I don't see any warnings if MASS is listed in Suggests in the DESCRIPTION.

Davor

On 2013-02-25, at 1:28 PM, Hadley Wickham wrote:

>> To summarize, it appears that the only way to call functions from a
>> suggested package is by using either 'require' (which will dynamically
>> attach it) or the double colon method. Is this something that should be
>> mentioned in R-exts?
> 
> Except the double colon method doesn't work (i.e. does not pass R CMD
> check) unless you also import the package, which means it's no longer
> just a suggestion - it must always be installed.
> 
> A simple test case (attached DESCRIPTION and R/test.r) yields this
> warning on R CMD check:
> 
> * checking for unstated dependencies in R code ... WARNING
> '::' or ':::' import not declared from: 'MASS'
> See the information on DESCRIPTION files in the chapter 'Creating R
> packages' of the 'Writing R Extensions' manual.
> 
> Hadley
> 
> -- 
> Chief Scientist, RStudio
> http://had.co.nz/
> <test.r><DESCRIPTION>


From nalimilan at club.fr  Tue Feb 26 10:58:25 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Tue, 26 Feb 2013 10:58:25 +0100
Subject: [Rd] Recommended way to call/import functions from a Suggested
 package
In-Reply-To: <4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
	<4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
Message-ID: <1361872705.15898.3.camel@milan>

Le lundi 25 f?vrier 2013 ? 12:59 -0800, Davor Cubranic a ?crit :
> I haven't gotten any complaints from "R CMD check" when I used Simon's
> suggestion, even with "--as-cran" flag. Hadley's suggestion to use
> 'require' also works, and its side-effect of attaching the other
> package can in some applications be seen by the end user as a nice
> bonus, so I'll probably have to decide on a case-by-case basis which
> method to use.
> 
> On the other hand, conditional import fails the check with "Namespace
> dependency not required: 'foo'", if 'foo' is only listed in the
> Suggests. Putting it in Imports gets rid of the warning, but then I
> don't need to conditionally import it any more. :-)
> 
> To summarize, it appears that the only way to call functions from a
> suggested package is by using either 'require' (which will dynamically
> attach it) or the double colon method. Is this something that should
> be mentioned in R-exts?
I second that request. As this thread illustrates, most of us do not
know the best way of using functions from suggested packages.

Regards

> Davor
> 
> 
> On 2013-02-22, at 8:40 PM, Hadley Wickham wrote:
> 
> > 
> > On Friday, February 22, 2013, Simon Urbanek wrote:
> > 
> > On Feb 22, 2013, at 9:13 PM, Hadley Wickham wrote:
> > 
> > > Hi Davor,
> > >
> > > To the best of my knowledge, there's only one way to use functions
> > > from a suggested package: with require:
> > >
> > > if (require("suggested_package")) {
> > >  function_from_suggested_package()
> > > } else {
> > >  stop("suggested package not installed")
> > > }
> > >
> > > Unfortunately I don't think there's any way to use a suggested package
> > > without polluting the search path.
> > >
> > 
> > Why -- wouldn't
> > 
> > if (is.function(try(foo::bar, silent=TRUE))) {
> >   foo::bar(...)
> > }
> > 
> > do the job?
> > 
> > 
> >  I may be misremembering, but I think r cmd check complains about that.
> > 
> > Hadley
> > 
> > 
> > -- 
> > Chief Scientist, RStudio
> > http://had.co.nz/
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pburns at pburns.seanet.com  Tue Feb 26 11:30:09 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Tue, 26 Feb 2013 10:30:09 +0000
Subject: [Rd] double bracket stripping names
Message-ID: <512C8EB1.8060401@pburns.seanet.com>

Is it on purpose that `[[` strips the
names when used on an atomic vector?

 > c(a=1, b=2)[1]
a
1
 > c(a=1, b=2)[[1]]
[1] 1


 > sessionInfo()
R Under development (unstable) (2013-02-11 r61902)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United Kingdom.1252
[2] LC_CTYPE=English_United Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base


-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From ripley at stats.ox.ac.uk  Tue Feb 26 11:41:26 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 26 Feb 2013 10:41:26 +0000
Subject: [Rd] double bracket stripping names
In-Reply-To: <512C8EB1.8060401@pburns.seanet.com>
References: <512C8EB1.8060401@pburns.seanet.com>
Message-ID: <512C9156.3050009@stats.ox.ac.uk>

On 26/02/2013 10:30, Patrick Burns wrote:
> Is it on purpose that `[[` strips the
> names when used on an atomic vector?

Yes, and documented! It does when used on a list, so is consistent.

           ?"[["? can be used to select
      a single element _dropping_ ?names?, whereas ?"["? keeps them,
      e.g., in ?c(abc = 123)[1]?.



>
>  > c(a=1, b=2)[1]
> a
> 1
>  > c(a=1, b=2)[[1]]
> [1] 1
>
>
>  > sessionInfo()
> R Under development (unstable) (2013-02-11 r61902)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From marcaurelkiefer at gmx.de  Tue Feb 26 11:07:43 2013
From: marcaurelkiefer at gmx.de (Marc Aurel Kiefer)
Date: Tue, 26 Feb 2013 11:07:43 +0100
Subject: [Rd] Running R scripts with interactive-style evaluation
Message-ID: <68D9049B548E6342A7FA7EC383707BA3F6EB7348EC@w2008srv.haus.local>

Hi,

when running a R-script like this:

enable_magic()
compute_stuff()
disable_magic()

the whole script is parsed into a single expression and then evaluated, whereas when using the interactive shell after each line entered, a REPL loop happens.

Is there a way to make a script evaluation behave like this, because I need a single REPL iteration for every expression in the script.

It doesn't matter if it's a source()-like way or "R CMD BATCH" or even feeding stdin to R or whatever...

Regards,

Marc


From murdoch.duncan at gmail.com  Tue Feb 26 14:06:08 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 26 Feb 2013 08:06:08 -0500
Subject: [Rd] Running R scripts with interactive-style evaluation
In-Reply-To: <68D9049B548E6342A7FA7EC383707BA3F6EB7348EC@w2008srv.haus.local>
References: <68D9049B548E6342A7FA7EC383707BA3F6EB7348EC@w2008srv.haus.local>
Message-ID: <512CB340.7020101@gmail.com>

On 13-02-26 5:07 AM, Marc Aurel Kiefer wrote:
> Hi,
>
> when running a R-script like this:
>
> enable_magic()
> compute_stuff()
> disable_magic()
>
> the whole script is parsed into a single expression and then evaluated, whereas when using the interactive shell after each line entered, a REPL loop happens.

It's actually a vector of expressions that are evaluated one at a time, 
but close enough...

> Is there a way to make a script evaluation behave like this, because I need a single REPL iteration for every expression in the script.

You don't say why you need that.  From your subject line, I'm guessing 
you want to do something like a user prompt, then wait for user input, 
then another user prompt, etc.? So the fact that disable_magic() was 
parsed at the beginning shouldn't matter.  Or does it?

>
> It doesn't matter if it's a source()-like way or "R CMD BATCH" or even feeding stdin to R or whatever...

I think it all depends on what kind of input users are allowed to type, 
but basically this is something you'll need to write yourself, I don't 
think any of the normal running modes of R will suit you.  Take a look 
at the source to source() or to the Sweave-related functions for ideas.

Duncan Murdoch


From murdoch.duncan at gmail.com  Tue Feb 26 14:12:06 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 26 Feb 2013 08:12:06 -0500
Subject: [Rd] double bracket stripping names
In-Reply-To: <512C8EB1.8060401@pburns.seanet.com>
References: <512C8EB1.8060401@pburns.seanet.com>
Message-ID: <512CB4A6.4060506@gmail.com>

On 13-02-26 5:30 AM, Patrick Burns wrote:
> Is it on purpose that `[[` strips the
> names when used on an atomic vector?
>
>   > c(a=1, b=2)[1]
> a
> 1
>   > c(a=1, b=2)[[1]]
> [1] 1


Yes, as Brian said.  And this makes sense:  the names are a property of 
the container, not a property of the contents.  Using single brackets 
creates a new container with a subset of the elements.  Using double 
brackets extracts an element.

The fact that there's no way to hold a number other than in a length one 
container means that the results are both length one containers, but 
conceptually there's a difference between subsetting and extracting. 
Perhaps at some distant date in the future scalar numbers will be 
possible, and then maybe c(a=1, b=2)[[1]] would give one.

Duncan Murdoch


From wdunlap at tibco.com  Tue Feb 26 17:47:18 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Tue, 26 Feb 2013 16:47:18 +0000
Subject: [Rd] Running R scripts with interactive-style evaluation
In-Reply-To: <68D9049B548E6342A7FA7EC383707BA3F6EB7348EC@w2008srv.haus.local>
References: <68D9049B548E6342A7FA7EC383707BA3F6EB7348EC@w2008srv.haus.local>
Message-ID: <E66794E69CFDE04D9A70842786030B931B909E15@PA-MBX04.na.tibco.com>

Which part of the read-eval-print loop loop ("REPL loop") do you need?

source(file, print=TRUE) gives you the printing part, which is what I usually want.

Opening a file connection and repeatedly calling parse(n=1) gives you the read part,
  > tf <- tempfile()
  > cat(file=tf, sep="\n", "x <- 1 +", "10 ; y <- 2:7", "10:3")
  > f <- file(tf, open="rt")
  > parse(f, n=1)
  expression(x <- 1 + 10)
  > parse(f, n=1)
  expression(y <- 2:7)
  > parse(f, n=1)
  expression(10:3)
  > parse(f, n=1)
  expression()
  > close(f)
and you can copy the code from source() to get the eval and print stuff right.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf
> Of Marc Aurel Kiefer
> Sent: Tuesday, February 26, 2013 2:08 AM
> To: r-devel at r-project.org
> Subject: [Rd] Running R scripts with interactive-style evaluation
> 
> Hi,
> 
> when running a R-script like this:
> 
> enable_magic()
> compute_stuff()
> disable_magic()
> 
> the whole script is parsed into a single expression and then evaluated, whereas when
> using the interactive shell after each line entered, a REPL loop happens.
> 
> Is there a way to make a script evaluation behave like this, because I need a single REPL
> iteration for every expression in the script.
> 
> It doesn't matter if it's a source()-like way or "R CMD BATCH" or even feeding stdin to R
> or whatever...
> 
> Regards,
> 
> Marc
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From h.wickham at gmail.com  Tue Feb 26 18:21:33 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 26 Feb 2013 11:21:33 -0600
Subject: [Rd] double bracket stripping names
In-Reply-To: <512CB4A6.4060506@gmail.com>
References: <512C8EB1.8060401@pburns.seanet.com> <512CB4A6.4060506@gmail.com>
Message-ID: <CABdHhvGe-ui+aeZO+bKF0zixbLaM9OsqqOMXhQaNhKFVUZfOag@mail.gmail.com>

> Yes, as Brian said.  And this makes sense:  the names are a property of the
> container, not a property of the contents.  Using single brackets creates a
> new container with a subset of the elements.  Using double brackets extracts
> an element.
>
> The fact that there's no way to hold a number other than in a length one
> container means that the results are both length one containers, but
> conceptually there's a difference between subsetting and extracting. Perhaps
> at some distant date in the future scalar numbers will be possible, and then
> maybe c(a=1, b=2)[[1]] would give one.

I like to make  the distinction between simplifying and preserving
subsetting (maybe not the best names but the best I've been able to
come up with).  It's unfortunate (but understandable) that the syntax
is inconsistent between lists and matrices:  x[i] / x[[i]], vs x[i, ,
drop = F], x[i, ]

Hadley


-- 
Chief Scientist, RStudio
http://had.co.nz/


From jon.clayden at gmail.com  Tue Feb 26 18:41:50 2013
From: jon.clayden at gmail.com (Jon Clayden)
Date: Tue, 26 Feb 2013 17:41:50 +0000
Subject: [Rd] Running R scripts with interactive-style evaluation
In-Reply-To: <68D9049B548E6342A7FA7EC383707BA3F6EB7348EC@w2008srv.haus.local>
References: <68D9049B548E6342A7FA7EC383707BA3F6EB7348EC@w2008srv.haus.local>
Message-ID: <CAM9CR=3LeRsG-4rCOUD6fpVGCNQQqFyZHuNjFVg9znLJ7440Mw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130226/ebedd043/attachment.pl>

From hpages at fhcrc.org  Tue Feb 26 23:47:51 2013
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 26 Feb 2013 14:47:51 -0800
Subject: [Rd] Recommended way to call/import functions from a Suggested
 package
In-Reply-To: <CABdHhvGp93siXObHgCiFAi7zyee=REy22XM5O05X75=fUaf0VQ@mail.gmail.com>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
	<4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
	<CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>
	<512BE76D.8090107@fhcrc.org>
	<CABdHhvGp93siXObHgCiFAi7zyee=REy22XM5O05X75=fUaf0VQ@mail.gmail.com>
Message-ID: <512D3B97.1040304@fhcrc.org>

Hi,

So MASS::huber(1:10) seems to do the job i.e. (1) loads the MASS
package (if it's installed), (2) does not pollute the search path,
(3) no 'R CMD check' warning if MASS is listed in Suggests,
and (4) descent error message if MASS is not installed:

   > MASS::huber(1:10)
   Error in loadNamespace(name) : there is no package called ?MASS?

So is this recommendable or are there good reasons for stating in
the manual that "this approach is usually not recommended"? (In which
case it would be good to know what the recommended way is.)

Thanks,
H.


On 02/25/2013 02:56 PM, Hadley Wickham wrote:
>> loadNamespaces loads but does not attach the package. Suggests: is enough to
>> quieten the warning with
>>
>> ~/tmp$ R --version
>> R Under development (unstable) (2013-02-21 r62017) -- "Unsuffered
>> Consequences"
>>
>> This is consistent with RShowDoc("R-exts") section 1.1.1
>>
>>    Namespaces accessed by the ?::? and ?:::? operators must be listed here,
>> or in ?Suggests? or ?Enhances? (see below).
>
> I guess that's changed since I last tried it.  (My reproducible
> example forgot to include MASS in the Suggests :/ )
>
> Thanks!
>
> Hadley
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.urbanek at r-project.org  Wed Feb 27 00:12:54 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 26 Feb 2013 18:12:54 -0500
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <512D3B97.1040304@fhcrc.org>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
	<4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
	<CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>
	<512BE76D.8090107@fhcrc.org>
	<CABdHhvGp93siXObHgCiFAi7zyee=REy22XM5O05X75=fUaf0VQ@mail.gmail.com>
	<512D3B97.1040304@fhcrc.org>
Message-ID: <518749A5-D21A-4686-A3C4-0221ED2062C1@r-project.org>


On Feb 26, 2013, at 5:47 PM, Herv? Pag?s wrote:

> Hi,
> 
> So MASS::huber(1:10) seems to do the job i.e. (1) loads the MASS
> package (if it's installed), (2) does not pollute the search path,
> (3) no 'R CMD check' warning if MASS is listed in Suggests,
> and (4) descent error message if MASS is not installed:
> 
>  > MASS::huber(1:10)
>  Error in loadNamespace(name) : there is no package called ?MASS?
> 

But (4) is a problem - it may not fail without MASS since it is only suggested, that's why you need the try() ... The whole thread (which you omitted) was started because the usual if(require(...)) { .. } has an unwanted side-effect which the requestor did not want so the question was what does the job and that got settled before you joined in ...

Cheers,
S




> So is this recommendable or are there good reasons for stating in
> the manual that "this approach is usually not recommended"? (In which
> case it would be good to know what the recommended way is.)
> 
> Thanks,
> H.
> 
> 
> On 02/25/2013 02:56 PM, Hadley Wickham wrote:
>>> loadNamespaces loads but does not attach the package. Suggests: is enough to
>>> quieten the warning with
>>> 
>>> ~/tmp$ R --version
>>> R Under development (unstable) (2013-02-21 r62017) -- "Unsuffered
>>> Consequences"
>>> 
>>> This is consistent with RShowDoc("R-exts") section 1.1.1
>>> 
>>>   Namespaces accessed by the ?::? and ?:::? operators must be listed here,
>>> or in ?Suggests? or ?Enhances? (see below).
>> 
>> I guess that's changed since I last tried it.  (My reproducible
>> example forgot to include MASS in the Suggests :/ )
>> 
>> Thanks!
>> 
>> Hadley
>> 
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> 


From hpages at fhcrc.org  Wed Feb 27 00:48:19 2013
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 26 Feb 2013 15:48:19 -0800
Subject: [Rd] Recommended way to call/import functions from a Suggested
 package
In-Reply-To: <518749A5-D21A-4686-A3C4-0221ED2062C1@r-project.org>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
	<4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
	<CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>
	<512BE76D.8090107@fhcrc.org>
	<CABdHhvGp93siXObHgCiFAi7zyee=REy22XM5O05X75=fUaf0VQ@mail.gmail.com>
	<512D3B97.1040304@fhcrc.org>
	<518749A5-D21A-4686-A3C4-0221ED2062C1@r-project.org>
Message-ID: <512D49C3.1060304@fhcrc.org>

On 02/26/2013 03:12 PM, Simon Urbanek wrote:
>
> On Feb 26, 2013, at 5:47 PM, Herv? Pag?s wrote:
>
>> Hi,
>>
>> So MASS::huber(1:10) seems to do the job i.e. (1) loads the MASS
>> package (if it's installed), (2) does not pollute the search path,
>> (3) no 'R CMD check' warning if MASS is listed in Suggests,
>> and (4) descent error message if MASS is not installed:
>>
>>   > MASS::huber(1:10)
>>   Error in loadNamespace(name) : there is no package called ?MASS?
>>
>
> But (4) is a problem - it may not fail without MASS since it is only suggested, that's why you need the try() ...

Not everybody needs the try(). Some functions in my package won't be
able to return anything if the suggested package is not installed, so 
they will have to fail, preferably loudly rather than silently. A pretty 
common situation.

Believe it or not, the discussion was not just about the recommended
way to call functions from the multicore package or another package
providing some kind of support for parallelization, where not having
it installed doesn't diminish the set of functionalities provided by
my package, only makes it slower.

> The whole thread (which you omitted) was started because the usual if(require(...)) { .. } has an unwanted side-effect which the requestor did not want so the question was what does the job and that got settled before you joined in ...

I didn't omit the thread: I actually read every answer including yours.
Are you claiming your solution is the recommended one? Thanks for
clarifying. Also as suggested by some posts in this thread, a
clarification in the official documentation would be nice.

Thanks,
H.

>
> Cheers,
> S
>
>
>
>
>> So is this recommendable or are there good reasons for stating in
>> the manual that "this approach is usually not recommended"? (In which
>> case it would be good to know what the recommended way is.)
>>
>> Thanks,
>> H.
>>
>>
>> On 02/25/2013 02:56 PM, Hadley Wickham wrote:
>>>> loadNamespaces loads but does not attach the package. Suggests: is enough to
>>>> quieten the warning with
>>>>
>>>> ~/tmp$ R --version
>>>> R Under development (unstable) (2013-02-21 r62017) -- "Unsuffered
>>>> Consequences"
>>>>
>>>> This is consistent with RShowDoc("R-exts") section 1.1.1
>>>>
>>>>    Namespaces accessed by the ?::? and ?:::? operators must be listed here,
>>>> or in ?Suggests? or ?Enhances? (see below).
>>>
>>> I guess that's changed since I last tried it.  (My reproducible
>>> example forgot to include MASS in the Suggests :/ )
>>>
>>> Thanks!
>>>
>>> Hadley
>>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fhcrc.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From hpages at fhcrc.org  Wed Feb 27 01:42:13 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 26 Feb 2013 16:42:13 -0800
Subject: [Rd] double bracket stripping names
In-Reply-To: <512C8EB1.8060401@pburns.seanet.com>
References: <512C8EB1.8060401@pburns.seanet.com>
Message-ID: <512D5665.8010902@fhcrc.org>

Hi Patrick,

On 02/26/2013 02:30 AM, Patrick Burns wrote:
> Is it on purpose that `[[` strips the
> names when used on an atomic vector?
>
>  > c(a=1, b=2)[1]
> a
> 1
>  > c(a=1, b=2)[[1]]
> [1] 1

FWIW, here are a couple of other interesting facts about this:

  (a) [[ is about twice faster than [ for me (64-bit Ubuntu)
      on a named atomic vector.

  (b) [[ raises an error if the subscript is out of bounds:

        > c(a=1, b=2)[3]
        <NA>
          NA

        > c(a=1, b=2)[[3]]
        Error in c(a = 1, b = 2)[[3]] : subscript out of bounds

      Can be useful in some contexts.

Cheers,
H.

>
>
>  > sessionInfo()
> R Under development (unstable) (2013-02-11 r61902)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From simon.urbanek at r-project.org  Wed Feb 27 02:28:17 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 26 Feb 2013 20:28:17 -0500
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <512D49C3.1060304@fhcrc.org>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
	<4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
	<CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>
	<512BE76D.8090107@fhcrc.org>
	<CABdHhvGp93siXObHgCiFAi7zyee=REy22XM5O05X75=fUaf0VQ@mail.gmail.com>
	<512D3B97.1040304@fhcrc.org>
	<518749A5-D21A-4686-A3C4-0221ED2062C1@r-project.org>
	<512D49C3.1060304@fhcrc.org>
Message-ID: <C864EA37-65A0-4704-AABD-108F12B4D51F@r-project.org>


On Feb 26, 2013, at 6:48 PM, Herv? Pag?s wrote:

> On 02/26/2013 03:12 PM, Simon Urbanek wrote:
>> 
>> On Feb 26, 2013, at 5:47 PM, Herv? Pag?s wrote:
>> 
>>> Hi,
>>> 
>>> So MASS::huber(1:10) seems to do the job i.e. (1) loads the MASS
>>> package (if it's installed), (2) does not pollute the search path,
>>> (3) no 'R CMD check' warning if MASS is listed in Suggests,
>>> and (4) descent error message if MASS is not installed:
>>> 
>>>  > MASS::huber(1:10)
>>>  Error in loadNamespace(name) : there is no package called ?MASS?
>>> 
>> 
>> But (4) is a problem - it may not fail without MASS since it is only suggested, that's why you need the try() ...
> 
> Not everybody needs the try(). Some functions in my package won't be
> able to return anything if the suggested package is not installed, so they will have to fail, preferably loudly rather than silently. A pretty common situation.
> 

Hmm.. according to the docs that is not quite as intended: a package must work without "suggests" dependencies in the entirety. You can (conditionally) use suggested packages in datasets, examples or vignettes. Obviously, you could be tempted to hide this deficiency (functions failing without suggested packages) by not calling the functions that fail in your examples or tests, but I'd argue that is bypassing the design of "suggests".


> Believe it or not, the discussion was not just about the recommended
> way to call functions from the multicore package or another package
> providing some kind of support for parallelization, where not having
> it installed doesn't diminish the set of functionalities provided by
> my package, only makes it slower.
> 

I have no assumptions about what the author intended this functionality for, nor what you intend to use it for.


>> The whole thread (which you omitted) was started because the usual if(require(...)) { .. } has an unwanted side-effect which the requestor did not want so the question was what does the job and that got settled before you joined in ...
> 
> I didn't omit the thread: I actually read every answer including yours.
> Are you claiming your solution is the recommended one?

No - but as far as I can see it is in the spirit of the documentation which explicitly mentions if(require(..)) and further down talks about :: and Suggests - so putting 1 + 1 (conditionality and ::) has led me to devise what I suggested.

Cheers,
Simon


> Thanks for
> clarifying. Also as suggested by some posts in this thread, a
> clarification in the official documentation would be nice.
> 




> Thanks,
> H.
> 
>> 
>> Cheers,
>> S
>> 
>> 
>> 
>> 
>>> So is this recommendable or are there good reasons for stating in
>>> the manual that "this approach is usually not recommended"? (In which
>>> case it would be good to know what the recommended way is.)
>>> 
>>> Thanks,
>>> H.
>>> 
>>> 
>>> On 02/25/2013 02:56 PM, Hadley Wickham wrote:
>>>>> loadNamespaces loads but does not attach the package. Suggests: is enough to
>>>>> quieten the warning with
>>>>> 
>>>>> ~/tmp$ R --version
>>>>> R Under development (unstable) (2013-02-21 r62017) -- "Unsuffered
>>>>> Consequences"
>>>>> 
>>>>> This is consistent with RShowDoc("R-exts") section 1.1.1
>>>>> 
>>>>>   Namespaces accessed by the ?::? and ?:::? operators must be listed here,
>>>>> or in ?Suggests? or ?Enhances? (see below).
>>>> 
>>>> I guess that's changed since I last tried it.  (My reproducible
>>>> example forgot to include MASS in the Suggests :/ )
>>>> 
>>>> Thanks!
>>>> 
>>>> Hadley
>>>> 
>>> 
>>> --
>>> Herv? Pag?s
>>> 
>>> Program in Computational Biology
>>> Division of Public Health Sciences
>>> Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N, M1-B514
>>> P.O. Box 19024
>>> Seattle, WA 98109-1024
>>> 
>>> E-mail: hpages at fhcrc.org
>>> Phone:  (206) 667-5791
>>> Fax:    (206) 667-1319
>>> 
>>> 
>> 
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> 


From winstonchang1 at gmail.com  Wed Feb 27 04:10:19 2013
From: winstonchang1 at gmail.com (Winston Chang)
Date: Tue, 26 Feb 2013 21:10:19 -0600
Subject: [Rd] double bracket stripping names
In-Reply-To: <512D5665.8010902@fhcrc.org>
References: <512C8EB1.8060401@pburns.seanet.com> <512D5665.8010902@fhcrc.org>
Message-ID: <CAFOpNVFakqBgFdteWCt5kW4FR0uRFv0G3NB+RD2DNOWdvgqjGQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130226/a8214e6e/attachment.pl>

From hpages at fhcrc.org  Wed Feb 27 06:54:28 2013
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 26 Feb 2013 21:54:28 -0800
Subject: [Rd] Recommended way to call/import functions from a Suggested
 package
In-Reply-To: <C864EA37-65A0-4704-AABD-108F12B4D51F@r-project.org>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
	<4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
	<CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>
	<512BE76D.8090107@fhcrc.org>
	<CABdHhvGp93siXObHgCiFAi7zyee=REy22XM5O05X75=fUaf0VQ@mail.gmail.com>
	<512D3B97.1040304@fhcrc.org>
	<518749A5-D21A-4686-A3C4-0221ED2062C1@r-project.org>
	<512D49C3.1060304@fhcrc.org>
	<C864EA37-65A0-4704-AABD-108F12B4D51F@r-project.org>
Message-ID: <512D9F94.1030501@fhcrc.org>

On 02/26/2013 05:28 PM, Simon Urbanek wrote:
>
> On Feb 26, 2013, at 6:48 PM, Herv? Pag?s wrote:
>
>> On 02/26/2013 03:12 PM, Simon Urbanek wrote:
>>>
>>> On Feb 26, 2013, at 5:47 PM, Herv? Pag?s wrote:
>>>
>>>> Hi,
>>>>
>>>> So MASS::huber(1:10) seems to do the job i.e. (1) loads the MASS
>>>> package (if it's installed), (2) does not pollute the search path,
>>>> (3) no 'R CMD check' warning if MASS is listed in Suggests,
>>>> and (4) descent error message if MASS is not installed:
>>>>
>>>>   > MASS::huber(1:10)
>>>>   Error in loadNamespace(name) : there is no package called ?MASS?
>>>>
>>>
>>> But (4) is a problem - it may not fail without MASS since it is only suggested, that's why you need the try() ...
>>
>> Not everybody needs the try(). Some functions in my package won't be
>> able to return anything if the suggested package is not installed, so they will have to fail, preferably loudly rather than silently. A pretty common situation.
>>
>
> Hmm.. according to the docs that is not quite as intended: a package must work without "suggests" dependencies in the entirety. You can (conditionally) use suggested packages in datasets, examples or vignettes. Obviously, you could be tempted to hide this deficiency (functions failing without suggested packages) by not calling the functions that fail in your examples or tests, but I'd argue that is bypassing the design of "suggests".

Here is what the "Writing R Extensions" manual says:

   The ?Suggests? field uses the same syntax as ?Depends? and lists
   packages that are not necessarily needed. This includes packages
   used only in examples, tests or vignettes (see Writing package
   vignettes), and *packages loaded in the body of functions*.

Then some examples are provided and they mostly focus on suggested
packages used in examples, tests or vignettes. I couldn't find
anywhere that ``a package must work without "suggests" dependencies
in the entirety''.

AFAIK there are many valid situations where one wants to provide
some additional functionalities in his/her package via suggested
packages. A typical example being a front-end function that supports
different back-ends defined in different packages: the default
back-end will generally be in Depends or Imports, the alternative
back-ends in Suggests. If the user specifies a back-end (thru
some argument passed to the front-end) that is not installed,
then s/he'll get an error.

I don't need to hide this deficiency by not calling the functions
that fail in my examples (or tests). I'll just call my front-end
without specifying an alternative back-end. Not a big deal if my
function generates a plot and if using the alternative back-end
would basically produce the same plot with only some small cosmetic
differences.

Cheers,
H.

>
>
>> Believe it or not, the discussion was not just about the recommended
>> way to call functions from the multicore package or another package
>> providing some kind of support for parallelization, where not having
>> it installed doesn't diminish the set of functionalities provided by
>> my package, only makes it slower.
>>
>
> I have no assumptions about what the author intended this functionality for, nor what you intend to use it for.
>
>
>>> The whole thread (which you omitted) was started because the usual if(require(...)) { .. } has an unwanted side-effect which the requestor did not want so the question was what does the job and that got settled before you joined in ...
>>
>> I didn't omit the thread: I actually read every answer including yours.
>> Are you claiming your solution is the recommended one?
>
> No - but as far as I can see it is in the spirit of the documentation which explicitly mentions if(require(..)) and further down talks about :: and Suggests - so putting 1 + 1 (conditionality and ::) has led me to devise what I suggested.
>
> Cheers,
> Simon
>
>
>> Thanks for
>> clarifying. Also as suggested by some posts in this thread, a
>> clarification in the official documentation would be nice.
>>
>
>
>
>
>> Thanks,
>> H.
>>
>>>
>>> Cheers,
>>> S
>>>
>>>
>>>
>>>
>>>> So is this recommendable or are there good reasons for stating in
>>>> the manual that "this approach is usually not recommended"? (In which
>>>> case it would be good to know what the recommended way is.)
>>>>
>>>> Thanks,
>>>> H.
>>>>
>>>>
>>>> On 02/25/2013 02:56 PM, Hadley Wickham wrote:
>>>>>> loadNamespaces loads but does not attach the package. Suggests: is enough to
>>>>>> quieten the warning with
>>>>>>
>>>>>> ~/tmp$ R --version
>>>>>> R Under development (unstable) (2013-02-21 r62017) -- "Unsuffered
>>>>>> Consequences"
>>>>>>
>>>>>> This is consistent with RShowDoc("R-exts") section 1.1.1
>>>>>>
>>>>>>    Namespaces accessed by the ?::? and ?:::? operators must be listed here,
>>>>>> or in ?Suggests? or ?Enhances? (see below).
>>>>>
>>>>> I guess that's changed since I last tried it.  (My reproducible
>>>>> example forgot to include MASS in the Suggests :/ )
>>>>>
>>>>> Thanks!
>>>>>
>>>>> Hadley
>>>>>
>>>>
>>>> --
>>>> Herv? Pag?s
>>>>
>>>> Program in Computational Biology
>>>> Division of Public Health Sciences
>>>> Fred Hutchinson Cancer Research Center
>>>> 1100 Fairview Ave. N, M1-B514
>>>> P.O. Box 19024
>>>> Seattle, WA 98109-1024
>>>>
>>>> E-mail: hpages at fhcrc.org
>>>> Phone:  (206) 667-5791
>>>> Fax:    (206) 667-1319
>>>>
>>>>
>>>
>>
>> --
>> Herv? Pag?s
>>
>> Program in Computational Biology
>> Division of Public Health Sciences
>> Fred Hutchinson Cancer Research Center
>> 1100 Fairview Ave. N, M1-B514
>> P.O. Box 19024
>> Seattle, WA 98109-1024
>>
>> E-mail: hpages at fhcrc.org
>> Phone:  (206) 667-5791
>> Fax:    (206) 667-1319
>>
>>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From renaud at mancala.cbio.uct.ac.za  Wed Feb 27 11:08:14 2013
From: renaud at mancala.cbio.uct.ac.za (Renaud)
Date: Wed, 27 Feb 2013 12:08:14 +0200
Subject: [Rd] Keeping up to date with R-devel
Message-ID: <CAHavPHF06qCEqiYqvCLOEfY_Zu9d8AWkyT7jKd0RnU=NmYeqqw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130227/6cc6ba03/attachment.pl>

From marcaurelkiefer at gmx.de  Tue Feb 26 14:28:57 2013
From: marcaurelkiefer at gmx.de (Marc Aurel Kiefer)
Date: Tue, 26 Feb 2013 14:28:57 +0100
Subject: [Rd]  Running R scripts with interactive-style evaluation
In-Reply-To: <512CB340.7020101@gmail.com>
References: <68D9049B548E6342A7FA7EC383707BA3F6EB7348EC@w2008srv.haus.local>,
	<512CB340.7020101@gmail.com>
Message-ID: <68D9049B548E6342A7FA7EC383707BA3F6EB72F72E@w2008srv.haus.local>

Thanks for your insights.

What I'm actually doing is the following:

I modified R in a way that the REPL loop always parses the input into an SEXPR, but depending on if "magic is enabled" or not, let R compute it or compute it via my own "backend".
As I wanted to keep the changes to R itself as minimally invasive as possible, there is a simple if-statement at the beginning of the REPL iteration which decides how to compute the expression.
using the R commands "enable/disable_magic()" one can change the behavior as required. This works fine when typing R code interactively, but not with a script, since it is only a single REPL iteration.
So I was looking for a way to get "interactive behavior" with scripts, without requiring too many changes to R itself.

Regards,

Marc
________________________________________
Von: Duncan Murdoch [murdoch.duncan at gmail.com]
Gesendet: Dienstag, 26. Februar 2013 14:06
An: Marc Aurel Kiefer
Cc: r-devel at r-project.org
Betreff: Re: [Rd] Running R scripts with interactive-style evaluation

On 13-02-26 5:07 AM, Marc Aurel Kiefer wrote:
> Hi,
>
> when running a R-script like this:
>
> enable_magic()
> compute_stuff()
> disable_magic()
>
> the whole script is parsed into a single expression and then evaluated, whereas when using the interactive shell after each line entered, a REPL loop happens.

It's actually a vector of expressions that are evaluated one at a time,
but close enough...

> Is there a way to make a script evaluation behave like this, because I need a single REPL iteration for every expression in the script.

You don't say why you need that.  From your subject line, I'm guessing
you want to do something like a user prompt, then wait for user input,
then another user prompt, etc.? So the fact that disable_magic() was
parsed at the beginning shouldn't matter.  Or does it?

>
> It doesn't matter if it's a source()-like way or "R CMD BATCH" or even feeding stdin to R or whatever...

I think it all depends on what kind of input users are allowed to type,
but basically this is something you'll need to write yourself, I don't
think any of the normal running modes of R will suit you.  Take a look
at the source to source() or to the Sweave-related functions for ideas.

Duncan Murdoch


From simon.urbanek at r-project.org  Wed Feb 27 13:28:25 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 27 Feb 2013 07:28:25 -0500
Subject: [Rd] Recommended way to call/import functions from a Suggested
	package
In-Reply-To: <512D9F94.1030501@fhcrc.org>
References: <FD2C7845-F6AD-4AA1-91C1-8CB14F43AA7D@stat.ubc.ca>
	<CABdHhvHkJkyzKODdDKKt+fmCeUAXJC7L24vXLuLPWmRYsYZtkQ@mail.gmail.com>
	<FDF2030A-2A91-4A40-B09F-C4DD78682A62@r-project.org>
	<CABdHhvHx1H09Qbx6mGBZUkB-yyta5nNv-cg=JgbS+0Js-iN7Yw@mail.gmail.com>
	<4F6FBC64-4EAE-43E2-B041-B54663CDF950@stat.ubc.ca>
	<CABdHhvEwU9mgnnL1=iHur-JMFwOOPkkv8P164g=uVuaf8xWajQ@mail.gmail.com>
	<512BE76D.8090107@fhcrc.org>
	<CABdHhvGp93siXObHgCiFAi7zyee=REy22XM5O05X75=fUaf0VQ@mail.gmail.com>
	<512D3B97.1040304@fhcrc.org>
	<518749A5-D21A-4686-A3C4-0221ED2062C1@r-project.org>
	<512D49C3.1060304@fhcrc.org>
	<C864EA37-65A0-4704-AABD-108F12B4D51F@r-project.org>
	<512D9F94.1030501@fhcrc.org>
Message-ID: <A1F8CB5E-6035-48BD-AD15-C1D717DAECC0@r-project.org>


On Feb 27, 2013, at 12:54 AM, Herv? Pag?s wrote:

> On 02/26/2013 05:28 PM, Simon Urbanek wrote:
>> 
>> On Feb 26, 2013, at 6:48 PM, Herv? Pag?s wrote:
>> 
>>> On 02/26/2013 03:12 PM, Simon Urbanek wrote:
>>>> 
>>>> On Feb 26, 2013, at 5:47 PM, Herv? Pag?s wrote:
>>>> 
>>>>> Hi,
>>>>> 
>>>>> So MASS::huber(1:10) seems to do the job i.e. (1) loads the MASS
>>>>> package (if it's installed), (2) does not pollute the search path,
>>>>> (3) no 'R CMD check' warning if MASS is listed in Suggests,
>>>>> and (4) descent error message if MASS is not installed:
>>>>> 
>>>>>  > MASS::huber(1:10)
>>>>>  Error in loadNamespace(name) : there is no package called ?MASS?
>>>>> 
>>>> 
>>>> But (4) is a problem - it may not fail without MASS since it is only suggested, that's why you need the try() ...
>>> 
>>> Not everybody needs the try(). Some functions in my package won't be
>>> able to return anything if the suggested package is not installed, so they will have to fail, preferably loudly rather than silently. A pretty common situation.
>>> 
>> 
>> Hmm.. according to the docs that is not quite as intended: a package must work without "suggests" dependencies in the entirety. You can (conditionally) use suggested packages in datasets, examples or vignettes. Obviously, you could be tempted to hide this deficiency (functions failing without suggested packages) by not calling the functions that fail in your examples or tests, but I'd argue that is bypassing the design of "suggests".
> 
> Here is what the "Writing R Extensions" manual says:
> 
>  The ?Suggests? field uses the same syntax as ?Depends? and lists
>  packages that are not necessarily needed. This includes packages
>  used only in examples, tests or vignettes (see Writing package
>  vignettes), and *packages loaded in the body of functions*.
> 
> Then some examples are provided and they mostly focus on suggested
> packages used in examples, tests or vignettes. I couldn't find
> anywhere that ``a package must work without "suggests" dependencies
> in the entirety''.
> 
> AFAIK there are many valid situations where one wants to provide
> some additional functionalities in his/her package via suggested
> packages. A typical example being a front-end function that supports
> different back-ends defined in different packages: the default
> back-end will generally be in Depends or Imports, the alternative
> back-ends in Suggests. If the user specifies a back-end (thru
> some argument passed to the front-end) that is not installed,
> then s/he'll get an error.
> 
> I don't need to hide this deficiency by not calling the functions
> that fail in my examples (or tests). I'll just call my front-end
> without specifying an alternative back-end.

*alternative*, yes.

Cheers,
Simon

> Not a big deal if my
> function generates a plot and if using the alternative back-end
> would basically produce the same plot with only some small cosmetic
> differences.
> 
> Cheers,
> H.
> 
>> 
>> 
>>> Believe it or not, the discussion was not just about the recommended
>>> way to call functions from the multicore package or another package
>>> providing some kind of support for parallelization, where not having
>>> it installed doesn't diminish the set of functionalities provided by
>>> my package, only makes it slower.
>>> 
>> 
>> I have no assumptions about what the author intended this functionality for, nor what you intend to use it for.
>> 
>> 
>>>> The whole thread (which you omitted) was started because the usual if(require(...)) { .. } has an unwanted side-effect which the requestor did not want so the question was what does the job and that got settled before you joined in ...
>>> 
>>> I didn't omit the thread: I actually read every answer including yours.
>>> Are you claiming your solution is the recommended one?
>> 
>> No - but as far as I can see it is in the spirit of the documentation which explicitly mentions if(require(..)) and further down talks about :: and Suggests - so putting 1 + 1 (conditionality and ::) has led me to devise what I suggested.
>> 
>> Cheers,
>> Simon
>> 
>> 
>>> Thanks for
>>> clarifying. Also as suggested by some posts in this thread, a
>>> clarification in the official documentation would be nice.
>>> 
>> 
>> 
>> 
>> 
>>> Thanks,
>>> H.
>>> 
>>>> 
>>>> Cheers,
>>>> S
>>>> 
>>>> 
>>>> 
>>>> 
>>>>> So is this recommendable or are there good reasons for stating in
>>>>> the manual that "this approach is usually not recommended"? (In which
>>>>> case it would be good to know what the recommended way is.)
>>>>> 
>>>>> Thanks,
>>>>> H.
>>>>> 
>>>>> 
>>>>> On 02/25/2013 02:56 PM, Hadley Wickham wrote:
>>>>>>> loadNamespaces loads but does not attach the package. Suggests: is enough to
>>>>>>> quieten the warning with
>>>>>>> 
>>>>>>> ~/tmp$ R --version
>>>>>>> R Under development (unstable) (2013-02-21 r62017) -- "Unsuffered
>>>>>>> Consequences"
>>>>>>> 
>>>>>>> This is consistent with RShowDoc("R-exts") section 1.1.1
>>>>>>> 
>>>>>>>   Namespaces accessed by the ?::? and ?:::? operators must be listed here,
>>>>>>> or in ?Suggests? or ?Enhances? (see below).
>>>>>> 
>>>>>> I guess that's changed since I last tried it.  (My reproducible
>>>>>> example forgot to include MASS in the Suggests :/ )
>>>>>> 
>>>>>> Thanks!
>>>>>> 
>>>>>> Hadley
>>>>>> 
>>>>> 
>>>>> --
>>>>> Herv? Pag?s
>>>>> 
>>>>> Program in Computational Biology
>>>>> Division of Public Health Sciences
>>>>> Fred Hutchinson Cancer Research Center
>>>>> 1100 Fairview Ave. N, M1-B514
>>>>> P.O. Box 19024
>>>>> Seattle, WA 98109-1024
>>>>> 
>>>>> E-mail: hpages at fhcrc.org
>>>>> Phone:  (206) 667-5791
>>>>> Fax:    (206) 667-1319
>>>>> 
>>>>> 
>>>> 
>>> 
>>> --
>>> Herv? Pag?s
>>> 
>>> Program in Computational Biology
>>> Division of Public Health Sciences
>>> Fred Hutchinson Cancer Research Center
>>> 1100 Fairview Ave. N, M1-B514
>>> P.O. Box 19024
>>> Seattle, WA 98109-1024
>>> 
>>> E-mail: hpages at fhcrc.org
>>> Phone:  (206) 667-5791
>>> Fax:    (206) 667-1319
>>> 
>>> 
>> 
> 
> -- 
> Herv? Pag?s
> 
> Program in Computational Biology
> Division of Public Health Sciences
> Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N, M1-B514
> P.O. Box 19024
> Seattle, WA 98109-1024
> 
> E-mail: hpages at fhcrc.org
> Phone:  (206) 667-5791
> Fax:    (206) 667-1319
> 
> 


From simon.urbanek at r-project.org  Wed Feb 27 14:54:30 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Wed, 27 Feb 2013 08:54:30 -0500
Subject: [Rd] Keeping up to date with R-devel
In-Reply-To: <CAHavPHF06qCEqiYqvCLOEfY_Zu9d8AWkyT7jKd0RnU=NmYeqqw@mail.gmail.com>
References: <CAHavPHF06qCEqiYqvCLOEfY_Zu9d8AWkyT7jKd0RnU=NmYeqqw@mail.gmail.com>
Message-ID: <E13F0A8B-2CAC-44F8-882B-EB35FCDE00B5@r-project.org>

On Feb 27, 2013, at 5:08 AM, Renaud wrote:

> Hi,
> 
> is checking out R SVN trunk the recommended way to keep up to date with
> R-devel and check packages with the latest version?
> 
> My objective is to be able to have both R and R-devel versions
> installed/working and up to date.
> R-devel binaries would be available as symlinks in my home directory so
> that I can do:
> 
> Rdevel CMD check mypkg
> Rdscript -e "some R code"
> 
> anywhere on my system.
> 
> So the workflow would be:
> 
> Only once:
> 
> svn co https://svn.r-project.org/R/trunk rdevel
> 
> Then in rdevel:
> 
> svn update
> 
> ./configure --prefix=~/bin/R-devel
> 

As the R-admin suggests it is recommended to not build in the source tree (this has been beaten to death on this list just recently).


> make
> 
> make install
> 

I prefer a different setup - changing the prefix means that in theory you are moving all your dependent libraries, system setting etc. there which is typically not always what you want. Instead I prefer leaving --prefix alone so you don't need to micro-manage everything and instead use rhome to point to the versioned install. This makes updating much easier IMHO since you just move the new tree in. But even if you point prefix to your home, the idea is that you keep the prefix fixed for all R versions and have only separate R_HOMEs.

make install DESTDIR=/tmp/dst rhome=/home/foo/R/devel

mkdir ~/R
mv /tmp/dst/home/foo/R/devel ~/R/
ln -sfn ~/R/devel/bin/R ~/bin/Rdevel

rm -rf /tmp/dst

typically, I also keep a "current" link ~/R/current -> devel and actually use
ln -sfn ~/R/current/bin/R ~/bin/R

This is just my personal preference, but it makes managing R versions across many machines and versions quite convenient.

You don't have to use DESTDIR if you want install to update the files, but I prefer a clean move to avoid pollution with old files or old packages.

Those are just some ideas that may or may not be useful to you.

Cheers,
Simon



> [Only after first compilation:
> cd ~/bin/; ln- s R-devel/bin/R Rdevel; ln- s R-devel/bin/Rscript Rdscript
> ]
> 
> Then build/check packages as usual, using Rdevel CMD instead of R CMD.
> Obviously contrib packages need to be installed/updated in Rdevel.
> 
> Can anybody see an issue in this workflow? Improvements? unneeded commands?
> possible conflcts in libraries?
> 
> Would be Is there any chance that the Linux binary repositories include
> Rdevel-base packages that would do all this and install R-devel system
> wide. It would be up to date via apt-get-like systems.
> Not sure how automatic it is to go from sources to .deb packages.
> 
> Thank you.
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 


From edd at debian.org  Wed Feb 27 15:43:18 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 27 Feb 2013 08:43:18 -0600
Subject: [Rd] Keeping up to date with R-devel
In-Reply-To: <CAHavPHF06qCEqiYqvCLOEfY_Zu9d8AWkyT7jKd0RnU=NmYeqqw@mail.gmail.com>
References: <CAHavPHF06qCEqiYqvCLOEfY_Zu9d8AWkyT7jKd0RnU=NmYeqqw@mail.gmail.com>
Message-ID: <20782.7046.512347.600130@max.nulle.part>


On 27 February 2013 at 12:08, Renaud wrote:
| is checking out R SVN trunk the recommended way to keep up to date with
| R-devel and check packages with the latest version?

In theory.

In practice you need a time machine as I just something rejected for a test
that did not exist when I submitted :-/

Until the package "timeMachine" appears on CRAN, I do keep an svn checkout
which I update about once a week.  I have a little build script which I
posted once and which I'd be happy to send to you but I can't show it in
public for risk of ex-communication as it builds in the very verboten place
(and no, I've never been bitten but yes I do make distclean too).

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From renaud at mancala.cbio.uct.ac.za  Wed Feb 27 16:16:20 2013
From: renaud at mancala.cbio.uct.ac.za (Renaud)
Date: Wed, 27 Feb 2013 17:16:20 +0200
Subject: [Rd] Keeping up to date with R-devel
In-Reply-To: <20782.7046.512347.600130@max.nulle.part>
References: <CAHavPHF06qCEqiYqvCLOEfY_Zu9d8AWkyT7jKd0RnU=NmYeqqw@mail.gmail.com>
	<20782.7046.512347.600130@max.nulle.part>
Message-ID: <CAHavPHG75CH=-qiPVUp9t964RtGCrgv71aVf5C1133yvzVzRTg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130227/7627cac6/attachment.pl>

From edd at debian.org  Wed Feb 27 17:08:49 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 27 Feb 2013 10:08:49 -0600
Subject: [Rd] Keeping up to date with R-devel
In-Reply-To: <CAHavPHG75CH=-qiPVUp9t964RtGCrgv71aVf5C1133yvzVzRTg@mail.gmail.com>
References: <CAHavPHF06qCEqiYqvCLOEfY_Zu9d8AWkyT7jKd0RnU=NmYeqqw@mail.gmail.com>
	<20782.7046.512347.600130@max.nulle.part>
	<CAHavPHG75CH=-qiPVUp9t964RtGCrgv71aVf5C1133yvzVzRTg@mail.gmail.com>
Message-ID: <20782.12177.599278.108515@max.nulle.part>


On 27 February 2013 at 17:16, Renaud wrote:
| Hi,
| 
| thanks for the responses.
| Dirk I found the script you posted once. Can anyone send me a link to the?
| "beaten to death post"?

Those were Simon's words, not mine, but I think he referred to the long-ish
and painful thread here:

   http://thread.gmane.org/gmane.comp.lang.r.devel/32779

Feel free to ignore the title, and most assertions by the OP which were never
replicated by anybody else.  

The "do not build in src" mantra was repeated a few times, and as I recall
also refuted once (not by me).  That is not a topic I care much about; I use
a shortcut, am aware of its (theoretical?) limits but for the casual R CMD
check use I get out of R-devel never had an issue.
 
| I am fine with these approaches and kind of already follow them.
| I imagine that after an R-devel update you have to re-install all the contrib
| packages that need to compile library objects, right?

At the R 3.0.0 juncture I had to as the ABI broke (due to the many changes),
otherwise no.  I only keep a handful of packages in the seperately managed
directory for r-devel.

Dirk 

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com  


From jari.oksanen at oulu.fi  Wed Feb 27 17:57:33 2013
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Wed, 27 Feb 2013 16:57:33 +0000
Subject: [Rd] Keeping up to date with R-devel
In-Reply-To: <20782.12177.599278.108515@max.nulle.part>
References: <CAHavPHF06qCEqiYqvCLOEfY_Zu9d8AWkyT7jKd0RnU=NmYeqqw@mail.gmail.com>
	<20782.7046.512347.600130@max.nulle.part>
	<CAHavPHG75CH=-qiPVUp9t964RtGCrgv71aVf5C1133yvzVzRTg@mail.gmail.com>
	<20782.12177.599278.108515@max.nulle.part>
Message-ID: <88D3425D-2FE1-4E1F-88A8-5D23684972B4@oulu.fi>


On 27/02/2013, at 18:08 PM, Dirk Eddelbuettel wrote:

> 
> On 27 February 2013 at 17:16, Renaud wrote:
> | Hi,
> | 
> | thanks for the responses.
> | Dirk I found the script you posted once. Can anyone send me a link to the 
> | "beaten to death post"?
> 
> Those were Simon's words, not mine, but I think he referred to the long-ish
> and painful thread here:
> 
>   http://thread.gmane.org/gmane.comp.lang.r.devel/32779
> 
> Feel free to ignore the title, and most assertions by the OP which were never
> replicated by anybody else.  
> 
> The "do not build in src" mantra was repeated a few times, and as I recall
> also refuted once (not by me).  That is not a topic I care much about; I use
> a shortcut, am aware of its (theoretical?) limits but for the casual R CMD
> check use I get out of R-devel never had an issue.
> 
FWIW, I also build in src, at least twice weekly. It is a bit scary to confess this, but I'll duck and cover and I hope they will not catch me. This is a no-no, and if you run in the trouble, you shall not make noise, but you got to clean up your mess all by yourself. I even didn't know about distclean, but I do manual cleaning. When I run in the trouble, the message is usually that there is "no rule to build 'x' from 'z'". So I go to the offending directory (folder for Windows users), check which files are not under version control (svn st), remove those, ./configure && make. It has worked so far. The day it won't work, I'll remove my old src and start from the square one  with a virgin checkout and following the instructions. This has not happened yet, and I have done this for several moths, over a year (I'm afraid that day of destruction is drawing nigh: this abomination must be be stopped). I only do this in my home directory in my office desktop, I don't make install, but I have a symbolic link in ~/bin to the built binary in the build directory so that I can either use the stock R of my system (which still runs in 2.14 series) with stable packages, or experimental R with experimental versions of packages. 

I think the rule is that you can do anything as long as you don't complain. If you want to complain, you must follow the instructions. 

Cheers, Jari Oksanen
--
Jari Oksanen, Dept Biology, Univ Oulu, 90014 Finland


From nalimilan at club.fr  Wed Feb 27 19:46:51 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 27 Feb 2013 19:46:51 +0100
Subject: [Rd] nobs() with glm(family="poisson")
In-Reply-To: <1361186543.2067.24.camel@milan.ined.fr>
References: <1361186543.2067.24.camel@milan.ined.fr>
Message-ID: <1361990811.1726.47.camel@milan>

I cannot believes nobody cares about this -- or I'm completely wrong and
in that case everybody should rush to put the shame on me... :-p

In the meantime, I have come up with an alternative way of fixing this:
when modeling count data, glm() could allow users to pass a table as the
data argument, and convert it to a data frame using
as.data.frame.table() instead of requiring the user to do it
beforehand[1]. This would become the recommended way of fitting models
for count data, and the fact that a table is passed could be used as the
sign that nobs() should return the sum of cell counts instead of the
number of rows in the data.frame.


Regards


1: gnm already supports this pattern, with the additional advantage that
e.g. fitted(), predict(), residuals() and weights() return an object of
the same dimensions and dimnames as the original table.


Le lundi 18 f?vrier 2013 ? 12:22 +0100, Milan Bouchet-Valat a ?crit :
> Hi!
> 
> The nobs() method for glm objects always returns the number of cases
> with non-null weights in the data, which does not correspond to the
> number of observations for Poisson regression/log-linear models, i.e.
> when family="poisson" or family="quasipoisson".
> 
> This sounds dangerous since nobs() is, as the documentation states,
> primarily aimed at computing the Bayesian information criterion. Raftery
> (1995:20) warned against this:
> > What should n be? Once again, it is best to use the actual number of
> > individuals, i.e. the sum of the cell counts, and not the number of
> > cells (Raftery, 1986a).
> 
> Is there a reason why this should not/cannot be done that way?
> 
> This behavior can be reproduced with with R 3.0.0 from SVN, using the
> example from ?glm:
> counts <- c(18,17,15,20,10,20,25,13,12)
> outcome <- gl(3,1,9)
> treatment <- gl(3,3)
> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
> nobs(glm.D93)
> # 9 == length(counts)
> # Should be 150 == sum(counts)
> 
> FWIW, stats:::nobs.glm is currently defined as:
> nobs.glm <- function (object, ...) 
>     if (!is.null(w <- object$prior.weights)) sum(w != 0) else length(object$residuals)
> 
> 
> Thanks!
> 
> 
> Raftery, Adrian E. 1995. ?Bayesian Model Selection in Social Research.?
> Sociological methodology 25:111?96.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Wed Feb 27 20:48:26 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 27 Feb 2013 20:48:26 +0100
Subject: [Rd] nobs() with glm(family="poisson")
In-Reply-To: <1361990811.1726.47.camel@milan>
References: <1361186543.2067.24.camel@milan.ined.fr>
	<1361990811.1726.47.camel@milan>
Message-ID: <CDF566D6-1023-48D4-BC5C-8714D46FF350@gmail.com>


On Feb 27, 2013, at 19:46 , Milan Bouchet-Valat wrote:

> I cannot believes nobody cares about this -- or I'm completely wrong and
> in that case everybody should rush to put the shame on me... :-p

Well, nobs() is the number of observations. If you have 5 Poisson distributed counts, you have 5 observations. If the number of observations is not the right thing to use in some context, use the right thing instead. Changing the definition of nobs() surely leads to madness. 

(I suppose that the fact that n is so obviously the wrong thing for one particularly well-digested family of distribution functions could be taken to indicate a generic weakness with the BIC.)

> 
> In the meantime, I have come up with an alternative way of fixing this:
> when modeling count data, glm() could allow users to pass a table as the
> data argument, and convert it to a data frame using
> as.data.frame.table() instead of requiring the user to do it
> beforehand[1]. This would become the recommended way of fitting models
> for count data, and the fact that a table is passed could be used as the
> sign that nobs() should return the sum of cell counts instead of the
> number of rows in the data.frame.
> 
> 
> Regards
> 
> 
> 1: gnm already supports this pattern, with the additional advantage that
> e.g. fitted(), predict(), residuals() and weights() return an object of
> the same dimensions and dimnames as the original table.
> 
> 
> Le lundi 18 f?vrier 2013 ? 12:22 +0100, Milan Bouchet-Valat a ?crit :
>> Hi!
>> 
>> The nobs() method for glm objects always returns the number of cases
>> with non-null weights in the data, which does not correspond to the
>> number of observations for Poisson regression/log-linear models, i.e.
>> when family="poisson" or family="quasipoisson".
>> 
>> This sounds dangerous since nobs() is, as the documentation states,
>> primarily aimed at computing the Bayesian information criterion. Raftery
>> (1995:20) warned against this:
>>> What should n be? Once again, it is best to use the actual number of
>>> individuals, i.e. the sum of the cell counts, and not the number of
>>> cells (Raftery, 1986a).
>> 
>> Is there a reason why this should not/cannot be done that way?
>> 
>> This behavior can be reproduced with with R 3.0.0 from SVN, using the
>> example from ?glm:
>> counts <- c(18,17,15,20,10,20,25,13,12)
>> outcome <- gl(3,1,9)
>> treatment <- gl(3,3)
>> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
>> nobs(glm.D93)
>> # 9 == length(counts)
>> # Should be 150 == sum(counts)
>> 
>> FWIW, stats:::nobs.glm is currently defined as:
>> nobs.glm <- function (object, ...) 
>>    if (!is.null(w <- object$prior.weights)) sum(w != 0) else length(object$residuals)
>> 
>> 
>> Thanks!
>> 
>> 
>> Raftery, Adrian E. 1995. ?Bayesian Model Selection in Social Research.?
>> Sociological methodology 25:111?96.
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From nalimilan at club.fr  Wed Feb 27 21:55:57 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 27 Feb 2013 21:55:57 +0100
Subject: [Rd] nobs() with glm(family="poisson")
In-Reply-To: <CDF566D6-1023-48D4-BC5C-8714D46FF350@gmail.com>
References: <1361186543.2067.24.camel@milan.ined.fr>
	<1361990811.1726.47.camel@milan>
	<CDF566D6-1023-48D4-BC5C-8714D46FF350@gmail.com>
Message-ID: <1361998557.1726.73.camel@milan>

Thanks for the (critical, indeed) answer!

Le mercredi 27 f?vrier 2013 ? 20:48 +0100, peter dalgaard a ?crit :
> On Feb 27, 2013, at 19:46 , Milan Bouchet-Valat wrote:
> 
> > I cannot believes nobody cares about this -- or I'm completely wrong and
> > in that case everybody should rush to put the shame on me... :-p
> 
> Well, nobs() is the number of observations. If you have 5 Poisson
> distributed counts, you have 5 observations.
Well, say that to the statistical offices that spend millions to survey
thousands of people with correct (but complex) sampling designs, they'll
be happy to know that the collected data only provides an information
equivalent to 5 independent outcomes. ;-)

> If the number of observations is not the right thing to use in some
> context, use the right thing instead. Changing the definition of
> nobs() surely leads to madness. 
It is common usage in the literature using log-linear models to report
the sum of counts as the number of observations. I think this indeed
makes sense, but I'm not particularly attached to the choice of words --
let's call it as you please.

The root issue is that nobs() was precisely introduced to be the basis
for the BIC() function, as ?nobs states explicitly:
>      Extract the number of ?observations? from a model fit.  This is
>      principally intended to be used in computing BIC (see ?AIC?)

So it's OK to say that the number of observations is the number of cells
(even if I think this is not very user-friendly), but then the
documentation is misleading, and the BIC() function returns incorrect
values for the very first example provided in ?glm.

> (I suppose that the fact that n is so obviously the wrong thing for
> one particularly well-digested family of distribution functions could
> be taken to indicate a generic weakness with the BIC.)
I'm sure we can agree on the fact that BIC has its weaknesses (and I'm
not the best person able to judge), but the point at stake is IMHO not
one of them. After all, usual statistics for the Poisson family, such as
deviance or residuals, are based on the sum of counts, not on the number
of cells, and nobody objects.

The fact that the AIC is perfectly integrated into S/R and BIC seems to
be merely an historical detail to me. Computing the AIC itself requires
glm.fit() to add twice the equivalent degrees of freedom to the value
returned by the family function, so why would an equivalent
special-casing of BIC be the sign of an intrinsic statistical
deficiency? Maybe the BIC is not a good indicator, but technical
arguments are somewhat secondary in that debate.


Of course, if BIC is a bad indicator, BIC() should probably be
discouraged in the documentation, and print a warning when the returned
value is known to be incorrect.


Regards

> > In the meantime, I have come up with an alternative way of fixing this:
> > when modeling count data, glm() could allow users to pass a table as the
> > data argument, and convert it to a data frame using
> > as.data.frame.table() instead of requiring the user to do it
> > beforehand[1]. This would become the recommended way of fitting models
> > for count data, and the fact that a table is passed could be used as the
> > sign that nobs() should return the sum of cell counts instead of the
> > number of rows in the data.frame.
> > 
> > 
> > Regards
> > 
> > 
> > 1: gnm already supports this pattern, with the additional advantage that
> > e.g. fitted(), predict(), residuals() and weights() return an object of
> > the same dimensions and dimnames as the original table.
> > 
> > 
> > Le lundi 18 f?vrier 2013 ? 12:22 +0100, Milan Bouchet-Valat a ?crit :
> >> Hi!
> >> 
> >> The nobs() method for glm objects always returns the number of cases
> >> with non-null weights in the data, which does not correspond to the
> >> number of observations for Poisson regression/log-linear models, i.e.
> >> when family="poisson" or family="quasipoisson".
> >> 
> >> This sounds dangerous since nobs() is, as the documentation states,
> >> primarily aimed at computing the Bayesian information criterion. Raftery
> >> (1995:20) warned against this:
> >>> What should n be? Once again, it is best to use the actual number of
> >>> individuals, i.e. the sum of the cell counts, and not the number of
> >>> cells (Raftery, 1986a).
> >> 
> >> Is there a reason why this should not/cannot be done that way?
> >> 
> >> This behavior can be reproduced with with R 3.0.0 from SVN, using the
> >> example from ?glm:
> >> counts <- c(18,17,15,20,10,20,25,13,12)
> >> outcome <- gl(3,1,9)
> >> treatment <- gl(3,3)
> >> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
> >> nobs(glm.D93)
> >> # 9 == length(counts)
> >> # Should be 150 == sum(counts)
> >> 
> >> FWIW, stats:::nobs.glm is currently defined as:
> >> nobs.glm <- function (object, ...) 
> >>    if (!is.null(w <- object$prior.weights)) sum(w != 0) else length(object$residuals)
> >> 
> >> 
> >> Thanks!
> >> 
> >> 
> >> Raftery, Adrian E. 1995. ?Bayesian Model Selection in Social Research.?
> >> Sociological methodology 25:111?96.
> >> 
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>


From smckinney at bccrc.ca  Wed Feb 27 23:26:10 2013
From: smckinney at bccrc.ca (Steven McKinney)
Date: Wed, 27 Feb 2013 14:26:10 -0800
Subject: [Rd] nobs() with glm(family="poisson")
In-Reply-To: <1361998557.1726.73.camel@milan>
References: <1361186543.2067.24.camel@milan.ined.fr>
	<1361990811.1726.47.camel@milan>
	<CDF566D6-1023-48D4-BC5C-8714D46FF350@gmail.com>
	<1361998557.1726.73.camel@milan>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0CB926AD92@crcmail4.BCCRC.CA>



> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Milan Bouchet-Valat
> Sent: February-27-13 12:56 PM
> To: peter dalgaard
> Cc: r-devel
> Subject: Re: [Rd] nobs() with glm(family="poisson")
> 
> Thanks for the (critical, indeed) answer!
> 
> Le mercredi 27 f?vrier 2013 ? 20:48 +0100, peter dalgaard a ?crit :
> > On Feb 27, 2013, at 19:46 , Milan Bouchet-Valat wrote:
> >
> > > I cannot believes nobody cares about this -- or I'm completely wrong
> and
> > > in that case everybody should rush to put the shame on me... :-p
> >
> > Well, nobs() is the number of observations. If you have 5 Poisson
> > distributed counts, you have 5 observations.
> Well, say that to the statistical offices that spend millions to survey
> thousands of people with correct (but complex) sampling designs, they'll
> be happy to know that the collected data only provides an information
> equivalent to 5 independent outcomes. ;-)

Milan:

It seems to me you are mixing up Binomial and Poisson situations,
and not assessing independence appropriately.

The above example discusses Bernoulli outcomes which are sometimes
aggregated into Binomial "cases" depending on the study design.
Now if the survey samples people in the same household or even
neighbourhood, those Bernoulli outcomes will not be independent
(hence clustered survey techniques) and summing the Binomial
denominators would not be appropriate, for the survey analysis or
for BIC calculations.  The "n" in the BIC calculation should
reflect independent observations.  If you knock on the same
door 1000 times and ask the person who they will vote for,
you do not have 1000 independent observations, even though
your Binomial denominator is 1000.

The example you show from ?glm is a Poisson example showing
9 independent Poisson counts.  If I count the number of cars
passing through an intersection during non-overlapping
one minute intervals (say 9 such intervals), then the number 
of observations I have is the number of non-overlapping 
one minute interval car count totals (e.g. the nine counts
c(18, 17, 15, 20, 10, 20, 25, 13, 12)), not the number of 
cars I saw in total.

A piece of software that adds things up can not know the
context from which the numbers were derived, so you have to
figure out the level of independence appropriate to your
study design and work out the BIC count accordingly.

Raftery alludes to this in a preceding section:

"When the data have been collected using a complex survey 
design with resulting weights, it is not yet clear what n 
should be, and this issue awaits further study.  However, 
it seems reasonable that if the model is based on an 
assumption of simple random sampling but the sampling 
design is less efficient, then n should be reduced to 
reflect the efficiency of the sampling design relative to 
simple random sampling."



Steven McKinney
Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre


> 
> > If the number of observations is not the right thing to use in some
> > context, use the right thing instead. Changing the definition of
> > nobs() surely leads to madness.
> It is common usage in the literature using log-linear models to report
> the sum of counts as the number of observations. I think this indeed
> makes sense, but I'm not particularly attached to the choice of words --
> let's call it as you please.
> 
> The root issue is that nobs() was precisely introduced to be the basis
> for the BIC() function, as ?nobs states explicitly:
> >      Extract the number of ?observations? from a model fit.  This is
> >      principally intended to be used in computing BIC (see ?AIC?)
> 
> So it's OK to say that the number of observations is the number of cells
> (even if I think this is not very user-friendly), but then the
> documentation is misleading, and the BIC() function returns incorrect
> values for the very first example provided in ?glm.
> 
> > (I suppose that the fact that n is so obviously the wrong thing for
> > one particularly well-digested family of distribution functions could
> > be taken to indicate a generic weakness with the BIC.)
> I'm sure we can agree on the fact that BIC has its weaknesses (and I'm
> not the best person able to judge), but the point at stake is IMHO not
> one of them. After all, usual statistics for the Poisson family, such as
> deviance or residuals, are based on the sum of counts, not on the number
> of cells, and nobody objects.
> 
> The fact that the AIC is perfectly integrated into S/R and BIC seems to
> be merely an historical detail to me. Computing the AIC itself requires
> glm.fit() to add twice the equivalent degrees of freedom to the value
> returned by the family function, so why would an equivalent
> special-casing of BIC be the sign of an intrinsic statistical
> deficiency? Maybe the BIC is not a good indicator, but technical
> arguments are somewhat secondary in that debate.
> 
> 
> Of course, if BIC is a bad indicator, BIC() should probably be
> discouraged in the documentation, and print a warning when the returned
> value is known to be incorrect.
> 
> 
> Regards
> 
> > > In the meantime, I have come up with an alternative way of fixing this:
> > > when modeling count data, glm() could allow users to pass a table as
> the
> > > data argument, and convert it to a data frame using
> > > as.data.frame.table() instead of requiring the user to do it
> > > beforehand[1]. This would become the recommended way of fitting models
> > > for count data, and the fact that a table is passed could be used as
> the
> > > sign that nobs() should return the sum of cell counts instead of the
> > > number of rows in the data.frame.
> > >
> > >
> > > Regards
> > >
> > >
> > > 1: gnm already supports this pattern, with the additional advantage
> that
> > > e.g. fitted(), predict(), residuals() and weights() return an object of
> > > the same dimensions and dimnames as the original table.
> > >
> > >
> > > Le lundi 18 f?vrier 2013 ? 12:22 +0100, Milan Bouchet-Valat a ?crit :
> > >> Hi!
> > >>
> > >> The nobs() method for glm objects always returns the number of cases
> > >> with non-null weights in the data, which does not correspond to the
> > >> number of observations for Poisson regression/log-linear models, i.e.
> > >> when family="poisson" or family="quasipoisson".
> > >>
> > >> This sounds dangerous since nobs() is, as the documentation states,
> > >> primarily aimed at computing the Bayesian information criterion.
> Raftery
> > >> (1995:20) warned against this:
> > >>> What should n be? Once again, it is best to use the actual number of
> > >>> individuals, i.e. the sum of the cell counts, and not the number of
> > >>> cells (Raftery, 1986a).
> > >>
> > >> Is there a reason why this should not/cannot be done that way?
> > >>
> > >> This behavior can be reproduced with with R 3.0.0 from SVN, using the
> > >> example from ?glm:
> > >> counts <- c(18,17,15,20,10,20,25,13,12)
> > >> outcome <- gl(3,1,9)
> > >> treatment <- gl(3,3)
> > >> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
> > >> nobs(glm.D93)
> > >> # 9 == length(counts)
> > >> # Should be 150 == sum(counts)
> > >>
> > >> FWIW, stats:::nobs.glm is currently defined as:
> > >> nobs.glm <- function (object, ...)
> > >>    if (!is.null(w <- object$prior.weights)) sum(w != 0) else
> length(object$residuals)
> > >>
> > >>
> > >> Thanks!
> > >>
> > >>
> > >> Raftery, Adrian E. 1995. ?Bayesian Model Selection in Social
> Research.?
> > >> Sociological methodology 25:111?96.
> > >>
> > >> ______________________________________________
> > >> R-devel at r-project.org mailing list
> > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



From nalimilan at club.fr  Wed Feb 27 23:58:40 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Wed, 27 Feb 2013 23:58:40 +0100
Subject: [Rd] nobs() with glm(family="poisson")
In-Reply-To: <DCE81E14EB74504B971DAD4D2DB0356B0CB926AD92@crcmail4.BCCRC.CA>
References: <1361186543.2067.24.camel@milan.ined.fr>
	<1361990811.1726.47.camel@milan>
	<CDF566D6-1023-48D4-BC5C-8714D46FF350@gmail.com>
	<1361998557.1726.73.camel@milan>
	<DCE81E14EB74504B971DAD4D2DB0356B0CB926AD92@crcmail4.BCCRC.CA>
Message-ID: <1362005920.1726.95.camel@milan>

Le mercredi 27 f?vrier 2013 ? 14:26 -0800, Steven McKinney a ?crit :
> 
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> > On Behalf Of Milan Bouchet-Valat
> > Sent: February-27-13 12:56 PM
> > To: peter dalgaard
> > Cc: r-devel
> > Subject: Re: [Rd] nobs() with glm(family="poisson")
> > 
> > Thanks for the (critical, indeed) answer!
> > 
> > Le mercredi 27 f?vrier 2013 ? 20:48 +0100, peter dalgaard a ?crit :
> > > On Feb 27, 2013, at 19:46 , Milan Bouchet-Valat wrote:
> > >
> > > > I cannot believes nobody cares about this -- or I'm completely wrong
> > and
> > > > in that case everybody should rush to put the shame on me... :-p
> > >
> > > Well, nobs() is the number of observations. If you have 5 Poisson
> > > distributed counts, you have 5 observations.
> > Well, say that to the statistical offices that spend millions to survey
> > thousands of people with correct (but complex) sampling designs, they'll
> > be happy to know that the collected data only provides an information
> > equivalent to 5 independent outcomes. ;-)
> 
> Milan:
> 
> It seems to me you are mixing up Binomial and Poisson situations,
> and not assessing independence appropriately.
> 
> The above example discusses Bernoulli outcomes which are sometimes
> aggregated into Binomial "cases" depending on the study design.
> Now if the survey samples people in the same household or even
> neighbourhood, those Bernoulli outcomes will not be independent
> (hence clustered survey techniques) and summing the Binomial
> denominators would not be appropriate, for the survey analysis or
> for BIC calculations.  The "n" in the BIC calculation should
> reflect independent observations.  If you knock on the same
> door 1000 times and ask the person who they will vote for,
> you do not have 1000 independent observations, even though
> your Binomial denominator is 1000.
My intention was not to introduce the issue of survey designs into the
discussion, but merely to make the point that in surveys, counts are
usually *to some extent at least* independent observations, even when
clustering is present, and that the fact that different people are asked
and that each answer costs money is the best indication of that. Anyway,
BIC does not apply if we are not assuming that the data comes from a
simple random sample, so let's leave this complication aside.

> The example you show from ?glm is a Poisson example showing
> 9 independent Poisson counts.  If I count the number of cars
> passing through an intersection during non-overlapping
> one minute intervals (say 9 such intervals), then the number 
> of observations I have is the number of non-overlapping 
> one minute interval car count totals (e.g. the nine counts
> c(18, 17, 15, 20, 10, 20, 25, 13, 12)), not the number of 
> cars I saw in total.
Interesting. Indeed in the observation setting you describe, 9 is AFAICT
the correct number of observations. Is this kind of data commonly fitted
using glm()?

Do you happen to possess a copy of the book where the ?glm example comes
from? There are not many of them here in France so I cannot consult it
easily. It seems to me that in the context of a randomized controlled
trial, the number of independent observations is the number of subjects,
not the number of groups. And thus, BIC() would still return a wrong
value for the ?glm example.

> A piece of software that adds things up can not know the
> context from which the numbers were derived, so you have to
> figure out the level of independence appropriate to your
> study design and work out the BIC count accordingly.
This is a strong argument indeed. It would mean that BIC() is at best a
function of very limited use, or even a dangerous one, unless one can
safely assume that the case were the number of observations equals the
number of rows in the data is by far the most common one. I am biased
due to my use of log-linear models, but I doubt this is the case. Is it
(I might perfectly be wrong)?

> Raftery alludes to this in a preceding section:
> 
> "When the data have been collected using a complex survey 
> design with resulting weights, it is not yet clear what n 
> should be, and this issue awaits further study.  However, 
> it seems reasonable that if the model is based on an 
> assumption of simple random sampling but the sampling 
> design is less efficient, then n should be reduced to 
> reflect the efficiency of the sampling design relative to 
> simple random sampling."
I think Raftery had in mind surveys in which the assumption of
independence between observations (counts, not rows) does not hold, but
where it is still the reference from which the sample deviates (lower
"efficiency"). In this case, the number of cells/rows by no means a good
measure of the number of observations either -- but as I said BIC is
usually considered as not defined in this case.


Thanks for sharing your remarks.


From pdalgd at gmail.com  Thu Feb 28 00:46:46 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 28 Feb 2013 00:46:46 +0100
Subject: [Rd] nobs() with glm(family="poisson")
In-Reply-To: <1361998557.1726.73.camel@milan>
References: <1361186543.2067.24.camel@milan.ined.fr>
	<1361990811.1726.47.camel@milan>
	<CDF566D6-1023-48D4-BC5C-8714D46FF350@gmail.com>
	<1361998557.1726.73.camel@milan>
Message-ID: <C23DFEF5-948C-4E0E-830C-1920241165A7@gmail.com>


On Feb 27, 2013, at 21:55 , Milan Bouchet-Valat wrote:

> Thanks for the (critical, indeed) answer!
> 
> Le mercredi 27 f?vrier 2013 ? 20:48 +0100, peter dalgaard a ?crit :
>> On Feb 27, 2013, at 19:46 , Milan Bouchet-Valat wrote:
>> 
>>> I cannot believes nobody cares about this -- or I'm completely wrong and
>>> in that case everybody should rush to put the shame on me... :-p
>> 
>> Well, nobs() is the number of observations. If you have 5 Poisson
>> distributed counts, you have 5 observations.
> Well, say that to the statistical offices that spend millions to survey
> thousands of people with correct (but complex) sampling designs, they'll
> be happy to know that the collected data only provides an information
> equivalent to 5 independent outcomes. ;-)

My objection is mainly technical/conceptual: Suppose 5 Poisson counts, say of the number of defaults in 5 counties, are not 5 observations. Then how many observations are 5 negative binomial counts, say of white blood cell counts in 5 patients? A generic function called nobs() should mork similarly across a range of fitted models and it would be inconsistent if it suddenly did something different in a single distribution.

> 
>> If the number of observations is not the right thing to use in some
>> context, use the right thing instead. Changing the definition of
>> nobs() surely leads to madness. 
> It is common usage in the literature using log-linear models to report
> the sum of counts as the number of observations. I think this indeed
> makes sense, but I'm not particularly attached to the choice of words --
> let's call it as you please.

It makes OK sense in isolation, I suppose. Especially if you interpret the table as multinomial counts rather than Poisson ones. If you interpret the total count as a Poisson variable, all cell counts become independent Poisson variables. However, the issue here is about coherent and consistent software design, and that goes beyond dealing with contingency tables.

> 
> The root issue is that nobs() was precisely introduced to be the basis
> for the BIC() function, as ?nobs states explicitly:
>>     Extract the number of ?observations? from a model fit.  This is
>>     principally intended to be used in computing BIC (see ?AIC?)
> 

I think it is unfortunate to specify a function in terms of what it is used for. It should be specified in terms of what it does.

> So it's OK to say that the number of observations is the number of cells
> (even if I think this is not very user-friendly), but then the
> documentation is misleading, and the BIC() function returns incorrect
> values for the very first example provided in ?glm.
> 
>> (I suppose that the fact that n is so obviously the wrong thing for
>> one particularly well-digested family of distribution functions could
>> be taken to indicate a generic weakness with the BIC.)
> I'm sure we can agree on the fact that BIC has its weaknesses (and I'm
> not the best person able to judge), but the point at stake is IMHO not
> one of them. After all, usual statistics for the Poisson family, such as
> deviance or residuals, are based on the sum of counts, not on the number
> of cells, and nobody objects.

At least for the deviance, that's just untrue. The deviance is zero for a saturated table. If some cells are split, the deviance becomes nonzero.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From jfox at mcmaster.ca  Thu Feb 28 00:59:01 2013
From: jfox at mcmaster.ca (John Fox)
Date: Wed, 27 Feb 2013 18:59:01 -0500
Subject: [Rd] nobs() with glm(family="poisson")
In-Reply-To: <1362005920.1726.95.camel@milan>
References: <1361186543.2067.24.camel@milan.ined.fr>	<1361990811.1726.47.camel@milan>	<CDF566D6-1023-48D4-BC5C-8714D46FF350@gmail.com>	<1361998557.1726.73.camel@milan>	<DCE81E14EB74504B971DAD4D2DB0356B0CB926AD92@crcmail4.BCCRC.CA>
	<1362005920.1726.95.camel@milan>
Message-ID: <004001ce1546$6ae21ae0$40a650a0$@mcmaster.ca>

Dear Milan and Steven,

At the risk of muddying the water further, I think that the potential confusion here is that Poisson GLMs are applied in two formally equivalent but substantively different situations: (1) where the counts are cells in a contingency table, in which case the Poisson GLM is used to fit an equivalent loglinear association model to the table; and (2) where the counts are observations on a non-negative integer response -- what's often called "Poisson regression." In the first case, but not the second, it makes sense to think of the sum of the counts as the natural sample size. I don't think that one can expect GLM software to distinguish these cases.

Best,
 John

> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org] On Behalf Of Milan Bouchet-Valat
> Sent: Wednesday, February 27, 2013 5:59 PM
> To: Steven McKinney
> Cc: r-devel
> Subject: Re: [Rd] nobs() with glm(family="poisson")
> 
> Le mercredi 27 f?vrier 2013 ? 14:26 -0800, Steven McKinney a ?crit :
> >
> > > -----Original Message-----
> > > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> project.org]
> > > On Behalf Of Milan Bouchet-Valat
> > > Sent: February-27-13 12:56 PM
> > > To: peter dalgaard
> > > Cc: r-devel
> > > Subject: Re: [Rd] nobs() with glm(family="poisson")
> > >
> > > Thanks for the (critical, indeed) answer!
> > >
> > > Le mercredi 27 f?vrier 2013 ? 20:48 +0100, peter dalgaard a ?crit :
> > > > On Feb 27, 2013, at 19:46 , Milan Bouchet-Valat wrote:
> > > >
> > > > > I cannot believes nobody cares about this -- or I'm completely
> wrong
> > > and
> > > > > in that case everybody should rush to put the shame on me... :-
> p
> > > >
> > > > Well, nobs() is the number of observations. If you have 5 Poisson
> > > > distributed counts, you have 5 observations.
> > > Well, say that to the statistical offices that spend millions to
> survey
> > > thousands of people with correct (but complex) sampling designs,
> they'll
> > > be happy to know that the collected data only provides an
> information
> > > equivalent to 5 independent outcomes. ;-)
> >
> > Milan:
> >
> > It seems to me you are mixing up Binomial and Poisson situations,
> > and not assessing independence appropriately.
> >
> > The above example discusses Bernoulli outcomes which are sometimes
> > aggregated into Binomial "cases" depending on the study design.
> > Now if the survey samples people in the same household or even
> > neighbourhood, those Bernoulli outcomes will not be independent
> > (hence clustered survey techniques) and summing the Binomial
> > denominators would not be appropriate, for the survey analysis or
> > for BIC calculations.  The "n" in the BIC calculation should
> > reflect independent observations.  If you knock on the same
> > door 1000 times and ask the person who they will vote for,
> > you do not have 1000 independent observations, even though
> > your Binomial denominator is 1000.
> My intention was not to introduce the issue of survey designs into the
> discussion, but merely to make the point that in surveys, counts are
> usually *to some extent at least* independent observations, even when
> clustering is present, and that the fact that different people are
> asked
> and that each answer costs money is the best indication of that.
> Anyway,
> BIC does not apply if we are not assuming that the data comes from a
> simple random sample, so let's leave this complication aside.
> 
> > The example you show from ?glm is a Poisson example showing
> > 9 independent Poisson counts.  If I count the number of cars
> > passing through an intersection during non-overlapping
> > one minute intervals (say 9 such intervals), then the number
> > of observations I have is the number of non-overlapping
> > one minute interval car count totals (e.g. the nine counts
> > c(18, 17, 15, 20, 10, 20, 25, 13, 12)), not the number of
> > cars I saw in total.
> Interesting. Indeed in the observation setting you describe, 9 is
> AFAICT
> the correct number of observations. Is this kind of data commonly
> fitted
> using glm()?
> 
> Do you happen to possess a copy of the book where the ?glm example
> comes
> from? There are not many of them here in France so I cannot consult it
> easily. It seems to me that in the context of a randomized controlled
> trial, the number of independent observations is the number of
> subjects,
> not the number of groups. And thus, BIC() would still return a wrong
> value for the ?glm example.
> 
> > A piece of software that adds things up can not know the
> > context from which the numbers were derived, so you have to
> > figure out the level of independence appropriate to your
> > study design and work out the BIC count accordingly.
> This is a strong argument indeed. It would mean that BIC() is at best a
> function of very limited use, or even a dangerous one, unless one can
> safely assume that the case were the number of observations equals the
> number of rows in the data is by far the most common one. I am biased
> due to my use of log-linear models, but I doubt this is the case. Is it
> (I might perfectly be wrong)?
> 
> > Raftery alludes to this in a preceding section:
> >
> > "When the data have been collected using a complex survey
> > design with resulting weights, it is not yet clear what n
> > should be, and this issue awaits further study.  However,
> > it seems reasonable that if the model is based on an
> > assumption of simple random sampling but the sampling
> > design is less efficient, then n should be reduced to
> > reflect the efficiency of the sampling design relative to
> > simple random sampling."
> I think Raftery had in mind surveys in which the assumption of
> independence between observations (counts, not rows) does not hold, but
> where it is still the reference from which the sample deviates (lower
> "efficiency"). In this case, the number of cells/rows by no means a
> good
> measure of the number of observations either -- but as I said BIC is
> usually considered as not defined in this case.
> 
> 
> Thanks for sharing your remarks.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pburns at pburns.seanet.com  Thu Feb 28 10:57:42 2013
From: pburns at pburns.seanet.com (Patrick Burns)
Date: Thu, 28 Feb 2013 09:57:42 +0000
Subject: [Rd] Fortune?
Message-ID: <512F2A16.1020702@pburns.seanet.com>

I think the rule is that you can do anything as long as you don't 
complain. If you want to complain, you must follow the instructions.

-- Jari Oksanen  in

Re: [Rd] Keeping up to date with R-devel


-- 
Patrick Burns
pburns at pburns.seanet.com
twitter: @burnsstat @portfolioprobe
http://www.portfolioprobe.com/blog
http://www.burns-stat.com
(home of:
  'Impatient R'
  'The R Inferno'
  'Tao Te Programming')


From jorismeys at gmail.com  Thu Feb 28 11:00:45 2013
From: jorismeys at gmail.com (Joris Meys)
Date: Thu, 28 Feb 2013 11:00:45 +0100
Subject: [Rd] Fortune?
In-Reply-To: <512F2A16.1020702@pburns.seanet.com>
References: <512F2A16.1020702@pburns.seanet.com>
Message-ID: <CAO1zAVb9+=PfQhbCQA_AQOh5pCuqhqy2D=5FHiV2t543EwkDEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130228/66d7e945/attachment.pl>

From James.Hawley at oicr.on.ca  Wed Feb 27 22:04:24 2013
From: James.Hawley at oicr.on.ca (James Hawley)
Date: Wed, 27 Feb 2013 21:04:24 +0000
Subject: [Rd] Bordered legend icons and Text in plots
Message-ID: <710FA29788E7F548A956267990D5103D1F1A1A@exmb2.ad.oicr.on.ca>

Hello,

My colleagues and I use lattice for a variety of different purposes, and we came across a couple issues involving legend.R and update.trellis.R:
1. When using xyplot, the shapes in the plots are able to have borders and fill colours, but not so in the legend. I created a short script to isolate the problem (see legend-icons.R and Nofill.png).
   After some tracing through the source code, it turned out that the "fill" argument in "key" was being dropped by the line
       pars <- pars[!sapply(pars, is.null)] # remove NULL components (lines 302 and 322)
   As in key$fill was NULL when passed. The issue seems to be from the function process.key(). The output list does not return "fill" as one of its arguments, and was dropped whenever "key" was processed.
2. Giving multiple grobs to the 'inside' part of 'legend' only uses the first grob if you use update.trellis to provide them. This is caused by the way modifyList handles list elements with the same name (which is called by update.trellis), and can be worked around (see update.trellis.R).
   The issue without modification to your code can be seen in Notext.png (created by legend-text.R). Multiple grobs could still be given to 'inside' via the other methods (e.g. xyplot and the like).

I've made a few modifications to the source code and uploaded them here as well (legend.R and update.trellis.R).
For Issue 1, I added the line "fill = fill," to the output list of process.key(), and this seems to have fixed the issue (see legend.R line 216 and Fill.png for results).
For Issue 2 there is a workaround in update.trellis.R lines 267-275 (see Text.png for the results).

James Hawley
Student

Ontario Institute for Cancer Research
MaRS Centre, South Tower
101 College Street, Suite 800
Toronto, Ontario, Canada M5G 0A3

Toll-free: 1-866-678-6427
Twitter: @OICR_news
www.oicr.on.ca

This message and any attachments may contain confidential and/or privileged information for the sole use of the intended recipient. Any review or distribution by anyone other than the person for whom it was originally intended is strictly prohibited. If you have received this message in error, please contact the sender and delete all copies. Opinions, conclusions or other information contained in this message may not be that of the organization.

From ravi.varadhan at jhu.edu  Wed Feb 27 23:56:40 2013
From: ravi.varadhan at jhu.edu (Ravi Varadhan)
Date: Wed, 27 Feb 2013 22:56:40 +0000
Subject: [Rd] nobs() with glm(family="poisson")
In-Reply-To: <DCE81E14EB74504B971DAD4D2DB0356B0CB926AD92@crcmail4.BCCRC.CA>
References: <1361186543.2067.24.camel@milan.ined.fr>
	<1361990811.1726.47.camel@milan>
	<CDF566D6-1023-48D4-BC5C-8714D46FF350@gmail.com>
	<1361998557.1726.73.camel@milan>
	<DCE81E14EB74504B971DAD4D2DB0356B0CB926AD92@crcmail4.BCCRC.CA>
Message-ID: <2F9EA67EF9AE1C48A147CB41BE2E15C3384072@DOM-EB-MAIL2.win.ad.jhu.edu>

This is getting further away from typical R-devel issues, but let me add another perspective:  the `n' in BIC reflects the rate at which the information in the log-likelihood grows.  

Ravi

-----Original Message-----
From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org] On Behalf Of Steven McKinney
Sent: Wednesday, February 27, 2013 5:26 PM
To: 'Milan Bouchet-Valat'
Cc: r-devel
Subject: Re: [Rd] nobs() with glm(family="poisson")



> -----Original Message-----
> From: r-devel-bounces at r-project.org 
> [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Milan Bouchet-Valat
> Sent: February-27-13 12:56 PM
> To: peter dalgaard
> Cc: r-devel
> Subject: Re: [Rd] nobs() with glm(family="poisson")
> 
> Thanks for the (critical, indeed) answer!
> 
> Le mercredi 27 f?vrier 2013 ? 20:48 +0100, peter dalgaard a ?crit :
> > On Feb 27, 2013, at 19:46 , Milan Bouchet-Valat wrote:
> >
> > > I cannot believes nobody cares about this -- or I'm completely 
> > > wrong
> and
> > > in that case everybody should rush to put the shame on me... :-p
> >
> > Well, nobs() is the number of observations. If you have 5 Poisson 
> > distributed counts, you have 5 observations.
> Well, say that to the statistical offices that spend millions to 
> survey thousands of people with correct (but complex) sampling 
> designs, they'll be happy to know that the collected data only 
> provides an information equivalent to 5 independent outcomes. ;-)

Milan:

It seems to me you are mixing up Binomial and Poisson situations, and not assessing independence appropriately.

The above example discusses Bernoulli outcomes which are sometimes aggregated into Binomial "cases" depending on the study design.
Now if the survey samples people in the same household or even neighbourhood, those Bernoulli outcomes will not be independent (hence clustered survey techniques) and summing the Binomial denominators would not be appropriate, for the survey analysis or for BIC calculations.  The "n" in the BIC calculation should reflect independent observations.  If you knock on the same door 1000 times and ask the person who they will vote for, you do not have 1000 independent observations, even though your Binomial denominator is 1000.

The example you show from ?glm is a Poisson example showing
9 independent Poisson counts.  If I count the number of cars passing through an intersection during non-overlapping one minute intervals (say 9 such intervals), then the number of observations I have is the number of non-overlapping one minute interval car count totals (e.g. the nine counts c(18, 17, 15, 20, 10, 20, 25, 13, 12)), not the number of cars I saw in total.

A piece of software that adds things up can not know the context from which the numbers were derived, so you have to figure out the level of independence appropriate to your study design and work out the BIC count accordingly.

Raftery alludes to this in a preceding section:

"When the data have been collected using a complex survey design with resulting weights, it is not yet clear what n should be, and this issue awaits further study.  However, it seems reasonable that if the model is based on an assumption of simple random sampling but the sampling design is less efficient, then n should be reduced to reflect the efficiency of the sampling design relative to simple random sampling."



Steven McKinney
Statistician
Molecular Oncology and Breast Cancer Program British Columbia Cancer Research Centre


> 
> > If the number of observations is not the right thing to use in some 
> > context, use the right thing instead. Changing the definition of
> > nobs() surely leads to madness.
> It is common usage in the literature using log-linear models to report 
> the sum of counts as the number of observations. I think this indeed 
> makes sense, but I'm not particularly attached to the choice of words 
> -- let's call it as you please.
> 
> The root issue is that nobs() was precisely introduced to be the basis 
> for the BIC() function, as ?nobs states explicitly:
> >      Extract the number of ?observations? from a model fit.  This is
> >      principally intended to be used in computing BIC (see ?AIC?)
> 
> So it's OK to say that the number of observations is the number of 
> cells (even if I think this is not very user-friendly), but then the 
> documentation is misleading, and the BIC() function returns incorrect 
> values for the very first example provided in ?glm.
> 
> > (I suppose that the fact that n is so obviously the wrong thing for 
> > one particularly well-digested family of distribution functions 
> > could be taken to indicate a generic weakness with the BIC.)
> I'm sure we can agree on the fact that BIC has its weaknesses (and I'm 
> not the best person able to judge), but the point at stake is IMHO not 
> one of them. After all, usual statistics for the Poisson family, such 
> as deviance or residuals, are based on the sum of counts, not on the 
> number of cells, and nobody objects.
> 
> The fact that the AIC is perfectly integrated into S/R and BIC seems 
> to be merely an historical detail to me. Computing the AIC itself 
> requires
> glm.fit() to add twice the equivalent degrees of freedom to the value 
> returned by the family function, so why would an equivalent 
> special-casing of BIC be the sign of an intrinsic statistical 
> deficiency? Maybe the BIC is not a good indicator, but technical 
> arguments are somewhat secondary in that debate.
> 
> 
> Of course, if BIC is a bad indicator, BIC() should probably be 
> discouraged in the documentation, and print a warning when the 
> returned value is known to be incorrect.
> 
> 
> Regards
> 
> > > In the meantime, I have come up with an alternative way of fixing this:
> > > when modeling count data, glm() could allow users to pass a table 
> > > as
> the
> > > data argument, and convert it to a data frame using
> > > as.data.frame.table() instead of requiring the user to do it 
> > > beforehand[1]. This would become the recommended way of fitting 
> > > models for count data, and the fact that a table is passed could 
> > > be used as
> the
> > > sign that nobs() should return the sum of cell counts instead of 
> > > the number of rows in the data.frame.
> > >
> > >
> > > Regards
> > >
> > >
> > > 1: gnm already supports this pattern, with the additional 
> > > advantage
> that
> > > e.g. fitted(), predict(), residuals() and weights() return an 
> > > object of the same dimensions and dimnames as the original table.
> > >
> > >
> > > Le lundi 18 f?vrier 2013 ? 12:22 +0100, Milan Bouchet-Valat a ?crit :
> > >> Hi!
> > >>
> > >> The nobs() method for glm objects always returns the number of 
> > >> cases with non-null weights in the data, which does not 
> > >> correspond to the number of observations for Poisson regression/log-linear models, i.e.
> > >> when family="poisson" or family="quasipoisson".
> > >>
> > >> This sounds dangerous since nobs() is, as the documentation 
> > >> states, primarily aimed at computing the Bayesian information criterion.
> Raftery
> > >> (1995:20) warned against this:
> > >>> What should n be? Once again, it is best to use the actual 
> > >>> number of individuals, i.e. the sum of the cell counts, and not 
> > >>> the number of cells (Raftery, 1986a).
> > >>
> > >> Is there a reason why this should not/cannot be done that way?
> > >>
> > >> This behavior can be reproduced with with R 3.0.0 from SVN, using 
> > >> the example from ?glm:
> > >> counts <- c(18,17,15,20,10,20,25,13,12) outcome <- gl(3,1,9) 
> > >> treatment <- gl(3,3)
> > >> glm.D93 <- glm(counts ~ outcome + treatment, family = poisson())
> > >> nobs(glm.D93)
> > >> # 9 == length(counts)
> > >> # Should be 150 == sum(counts)
> > >>
> > >> FWIW, stats:::nobs.glm is currently defined as:
> > >> nobs.glm <- function (object, ...)
> > >>    if (!is.null(w <- object$prior.weights)) sum(w != 0) else
> length(object$residuals)
> > >>
> > >>
> > >> Thanks!
> > >>
> > >>
> > >> Raftery, Adrian E. 1995. ?Bayesian Model Selection in Social
> Research.?
> > >> Sociological methodology 25:111?96.
> > >>
> > >> ______________________________________________
> > >> R-devel at r-project.org mailing list 
> > >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list 
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From Achim.Zeileis at uibk.ac.at  Thu Feb 28 20:15:28 2013
From: Achim.Zeileis at uibk.ac.at (Achim Zeileis)
Date: Thu, 28 Feb 2013 20:15:28 +0100 (CET)
Subject: [Rd] Fortune?
In-Reply-To: <CAO1zAVb9+=PfQhbCQA_AQOh5pCuqhqy2D=5FHiV2t543EwkDEg@mail.gmail.com>
References: <512F2A16.1020702@pburns.seanet.com>
	<CAO1zAVb9+=PfQhbCQA_AQOh5pCuqhqy2D=5FHiV2t543EwkDEg@mail.gmail.com>
Message-ID: <alpine.DEB.2.02.1302282015050.5569@paninaro.uibk.ac.at>

On Thu, 28 Feb 2013, Joris Meys wrote:

> Has my vote!

Mine as well :-)
Added to the devel-version on R-Forge now.

thx,
Z

> On Thu, Feb 28, 2013 at 10:57 AM, Patrick Burns <pburns at pburns.seanet.com>wrote:
>
>> I think the rule is that you can do anything as long as you don't
>> complain. If you want to complain, you must follow the instructions.
>>
>> -- Jari Oksanen  in
>>
>> Re: [Rd] Keeping up to date with R-devel
>>
>>
>> --
>> Patrick Burns
>> pburns at pburns.seanet.com
>> twitter: @burnsstat @portfolioprobe
>> http://www.portfolioprobe.com/**blog <http://www.portfolioprobe.com/blog>
>> http://www.burns-stat.com
>> (home of:
>>  'Impatient R'
>>  'The R Inferno'
>>  'Tao Te Programming')
>>
>> ______________________________**________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/**listinfo/r-devel<https://stat.ethz.ch/mailman/listinfo/r-devel>
>>
>
>
>
> -- 
> Joris Meys
> Statistical consultant
>
> Ghent University
> Faculty of Bioscience Engineering
> Department of Mathematical Modelling, Statistics and Bio-Informatics
>
> tel : +32 9 264 59 87
> Joris.Meys at Ugent.be
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From tlumley at uw.edu  Thu Feb 28 21:21:57 2013
From: tlumley at uw.edu (Thomas Lumley)
Date: Fri, 1 Mar 2013 09:21:57 +1300
Subject: [Rd] S3 generics in packages: default method
Message-ID: <CAJ55+d+DRyxFz+Tioaz9D=c5aMsXLZkZbTrx+AJOvks=OWWUjA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130301/71a2484c/attachment.pl>

From ggrothendieck at gmail.com  Thu Feb 28 21:44:03 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 28 Feb 2013 15:44:03 -0500
Subject: [Rd] Return value of S4 validity function
Message-ID: <CAP01uRkz=jagOQf_7V3zKw5cBvFKWDUgJ+jiNAsv1i9eMVgxMg@mail.gmail.com>

This issues a message about a needing to be non-negative as expected:

setClass("A",
  representation = list(a = "numeric"),
  prototype = list(a = 0),
  validity = function(object) {
    out <- if (object at a < 0) "a must be non-negative"
    if (is.null(out)) TRUE else out ##
  })
new("A", a = -1)

but it also works if the ## line is omitted so it appears that one can
use NULL in place of TRUE.  I wonder if the use of NULL as an
alternative to TRUE could be officially supported as it would allow
one to write validity methods in a more concise manner.  It appears
that this would only require a change to the documentation.

--
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ggrothendieck at gmail.com  Thu Feb 28 21:46:17 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Thu, 28 Feb 2013 15:46:17 -0500
Subject: [Rd] Return value of S4 validity function
In-Reply-To: <CAP01uRkz=jagOQf_7V3zKw5cBvFKWDUgJ+jiNAsv1i9eMVgxMg@mail.gmail.com>
References: <CAP01uRkz=jagOQf_7V3zKw5cBvFKWDUgJ+jiNAsv1i9eMVgxMg@mail.gmail.com>
Message-ID: <CAP01uRmRa8tRtJCtuym8RufT16eAnXu2C6WAsOnQY2tBBD2j9A@mail.gmail.com>

On Thu, Feb 28, 2013 at 3:44 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> This issues a message about a needing to be non-negative as expected:
>
> setClass("A",
>   representation = list(a = "numeric"),
>   prototype = list(a = 0),
>   validity = function(object) {
>     out <- if (object at a < 0) "a must be non-negative"
>     if (is.null(out)) TRUE else out ##
>   })
> new("A", a = -1)
>
> but it also works if the ## line is omitted so it appears that one can
> use NULL in place of TRUE.  I wonder if the use of NULL as an
> alternative to TRUE could be officially supported as it would allow
> one to write validity methods in a more concise manner.  It appears
> that this would only require a change to the documentation.
>

Pressed return too quickly.  This should have continued on to give this example:

new("A")

with and without the ## line both of which work since it appears that
NULL can be used in place of TRUE.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From tlumley at uw.edu  Thu Feb 28 21:51:30 2013
From: tlumley at uw.edu (Thomas Lumley)
Date: Fri, 1 Mar 2013 09:51:30 +1300
Subject: [Rd] nobs() with glm(family="poisson")
In-Reply-To: <2F9EA67EF9AE1C48A147CB41BE2E15C3384072@DOM-EB-MAIL2.win.ad.jhu.edu>
References: <1361186543.2067.24.camel@milan.ined.fr>
	<1361990811.1726.47.camel@milan>
	<CDF566D6-1023-48D4-BC5C-8714D46FF350@gmail.com>
	<1361998557.1726.73.camel@milan>
	<DCE81E14EB74504B971DAD4D2DB0356B0CB926AD92@crcmail4.BCCRC.CA>
	<2F9EA67EF9AE1C48A147CB41BE2E15C3384072@DOM-EB-MAIL2.win.ad.jhu.edu>
Message-ID: <CAJ55+dJRzu33ne0-gT05wqNwPb33JssrDFZ8yZe=sOb9xmNrUw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20130301/e32d7599/attachment.pl>

From nalimilan at club.fr  Thu Feb 28 22:59:43 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Thu, 28 Feb 2013 22:59:43 +0100
Subject: [Rd] nobs() with glm(family="poisson")
In-Reply-To: <004001ce1546$6ae21ae0$40a650a0$@mcmaster.ca>
References: <1361186543.2067.24.camel@milan.ined.fr>
	<1361990811.1726.47.camel@milan>
	<CDF566D6-1023-48D4-BC5C-8714D46FF350@gmail.com>
	<1361998557.1726.73.camel@milan>
	<DCE81E14EB74504B971DAD4D2DB0356B0CB926AD92@crcmail4.BCCRC.CA>
	<1362005920.1726.95.camel@milan>
	<004001ce1546$6ae21ae0$40a650a0$@mcmaster.ca>
Message-ID: <1362088783.18589.16.camel@milan>

Le mercredi 27 f?vrier 2013 ? 18:59 -0500, John Fox a ?crit :
> Dear Milan and Steven,
> 
> At the risk of muddying the water further, I think that the potential
> confusion here is that Poisson GLMs are applied in two formally
> equivalent but substantively different situations: (1) where the
> counts are cells in a contingency table, in which case the Poisson GLM
> is used to fit an equivalent loglinear association model to the table;
> and (2) where the counts are observations on a non-negative integer
> response -- what's often called "Poisson regression." In the first
> case, but not the second, it makes sense to think of the sum of the
> counts as the natural sample size. I don't think that one can expect
> GLM software to distinguish these cases.
Thanks, that sounds like a good summary of the situation. There are two
legitimate use cases and definitions of number of observations, yet only
one nobs() and one BIC() function.

Indeed software can hardly find out which situation applies, except
maybe if it is possible to consider (as I suggested above) that
log-linear models are always fitted to tabular data (several
observations per cell), while poisson regressions are fitted to data
frames (one observation per row). If this is right, then a possible
solution would be to define nobs.glm() like this:

nobs.glm <- function(object, ...) {
    w <- object$prior.weights

    if(is.matrix(object$data)) {
        if (!is.null(w)) sum(object$data[w != 0], na.rm=TRUE)
        else sum(object$data, na.rm=TRUE)
    }
    else {
        if (!is.null(w)) sum(w != 0) else length(object$residuals)
    }
}

This would just require glm() to call as.data.frame(data) when passed a
table.


(loglin() could be considered the most natural way of fitting log-linear
models, but glm() is very useful too since it supports the quasipoisson
family, and the negative binomial via glm.nb(); finally, glm() handles
structural zeros better than loglin().)


Regards

> Best,
>  John
> 
> > -----Original Message-----
> > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> > project.org] On Behalf Of Milan Bouchet-Valat
> > Sent: Wednesday, February 27, 2013 5:59 PM
> > To: Steven McKinney
> > Cc: r-devel
> > Subject: Re: [Rd] nobs() with glm(family="poisson")
> > 
> > Le mercredi 27 f?vrier 2013 ? 14:26 -0800, Steven McKinney a ?crit :
> > >
> > > > -----Original Message-----
> > > > From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-
> > project.org]
> > > > On Behalf Of Milan Bouchet-Valat
> > > > Sent: February-27-13 12:56 PM
> > > > To: peter dalgaard
> > > > Cc: r-devel
> > > > Subject: Re: [Rd] nobs() with glm(family="poisson")
> > > >
> > > > Thanks for the (critical, indeed) answer!
> > > >
> > > > Le mercredi 27 f?vrier 2013 ? 20:48 +0100, peter dalgaard a ?crit :
> > > > > On Feb 27, 2013, at 19:46 , Milan Bouchet-Valat wrote:
> > > > >
> > > > > > I cannot believes nobody cares about this -- or I'm completely
> > wrong
> > > > and
> > > > > > in that case everybody should rush to put the shame on me... :-
> > p
> > > > >
> > > > > Well, nobs() is the number of observations. If you have 5 Poisson
> > > > > distributed counts, you have 5 observations.
> > > > Well, say that to the statistical offices that spend millions to
> > survey
> > > > thousands of people with correct (but complex) sampling designs,
> > they'll
> > > > be happy to know that the collected data only provides an
> > information
> > > > equivalent to 5 independent outcomes. ;-)
> > >
> > > Milan:
> > >
> > > It seems to me you are mixing up Binomial and Poisson situations,
> > > and not assessing independence appropriately.
> > >
> > > The above example discusses Bernoulli outcomes which are sometimes
> > > aggregated into Binomial "cases" depending on the study design.
> > > Now if the survey samples people in the same household or even
> > > neighbourhood, those Bernoulli outcomes will not be independent
> > > (hence clustered survey techniques) and summing the Binomial
> > > denominators would not be appropriate, for the survey analysis or
> > > for BIC calculations.  The "n" in the BIC calculation should
> > > reflect independent observations.  If you knock on the same
> > > door 1000 times and ask the person who they will vote for,
> > > you do not have 1000 independent observations, even though
> > > your Binomial denominator is 1000.
> > My intention was not to introduce the issue of survey designs into the
> > discussion, but merely to make the point that in surveys, counts are
> > usually *to some extent at least* independent observations, even when
> > clustering is present, and that the fact that different people are
> > asked
> > and that each answer costs money is the best indication of that.
> > Anyway,
> > BIC does not apply if we are not assuming that the data comes from a
> > simple random sample, so let's leave this complication aside.
> > 
> > > The example you show from ?glm is a Poisson example showing
> > > 9 independent Poisson counts.  If I count the number of cars
> > > passing through an intersection during non-overlapping
> > > one minute intervals (say 9 such intervals), then the number
> > > of observations I have is the number of non-overlapping
> > > one minute interval car count totals (e.g. the nine counts
> > > c(18, 17, 15, 20, 10, 20, 25, 13, 12)), not the number of
> > > cars I saw in total.
> > Interesting. Indeed in the observation setting you describe, 9 is
> > AFAICT
> > the correct number of observations. Is this kind of data commonly
> > fitted
> > using glm()?
> > 
> > Do you happen to possess a copy of the book where the ?glm example
> > comes
> > from? There are not many of them here in France so I cannot consult it
> > easily. It seems to me that in the context of a randomized controlled
> > trial, the number of independent observations is the number of
> > subjects,
> > not the number of groups. And thus, BIC() would still return a wrong
> > value for the ?glm example.
> > 
> > > A piece of software that adds things up can not know the
> > > context from which the numbers were derived, so you have to
> > > figure out the level of independence appropriate to your
> > > study design and work out the BIC count accordingly.
> > This is a strong argument indeed. It would mean that BIC() is at best a
> > function of very limited use, or even a dangerous one, unless one can
> > safely assume that the case were the number of observations equals the
> > number of rows in the data is by far the most common one. I am biased
> > due to my use of log-linear models, but I doubt this is the case. Is it
> > (I might perfectly be wrong)?
> > 
> > > Raftery alludes to this in a preceding section:
> > >
> > > "When the data have been collected using a complex survey
> > > design with resulting weights, it is not yet clear what n
> > > should be, and this issue awaits further study.  However,
> > > it seems reasonable that if the model is based on an
> > > assumption of simple random sampling but the sampling
> > > design is less efficient, then n should be reduced to
> > > reflect the efficiency of the sampling design relative to
> > > simple random sampling."
> > I think Raftery had in mind surveys in which the assumption of
> > independence between observations (counts, not rows) does not hold, but
> > where it is still the reference from which the sample deviates (lower
> > "efficiency"). In this case, the number of cells/rows by no means a
> > good
> > measure of the number of observations either -- but as I said BIC is
> > usually considered as not defined in this case.
> > 
> > 
> > Thanks for sharing your remarks.
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel


From bunny at lautloscrew.com  Thu Feb 28 23:09:08 2013
From: bunny at lautloscrew.com (Bunny)
Date: Thu, 28 Feb 2013 23:09:08 +0100
Subject: [Rd] conflict between rJava and data.table
Message-ID: <65A7F5D5-655A-4DCA-8A0F-F4ADD18DF0E7@lautloscrew.com>

Dear devel-listers, 

I found a conflct between rJava and data.table. Actually me questions is where to report it? 
Should I rather send it directly to the package maintainers or post it on some bug tracker. 
The problem is that data.table has a function called "J" and rJava uses the same quite intensively. 
I used the  xlsx R package which depends on rJava to write .xls files and ran into an error. 

write.xls from this package uses the functions and returns an error depending on the sequence the packages
were loaded. 


Error in .jnew("org/apache/poi/xssf/usermodel/XSSFWorkbook") : 
  java.lang.AbstractMethodError: java.lang.ClassLoader.loadClass(Ljava/lang/String;)Ljava/lang/Class;


data.table::J
rJava::J

I can work around this by loading and unloading packages, but I feel this should be addressed because 
loading these two packages that both deal with tables of data does not seem that unlikely to me. 

best

matt


