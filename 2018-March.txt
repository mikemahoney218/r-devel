From christian.krause at idiv.de  Thu Mar  1 09:19:33 2018
From: christian.krause at idiv.de (Christian Krause)
Date: Thu, 1 Mar 2018 09:19:33 +0100
Subject: [Rd] [parallel] fixes load balancing of parLapplyLB
In-Reply-To: <097719f7-da88-7a01-c4ec-3154328d6e58@gmail.com>
References: <a6e9c1ab509941489f0de6dcc1fac398@urzdommbx02.dom.uni-leipzig.de>
 <ee05a2d4382544cdb540665cd0ac3839@urzdommbx02.dom.uni-leipzig.de>
 <CAFDcVCRX82QZgs1BNzo-+PL92nULfG21CDpjDDKiPFhF2kH1Yg@mail.gmail.com>
 <1f1c808a24e9471784537dabde08d477@urzdommbx02.dom.uni-leipzig.de>
 <097719f7-da88-7a01-c4ec-3154328d6e58@gmail.com>
Message-ID: <109bbbed255f49fbb6bac484cf753286@urzdommbx02.dom.uni-leipzig.de>

Dear Tomas,

Thanks for your commitment to fix this issue and also to add the chunk size as an argument. If you want our input, let us know ;)

Best Regards

On 02/26/2018 04:01 PM, Tomas Kalibera wrote:
> Dear Christian and Henrik,
> 
> thank you for spotting the problem and suggestions for a fix. We'll probably add a chunk.size argument to parLapplyLB and parLapply to follow OpenMP terminology, which has already been an inspiration for the present code (parLapply already implements static scheduling via internal function staticClusterApply, yet with a fixed chunk size; parLapplyLB already implements dynamic scheduling via internal function dynamicClusterApply, but with a fixed chunk size set to an unlucky value so that it behaves like static scheduling). The default chunk size for parallelLapplyLB will be set so that there is some dynamism in the schedule even by default. I am now testing a patch with these changes.
> 
> Best
> Tomas
> 
> 
> On 02/20/2018 11:45 AM, Christian Krause wrote:
>> Dear Henrik,
>>
>> The rationale is just that it is within these extremes and that it is really simple to calculate, without making any assumptions and knowing that it won't be perfect.
>>
>> The extremes A and B you are mentioning are special cases based on assumptions. Case A is based on the assumption that the function has a long runtime or varying runtime, then you are likely to get the best load balancing with really small chunks. Case B is based on the assumption that the function runtime is the same for each list element, i.e. where you don't actually need load balancing, i.e. just use `parLapply` without load balancing.
>>
>> This new default is **not the best one**. It's just a better one than we had before. There is no best one we can use as default because **we don't know the function runtime and how it varies**. The user needs to decide that because he/she knows the function. As mentioned before, I will write a patch that makes the chunk size an optional argument, so the user can decide because only he/she has all the information to choose the best chunk size, just like you did with the `future.scheduling` parameter.
>>
>> Best Regards
>>
>> On February 19, 2018 10:11:04 PM GMT+01:00, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>> Hi, I'm trying to understand the rationale for your proposed amount of
>>> splitting and more precisely why that one is THE one.
>>>
>>> If I put labels on your example numbers in one of your previous post:
>>>
>>> nbrOfElements <- 97
>>> nbrOfWorkers <- 5
>>>
>>> With these, there are two extremes in how you can split up the
>>> processing in chunks such that all workers are utilized:
>>>
>>> (A) Each worker, called multiple times, processes one element each
>>> time:
>>>
>>>> nbrOfElements <- 97
>>>> nbrOfWorkers <- 5
>>>> nbrOfChunks <- nbrOfElements
>>>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
>>> [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>>> [30] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>>> [59] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>>> [88] 1 1 1 1 1 1 1 1 1 1
>>>
>>>
>>> (B) Each worker, called once, processes multiple element:
>>>
>>>> nbrOfElements <- 97
>>>> nbrOfWorkers <- 5
>>>> nbrOfChunks <- nbrOfWorkers
>>>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
>>> [1] 20 19 19 19 20
>>>
>>> I understand that neither of these two extremes may be the best when
>>> it comes to orchestration overhead and load balancing. Instead, the
>>> best might be somewhere in-between, e.g.
>>>
>>> (C) Each worker, called multiple times, processing multiple elements:
>>>
>>>> nbrOfElements <- 97
>>>> nbrOfWorkers <- 5
>>>> nbrOfChunks <- nbrOfElements / nbrOfWorkers
>>>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
>>> [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5
>>>
>>> However, there are multiple alternatives between the two extremes, e.g.
>>>
>>>> nbrOfChunks <- scale * nbrOfElements / nbrOfWorkers
>>> So, is there a reason why you argue for scale = 1.0 to be the optimal?
>>>
>>> FYI, In future.apply::future_lapply(X, FUN, ...) there is a
>>> 'future.scheduling' scale factor(*) argument where default
>>> future.scheduling = 1 corresponds to (B) and future.scheduling = +Inf
>>> to (A).? Using future.scheduling = 4 achieves the amount of
>>> load-balancing you propose in (C).?? (*) Different definition from the
>>> above 'scale'. (Disclaimer: I'm the author)
>>>
>>> /Henrik
>>>
>>> On Mon, Feb 19, 2018 at 10:21 AM, Christian Krause
>>> <christian.krause at idiv.de> wrote:
>>>> Dear R-Devel List,
>>>>
>>>> I have installed R 3.4.3 with the patch applied on our cluster and
>>> ran a *real-world* job of one of our users to confirm that the patch
>>> works to my satisfaction. Here are the results.
>>>> The original was a series of jobs, all essentially doing the same
>>> stuff using bootstrapped data, so for the original there is more data
>>> and I show the arithmetic mean with standard deviation. The
>>> confirmation with the patched R was only a single instance of that
>>> series of jobs.
>>>> ## Job Efficiency
>>>>
>>>> The job efficiency is defined as (this is what the `qacct-efficiency`
>>> tool below does):
>>>> ```
>>>> efficiency = cputime / cores / wallclocktime * 100%
>>>> ```
>>>>
>>>> In simpler words: how well did the job utilize its CPU cores. It
>>> shows the percentage of time the job was actually doing stuff, as
>>> opposed to the difference:
>>>> ```
>>>> wasted = 100% - efficiency
>>>> ```
>>>>
>>>> ... which, essentially, tells us how much of the resources were
>>> wasted, i.e. CPU cores just idling, without being used by anyone. We
>>> care a lot about that because, for our scientific computing cluster,
>>> wasted resources is like burning money.
>>>> ### original
>>>>
>>>> This is the entire series from our job accounting database, filteres
>>> the successful jobs, calculates efficiency and then shows the average
>>> and standard deviation of the efficiency:
>>>> ```
>>>> $ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd
>>>> n=945 ? 61.7276 ? 7.78719
>>>> ```
>>>>
>>>> This is the entire series from our job accounting database, filteres
>>> the successful jobs, calculates efficiency and does sort of a
>>> histogram-like binning before calculation of mean and standard
>>> deviation (to get a more detailed impression of the distribution when
>>> standard deviation of the previous command is comparatively high):
>>>> ```
>>>> $ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd-bin -w
>>> 10 | sort -gk1 | column -t
>>>> 10? -? 20? ->? n=3??? ?? 19.21666666666667?? ?? 0.9112811494447459
>>>> 20? -? 30? ->? n=6??? ?? 26.418333333333333? ?? 2.665996374091058
>>>> 30? -? 40? ->? n=12?? ?? 35.11583333333334?? ?? 2.8575783082671196
>>>> 40? -? 50? ->? n=14?? ?? 45.35285714285715?? ?? 2.98623361591005
>>>> 50? -? 60? ->? n=344? ?? 57.114593023255814? ?? 2.1922005551774415
>>>> 60? -? 70? ->? n=453? ?? 64.29536423841049?? ?? 2.8334788433963856
>>>> 70? -? 80? ->? n=108? ?? 72.95592592592598?? ?? 2.5219474143639276
>>>> 80? -? 90? ->? n=5??? ?? 81.526????????????? ?? 1.2802265424525452
>>>> ```
>>>>
>>>> I have attached an example graph from our monitoring system of a
>>> single instance in my previous mail. There you can see that the load
>>> balancing does not actually work, i.e. same as `parLapply`. This
>>> reflects in the job efficiency.
>>>> ### patch applied
>>>>
>>>> This is the single instance I used to confirm that the patch works:
>>>>
>>>> ```
>>>> $ qacct -j 4562202 | qacct-efficiency
>>>> 97.36
>>>> ```
>>>>
>>>> The graph from our monitoring system is attached. As you can see, the
>>> load balancing works to a satisfying degree and the efficiency is well
>>> above 90% which was what I had hoped for :-)
>>>> ## Additional Notes
>>>>
>>>> The list used in this jobs `parLapplyLB` is 5812 elements long. With
>>> the `splitList`-chunking from the patch, you'll get 208 lists of about
>>> 28 elements (208 chunks of size 28). The job ran on 28 CPU cores and
>>> had a wallclock time of 120351.590 seconds, i.e. 33.43 hours. Thus, the
>>> function we apply to our list takes about 580 seconds per list element,
>>> i.e. about 10 minutes. I suppose, for that runtime, we would get even
>>> better load balancing if we would reduce the chunk size even further,
>>> maybe even down to 1, thus getting our efficiency even closer to 100%.
>>>> Of course, for really short-running functions, a higher chunk size
>>> may be more efficient because of the overhead. In our case, the
>>> overhead is negligible and that is why the low chunk size works really
>>> well. In contrast, for smallish lists with short-running functions, you
>>> might not even need load balancing and `parLapply` suffices. It only
>>> becomes an issue, when the runtime of the function is high and / or
>>> varying.
>>>> In our case, the entire runtime of the entire series of jobs was:
>>>>
>>>> ```
>>>> $ qacct -j 4433299 | awk '$1 == "wallclock" { sum += $2 } END { print
>>> sum, "seconds" }'
>>>> 4.72439e+09 seconds
>>>> ```
>>>>
>>>> Thats about 150 years on a single core or 7.5 years on a 20 core
>>> server! Our user was constantly using about 500 cores, so this took
>>> about 110 days. If you compare this to my 97% efficiency example, the
>>> jobs could have been finished in 75 days instead ;-)
>>>> ## Upcoming Patch
>>>>
>>>> If this patch gets applied to the R code base (and I hope it will
>>> :-)) my colleague and I will submit another patch that adds the chunk
>>> size as an optional parameter to all off the load balancing functions.
>>> With that parameter, users of these functions *can* decide for
>>> themselves which chunk size they prefer for their code. As mentioned
>>> before, the most efficient chunk size depends on the used functions
>>> runtime, which is the only thing R does not know and users really
>>> should be allowed to specify explicitly. The default of this new
>>> optional parameter would be the one we used here and this would make
>>> that upcoming patch fully source-compatible.
>>>> Best Regards
>>>>
>>>> On 02/12/2018 08:08 PM, Christian Krause wrote:
>>>>> Dear R-Devel List,
>>>>>
>>>>> **TL;DR:** The function **parLapplyLB** of the parallel package has
>>> [reportedly][1] (see also attached RRD output) not
>>>>> been doing its job, i.e. not actually balancing the load. My
>>> colleague Dirk Sarpe and I found the cause of the problem
>>>>> and we also have a patch to fix it (attached). A similar fix has
>>> also been provided [here][2].
>>>>> [1]:
>>> https://stackoverflow.com/questions/38230831/why-does-parlapplylb-not-actually-balance-load
>>>>> [2]: https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16792
>>>>>
>>>>>
>>>>> ## The Call Chain
>>>>>
>>>>> First, we traced the relevant R function calls through the code,
>>> beginning with `parLapplyLB`:
>>>>> 1.? **parLapplyLB:** clusterApply.R:177, calls **splitList**, then
>>> **clusterApplyLB**
>>>>> 2.? **splitList:** clusterApply.R:157
>>>>> 3.? **clusterApplyLB:** clusterApply.R:87, calls
>>> **dynamicClusterApply**
>>>>> 4.? **dynamicClusterApply:** clusterApply.R:39
>>>>>
>>>>>
>>>>> ## splitList
>>>>>
>>>>> We used both our whiteboard and an R session to manually *run* a few
>>> examples. We were using lists of 100 elements and 5
>>>>> workers. First, lets take a look at **splitList**:
>>>>>
>>>>> ```r
>>>>>> sapply(parallel:::splitList(1:100, 5), length)
>>>>> [1] 20 20 20 20 20
>>>>>
>>>>>> sapply(parallel:::splitList(1:97, 5), length)
>>>>> [1] 20 19 19 19 20
>>>>>
>>>>>> sapply(parallel:::splitList(1:97, 20), length)
>>>>> ? [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5
>>>>> ```
>>>>>
>>>>> As we can see in the examples, the work is distributed as equally as
>>> possible.
>>>>>
>>>>> ## dynamicClusterApply
>>>>>
>>>>> **dynamicClusterApply** works this way (simplified):
>>>>>
>>>>> 1.? it first gives a chunk to each worker
>>>>> 2.? once a worker comes back with the result, it is given the next
>>> chunk
>>>>> **This is the important part:** As long as there are **more** chunks
>>> than workers, there will be load balancing. If
>>>>> there are fewer chunks than workers, each worker will get **at most
>>> one chunk** and there is **no** load balancing.
>>>>>
>>>>> ## parLapplyLB
>>>>>
>>>>> This is how **parLapplyLB** splits the input list (with a bit of
>>> refactoring, for readability):
>>>>> ```r
>>>>> parLapplyLB <- function(cl = NULL, X, fun, ...)
>>>>> {
>>>>> ???? cl <- defaultCluster(cl)
>>>>>
>>>>> ???? chunks <- splitList(X, length(cl))
>>>>>
>>>>> ???? do.call(c,
>>>>> ???????????? clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>>>>> ???????????? quote = TRUE)
>>>>> }
>>>>> ```
>>>>>
>>>>> For our examples, the chunks have these sizes:
>>>>>
>>>>> ```r
>>>>>> sapply(parallel:::splitList(1:100, 5), length)
>>>>> [1] 20 20 20 20 20
>>>>> ```
>>>>>
>>>>> There we have it: 5 chunks. 5 workers. With this work distribution,
>>> there can't possibly be any load balancing, because
>>>>> each worker is given a single chunk and then it stops working
>>> because there are no more chunks.
>>>>> Instead, **parLapplyLB** should look like this (patch is attached):
>>>>>
>>>>> ```r
>>>>> parLapplyLB <- function(cl = NULL, X, fun, ...)
>>>>> {
>>>>> ???? cl <- defaultCluster(cl)
>>>>>
>>>>> ???? chunkSize <- max(length(cl), ceiling(length(X) / length(cl)))
>>>>>
>>>>> ???? chunks <- splitList(X, chunkSize)
>>>>>
>>>>> ???? do.call(c,
>>>>> ???????????? clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>>>>> ???????????? quote = TRUE)
>>>>> }
>>>>> ```
>>>>>
>>>>> Examples with a cluster of 5 workers:
>>>>>
>>>>> ```r
>>>>> # length(cl) < length(X)
>>>>>> sapply(parallel:::splitList(1:100, ceiling(100 / 5)), length)
>>>>> ? [1] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
>>>>>
>>>>> # length(cl) >= length(X)
>>>>>> sapply(parallel:::splitList(1:4, 4), length)
>>>>> [1] 1 1 1 1
>>>>> # one worker idles here, but we can't do better than that
>>>>> ```
>>>>>
>>>>> With this patch, the number of chunks is larger than the number of
>>> workers, if possible at all, and then load balancing
>>>>> should work.
>>>>>
>>>>> Best Regards
>>>>>
>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>> -- 
>>>> Christian Krause
>>>>
>>>> Scientific Computing Administration and Support
>>>>
>>>>
>>> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>> Email: christian.krause at idiv.de
>>>>
>>>> Office: BioCity Leipzig 5e, Room 3.201.3
>>>>
>>>> Phone: +49 341 97 33144
>>>>
>>>>
>>> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>> German Centre for Integrative Biodiversity Research (iDiv)
>>> Halle-Jena-Leipzig
>>>> Deutscher Platz 5e
>>>>
>>>> 04103 Leipzig
>>>>
>>>> Germany
>>>>
>>>>
>>> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>> iDiv is a research centre of the DFG ? Deutsche
>>> Forschungsgemeinschaft
>>>> iDiv ist eine zentrale Einrichtung der Universit?t Leipzig im Sinne
>>> des ? 92 Abs. 1 S?chsHSFG und wird zusammen mit der
>>> Martin-Luther-Universit?t Halle-Wittenberg und der
>>> Friedrich-Schiller-Universit?t Jena betrieben sowie in Kooperation mit
>>> dem Helmholtz-Zentrum f?r Umweltforschung GmbH ? UFZ. Beteiligte
>>> Kooperationspartner sind die folgenden au?eruniversit?ren
>>> Forschungseinrichtungen: das Helmholtz-Zentrum f?r Umweltforschung GmbH
>>> - UFZ, das Max-Planck-Institut f?r Biogeochemie (MPI BGC), das
>>> Max-Planck-Institut f?r chemische ?kologie (MPI CE), das
>>> Max-Planck-Institut f?r evolution?re Anthropologie (MPI EVA), das
>>> Leibniz-Institut Deutsche Sammlung von Mikroorganismen und Zellkulturen
>>> (DSMZ), das Leibniz-Institut f?r Pflanzenbiochemie (IPB), das
>>> Leibniz-Institut f?r Pflanzengenetik und Kulturpflanzenforschung (IPK)
>>> und das Leibniz-Institut Senckenberg Museum f?r Naturkunde G?rlitz
>>> (SMNG). USt-IdNr. DE 141510383
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
> 
> 

-- 
Christian Krause

Scientific Computing Administration and Support

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

Email: christian.krause at idiv.de

Office: BioCity Leipzig 5e, Room 3.201.3

Phone: +49 341 97 33144

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

German Centre for Integrative Biodiversity Research (iDiv) Halle-Jena-Leipzig

Deutscher Platz 5e

04103 Leipzig

Germany

------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------

iDiv is a research centre of the DFG ? Deutsche Forschungsgemeinschaft

iDiv ist eine zentrale Einrichtung der Universit?t Leipzig im Sinne des ? 92 Abs. 1 S?chsHSFG und wird zusammen mit der Martin-Luther-Universit?t Halle-Wittenberg und der Friedrich-Schiller-Universit?t Jena betrieben sowie in Kooperation mit dem Helmholtz-Zentrum f?r Umweltforschung GmbH ? UFZ. Beteiligte Kooperationspartner sind die folgenden au?eruniversit?ren Forschungseinrichtungen: das Helmholtz-Zentrum f?r Umweltforschung GmbH - UFZ, das Max-Planck-Institut f?r Biogeochemie (MPI BGC), das Max-Planck-Institut f?r chemische ?kologie (MPI CE), das Max-Planck-Institut f?r evolution?re Anthropologie (MPI EVA), das Leibniz-Institut Deutsche Sammlung von Mikroorganismen und Zellkulturen (DSMZ), das Leibniz-Institut f?r Pflanzenbiochemie (IPB), das Leibniz-Institut f?r Pflanzengenetik und Kulturpflanzenforschung (IPK) und das Leibniz-Institut Senckenberg Museum f?r Naturkunde G?rlitz (SMNG). USt-IdNr. DE 141510383



-------------- next part --------------
A non-text attachment was scrubbed...
Name: signature.asc
Type: application/pgp-signature
Size: 833 bytes
Desc: OpenPGP digital signature
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180301/67e697a4/attachment.sig>

From willjouo at gmail.com  Thu Mar  1 15:10:37 2018
From: willjouo at gmail.com (William)
Date: Thu, 1 Mar 2018 15:10:37 +0100
Subject: [Rd] Small program embedding R crashes in 64 bits
Message-ID: <CAO6b4At8v5pnpkix8_RA=3=7U7+eCuhzhzSUv2u7UyPuukG1VA@mail.gmail.com>

Hi everyone,

I'm trying to create a small C++ program which embed R, but I'm having
problems when I try to do it on Windows 64 bits. I have created a
minimal reproducible example which is just the
src/gnuwin32/front-ends/rtest.c file with the R_ReplDLLdo1() loop, the
only difference is that I set the interactive mode to TRUE. Here is
the cpp file: https://gist.github.com/anonymous/08b42e83c949e250f60b068d58a3ec51

When compiled in 32 bits, everything works: I enter R commands and no
crash. When compiled in 64 bits (mingw64 and R x64 libs, and executed
with R x64 in the PATH), everything works except when there is an
error in R with a command entered by the user. Typically, entering "a"
shows "Error: object 'a' not found" and then the program immediately
crashes. Typing a stop() also trigger a crash.

Code returned by the program is 0xC0000028, which is STATUS_BAD_STACK
with the description: "An invalid or unaligned stack was encountered
during an unwind operation". I'm not really good at C++ or
makefile/compiler stuff, but I can't get it to work. I'm guessing this
as to do with some longjumps to return to the prompt when there is an
error but I don't know how to fix it.

Compiling in 32 bits:
P:/Rtools/mingw_32/bin/g++ -O3 -Wall -pedantic -IP:/R/R-3.4.3/include
-c testr.cpp -o testr.o
P:/Rtools/mingw_32/bin/g++ -o ./32.exe ./testr.o
-LP:/R/R-3.4.3/bin/i386 -lR -lRgraphapp

Results in:
C:\test> 32.exe
> a
Error: object 'a' not found
> # it works!

But compiling in 64 bits:
P:/Rtools/mingw_64/bin/g++ -O3 -Wall -pedantic -IP:/R/R-3.4.3/include
-c testr.cpp -o testr.o
P:/Rtools/mingw_64/bin/g++ -o ./64.exe ./testr.o
-LP:/R/R-3.4.3/bin/x64 -lR -lRgraphapp

Fails like this:
C:\test> 64.exe
> b <- 1
> b
[1] 1
> a
Error: object 'a' not found
<Program crashes with 0xC0000028 error, no prompt displayed>

I've tried lots of -std= flags, -DWIN64 -D_WIN64 and lots of other
defines I could find or think of but with no luck. What is missing?

Thanks,

William.


From ron.ammar at gmail.com  Thu Mar  1 15:36:41 2018
From: ron.ammar at gmail.com (Ron)
Date: Thu, 1 Mar 2018 09:36:41 -0500
Subject: [Rd] Bug report - duplicate row names with as.data.frame()
Message-ID: <CA+Dgj-7g35bUpULcrqKiyM8daHWOEY-MzU=7Snee6SUjQWrF6w@mail.gmail.com>

Hello,

I'd like to report what I think is a bug: using as.data.frame() we can
create duplicate row names in a data frame. R version 3.4.3 (current stable
release).

Rather than paste code in an email, please see the example formatted code
here:
https://stackoverflow.com/questions/49031523/duplicate-row-names-in-r-using-as-data-frame

I posted to StackOverflow, and consensus was that we should proceed with
this as a bug report.

Thanks,
Ron

	[[alternative HTML version deleted]]


From plummerm at iarc.fr  Thu Mar  1 18:23:04 2018
From: plummerm at iarc.fr (Martyn Plummer)
Date: Thu, 1 Mar 2018 17:23:04 +0000
Subject: [Rd] Bug report - duplicate row names with as.data.frame()
In-Reply-To: <CA+Dgj-7g35bUpULcrqKiyM8daHWOEY-MzU=7Snee6SUjQWrF6w@mail.gmail.com>
References: <CA+Dgj-7g35bUpULcrqKiyM8daHWOEY-MzU=7Snee6SUjQWrF6w@mail.gmail.com>
Message-ID: <1519924984.4751.69.camel@iarc.fr>

On Thu, 2018-03-01 at 09:36 -0500, Ron wrote:
> Hello,
> 
> I'd like to report what I think is a bug: using as.data.frame() we can
> create duplicate row names in a data frame. R version 3.4.3 (current stable
> release).
> 
> Rather than paste code in an email, please see the example formatted code
> here:
> https://stackoverflow.com/questions/49031523/duplicate-row-names-in-r-using-as-data-frame
> 
> I posted to StackOverflow, and consensus was that we should proceed with
> this as a bug report.

Yes that is definitely a bug. 

The end of the as.data.frame.matrix method has:

    attr(value, "row.names") <- row.names
    class(value) <- "data.frame"
    value

Changing this to:

    class(value) <- "data.frame"
    row.names(value) <- row.names
    value

ensures that the row.names<-.data.frame method is called with its built
-in check for duplicate names.

There are quite a few as.data.frame methods so this could be a
recurring problem. I will check.

Martyn


> Thanks,
> Ron
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From maechler at stat.math.ethz.ch  Thu Mar  1 18:52:46 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 1 Mar 2018 18:52:46 +0100
Subject: [Rd] scale.default gives an incorrect error message when
 is.numeric() fails on a dgeMatrix
In-Reply-To: <CAPRVBcyZwt6bYiqeZ3Lz2ivye2oFfLoUShuobps4k5yKg=JGDg@mail.gmail.com>
References: <CAPRVBcyZwt6bYiqeZ3Lz2ivye2oFfLoUShuobps4k5yKg=JGDg@mail.gmail.com>
Message-ID: <23192.15854.546339.168134@stat.math.ethz.ch>

>>>>> Michael Chirico <michaelchirico4 at gmail.com>
>>>>>     on Tue, 27 Feb 2018 20:18:34 +0800 writes:

Slightly amended 'Subject': (unimportant mistake: a dgeMatrix is *not* sparse)

MM: modified to commented R code,  slightly changed from your post:


## I am attempting to use the lars package with a sparse input feature matrix,
## but the following fails:

library(Matrix)
library(lars)
data(diabetes) # from 'lars'
##UAagghh! not like this -- both attach() *and*   as.data.frame()  are horrific!
##UA  attach(diabetes)
##UA  x = as(as.matrix(as.data.frame(x)), 'dgCMatrix')
x <- as(unclass(diabetes$x), "dgCMatrix")
lars(x, y, intercept = FALSE)
## Error in scale.default(x, FALSE, normx) :
##   length of 'scale' must equal the number of columns of 'x'

## More specifically, scale.default fails as called from lars():
normx <- new("dgeMatrix",
  x = c(4, 0, 9, 1, 1, -1, 4, -2, 6, 6)*1e-14, Dim = c(1L, 10L),
  Dimnames = list(NULL,
                  c("x.age", "x.sex", "x.bmi", "x.map", "x.tc",
                    "x.ldl", "x.hdl", "x.tch", "x.ltg", "x.glu")))
scale.default(x, center=FALSE, scale = normx)
## Error in scale.default(x, center = FALSE, scale = normx) :
##   length of 'scale' must equal the number of columns of 'x'

>  The problem is that this check fails because is.numeric(normx) is FALSE:

>  if (is.numeric(scale) && length(scale) == nc)

>  So, the error message is misleading. In fact length(scale) is the same as
>  nc.

Correct, twice.

>  At a minimum, the error message needs to be repaired; do we also want to
>  attempt as.numeric(normx) (which I believe would have allowed scale to work
>  in this case)?

It seems sensible to allow  both 'center' and 'scale' to only
have to *obey*  as.numeric(.)  rather than fulfill is.numeric(.).

Though that is not a bug in scale()  as its help page has always
said that 'center' and 'scale' should either be a logical value
or a numeric vector.

For that reason I can really claim a bug in 'lars' which should
really not use

       scale(x, FALSE, normx)

but rather

       scale(x, FALSE, scale = as.numeric(normx))

and then all would work.

> -----------------

>  (I'm aware that there's some import issues in lars, as the offending line
>  to create normx *should* work, as is.numeric(sqrt(drop(rep(1, nrow(x)) %*%
>  (x^2)))) is TRUE -- it's simply that lars doesn't import the appropriate S4
>  methods)

>  Michael Chirico

Yes, 'lars' has _not_ been updated since  Spring 2013, notably
because its authors have been saying (for rather more than 5
years I think) that one should really use 

 require("glmnet")

instead.

Your point is still valid that it would be easy to enhance
base :: scale.default()  so it'd work in more cases.

Thank you for that.  I do plan to consider such a change in
R-devel (planned to become R 3.5.0 in April).

Martin Maechler,
ETH Zurich


From michaelchirico4 at gmail.com  Fri Mar  2 01:27:07 2018
From: michaelchirico4 at gmail.com (Michael Chirico)
Date: Fri, 2 Mar 2018 08:27:07 +0800
Subject: [Rd] scale.default gives an incorrect error message when
 is.numeric() fails on a dgeMatrix
In-Reply-To: <23192.15854.546339.168134@stat.math.ethz.ch>
References: <CAPRVBcyZwt6bYiqeZ3Lz2ivye2oFfLoUShuobps4k5yKg=JGDg@mail.gmail.com>
 <23192.15854.546339.168134@stat.math.ethz.ch>
Message-ID: <CAPRVBcxXavsg84qqcES1GWvAitfZrXicf8QsMMdO6EEkDuvq3Q@mail.gmail.com>

thanks. I know the setup code is a mess, just duct-taped something together
from the examples in lars (which are a mess in turn). in fact when I
messaged Prof. Hastie he recommended using glmnet. I wonder why lars is
kept on CRAN if they've no intention of maintaining it... but I digress...

On Mar 2, 2018 1:52 AM, "Martin Maechler" <maechler at stat.math.ethz.ch>
wrote:

> >>>>> Michael Chirico <michaelchirico4 at gmail.com>
> >>>>>     on Tue, 27 Feb 2018 20:18:34 +0800 writes:
>
> Slightly amended 'Subject': (unimportant mistake: a dgeMatrix is *not*
> sparse)
>
> MM: modified to commented R code,  slightly changed from your post:
>
>
> ## I am attempting to use the lars package with a sparse input feature
> matrix,
> ## but the following fails:
>
> library(Matrix)
> library(lars)
> data(diabetes) # from 'lars'
> ##UAagghh! not like this -- both attach() *and*   as.data.frame()  are
> horrific!
> ##UA  attach(diabetes)
> ##UA  x = as(as.matrix(as.data.frame(x)), 'dgCMatrix')
> x <- as(unclass(diabetes$x), "dgCMatrix")
> lars(x, y, intercept = FALSE)
> ## Error in scale.default(x, FALSE, normx) :
> ##   length of 'scale' must equal the number of columns of 'x'
>
> ## More specifically, scale.default fails as called from lars():
> normx <- new("dgeMatrix",
>   x = c(4, 0, 9, 1, 1, -1, 4, -2, 6, 6)*1e-14, Dim = c(1L, 10L),
>   Dimnames = list(NULL,
>                   c("x.age", "x.sex", "x.bmi", "x.map", "x.tc",
>                     "x.ldl", "x.hdl", "x.tch", "x.ltg", "x.glu")))
> scale.default(x, center=FALSE, scale = normx)
> ## Error in scale.default(x, center = FALSE, scale = normx) :
> ##   length of 'scale' must equal the number of columns of 'x'
>
> >  The problem is that this check fails because is.numeric(normx) is FALSE:
>
> >  if (is.numeric(scale) && length(scale) == nc)
>
> >  So, the error message is misleading. In fact length(scale) is the same
> as
> >  nc.
>
> Correct, twice.
>
> >  At a minimum, the error message needs to be repaired; do we also want to
> >  attempt as.numeric(normx) (which I believe would have allowed scale to
> work
> >  in this case)?
>
> It seems sensible to allow  both 'center' and 'scale' to only
> have to *obey*  as.numeric(.)  rather than fulfill is.numeric(.).
>
> Though that is not a bug in scale()  as its help page has always
> said that 'center' and 'scale' should either be a logical value
> or a numeric vector.
>
> For that reason I can really claim a bug in 'lars' which should
> really not use
>
>        scale(x, FALSE, normx)
>
> but rather
>
>        scale(x, FALSE, scale = as.numeric(normx))
>
> and then all would work.
>
> > -----------------
>
> >  (I'm aware that there's some import issues in lars, as the offending
> line
> >  to create normx *should* work, as is.numeric(sqrt(drop(rep(1, nrow(x))
> %*%
> >  (x^2)))) is TRUE -- it's simply that lars doesn't import the
> appropriate S4
> >  methods)
>
> >  Michael Chirico
>
> Yes, 'lars' has _not_ been updated since  Spring 2013, notably
> because its authors have been saying (for rather more than 5
> years I think) that one should really use
>
>  require("glmnet")
>
> instead.
>
> Your point is still valid that it would be easy to enhance
> base :: scale.default()  so it'd work in more cases.
>
> Thank you for that.  I do plan to consider such a change in
> R-devel (planned to become R 3.5.0 in April).
>
> Martin Maechler,
> ETH Zurich
>
>
>

	[[alternative HTML version deleted]]


From r.turner at auckland.ac.nz  Fri Mar  2 01:43:47 2018
From: r.turner at auckland.ac.nz (Rolf Turner)
Date: Fri, 2 Mar 2018 13:43:47 +1300
Subject: [Rd] Repeated use of dyn.load().
Message-ID: <01b67982-643f-0d4d-02bd-6bf0e73a4dd5@auckland.ac.nz>


I sent this enquiry to r-help and received several sympathetic replies, 
none of which were definitive.

It was kindly suggested to me that I might get better mileage out of 
r-devel, so I'm trying here.  I hope that this is not inappropriate.

My original enquiry to r-help:

==========================================================================
I am working with a function "foo" that explicitly dynamically loads a 
shared object library or "DLL", doing something like dyn.load("bar.so"). 
  This is a debugging exercise so I make changes to the underlying 
Fortran code (yes, I acknowledge that I am a dinosaur) remake the DLL 
"bar.so" and then run foo again.  This is all *without* quitting and 
restarting R.  (I'm going to have to do this a few brazillion times, and
I want the iterations to be as quick as possible.)

This seems to work --- i.e. foo seems to obtain the latest version of 
bar.so.  But have I just been lucky so far?  (I have not experimented 
heavily).

Am I running risks of leading myself down the garden path?  Are there 
Traps for Young (or even Old) Players lurking about?

I would appreciate Wise Counsel.
==========================================================================

One of the replies that I received from r-help indicated that it might 
be safer if I were to apply dyn.unload() on each iteration.  So I 
thought I might put in the line of code

     on.exit(dyn.unload("bar.so"))

immediately after my call to dyn.load().

Comments?

Another reply pointed out that "Writing R Extensions" indicates that 
there could be problems under Solaris, but does not single out any other 
OS for comment.  Might I infer that I am "safe" as long as I don't use 
Solaris?  (Which I certainly *won't* be doing.)

Thanks.

cheers,

Rolf Turner

-- 
Technical Editor ANZJS
Department of Statistics
University of Auckland
Phone: +64-9-373-7599 ext. 88276


From radoslaw.piliszek at gmail.com  Fri Mar  2 09:26:46 2018
From: radoslaw.piliszek at gmail.com (=?UTF-8?Q?Rados=C5=82aw_Piliszek?=)
Date: Fri, 2 Mar 2018 09:26:46 +0100
Subject: [Rd] Makevars CXX_STD variable ignored when no *.cpp files in src/
Message-ID: <CAB6MLKNjRFNF6rh1NNF-m_pDqsYSBh8rKF-bpKjFJq-gy0FiuA@mail.gmail.com>

Hello!

I might have found a bug in the way that R handles Makevars file when
building a package.

Value of variable CXX_STD is ignored - i.e. R does not use the correct
compiler/flags - if there are no *.cpp files directly in the src/
directory (e.g. all *.cpp are in subdirectories, and OBJECTS variable
is set accordingly). Adding a bogus *.cpp file fixes this issue.
However, this is not very obvious (I would dare saying it is not
obvious at all) and I spent quite a time checking what went wrong
after I organized my src files better. :-)

Kind regards,
Rados?aw Piliszek


From plummerm at iarc.fr  Fri Mar  2 10:42:27 2018
From: plummerm at iarc.fr (Martyn Plummer)
Date: Fri, 2 Mar 2018 09:42:27 +0000
Subject: [Rd] 
 Makevars CXX_STD variable ignored when no *.cpp files in src/
In-Reply-To: <CAB6MLKNjRFNF6rh1NNF-m_pDqsYSBh8rKF-bpKjFJq-gy0FiuA@mail.gmail.com>
References: <CAB6MLKNjRFNF6rh1NNF-m_pDqsYSBh8rKF-bpKjFJq-gy0FiuA@mail.gmail.com>
Message-ID: <1519983746.4751.73.camel@iarc.fr>

You are not the first person to report this, but last time when I tried
it myself I could not reproduce the bug. Let me try it again.

Martyn

On Fri, 2018-03-02 at 09:26 +0100, Rados?aw Piliszek wrote:
> Hello!
> 
> I might have found a bug in the way that R handles Makevars file when
> building a package.
> 
> Value of variable CXX_STD is ignored - i.e. R does not use the
> correct
> compiler/flags - if there are no *.cpp files directly in the src/
> directory (e.g. all *.cpp are in subdirectories, and OBJECTS variable
> is set accordingly). Adding a bogus *.cpp file fixes this issue.
> However, this is not very obvious (I would dare saying it is not
> obvious at all) and I spent quite a time checking what went wrong
> after I organized my src files better. :-)
> 
> Kind regards,
> Rados?aw Piliszek
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From plummerm at iarc.fr  Fri Mar  2 18:02:48 2018
From: plummerm at iarc.fr (Martyn Plummer)
Date: Fri, 2 Mar 2018 17:02:48 +0000
Subject: [Rd] 
 Makevars CXX_STD variable ignored when no *.cpp files in src/
In-Reply-To: <1519983746.4751.73.camel@iarc.fr>
References: <CAB6MLKNjRFNF6rh1NNF-m_pDqsYSBh8rKF-bpKjFJq-gy0FiuA@mail.gmail.com>
 <1519983746.4751.73.camel@iarc.fr>
Message-ID: <1520010167.4751.93.camel@iarc.fr>

Radoslaw sent me a reproducible example. I have been able to identify
the problem and fix it. I have copied in Alexander Loboda who
previously reported the same problem.

Briefly, the tools package relied on the presence of files with
extension .cpp or .cc in the src directory to determine whether the C++
compiler is required. In the absence of any such files, the code to set
the C++ compiler flags correctly was never run.

Martyn

On Fri, 2018-03-02 at 09:42 +0000, Martyn Plummer wrote:
> You are not the first person to report this, but last time when I tried
> it myself I could not reproduce the bug. Let me try it again.
> 
> Martyn
> 
> On Fri, 2018-03-02 at 09:26 +0100, Rados?aw Piliszek wrote:
> > Hello!
> > 
> > I might have found a bug in the way that R handles Makevars file when
> > building a package.
> > 
> > Value of variable CXX_STD is ignored - i.e. R does not use the
> > correct
> > compiler/flags - if there are no *.cpp files directly in the src/
> > directory (e.g. all *.cpp are in subdirectories, and OBJECTS variable
> > is set accordingly). Adding a bogus *.cpp file fixes this issue.
> > However, this is not very obvious (I would dare saying it is not
> > obvious at all) and I spent quite a time checking what went wrong
> > after I organized my src files better. :-)
> > 
> > Kind regards,
> > Rados?aw Piliszek
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

From davidhughjones at gmail.com  Sat Mar  3 20:33:46 2018
From: davidhughjones at gmail.com (David Hugh-Jones)
Date: Sat, 3 Mar 2018 19:33:46 +0000
Subject: [Rd] install.packages doesn't produce warnings unless qualified
 with utils::
Message-ID: <CAARY7kgJNpGOB1HhTzVWVFnwwh-AH=r8Ke7678XPM-snpp99xA@mail.gmail.com>

Hi all,

Assuming this is an R core issue:

tryCatch(install.packages("clipr", repos = "bullshit"), warning = function
(w) cat("got a warning"))
Warning in install.packages :
  unable to access index for repository bullshit/src/contrib:
  cannot open URL 'bullshit/src/contrib/PACKAGES'
Warning in install.packages :
  package ?clipr? is not available (for R version 3.4.3)
Warning in install.packages :
  unable to access index for repository
bullshit/bin/macosx/el-capitan/contrib/3.4:
  cannot open URL 'bullshit/bin/macosx/el-capitan/contrib/3.4/PACKAGES'

In other words, lots of warnings, but none are caught.

It works if you use the fully qualified version in utils:

tryCatch(utils::install.packages("clipr", repos = "bullshit"), warning =
function (w) cat("got a warning"))
got a warning

Any ideas?
Cheers,
David

	[[alternative HTML version deleted]]


From josh.m.ulrich at gmail.com  Sat Mar  3 21:00:54 2018
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Sat, 3 Mar 2018 14:00:54 -0600
Subject: [Rd] install.packages doesn't produce warnings unless qualified
 with utils::
In-Reply-To: <CAARY7kgJNpGOB1HhTzVWVFnwwh-AH=r8Ke7678XPM-snpp99xA@mail.gmail.com>
References: <CAARY7kgJNpGOB1HhTzVWVFnwwh-AH=r8Ke7678XPM-snpp99xA@mail.gmail.com>
Message-ID: <CAPPM_gRzeLntvQm6NQLLasaJuR2pLU89Z4qwpuMX9uy0Y5218A@mail.gmail.com>

On Sat, Mar 3, 2018 at 1:33 PM, David Hugh-Jones
<davidhughjones at gmail.com> wrote:
> Hi all,
>
> Assuming this is an R core issue:
>
> tryCatch(install.packages("clipr", repos = "bullshit"), warning = function
> (w) cat("got a warning"))
> Warning in install.packages :
>   unable to access index for repository bullshit/src/contrib:
>   cannot open URL 'bullshit/src/contrib/PACKAGES'
> Warning in install.packages :
>   package ?clipr? is not available (for R version 3.4.3)
> Warning in install.packages :
>   unable to access index for repository
> bullshit/bin/macosx/el-capitan/contrib/3.4:
>   cannot open URL 'bullshit/bin/macosx/el-capitan/contrib/3.4/PACKAGES'
>
> In other words, lots of warnings, but none are caught.
>
Using R-3.4.3 on 64-bit Ubuntu throws and catches the warning.

R> tryCatch(install.packages("clipr", repos="w"), warning=function(w)
cat("got a warning!\n"))
Installing package into '/home/josh/R/library'
(as 'lib' is unspecified)
got a warning!

> It works if you use the fully qualified version in utils:
>
> tryCatch(utils::install.packages("clipr", repos = "bullshit"), warning =
> function (w) cat("got a warning"))
> got a warning
>
My guess is that something (a package, console, etc) is masking
utils::install.packages().

> Any ideas?
> Cheers,
> David
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com
R/Finance 2018 | www.rinfinance.com


From murdoch.duncan at gmail.com  Sun Mar  4 06:23:51 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 4 Mar 2018 00:23:51 -0500
Subject: [Rd] install.packages doesn't produce warnings unless qualified
 with utils::
In-Reply-To: <CAPPM_gRzeLntvQm6NQLLasaJuR2pLU89Z4qwpuMX9uy0Y5218A@mail.gmail.com>
References: <CAARY7kgJNpGOB1HhTzVWVFnwwh-AH=r8Ke7678XPM-snpp99xA@mail.gmail.com>
 <CAPPM_gRzeLntvQm6NQLLasaJuR2pLU89Z4qwpuMX9uy0Y5218A@mail.gmail.com>
Message-ID: <41ca150b-b464-e425-59f6-cd72a1dea988@gmail.com>

On 03/03/2018 3:00 PM, Joshua Ulrich wrote:
> On Sat, Mar 3, 2018 at 1:33 PM, David Hugh-Jones
> <davidhughjones at gmail.com> wrote:
>> Hi all,
>>
>> Assuming this is an R core issue:
>>
>> tryCatch(install.packages("clipr", repos = "bullshit"), warning = function
>> (w) cat("got a warning"))
>> Warning in install.packages :
>>    unable to access index for repository bullshit/src/contrib:
>>    cannot open URL 'bullshit/src/contrib/PACKAGES'
>> Warning in install.packages :
>>    package ?clipr? is not available (for R version 3.4.3)
>> Warning in install.packages :
>>    unable to access index for repository
>> bullshit/bin/macosx/el-capitan/contrib/3.4:
>>    cannot open URL 'bullshit/bin/macosx/el-capitan/contrib/3.4/PACKAGES'
>>
>> In other words, lots of warnings, but none are caught.
>>
> Using R-3.4.3 on 64-bit Ubuntu throws and catches the warning.
> 
> R> tryCatch(install.packages("clipr", repos="w"), warning=function(w)
> cat("got a warning!\n"))
> Installing package into '/home/josh/R/library'
> (as 'lib' is unspecified)
> got a warning!
> 
>> It works if you use the fully qualified version in utils:
>>
>> tryCatch(utils::install.packages("clipr", repos = "bullshit"), warning =
>> function (w) cat("got a warning"))
>> got a warning
>>
> My guess is that something (a package, console, etc) is masking
> utils::install.packages().

RStudio does that.

Duncan Murdoch


From davidhughjones at gmail.com  Sun Mar  4 10:40:19 2018
From: davidhughjones at gmail.com (David Hugh-Jones)
Date: Sun, 4 Mar 2018 09:40:19 +0000
Subject: [Rd] Fwd: install.packages doesn't produce warnings unless
 qualified with utils::
In-Reply-To: <CAARY7kgx4h7_0zQkNXrfO+r3LEopBJkHQHDg9P2PCAd8qXAFBg@mail.gmail.com>
References: <CAARY7kgJNpGOB1HhTzVWVFnwwh-AH=r8Ke7678XPM-snpp99xA@mail.gmail.com>
 <CAPPM_gRzeLntvQm6NQLLasaJuR2pLU89Z4qwpuMX9uy0Y5218A@mail.gmail.com>
 <CAARY7kgx4h7_0zQkNXrfO+r3LEopBJkHQHDg9P2PCAd8qXAFBg@mail.gmail.com>
Message-ID: <CAARY7kjp7FhmjVYOgFUgC_fkfBr81+gHeD-90mFCVsO0WTfygQ@mail.gmail.com>

On Sat, 3 Mar 2018 at 20:01, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:

>
> >
> My guess is that something (a package, console, etc) is masking
> utils::install.packages().
>
>
This looks about right. On R in the terminal the warning is thrown. In
Rstudio I have the problem, and:

 > getAnywhere('install.packages')
2 differing objects matching ?install.packages? were found
in the following places
  package:utils
  namespace:utils
Use [] to view one of them

And the version in package.utils looks like:

function (...)
.rs.callAs(name, hook, original, ...)

OK, so an RStudio issue. Indeed, this looks like the problem:

https://github.com/rstudio/rstudio/blob/master/src/cpp/r/R/Tools.R

There, callAs is defined as running a function with error handlers which
use `cat` to reprint warnings.

Thanks!
David
-- 
Sent from Gmail Mobile

	[[alternative HTML version deleted]]


From hugh.parsonage at gmail.com  Mon Mar  5 03:39:24 2018
From: hugh.parsonage at gmail.com (Hugh Parsonage)
Date: Mon, 5 Mar 2018 13:39:24 +1100
Subject: [Rd] Unclosed parenthesis in grep.Rd
Message-ID: <CAJmOi+PmYn3Xsb7OzsNBLTHQHtSueheg9yTB2=LAPEE2HTtkmw@mail.gmail.com>

Lines 129-131:
\code{grep(value = FALSE)} returns a vector of the indices
of the elements of \code{x} that yielded a match (or not, for
\code{invert = TRUE}. This will be an integer vector unless the input

There should be a closing parenthesis after \code{invert = TRUE}


From maechler at stat.math.ethz.ch  Mon Mar  5 09:27:52 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 5 Mar 2018 09:27:52 +0100
Subject: [Rd] Unclosed parenthesis in grep.Rd
In-Reply-To: <CAJmOi+PmYn3Xsb7OzsNBLTHQHtSueheg9yTB2=LAPEE2HTtkmw@mail.gmail.com>
References: <CAJmOi+PmYn3Xsb7OzsNBLTHQHtSueheg9yTB2=LAPEE2HTtkmw@mail.gmail.com>
Message-ID: <23196.65416.625348.282322@stat.math.ethz.ch>

>>>>> Hugh Parsonage <hugh.parsonage at gmail.com>
>>>>>     on Mon, 5 Mar 2018 13:39:24 +1100 writes:

    > Lines 129-131: \code{grep(value = FALSE)} returns a vector
    > of the indices of the elements of \code{x} that yielded a
    > match (or not, for \code{invert = TRUE}. This will be an
    > integer vector unless the input

    > There should be a closing parenthesis after \code{invert =
    > TRUE}

Thank you, Hugh!  I've added the ')' now.
Martin


From michaelchirico4 at gmail.com  Mon Mar  5 16:59:03 2018
From: michaelchirico4 at gmail.com (Michael Chirico)
Date: Mon, 5 Mar 2018 23:59:03 +0800
Subject: [Rd] model.frame strips class as promised,
 but fails to strip OBJECT in C
Message-ID: <CAPRVBcxiXUc_e76jB56HuZk4Kai7Hbe85mTntbAJJ6zeQzCCbQ@mail.gmail.com>

Full thread here:

https://github.com/tidyverse/broom/issues/287

Reproducible example:

is.object(freeny$y)
# [1] TRUE
attr(freeny$y, 'class')
# [1] "ts"
class(freeny$y)
# [1] "ts"

# ts attribute wiped by model.frame
class(model.frame(y ~ ., data = freeny)$y)
# [1] "numeric"
attr(model.frame(y ~ ., data = freeny)$y, 'class')
# NULL

# but still:
is.object(model.frame(y ~ ., data = freeny)$y)
# [1] TRUE

That is, given a numeric vector with class "ts", model.frame strips the
"ts" attribute but keeps the is.object property.

This behavior is alluded to in ?model.frame:

Unless na.action = NULL, time-series attributes will be removed from the
> variables found (since they will be wrong if NAs are removed).
>

And in fact explicitly setting na.action = NULL prevents dropping the class:

class(model.frame(y ~ ., data = freeny, na.action = NULL)$y)
# [1] "ts"

The reason this looks especially like a bug is that it differs from how
na.omit behaves:

DF <- data.frame(x = c(1, 2, 3), y = c(0, 10, NA))
is.object(DF$y)
# [1] FALSE
class(DF$y) = 'foo'
is.object(DF$y)
# [1] TRUE
class(na.omit(DF)$y)
# [1] "numeric"
is.object(na.omit(DF)$y)
# [1] FALSE


That is, similarly presented with a classed object, na.omit strips the
class *and* the OBJECT attribute.

Thanks,
Michael Chirico

	[[alternative HTML version deleted]]


From etiennesanchez2 at gmail.com  Mon Mar  5 17:48:19 2018
From: etiennesanchez2 at gmail.com (Etienne Sanchez)
Date: Mon, 5 Mar 2018 17:48:19 +0100
Subject: [Rd] Unclosed parenthesis in grep.Rd
In-Reply-To: <23196.65416.625348.282322@stat.math.ethz.ch>
References: <CAJmOi+PmYn3Xsb7OzsNBLTHQHtSueheg9yTB2=LAPEE2HTtkmw@mail.gmail.com>
 <23196.65416.625348.282322@stat.math.ethz.ch>
Message-ID: <CANgsd59hAjutKGQc5m-_q0XLsFFunPRZGao1jhNC_AfcHgT3oA@mail.gmail.com>

There are probably more unmatched parentheses around:

detect <- function(file) {
  text <- paste(readLines(file), collapse = "")
  nchar(gsub("[^(]", "", text)) != nchar(gsub("[^)]", "", text))
}

docs <- list.files("r-source-trunk/src/library",
                   pattern = "\\.Rd$",
                   full.names = TRUE,
                   recursive = TRUE)

suspicious <- docs[sapply(docs, detect)]

length(suspicious)
# [1] 114


2018-03-05 9:27 GMT+01:00 Martin Maechler <maechler at stat.math.ethz.ch>:
>
> >>>>> Hugh Parsonage <hugh.parsonage at gmail.com>
> >>>>>     on Mon, 5 Mar 2018 13:39:24 +1100 writes:
>
>     > Lines 129-131: \code{grep(value = FALSE)} returns a vector
>     > of the indices of the elements of \code{x} that yielded a
>     > match (or not, for \code{invert = TRUE}. This will be an
>     > integer vector unless the input
>
>     > There should be a closing parenthesis after \code{invert =
>     > TRUE}
>
> Thank you, Hugh!  I've added the ')' now.
> Martin
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Mon Mar  5 20:33:22 2018
From: jorismeys at gmail.com (Joris Meys)
Date: Mon, 5 Mar 2018 20:33:22 +0100
Subject: [Rd] model.frame strips class as promised,
 but fails to strip OBJECT in C
In-Reply-To: <CAPRVBcxiXUc_e76jB56HuZk4Kai7Hbe85mTntbAJJ6zeQzCCbQ@mail.gmail.com>
References: <CAPRVBcxiXUc_e76jB56HuZk4Kai7Hbe85mTntbAJJ6zeQzCCbQ@mail.gmail.com>
Message-ID: <CAO1zAVbjbV4ruB+=mA+Xfsm6c_O0y=Kj9o85SMHsRHP89tV2SA@mail.gmail.com>

Given the documentation in ?is.object and the info in R Internals section
1.1.2, I'd argue that this indeed a bug.

Looking at
https://github.com/wch/r-source/blob/trunk/src/library/stats/src/model.c
(line 220 and following) the function copyMostAttribNoTs is called to copy
the attributes lost after the na.action. This decision makes sense, but
when I look at that functiion copyMostAttribNoTs it sets the object bit to
the original state of the input, whereas in the case of a ts object, both
the class and the tsp attribute were dropped and not restored. More
specifically, line 338 of
https://github.com/wch/r-source/blob/3d0650af456d97648c72de66a40b85d3ec96a497/src/main/attrib.c
is imho the place where the object bit is set on a previous ts object that
lost its attributes, and if I read R Internals correctly, that shouldn't
happen.

Cheers
Joris

On Mon, Mar 5, 2018 at 4:59 PM, Michael Chirico <michaelchirico4 at gmail.com>
wrote:

> Full thread here:
>
> https://github.com/tidyverse/broom/issues/287
>
> Reproducible example:
>
> is.object(freeny$y)
> # [1] TRUE
> attr(freeny$y, 'class')
> # [1] "ts"
> class(freeny$y)
> # [1] "ts"
>
> # ts attribute wiped by model.frame
> class(model.frame(y ~ ., data = freeny)$y)
> # [1] "numeric"
> attr(model.frame(y ~ ., data = freeny)$y, 'class')
> # NULL
>
> # but still:
> is.object(model.frame(y ~ ., data = freeny)$y)
> # [1] TRUE
>
> That is, given a numeric vector with class "ts", model.frame strips the
> "ts" attribute but keeps the is.object property.
>
> This behavior is alluded to in ?model.frame:
>
> Unless na.action = NULL, time-series attributes will be removed from the
> > variables found (since they will be wrong if NAs are removed).
> >
>
> And in fact explicitly setting na.action = NULL prevents dropping the
> class:
>
> class(model.frame(y ~ ., data = freeny, na.action = NULL)$y)
> # [1] "ts"
>
> The reason this looks especially like a bug is that it differs from how
> na.omit behaves:
>
> DF <- data.frame(x = c(1, 2, 3), y = c(0, 10, NA))
> is.object(DF$y)
> # [1] FALSE
> class(DF$y) = 'foo'
> is.object(DF$y)
> # [1] TRUE
> class(na.omit(DF)$y)
> # [1] "numeric"
> is.object(na.omit(DF)$y)
> # [1] FALSE
>
>
> That is, similarly presented with a classed object, na.omit strips the
> class *and* the OBJECT attribute.
>
> Thanks,
> Michael Chirico
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Department of Data Analysis and Mathematical Modelling
Ghent University
Coupure Links 653, B-9000 Gent (Belgium)
<https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>

-----------
Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon Mar  5 20:50:41 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 5 Mar 2018 14:50:41 -0500
Subject: [Rd] Unclosed parenthesis in grep.Rd
In-Reply-To: <CANgsd59hAjutKGQc5m-_q0XLsFFunPRZGao1jhNC_AfcHgT3oA@mail.gmail.com>
References: <CAJmOi+PmYn3Xsb7OzsNBLTHQHtSueheg9yTB2=LAPEE2HTtkmw@mail.gmail.com>
 <23196.65416.625348.282322@stat.math.ethz.ch>
 <CANgsd59hAjutKGQc5m-_q0XLsFFunPRZGao1jhNC_AfcHgT3oA@mail.gmail.com>
Message-ID: <f35b4deb-a85a-d47a-816b-f79b52e63002@gmail.com>

On 05/03/2018 11:48 AM, Etienne Sanchez wrote:
> There are probably more unmatched parentheses around:
> 
> detect <- function(file) {
>    text <- paste(readLines(file), collapse = "")
>    nchar(gsub("[^(]", "", text)) != nchar(gsub("[^)]", "", text))
> }
> 
> docs <- list.files("r-source-trunk/src/library",
>                     pattern = "\\.Rd$",
>                     full.names = TRUE,
>                     recursive = TRUE)
> 
> suspicious <- docs[sapply(docs, detect)]
> 
> length(suspicious)
> # [1] 114

Doing an automatic search is a good idea.  Here's a function that finds 
some errors that would be missed by yours, and gives a more informative 
report.

detect <- function(file) {
   text <- readLines(file)
   letters <- strsplit(text, "")
   line <- unlist(lapply(seq_along(letters), function(i) rep(i, 
length(letters[[i]]))))
   column <- unlist(lapply(seq_along(letters), function(i) 
seq_len(length(letters[[i]]))))
   letters <- unlist(letters)
   open <- letters == "("
   close <- letters == ")"
   sum <- cumsum(open) - cumsum(close)

   result <- FALSE
   report <- function(msg, where) {
   	message(msg, paste(file, line[where], column[where], sep=":"))
   	message(text[line[where]])
   	message(paste(c(rep(" ", column[where] - 1), "^"), collapse = ""))
   	## rstudioapi::navigateToFile(file, line[where], column[where])
   }
   if (any(sum < 0)) {
   	report("Extra close paren: ", match(TRUE, sum < 0))
   	result <- TRUE
   }
   if (sum[length(sum)] > 0) {
   	report("Extra open paren: ", length(sum) - match(TRUE, rev(sum == 
0)) + 2)
   	result <- TRUE
   }
}

If you use RStudio, you can uncomment the ## line to have it jump to the 
location of the suspicious entry.

Duncan Murdoch

> 
> 
> 2018-03-05 9:27 GMT+01:00 Martin Maechler <maechler at stat.math.ethz.ch>:
>>
>>>>>>> Hugh Parsonage <hugh.parsonage at gmail.com>
>>>>>>>      on Mon, 5 Mar 2018 13:39:24 +1100 writes:
>>
>>      > Lines 129-131: \code{grep(value = FALSE)} returns a vector
>>      > of the indices of the elements of \code{x} that yielded a
>>      > match (or not, for \code{invert = TRUE}. This will be an
>>      > integer vector unless the input
>>
>>      > There should be a closing parenthesis after \code{invert =
>>      > TRUE}
>>
>> Thank you, Hugh!  I've added the ')' now.
>> Martin
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From therneau at mayo.edu  Mon Mar  5 21:55:30 2018
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Mon, 05 Mar 2018 14:55:30 -0600
Subject: [Rd] backquotes and term.labels
Message-ID: <fd55f7$90njgf@ironport10.mayo.edu>

A user reported a problem with the survdiff function and the use of variables that contain 
a space.? Here is a simple example.? The same issue occurs in survfit for the same reason.

lung2 <- lung
names(lung2)[1] <- "in st"?? # old name is inst
survdiff(Surv(time, status) ~ `in st`, data=lung2)
Error in `[.data.frame`(m, ll) : undefined columns selected

In the body of the code the program want to send all of the right-hand side variables 
forward to the strata() function.? The code looks more or less like this, where m is the 
model frame

 ? Terms <- terms(m)
 ? index <- attr(Terms, "term.labels")
 ? if (length(index) ==0)? X <- rep(1L, n)? # no coariates
 ? else X <- strata(m[index])

For the variable with a space in the name the term.label is "`in st`", and the subscript 
fails.

Is this intended behaviour or a bug?? The issue is that the name of this column in the 
model frame does not have the backtics, while the terms structure does have them.

Terry T.


From wdunlap at tibco.com  Mon Mar  5 22:55:27 2018
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 5 Mar 2018 13:55:27 -0800
Subject: [Rd] backquotes and term.labels
In-Reply-To: <fd55f7$90njgf@ironport10.mayo.edu>
References: <fd55f7$90njgf@ironport10.mayo.edu>
Message-ID: <CAF8bMcb_cW4YgsicfwPWw-bKYLkmKtj+wYqSjqWtJu5GJuJmsg@mail.gmail.com>

I believe this has to do terms() making "term.labels" (hence the dimnames
of "factors")
with deparse(), so that the backquotes are included for non-syntactic
names.  The backquotes
are not in the column names of the input data.frame (nor model frame) so
you get a mismatch
when subscripting the data.frame or model.frame with elements of
terms()$term.labels.

I think you can avoid the problem by adding right after
    ll <- attr(Terms, "term.labels")
the line
    ll <- gsub("^`|`$", "", ll)

E.g.,

> d <- data.frame(check.names=FALSE, y=1/(1:5), `b$a$d`=sin(1:5)+2, `x y
z`=cos(1:5)+2)
> Terms <- terms( y ~ log(`b$a$d`) + `x y z` )
> m <- model.frame(Terms, data=d)
> colnames(m)
[1] "y"            "log(`b$a$d`)" "x y z"
> attr(Terms, "term.labels")
[1] "log(`b$a$d`)" "`x y z`"
>   ll <- attr(Terms, "term.labels")
> gsub("^`|`$", "", ll)
[1] "log(`b$a$d`)" "x y z"

It is a bit of a mess.


Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Mon, Mar 5, 2018 at 12:55 PM, Therneau, Terry M., Ph.D. via R-devel <
r-devel at r-project.org> wrote:

> A user reported a problem with the survdiff function and the use of
> variables that contain a space.  Here is a simple example.  The same issue
> occurs in survfit for the same reason.
>
> lung2 <- lung
> names(lung2)[1] <- "in st"   # old name is inst
> survdiff(Surv(time, status) ~ `in st`, data=lung2)
> Error in `[.data.frame`(m, ll) : undefined columns selected
>
> In the body of the code the program want to send all of the right-hand
> side variables forward to the strata() function.  The code looks more or
> less like this, where m is the model frame
>
>   Terms <- terms(m)
>   index <- attr(Terms, "term.labels")
>   if (length(index) ==0)  X <- rep(1L, n)  # no coariates
>   else X <- strata(m[index])
>
> For the variable with a space in the name the term.label is "`in st`", and
> the subscript fails.
>
> Is this intended behaviour or a bug?  The issue is that the name of this
> column in the model frame does not have the backtics, while the terms
> structure does have them.
>
> Terry T.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From therneau at mayo.edu  Wed Mar  7 14:22:45 2018
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Wed, 07 Mar 2018 07:22:45 -0600
Subject: [Rd] backquotes and term.labels
In-Reply-To: <CAF8bMcb_cW4YgsicfwPWw-bKYLkmKtj+wYqSjqWtJu5GJuJmsg@mail.gmail.com>
References: <fd55f7$90njgf@ironport10.mayo.edu>
 <CAF8bMcb_cW4YgsicfwPWw-bKYLkmKtj+wYqSjqWtJu5GJuJmsg@mail.gmail.com>
Message-ID: <fd55f7$912t1l@ironport10.mayo.edu>

Thanks to Bill Dunlap for the clarification.  On follow-up it turns out that this will be 
an issue for many if not most of the routines in the survival package: a lot of them look 
at the terms structure and make use of the dimnames of attr(terms, 'factors'), which also 
keeps the unneeded backquotes.  Others use the term.labels attribute.  To dodge this I 
will need to create a fixterms() routine which I call at the top of every single routine 
in the library.

Is there a chance for a fix at a higher level?

Terry T.



On 03/05/2018 03:55 PM, William Dunlap wrote:
> I believe this has to do terms() making "term.labels" (hence the dimnames of "factors")
> with deparse(), so that the backquotes are included for non-syntactic names.? The backquotes
> are not in the column names of the input data.frame (nor model frame) so you get a mismatch
> when subscripting the data.frame or model.frame with elements of terms()$term.labels.
> 
> I think you can avoid the problem by adding right after
>  ? ? ll <- attr(Terms, "term.labels")
> the line
>  ? ? ll <- gsub("^`|`$", "", ll)
> 
> E.g.,
> 
>  > d <- data.frame(check.names=FALSE, y=1/(1:5), `b$a$d`=sin(1:5)+2, `x y z`=cos(1:5)+2)
>  > Terms <- terms( y ~ log(`b$a$d`) + `x y z` )
>  > m <- model.frame(Terms, data=d)
>  > colnames(m)
> [1] "y"? ? ? ? ? ? "log(`b$a$d`)" "x y z"
>  > attr(Terms, "term.labels")
> [1] "log(`b$a$d`)" "`x y z`"
>  >? ?ll <- attr(Terms, "term.labels")
>  > gsub("^`|`$", "", ll)
> [1] "log(`b$a$d`)" "x y z"
> 
> It is a bit of a mess.
> 
> 
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com <http://tibco.com>
> 
> On Mon, Mar 5, 2018 at 12:55 PM, Therneau, Terry M., Ph.D. via R-devel 
> <r-devel at r-project.org <mailto:r-devel at r-project.org>> wrote:
> 
>     A user reported a problem with the survdiff function and the use of variables that
>     contain a space.? Here is a simple example.? The same issue occurs in survfit for the
>     same reason.
> 
>     lung2 <- lung
>     names(lung2)[1] <- "in st"?? # old name is inst
>     survdiff(Surv(time, status) ~ `in st`, data=lung2)
>     Error in `[.data.frame`(m, ll) : undefined columns selected
> 
>     In the body of the code the program want to send all of the right-hand side variables
>     forward to the strata() function.? The code looks more or less like this, where m is
>     the model frame
> 
>      ? Terms <- terms(m)
>      ? index <- attr(Terms, "term.labels")
>      ? if (length(index) ==0)? X <- rep(1L, n)? # no coariates
>      ? else X <- strata(m[index])
> 
>     For the variable with a space in the name the term.label is "`in st`", and the
>     subscript fails.
> 
>     Is this intended behaviour or a bug?? The issue is that the name of this column in the
>     model frame does not have the backtics, while the terms structure does have them.
> 
>     Terry T.
> 
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
> 
>


From bbolker at gmail.com  Wed Mar  7 14:39:08 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 7 Mar 2018 08:39:08 -0500
Subject: [Rd] backquotes and term.labels
In-Reply-To: <fd55f7$912t1l@ironport10.mayo.edu>
References: <fd55f7$90njgf@ironport10.mayo.edu>
 <CAF8bMcb_cW4YgsicfwPWw-bKYLkmKtj+wYqSjqWtJu5GJuJmsg@mail.gmail.com>
 <fd55f7$912t1l@ironport10.mayo.edu>
Message-ID: <CABghstS-WpteBUBXWW8=j0hC+mOARdDY443hqc5X3B6yxAnaJA@mail.gmail.com>

I knew I had seen this before but couldn't previously remember where.
https://github.com/lme4/lme4/issues/441 ... I initially fixed with
gsub(), but (pushed by Martin Maechler to do better) I eventually
fixed it by storing the original names of the model frame (without
backticks) as an attribute for later retrieval:
https://github.com/lme4/lme4/commit/56416fc8b3b5153df7df5547082835c5d5725e89.


On Wed, Mar 7, 2018 at 8:22 AM, Therneau, Terry M., Ph.D. via R-devel
<r-devel at r-project.org> wrote:
> Thanks to Bill Dunlap for the clarification.  On follow-up it turns out that
> this will be an issue for many if not most of the routines in the survival
> package: a lot of them look at the terms structure and make use of the
> dimnames of attr(terms, 'factors'), which also keeps the unneeded
> backquotes.  Others use the term.labels attribute.  To dodge this I will
> need to create a fixterms() routine which I call at the top of every single
> routine in the library.
>
> Is there a chance for a fix at a higher level?
>
> Terry T.
>
>
>
> On 03/05/2018 03:55 PM, William Dunlap wrote:
>>
>> I believe this has to do terms() making "term.labels" (hence the dimnames
>> of "factors")
>> with deparse(), so that the backquotes are included for non-syntactic
>> names.  The backquotes
>> are not in the column names of the input data.frame (nor model frame) so
>> you get a mismatch
>> when subscripting the data.frame or model.frame with elements of
>> terms()$term.labels.
>>
>> I think you can avoid the problem by adding right after
>>      ll <- attr(Terms, "term.labels")
>> the line
>>      ll <- gsub("^`|`$", "", ll)
>>
>> E.g.,
>>
>>  > d <- data.frame(check.names=FALSE, y=1/(1:5), `b$a$d`=sin(1:5)+2, `x y
>> z`=cos(1:5)+2)
>>  > Terms <- terms( y ~ log(`b$a$d`) + `x y z` )
>>  > m <- model.frame(Terms, data=d)
>>  > colnames(m)
>> [1] "y"            "log(`b$a$d`)" "x y z"
>>  > attr(Terms, "term.labels")
>> [1] "log(`b$a$d`)" "`x y z`"
>>  >   ll <- attr(Terms, "term.labels")
>>  > gsub("^`|`$", "", ll)
>> [1] "log(`b$a$d`)" "x y z"
>>
>> It is a bit of a mess.
>>
>>
>> Bill Dunlap
>> TIBCO Software
>> wdunlap tibco.com <http://tibco.com>
>>
>> On Mon, Mar 5, 2018 at 12:55 PM, Therneau, Terry M., Ph.D. via R-devel
>> <r-devel at r-project.org <mailto:r-devel at r-project.org>> wrote:
>>
>>     A user reported a problem with the survdiff function and the use of
>> variables that
>>     contain a space.  Here is a simple example.  The same issue occurs in
>> survfit for the
>>     same reason.
>>
>>     lung2 <- lung
>>     names(lung2)[1] <- "in st"   # old name is inst
>>     survdiff(Surv(time, status) ~ `in st`, data=lung2)
>>     Error in `[.data.frame`(m, ll) : undefined columns selected
>>
>>     In the body of the code the program want to send all of the right-hand
>> side variables
>>     forward to the strata() function.  The code looks more or less like
>> this, where m is
>>     the model frame
>>
>>        Terms <- terms(m)
>>        index <- attr(Terms, "term.labels")
>>        if (length(index) ==0)  X <- rep(1L, n)  # no coariates
>>        else X <- strata(m[index])
>>
>>     For the variable with a space in the name the term.label is "`in st`",
>> and the
>>     subscript fails.
>>
>>     Is this intended behaviour or a bug?  The issue is that the name of
>> this column in the
>>     model frame does not have the backtics, while the terms structure does
>> have them.
>>
>>     Terry T.
>>
>>     ______________________________________________
>>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>     https://stat.ethz.ch/mailman/listinfo/r-devel
>>     <https://stat.ethz.ch/mailman/listinfo/r-devel>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Thu Mar  8 15:39:42 2018
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 08 Mar 2018 08:39:42 -0600
Subject: [Rd] Fwd: Re: [EXTERNAL] Re:  backquotes and term.labels
In-Reply-To: <d0ca8b9a-bcf6-f01b-a4c2-445e28cb7fa4@mayo.edu>
References: <d0ca8b9a-bcf6-f01b-a4c2-445e28cb7fa4@mayo.edu>
Message-ID: <fd55f7$91bjv9@ironport10.mayo.edu>

Ben,

Looking at your notes, it appears that your solution is to write your own terms() function
for lme.? It is easy to verify that the "varnames.fixed" attribute is not returned by the
ususal terms function.

Then I also need to write my own terms function for the survival and coxme pacakges?
Because of the need to treat strata() terms in a special way I manipulate the
formula/terms in nearly every routine.

Extrapolating: every R package that tries to examine formulas and partition them into bits
needs its own terms function?? This does not look like a good solution to me.

On 03/07/2018 07:39 AM, Ben Bolker wrote:
> I knew I had seen this before but couldn't previously remember where.
> https://github.com/lme4/lme4/issues/441 ... I initially fixed with
> gsub(), but (pushed by Martin Maechler to do better) I eventually
> fixed it by storing the original names of the model frame (without
> backticks) as an attribute for later retrieval:
> https://github.com/lme4/lme4/commit/56416fc8b3b5153df7df5547082835c5d5725e89.
>
>
> On Wed, Mar 7, 2018 at 8:22 AM, Therneau, Terry M., Ph.D. via R-devel
> <r-devel at r-project.org> wrote:
>> Thanks to Bill Dunlap for the clarification.  On follow-up it turns out that
>> this will be an issue for many if not most of the routines in the survival
>> package: a lot of them look at the terms structure and make use of the
>> dimnames of attr(terms, 'factors'), which also keeps the unneeded
>> backquotes.  Others use the term.labels attribute.  To dodge this I will
>> need to create a fixterms() routine which I call at the top of every single
>> routine in the library.
>>
>> Is there a chance for a fix at a higher level?
>>
>> Terry T.
>>
>>
>>
>> On 03/05/2018 03:55 PM, William Dunlap wrote:
>>> I believe this has to do terms() making "term.labels" (hence the dimnames
>>> of "factors")
>>> with deparse(), so that the backquotes are included for non-syntactic
>>> names.  The backquotes
>>> are not in the column names of the input data.frame (nor model frame) so
>>> you get a mismatch
>>> when subscripting the data.frame or model.frame with elements of
>>> terms()$term.labels.
>>>
>>> I think you can avoid the problem by adding right after
>>>       ll <- attr(Terms, "term.labels")
>>> the line
>>>       ll <- gsub("^`|`$", "", ll)
>>>
>>> E.g.,
>>>
>>>   > d <- data.frame(check.names=FALSE, y=1/(1:5), `b$a$d`=sin(1:5)+2, `x y
>>> z`=cos(1:5)+2)
>>>   > Terms <- terms( y ~ log(`b$a$d`) + `x y z` )
>>>   > m <- model.frame(Terms, data=d)
>>>   > colnames(m)
>>> [1] "y"            "log(`b$a$d`)" "x y z"
>>>   > attr(Terms, "term.labels")
>>> [1] "log(`b$a$d`)" "`x y z`"
>>>   >   ll <- attr(Terms, "term.labels")
>>>   > gsub("^`|`$", "", ll)
>>> [1] "log(`b$a$d`)" "x y z"
>>>
>>> It is a bit of a mess.
>>>
>>>
>>> Bill Dunlap
>>> TIBCO Software
>>> wdunlap tibco.com <http://tibco.com>
>>>
>>> On Mon, Mar 5, 2018 at 12:55 PM, Therneau, Terry M., Ph.D. via R-devel
>>> <r-devel at r-project.org <mailto:r-devel at r-project.org>> wrote:
>>>
>>>      A user reported a problem with the survdiff function and the use of
>>> variables that
>>>      contain a space.  Here is a simple example.  The same issue occurs in
>>> survfit for the
>>>      same reason.
>>>
>>>      lung2 <- lung
>>>      names(lung2)[1] <- "in st"   # old name is inst
>>>      survdiff(Surv(time, status) ~ `in st`, data=lung2)
>>>      Error in `[.data.frame`(m, ll) : undefined columns selected
>>>
>>>      In the body of the code the program want to send all of the right-hand
>>> side variables
>>>      forward to the strata() function.  The code looks more or less like
>>> this, where m is
>>>      the model frame
>>>
>>>         Terms <- terms(m)
>>>         index <- attr(Terms, "term.labels")
>>>         if (length(index) ==0)  X <- rep(1L, n)  # no coariates
>>>         else X <- strata(m[index])
>>>
>>>      For the variable with a space in the name the term.label is "`in st`",
>>> and the
>>>      subscript fails.
>>>
>>>      Is this intended behaviour or a bug?  The issue is that the name of
>>> this column in the
>>>      model frame does not have the backtics, while the terms structure does
>>> have them.
>>>
>>>      Terry T.
>>>
>>>      ______________________________________________
>>>      R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>>      https://stat.ethz.ch/mailman/listinfo/r-devel
>>>      <https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From bbolker at gmail.com  Thu Mar  8 15:42:40 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 8 Mar 2018 09:42:40 -0500
Subject: [Rd] Fwd: Re: [EXTERNAL] Re: backquotes and term.labels
In-Reply-To: <fd55f7$91bjv9@ironport10.mayo.edu>
References: <d0ca8b9a-bcf6-f01b-a4c2-445e28cb7fa4@mayo.edu>
 <fd55f7$91bjv9@ironport10.mayo.edu>
Message-ID: <CABghstR_oezPZt4ch5xm38BFKEHhZOTZXE3sKLjwvR7zm6J9gA@mail.gmail.com>

Meant to respond to this but forgot.

 I didn't write a new terms() function  -- I added an attribute to the
terms() (a vector of the names
of the constructed model matrix), thus preserving the information at
the point when it was available.
  I do agree that it would be preferable to have an upstream fix ...


On Thu, Mar 8, 2018 at 9:39 AM, Therneau, Terry M., Ph.D. via R-devel
<r-devel at r-project.org> wrote:
> Ben,
>
>
> Looking at your notes, it appears that your solution is to write your own
> terms() function
> for lme.  It is easy to verify that the "varnames.fixed" attribute is not
> returned by the
> ususal terms function.
>
> Then I also need to write my own terms function for the survival and coxme
> pacakges?
> Because of the need to treat strata() terms in a special way I manipulate
> the
> formula/terms in nearly every routine.
>
> Extrapolating: every R package that tries to examine formulas and partition
> them into bits
> needs its own terms function?  This does not look like a good solution to
> me.
>
> On 03/07/2018 07:39 AM, Ben Bolker wrote:
>>
>> I knew I had seen this before but couldn't previously remember where.
>> https://github.com/lme4/lme4/issues/441 ... I initially fixed with
>> gsub(), but (pushed by Martin Maechler to do better) I eventually
>> fixed it by storing the original names of the model frame (without
>> backticks) as an attribute for later retrieval:
>>
>> https://github.com/lme4/lme4/commit/56416fc8b3b5153df7df5547082835c5d5725e89.
>>
>>
>> On Wed, Mar 7, 2018 at 8:22 AM, Therneau, Terry M., Ph.D. via R-devel
>> <r-devel at r-project.org> wrote:
>>>
>>> Thanks to Bill Dunlap for the clarification.  On follow-up it turns out
>>> that
>>> this will be an issue for many if not most of the routines in the
>>> survival
>>> package: a lot of them look at the terms structure and make use of the
>>> dimnames of attr(terms, 'factors'), which also keeps the unneeded
>>> backquotes.  Others use the term.labels attribute.  To dodge this I will
>>> need to create a fixterms() routine which I call at the top of every
>>> single
>>> routine in the library.
>>>
>>> Is there a chance for a fix at a higher level?
>>>
>>> Terry T.
>>>
>>>
>>>
>>> On 03/05/2018 03:55 PM, William Dunlap wrote:
>>>>
>>>> I believe this has to do terms() making "term.labels" (hence the
>>>> dimnames
>>>> of "factors")
>>>> with deparse(), so that the backquotes are included for non-syntactic
>>>> names.  The backquotes
>>>> are not in the column names of the input data.frame (nor model frame) so
>>>> you get a mismatch
>>>> when subscripting the data.frame or model.frame with elements of
>>>> terms()$term.labels.
>>>>
>>>> I think you can avoid the problem by adding right after
>>>>       ll <- attr(Terms, "term.labels")
>>>> the line
>>>>       ll <- gsub("^`|`$", "", ll)
>>>>
>>>> E.g.,
>>>>
>>>>   > d <- data.frame(check.names=FALSE, y=1/(1:5), `b$a$d`=sin(1:5)+2, `x
>>>> y
>>>> z`=cos(1:5)+2)
>>>>   > Terms <- terms( y ~ log(`b$a$d`) + `x y z` )
>>>>   > m <- model.frame(Terms, data=d)
>>>>   > colnames(m)
>>>> [1] "y"            "log(`b$a$d`)" "x y z"
>>>>   > attr(Terms, "term.labels")
>>>> [1] "log(`b$a$d`)" "`x y z`"
>>>>   >   ll <- attr(Terms, "term.labels")
>>>>   > gsub("^`|`$", "", ll)
>>>> [1] "log(`b$a$d`)" "x y z"
>>>>
>>>> It is a bit of a mess.
>>>>
>>>>
>>>> Bill Dunlap
>>>> TIBCO Software
>>>> wdunlap tibco.com <http://tibco.com>
>>>>
>>>> On Mon, Mar 5, 2018 at 12:55 PM, Therneau, Terry M., Ph.D. via R-devel
>>>> <r-devel at r-project.org <mailto:r-devel at r-project.org>> wrote:
>>>>
>>>>      A user reported a problem with the survdiff function and the use of
>>>> variables that
>>>>      contain a space.  Here is a simple example.  The same issue occurs
>>>> in
>>>> survfit for the
>>>>      same reason.
>>>>
>>>>      lung2 <- lung
>>>>      names(lung2)[1] <- "in st"   # old name is inst
>>>>      survdiff(Surv(time, status) ~ `in st`, data=lung2)
>>>>      Error in `[.data.frame`(m, ll) : undefined columns selected
>>>>
>>>>      In the body of the code the program want to send all of the
>>>> right-hand
>>>> side variables
>>>>      forward to the strata() function.  The code looks more or less like
>>>> this, where m is
>>>>      the model frame
>>>>
>>>>         Terms <- terms(m)
>>>>         index <- attr(Terms, "term.labels")
>>>>         if (length(index) ==0)  X <- rep(1L, n)  # no coariates
>>>>         else X <- strata(m[index])
>>>>
>>>>      For the variable with a space in the name the term.label is "`in
>>>> st`",
>>>> and the
>>>>      subscript fails.
>>>>
>>>>      Is this intended behaviour or a bug?  The issue is that the name of
>>>> this column in the
>>>>      model frame does not have the backtics, while the terms structure
>>>> does
>>>> have them.
>>>>
>>>>      Terry T.
>>>>
>>>>      ______________________________________________
>>>>      R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>>>>      https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>      <https://stat.ethz.ch/mailman/listinfo/r-devel>
>>>>
>>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Thu Mar  8 16:07:12 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 8 Mar 2018 16:07:12 +0100
Subject: [Rd] Fwd: Re: [EXTERNAL] Re: backquotes and term.labels
In-Reply-To: <CABghstR_oezPZt4ch5xm38BFKEHhZOTZXE3sKLjwvR7zm6J9gA@mail.gmail.com>
References: <d0ca8b9a-bcf6-f01b-a4c2-445e28cb7fa4@mayo.edu>
 <fd55f7$91bjv9@ironport10.mayo.edu>
 <CABghstR_oezPZt4ch5xm38BFKEHhZOTZXE3sKLjwvR7zm6J9gA@mail.gmail.com>
Message-ID: <23201.20896.4307.918045@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Thu, 8 Mar 2018 09:42:40 -0500 writes:

    > Meant to respond to this but forgot.
    > I didn't write a new terms() function  -- I added an attribute to the
    > terms() (a vector of the names
    > of the constructed model matrix), thus preserving the information at
    > the point when it was available.
    > I do agree that it would be preferable to have an upstream fix ...

did anybody ever propose a small patch to the upstream sources ?

-- including a REPREX (or 2: one for lme4, one for survival) 

I'm open to look at one .. not for the next few days, though.

Martin


    > On Thu, Mar 8, 2018 at 9:39 AM, Therneau, Terry M., Ph.D. via R-devel
    > <r-devel at r-project.org> wrote:
    >> Ben,
    >> 
    >> 
    >> Looking at your notes, it appears that your solution is to write your own
    >> terms() function
    >> for lme.  It is easy to verify that the "varnames.fixed" attribute is not
    >> returned by the
    >> ususal terms function.
    >> 
    >> Then I also need to write my own terms function for the survival and coxme
    >> pacakges?
    >> Because of the need to treat strata() terms in a special way I manipulate
    >> the
    >> formula/terms in nearly every routine.
    >> 
    >> Extrapolating: every R package that tries to examine formulas and partition
    >> them into bits
    >> needs its own terms function?  This does not look like a good solution to
    >> me.
    >> 
    >> On 03/07/2018 07:39 AM, Ben Bolker wrote:
    >>> 
    >>> I knew I had seen this before but couldn't previously remember where.
    >>> https://github.com/lme4/lme4/issues/441 ... I initially fixed with
    >>> gsub(), but (pushed by Martin Maechler to do better) I eventually
    >>> fixed it by storing the original names of the model frame (without
    >>> backticks) as an attribute for later retrieval:
    >>> 
    >>> https://github.com/lme4/lme4/commit/56416fc8b3b5153df7df5547082835c5d5725e89.
    >>> 
    >>> 
    >>> On Wed, Mar 7, 2018 at 8:22 AM, Therneau, Terry M., Ph.D. via R-devel
    >>> <r-devel at r-project.org> wrote:
    >>>> 
    >>>> Thanks to Bill Dunlap for the clarification.  On follow-up it turns out
    >>>> that
    >>>> this will be an issue for many if not most of the routines in the
    >>>> survival
    >>>> package: a lot of them look at the terms structure and make use of the
    >>>> dimnames of attr(terms, 'factors'), which also keeps the unneeded
    >>>> backquotes.  Others use the term.labels attribute.  To dodge this I will
    >>>> need to create a fixterms() routine which I call at the top of every
    >>>> single
    >>>> routine in the library.
    >>>> 
    >>>> Is there a chance for a fix at a higher level?
    >>>> 
    >>>> Terry T.
    >>>> 
    >>>> 
    >>>> 
    >>>> On 03/05/2018 03:55 PM, William Dunlap wrote:
    >>>>> 
    >>>>> I believe this has to do terms() making "term.labels" (hence the
    >>>>> dimnames
    >>>>> of "factors")
    >>>>> with deparse(), so that the backquotes are included for non-syntactic
    >>>>> names.  The backquotes
    >>>>> are not in the column names of the input data.frame (nor model frame) so
    >>>>> you get a mismatch
    >>>>> when subscripting the data.frame or model.frame with elements of
    >>>>> terms()$term.labels.
    >>>>> 
    >>>>> I think you can avoid the problem by adding right after
    >>>>> ll <- attr(Terms, "term.labels")
    >>>>> the line
    >>>>> ll <- gsub("^`|`$", "", ll)
    >>>>> 
    >>>>> E.g.,
    >>>>> 
    >>>>> > d <- data.frame(check.names=FALSE, y=1/(1:5), `b$a$d`=sin(1:5)+2, `x
    >>>>> y
    >>>>> z`=cos(1:5)+2)
    >>>>> > Terms <- terms( y ~ log(`b$a$d`) + `x y z` )
    >>>>> > m <- model.frame(Terms, data=d)
    >>>>> > colnames(m)
    >>>>> [1] "y"            "log(`b$a$d`)" "x y z"
    >>>>> > attr(Terms, "term.labels")
    >>>>> [1] "log(`b$a$d`)" "`x y z`"
    >>>>> >   ll <- attr(Terms, "term.labels")
    >>>>> > gsub("^`|`$", "", ll)
    >>>>> [1] "log(`b$a$d`)" "x y z"
    >>>>> 
    >>>>> It is a bit of a mess.
    >>>>> 
    >>>>> 
    >>>>> Bill Dunlap
    >>>>> TIBCO Software
    >>>>> wdunlap tibco.com <http://tibco.com>
    >>>>> 
    >>>>> On Mon, Mar 5, 2018 at 12:55 PM, Therneau, Terry M., Ph.D. via R-devel
    >>>>> <r-devel at r-project.org <mailto:r-devel at r-project.org>> wrote:
    >>>>> 
    >>>>> A user reported a problem with the survdiff function and the use of
    >>>>> variables that
    >>>>> contain a space.  Here is a simple example.  The same issue occurs
    >>>>> in
    >>>>> survfit for the
    >>>>> same reason.
    >>>>> 
    >>>>> lung2 <- lung
    >>>>> names(lung2)[1] <- "in st"   # old name is inst
    >>>>> survdiff(Surv(time, status) ~ `in st`, data=lung2)
    >>>>> Error in `[.data.frame`(m, ll) : undefined columns selected
    >>>>> 
    >>>>> In the body of the code the program want to send all of the
    >>>>> right-hand
    >>>>> side variables
    >>>>> forward to the strata() function.  The code looks more or less like
    >>>>> this, where m is
    >>>>> the model frame
    >>>>> 
    >>>>> Terms <- terms(m)
    >>>>> index <- attr(Terms, "term.labels")
    >>>>> if (length(index) ==0)  X <- rep(1L, n)  # no coariates
    >>>>> else X <- strata(m[index])
    >>>>> 
    >>>>> For the variable with a space in the name the term.label is "`in
    >>>>> st`",
    >>>>> and the
    >>>>> subscript fails.
    >>>>> 
    >>>>> Is this intended behaviour or a bug?  The issue is that the name of
    >>>>> this column in the
    >>>>> model frame does not have the backtics, while the terms structure
    >>>>> does
    >>>>> have them.
    >>>>> 
    >>>>> Terry T.
    >>>>> 
    >>>>> ______________________________________________
    >>>>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
    >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>>>> <https://stat.ethz.ch/mailman/listinfo/r-devel>
    >>>>> 
    >>>>> 
    >>>> ______________________________________________
    >>>> R-devel at r-project.org mailing list
    >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From bbolker at gmail.com  Thu Mar  8 17:11:28 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 8 Mar 2018 11:11:28 -0500
Subject: [Rd] Fwd: Re: [EXTERNAL] Re: backquotes and term.labels
In-Reply-To: <23201.20896.4307.918045@stat.math.ethz.ch>
References: <d0ca8b9a-bcf6-f01b-a4c2-445e28cb7fa4@mayo.edu>
 <fd55f7$91bjv9@ironport10.mayo.edu>
 <CABghstR_oezPZt4ch5xm38BFKEHhZOTZXE3sKLjwvR7zm6J9gA@mail.gmail.com>
 <23201.20896.4307.918045@stat.math.ethz.ch>
Message-ID: <bf201c4c-b554-7963-5e77-81196637532a@gmail.com>



On 18-03-08 10:07 AM, Martin Maechler wrote:
>>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>>     on Thu, 8 Mar 2018 09:42:40 -0500 writes:
> 
>     > Meant to respond to this but forgot.
>     > I didn't write a new terms() function  -- I added an attribute to the
>     > terms() (a vector of the names
>     > of the constructed model matrix), thus preserving the information at
>     > the point when it was available.
>     > I do agree that it would be preferable to have an upstream fix ...
> 
> did anybody ever propose a small patch to the upstream sources ?
> 
> -- including a REPREX (or 2: one for lme4, one for survival) 
> 
> I'm open to look at one .. not for the next few days, though.
> 
> Martin

  Didn't get around to it ...  a bit worried about doing it 100%
back-compatibly, also a bit scared in general of messing with such deep
stuff. It could probably done *non*-backward-compatibly simply by
changing line 459 of library/stats/R/models.R to

    varnames <- vapply(vars, function(x) deparse2(x,backtick=FALSE),
        " ")[-1L]

... ?


> 
> 
>     > On Thu, Mar 8, 2018 at 9:39 AM, Therneau, Terry M., Ph.D. via R-devel
>     > <r-devel at r-project.org> wrote:
>     >> Ben,
>     >> 
>     >> 
>     >> Looking at your notes, it appears that your solution is to write your own
>     >> terms() function
>     >> for lme.  It is easy to verify that the "varnames.fixed" attribute is not
>     >> returned by the
>     >> ususal terms function.
>     >> 
>     >> Then I also need to write my own terms function for the survival and coxme
>     >> pacakges?
>     >> Because of the need to treat strata() terms in a special way I manipulate
>     >> the
>     >> formula/terms in nearly every routine.
>     >> 
>     >> Extrapolating: every R package that tries to examine formulas and partition
>     >> them into bits
>     >> needs its own terms function?  This does not look like a good solution to
>     >> me.
>     >> 
>     >> On 03/07/2018 07:39 AM, Ben Bolker wrote:
>     >>> 
>     >>> I knew I had seen this before but couldn't previously remember where.
>     >>> https://github.com/lme4/lme4/issues/441 ... I initially fixed with
>     >>> gsub(), but (pushed by Martin Maechler to do better) I eventually
>     >>> fixed it by storing the original names of the model frame (without
>     >>> backticks) as an attribute for later retrieval:
>     >>> 
>     >>> https://github.com/lme4/lme4/commit/56416fc8b3b5153df7df5547082835c5d5725e89.
>     >>> 
>     >>> 
>     >>> On Wed, Mar 7, 2018 at 8:22 AM, Therneau, Terry M., Ph.D. via R-devel
>     >>> <r-devel at r-project.org> wrote:
>     >>>> 
>     >>>> Thanks to Bill Dunlap for the clarification.  On follow-up it turns out
>     >>>> that
>     >>>> this will be an issue for many if not most of the routines in the
>     >>>> survival
>     >>>> package: a lot of them look at the terms structure and make use of the
>     >>>> dimnames of attr(terms, 'factors'), which also keeps the unneeded
>     >>>> backquotes.  Others use the term.labels attribute.  To dodge this I will
>     >>>> need to create a fixterms() routine which I call at the top of every
>     >>>> single
>     >>>> routine in the library.
>     >>>> 
>     >>>> Is there a chance for a fix at a higher level?
>     >>>> 
>     >>>> Terry T.
>     >>>> 
>     >>>> 
>     >>>> 
>     >>>> On 03/05/2018 03:55 PM, William Dunlap wrote:
>     >>>>> 
>     >>>>> I believe this has to do terms() making "term.labels" (hence the
>     >>>>> dimnames
>     >>>>> of "factors")
>     >>>>> with deparse(), so that the backquotes are included for non-syntactic
>     >>>>> names.  The backquotes
>     >>>>> are not in the column names of the input data.frame (nor model frame) so
>     >>>>> you get a mismatch
>     >>>>> when subscripting the data.frame or model.frame with elements of
>     >>>>> terms()$term.labels.
>     >>>>> 
>     >>>>> I think you can avoid the problem by adding right after
>     >>>>> ll <- attr(Terms, "term.labels")
>     >>>>> the line
>     >>>>> ll <- gsub("^`|`$", "", ll)
>     >>>>> 
>     >>>>> E.g.,
>     >>>>> 
>     >>>>> > d <- data.frame(check.names=FALSE, y=1/(1:5), `b$a$d`=sin(1:5)+2, `x
>     >>>>> y
>     >>>>> z`=cos(1:5)+2)
>     >>>>> > Terms <- terms( y ~ log(`b$a$d`) + `x y z` )
>     >>>>> > m <- model.frame(Terms, data=d)
>     >>>>> > colnames(m)
>     >>>>> [1] "y"            "log(`b$a$d`)" "x y z"
>     >>>>> > attr(Terms, "term.labels")
>     >>>>> [1] "log(`b$a$d`)" "`x y z`"
>     >>>>> >   ll <- attr(Terms, "term.labels")
>     >>>>> > gsub("^`|`$", "", ll)
>     >>>>> [1] "log(`b$a$d`)" "x y z"
>     >>>>> 
>     >>>>> It is a bit of a mess.
>     >>>>> 
>     >>>>> 
>     >>>>> Bill Dunlap
>     >>>>> TIBCO Software
>     >>>>> wdunlap tibco.com <http://tibco.com>
>     >>>>> 
>     >>>>> On Mon, Mar 5, 2018 at 12:55 PM, Therneau, Terry M., Ph.D. via R-devel
>     >>>>> <r-devel at r-project.org <mailto:r-devel at r-project.org>> wrote:
>     >>>>> 
>     >>>>> A user reported a problem with the survdiff function and the use of
>     >>>>> variables that
>     >>>>> contain a space.  Here is a simple example.  The same issue occurs
>     >>>>> in
>     >>>>> survfit for the
>     >>>>> same reason.
>     >>>>> 
>     >>>>> lung2 <- lung
>     >>>>> names(lung2)[1] <- "in st"   # old name is inst
>     >>>>> survdiff(Surv(time, status) ~ `in st`, data=lung2)
>     >>>>> Error in `[.data.frame`(m, ll) : undefined columns selected
>     >>>>> 
>     >>>>> In the body of the code the program want to send all of the
>     >>>>> right-hand
>     >>>>> side variables
>     >>>>> forward to the strata() function.  The code looks more or less like
>     >>>>> this, where m is
>     >>>>> the model frame
>     >>>>> 
>     >>>>> Terms <- terms(m)
>     >>>>> index <- attr(Terms, "term.labels")
>     >>>>> if (length(index) ==0)  X <- rep(1L, n)  # no coariates
>     >>>>> else X <- strata(m[index])
>     >>>>> 
>     >>>>> For the variable with a space in the name the term.label is "`in
>     >>>>> st`",
>     >>>>> and the
>     >>>>> subscript fails.
>     >>>>> 
>     >>>>> Is this intended behaviour or a bug?  The issue is that the name of
>     >>>>> this column in the
>     >>>>> model frame does not have the backtics, while the terms structure
>     >>>>> does
>     >>>>> have them.
>     >>>>> 
>     >>>>> Terry T.
>     >>>>> 
>     >>>>> ______________________________________________
>     >>>>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     >>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >>>>> <https://stat.ethz.ch/mailman/listinfo/r-devel>
>     >>>>> 
>     >>>>> 
>     >>>> ______________________________________________
>     >>>> R-devel at r-project.org mailing list
>     >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>     >> 
>     >> 
>     >> ______________________________________________
>     >> R-devel at r-project.org mailing list
>     >> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>     > ______________________________________________
>     > R-devel at r-project.org mailing list
>     > https://stat.ethz.ch/mailman/listinfo/r-devel
>


From therneau at mayo.edu  Thu Mar  8 17:24:49 2018
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Thu, 08 Mar 2018 10:24:49 -0600
Subject: [Rd] [EXTERNAL] Re:  Fwd: Re: Re: backquotes and term.labels
In-Reply-To: <CABghstR_oezPZt4ch5xm38BFKEHhZOTZXE3sKLjwvR7zm6J9gA@mail.gmail.com>
References: <d0ca8b9a-bcf6-f01b-a4c2-445e28cb7fa4@mayo.edu>
 <fd55f7$91bjv9@ironport10.mayo.edu>
 <CABghstR_oezPZt4ch5xm38BFKEHhZOTZXE3sKLjwvR7zm6J9gA@mail.gmail.com>
Message-ID: <fd55f7$91cvba@ironport10.mayo.edu>

Ben,
I looked at the source code you pointed out, and the line
     fr <- fr[attr(terms(fr),"varnames.fixed")]

sure looks to me as though the terms() function has returned an object with a 
varnames.fixed attribute.  Either that or your code has inside knowledge that a reader 
like me won't know.  Given what you said I will guess that terms(x) returns the terms 
attribute of x if that already exists, doing no processing, and you know that fr has 
already been thusly modified?

I have code that uses the variables, term.names, and factors attributes of the terms() 
structure, and all of those have the backticks.  I know the second two will currently 
break the coxme and survival packages, I haven't chased down the effect on the first.


On 03/08/2018 08:42 AM, Ben Bolker wrote:
> Meant to respond to this but forgot.
> 
>   I didn't write a new terms() function  -- I added an attribute to the
> terms() (a vector of the names
> of the constructed model matrix), thus preserving the information at
> the point when it was available.
>    I do agree that it would be preferable to have an upstream fix ...
>


From ligges at statistik.tu-dortmund.de  Thu Mar  8 18:05:10 2018
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 8 Mar 2018 18:05:10 +0100
Subject: [Rd] CRAN incoming services and winbuilder down Mar 9-10
Message-ID: <0dc1c46d-ec94-86fd-a8d5-b0b54e9cb1c4@statistik.tu-dortmund.de>

Dear list,

due to a full power shutdown in the relevant building at TU Dortmund 
University we have to shut down winbuilder and the CRAN incoming check 
service from
Mar 9, 5pm CET
to
Mar 10, 5pm CET

Best,
Uwe Ligges
(CRAN team)


From maechler at stat.math.ethz.ch  Thu Mar  8 18:09:52 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 8 Mar 2018 18:09:52 +0100
Subject: [Rd] Bug report - duplicate row names with as.data.frame()
In-Reply-To: <1519924984.4751.69.camel@iarc.fr>
References: <CA+Dgj-7g35bUpULcrqKiyM8daHWOEY-MzU=7Snee6SUjQWrF6w@mail.gmail.com>
 <1519924984.4751.69.camel@iarc.fr>
Message-ID: <23201.28256.962264.843553@stat.math.ethz.ch>

>>>>> Martyn Plummer <plummerm at iarc.fr>
>>>>>     on Thu, 1 Mar 2018 17:23:04 +0000 writes:

    > On Thu, 2018-03-01 at 09:36 -0500, Ron wrote:
    >> Hello,
    >> 
    >> I'd like to report what I think is a bug: using as.data.frame() we can
    >> create duplicate row names in a data frame. R version 3.4.3 (current stable
    >> release).
    >> 
    >> Rather than paste code in an email, please see the example formatted code
    >> here:
    >> https://stackoverflow.com/questions/49031523/duplicate-row-names-in-r-using-as-data-frame
    >> 
    >> I posted to StackOverflow, and consensus was that we should proceed with
    >> this as a bug report.

    > Yes that is definitely a bug. 

    > The end of the as.data.frame.matrix method has:

    > attr(value, "row.names") <- row.names
    > class(value) <- "data.frame"
    > value

    > Changing this to:

    > class(value) <- "data.frame"
    > row.names(value) <- row.names
    > value

    > ensures that the row.names<-.data.frame method is called with its built
    > -in check for duplicate names.

    > There are quite a few as.data.frame methods so this could be a
    > recurring problem. I will check.

and Martyn found other cases and proposed a more principled
approach to conceptually all such situations.

>From that, I have addressed at least the current bug
(and its immediate surroundings).  I now have committed the
following to 'R-devel' (= the R sources development "trunk") :

------------------------------------------------------------------------
r74373 | maechler | 2018-03-08 17:49:32 +0100 (Thu, 08. Mar 2018)

   M doc/NEWS.Rd
   M src/library/base/R/dataframe.R
   M src/library/base/man/as.data.frame.Rd
   M src/library/base/man/row.names.Rd
   M tests/eval-etc.Rout.save
   M tests/reg-tests-1c.R
   M tests/reg-tests-1d.R
   M tests/reg-tests-2.Rout.save

duplicated rownames in as.data.frame.matrix() are handled now (gracefully by default)
------------------------------------------------------------------------

The NEWS entry is

    ? Some as.data.frame() methods, notably the matrix one, are now
      more careful in not accepting duplicated or NA row names, and by
      default produce unique non-NA row names.  This is based on
      row.names(x, make.names = *) <- rNms where make.names is a new
      logical, with back compatible default.


and the not-quite-back-compatible API change is that the
`row.names<-` S3 generic function now does have a new optional
'make.names' argument -- with back compatible default FALSE
(meaning that invalid rownames by default continue to lead to an error).

It may happen that this or the other changes have some negative
impact on the CRAN package check results, (I do expect *some*
check problems), e.g. producing new warnings if packages use the
current R <= 3.4.x  signature of `row.names<-`

But I think the new feature of allowing indicating on how to treat
invalid row names --- notably, allowing to use  make.names(*, unique=TRUE)
getting valid row names --- is attractive and leads to Martyn's
proposed behavior which entails that  as.data.frame.*(x)  (and
similar coercions to data frames) should typically _handle_
invalid row names rather than signal errors.

Feedback is welcome !

((though I will be slow in replying, going basicaly off work for
  my early-starting weekend in the Alps))

Martin Maechler,
ETH Zurich


From bbolker at gmail.com  Thu Mar  8 18:51:15 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Thu, 8 Mar 2018 12:51:15 -0500
Subject: [Rd] [EXTERNAL] Re:  Fwd: Re: Re: backquotes and term.labels
In-Reply-To: <fd55f7$91cvb9@ironport10.mayo.edu>
References: <d0ca8b9a-bcf6-f01b-a4c2-445e28cb7fa4@mayo.edu>
 <fd55f7$91bjv9@ironport10.mayo.edu>
 <CABghstR_oezPZt4ch5xm38BFKEHhZOTZXE3sKLjwvR7zm6J9gA@mail.gmail.com>
 <fd55f7$91cvb9@ironport10.mayo.edu>
Message-ID: <001cc8ed-aabe-cfc6-d46b-7ea0f9b3b05e@gmail.com>


  That's more or less right.  We wrote a terms.merMod method, which
accesses the terms component of the @frame slot, which we have modified
upstream ...

  Do you mean term.labels rather than term.names?

BTW ?terms.object says (under the "term.labels" element):

 Non-syntactic names will be quoted by backticks: this makes
          it easier to re-construct the formula from the term labels.

  This suggests, alas, that this was an intentional design decision --
so harder to change.

  cheers
   Ben


On 18-03-08 11:24 AM, Therneau, Terry M., Ph.D. wrote:
> Ben,
> I looked at the source code you pointed out, and the line
> ??? fr <- fr[attr(terms(fr),"varnames.fixed")]
> 
> sure looks to me as though the terms() function has returned an object
> with a varnames.fixed attribute.? Either that or your code has inside
> knowledge that a reader like me won't know.? Given what you said I will
> guess that terms(x) returns the terms attribute of x if that already
> exists, doing no processing, and you know that fr has already been
> thusly modified?
> 
> I have code that uses the variables, term.names, and factors attributes
> of the terms() structure, and all of those have the backticks.? I know
> the second two will currently break the coxme and survival packages, I
> haven't chased down the effect on the first.
> 
> 
> On 03/08/2018 08:42 AM, Ben Bolker wrote:
>> Meant to respond to this but forgot.
>>
>> ? I didn't write a new terms() function? -- I added an attribute to the
>> terms() (a vector of the names
>> of the constructed model matrix), thus preserving the information at
>> the point when it was available.
>> ?? I do agree that it would be preferable to have an upstream fix ...
>>


From i at azurefx.name  Thu Mar  8 18:54:28 2018
From: i at azurefx.name (Azure)
Date: Thu, 8 Mar 2018 17:54:28 +0000
Subject: [Rd] [Bug report] Chinese characters are not handled correctly in
 Rterm for Windows
Message-ID: <PS1PR0302MB250778E72D430F253CBE11AFDDDF0@PS1PR0302MB2507.apcprd03.prod.outlook.com>

Hello everyone,


I am new to R and I have experienced some bugs when using Rterm on Windows.

Chinese characters in the console output are discarded by Rterm, and trying

to type them into the console will crash the Rterm application.


---ENVIRONMENT---

Platform = x86_64-w64-mingw32

OS = Windows 10 Pro 1709 chs

R version = 3.4.3

Active code page = 936 (Simplified Chinese)


---STEPS TO REPRODUCE---

1. Run cmd and start bin\x64\R.exe


2. Note that all Chinese characters in the startup banner are missing


3. > Sys.getlocale()

[1] "LC_COLLATE=Chinese (Simplified)_China.936;LC_CTYPE=Chinese (Simplified)
_China.936;LC_MONETARY=Chinese (Simplified)_China.936;LC_NUMERIC=C;LC_
TIME=Chinese (Simplified)_China.936"

4. > print("ABC\u4f60\u597dDEF")
[1] "ABCDEF"
(Unicode code points for "???")

5. Use Microsoft Pinyin IME to type "???" into the console. An error message appeared:
> invalid multibyte character in mbcs_get_next
Then the program crashed. My debugger reported a heap corruption, displayed as follows:
0x00007FFE2F3687BB (ntdll.dll) (Rterm.exe ??)??????????????: 0xC0000374: ??????? (????: 0x00007FFE2F3CC6E0)??
However, if the text is pasted into the console, it will not crash.

---ADDITIONAL INFO---
Both 32-bit and 64-bit versions have the same problem.
I attached a debugger to observe Rterm's behavior. The command in step 4
produced the following calling sequence of C library function "fputc":

fputc ( 91, 0x00007ffe2d1aea40 ) //'['
fputc ( 49, 0x00007ffe2d1aea40 ) //'1'
fputc ( 93, 0x00007ffe2d1aea40 ) //']'
//fflush ( 0x00007ffe2d1aea40 )
fputc ( 32, 0x00007ffe2d1aea40 ) //' '
fputc ( 34, 0x00007ffe2d1aea40 ) //'\"'
fputc ( 65, 0x00007ffe2d1aea40 ) //'A'
fputc ( 66, 0x00007ffe2d1aea40 ) //'B'
fputc ( 67, 0x00007ffe2d1aea40 ) //'C'
fputc ( 196, 0x00007ffe2d1aea40 ) //FAILED!
fputc ( 227, 0x00007ffe2d1aea40 ) //FAILED!
fputc ( 186, 0x00007ffe2d1aea40 ) //FAILED!
fputc ( 195, 0x00007ffe2d1aea40 ) //FAILED!
fputc ( 68, 0x00007ffe2d1aea40 ) //'D'
fputc ( 69, 0x00007ffe2d1aea40 ) //'E'
fputc ( 70, 0x00007ffe2d1aea40 ) //'F'
fputc ( 34, 0x00007ffe2d1aea40 ) //'\"'
//fflush ( 0x00007ffe2d1aea40 )
fputc ( 10, 0x00007ffe2d1aea40 ) //'\n'

{196, 227, 186, 195} or {C4 E3 BA C3} is multi-byte-encoded "???" in GBK (Code page 936).
These calls failed with a Windows error code 28 (No space left on device), while the subsequent
calls to fputc succeeded.

Then I used C++ to implement a terminal front-end with REmbedded facilities. R outputs were
simply printf-ed to stdout. Everything worked as expected:

Initializing R environment
R version 3.4.3 detected
> print("???????????????????R is great!")
[1] "???????????????????R is great!"
> Sys.getlocale()
[1] "LC_COLLATE=Chinese (Simplified)_China.936;LC_CTYPE=Chinese (Simplified)
_China.936;LC_MONETARY=Chinese (Simplified)_China.936;LC_NUMERIC=C;LC_
TIME=Chinese (Simplified)_China.936"
>

I hope these information are helpful.

Best regards,
AzureFx

	[[alternative HTML version deleted]]


From edward.m at psu.ac.th  Thu Mar  8 21:05:36 2018
From: edward.m at psu.ac.th (Edward McNeil)
Date: Fri, 9 Mar 2018 03:05:36 +0700
Subject: [Rd] reshape function: allow split argument to include perl
Message-ID: <5373b30a8ed891599ce278523c4c926a.squirrel@webmail.psu.ac.th>

Hi,
I'd like to request that the "split" argument of the reshape function include the perl
argument so that "splitting" is more flexible.

An example is if the varying argument contains "Q1.1.1, Q1.1.2, Q1.2.1, Q1.2.2, " etc.
Splitting on the last "dot" seems to be only possible using perl.

> x <- c("Q1.1.1", "Q1.1.2", "Q1.2.1", "Q1.2.2")
> strsplit(x, "(\\.)(?=[^\\.]$)", perl=TRUE)
[[1]]
[1] "Q1.1" "1"

[[2]]
[1] "Q1.1" "2"

[[3]]
[1] "Q1.2" "1"

[[4]]
[1] "Q1.2" "2"

Thanks.
-- 
Edward McNeil


From henrik.bengtsson at gmail.com  Fri Mar  9 04:05:47 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 8 Mar 2018 19:05:47 -0800
Subject: [Rd] parallel:::newPSOCKnode(): background worker fails immediately
 if socket on master is not set up in time (BUG?)
Message-ID: <CAFDcVCTGR4Ft7XTJzXqr=jtDn18ZdJQ7n-NLRuoW1-=70PGXsQ@mail.gmail.com>

BACKGROUND:

While troubleshooting random, occasionally occurring, errors from
parallel::makePSOCKcluster("localhost", port = 11000);

Error in socketConnection("localhost", port = port, server = TRUE,
blocking = TRUE, :
    cannot open the connection

I had another look at parallel:::newPSOCKnode(), which is used
internally to set up each background worker.  It is designed to, first
launch the background worker as:

  system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=TRUE',
wait = FALSE)

which immediately tries to connect to a socket on localhost:11000 with
timeout.  Immediately after the master launched the above (without
waiting), it will set up the connection waiting for the connect from
the background worker:

    con <- socketConnection("localhost", port = 11000, server = TRUE,
        blocking = TRUE, open = "a+b", timeout = timeout)


ISSUE:

If we emulate the above process, and remove the OUT=/dev/null such
that we can see the output produces by the worker, as:

setup <- function(delay = 0) {
  system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
MASTER=localhost PORT=11000 TIMEOUT=2592000 XDR=TRUE', wait = FALSE)
  Sys.sleep(delay)
  socketConnection("localhost", port = 11000, server = TRUE, blocking
= TRUE, open = "a+b", timeout = 20)
}

doing:

> con <- setup(0)
starting worker pid=24983 on localhost:11000 at 18:44:30.087

will most likely work, but adding a delay:

> con <- setup(5)
starting worker pid=25099 on localhost:11000 at 18:45:23.617
Warning in socketConnection(master, port = port, blocking = TRUE, open
= "a+b",  :
  localhost:11000 cannot be opened
Error in socketConnection(master, port = port, blocking = TRUE, open = "a+b",  :
  cannot open the connection
Calls: <Anonymous> ... doTryCatch -> recvData -> makeSOCKmaster ->
socketConnection

will produce an *instant* error on the worker, and before master opens
the server socket.  Eventually, master will produce the originally
observed error:

Error in socketConnection("localhost", port = 11000, server = TRUE,
blocking = TRUE,  :
  cannot open the connection

In other words, if the master fails to setup socketConnection()
*before* the background workers attempts to connect, it all fails.
Such a delay may happen for instance when there is a large CPU load on
the test machine.

Is this the above bug?

/Henrik

PS. The background is that I, very occasionally, observe R CMD check
error on the above (on CRAN and elsewhere) when testing my future
package. The error always go away when retested. This far I've though
this is due to port clashes (since the port is random selected in
[11000:11999]) and accepted that it happens.  However, after
discovering the above, it could be due to the worker launching "too
soon".

> sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.4 LTS

Matrix products: default
BLAS: /usr/lib/atlas-base/atlas/libblas.so.3.0
LAPACK: /usr/lib/atlas-base/atlas/liblapack.so.3.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.3


From henrik.bengtsson at gmail.com  Fri Mar  9 04:36:54 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 8 Mar 2018 19:36:54 -0800
Subject: [Rd] 
 parallel:::newPSOCKnode(): background worker fails immediately
 if socket on master is not set up in time (BUG?)
In-Reply-To: <CAFDcVCTGR4Ft7XTJzXqr=jtDn18ZdJQ7n-NLRuoW1-=70PGXsQ@mail.gmail.com>
References: <CAFDcVCTGR4Ft7XTJzXqr=jtDn18ZdJQ7n-NLRuoW1-=70PGXsQ@mail.gmail.com>
Message-ID: <CAFDcVCRMiVNVJeDsJdUH+jLeWJt3-cEiHm-+hTZPePt2WvskOA@mail.gmail.com>

I just noticed that parallel:::.slaveRSOCK() passes 'timeout' to
socketConnection() as a character, i.e. there's a missing timeout <-
as.integer(timeout), cf. port <- as.integer(port) and useXDR <-
as.logical(value):

> parallel:::.slaveRSOCK
function ()
{
    makeSOCKmaster <- function(master, port, timeout, useXDR) {
        port <- as.integer(port)
        con <- socketConnection(master, port = port, blocking = TRUE,
            open = "a+b", timeout = timeout)
        structure(list(con = con), class = if (useXDR)
            "SOCKnode"
        else "SOCK0node")
    }
    master <- "localhost"
    port <- NA_integer_
    outfile <- Sys.getenv("R_SNOW_OUTFILE")
    methods <- TRUE
    useXDR <- TRUE
    for (a in commandArgs(TRUE)) {
        pos <- regexpr("=", a)
        name <- substr(a, 1L, pos - 1L)
        value <- substr(a, pos + 1L, nchar(a))
        switch(name, MASTER = {
            master <- value
        }, PORT = {
            port <- value
        }, OUT = {
            outfile <- value
        }, TIMEOUT = {
            timeout <- value
        }, XDR = {
            useXDR <- as.logical(value)
        })
    }
    if (is.na(port))
        stop("PORT must be specified")
    sinkWorkerOutput(outfile)
    msg <- sprintf("starting worker pid=%d on %s at %s\n", Sys.getpid(),
        paste(master, port, sep = ":"), format(Sys.time(), "%H:%M:%OS3"))
    cat(msg)
    slaveLoop(makeSOCKmaster(master, port, timeout, useXDR))
}
<bytecode: 0x4bd4b58>
<environment: namespace:parallel>

Yet, fix that does *not* seem to change anything.

/Henrik

On Thu, Mar 8, 2018 at 7:05 PM, Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
> BACKGROUND:
>
> While troubleshooting random, occasionally occurring, errors from
> parallel::makePSOCKcluster("localhost", port = 11000);
>
> Error in socketConnection("localhost", port = port, server = TRUE,
> blocking = TRUE, :
>     cannot open the connection
>
> I had another look at parallel:::newPSOCKnode(), which is used
> internally to set up each background worker.  It is designed to, first
> launch the background worker as:
>
>   system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
> MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=TRUE',
> wait = FALSE)
>
> which immediately tries to connect to a socket on localhost:11000 with
> timeout.  Immediately after the master launched the above (without
> waiting), it will set up the connection waiting for the connect from
> the background worker:
>
>     con <- socketConnection("localhost", port = 11000, server = TRUE,
>         blocking = TRUE, open = "a+b", timeout = timeout)
>
>
> ISSUE:
>
> If we emulate the above process, and remove the OUT=/dev/null such
> that we can see the output produces by the worker, as:
>
> setup <- function(delay = 0) {
>   system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
> MASTER=localhost PORT=11000 TIMEOUT=2592000 XDR=TRUE', wait = FALSE)
>   Sys.sleep(delay)
>   socketConnection("localhost", port = 11000, server = TRUE, blocking
> = TRUE, open = "a+b", timeout = 20)
> }
>
> doing:
>
>> con <- setup(0)
> starting worker pid=24983 on localhost:11000 at 18:44:30.087
>
> will most likely work, but adding a delay:
>
>> con <- setup(5)
> starting worker pid=25099 on localhost:11000 at 18:45:23.617
> Warning in socketConnection(master, port = port, blocking = TRUE, open
> = "a+b",  :
>   localhost:11000 cannot be opened
> Error in socketConnection(master, port = port, blocking = TRUE, open = "a+b",  :
>   cannot open the connection
> Calls: <Anonymous> ... doTryCatch -> recvData -> makeSOCKmaster ->
> socketConnection
>
> will produce an *instant* error on the worker, and before master opens
> the server socket.  Eventually, master will produce the originally
> observed error:
>
> Error in socketConnection("localhost", port = 11000, server = TRUE,
> blocking = TRUE,  :
>   cannot open the connection
>
> In other words, if the master fails to setup socketConnection()
> *before* the background workers attempts to connect, it all fails.
> Such a delay may happen for instance when there is a large CPU load on
> the test machine.
>
> Is this the above bug?
>
> /Henrik
>
> PS. The background is that I, very occasionally, observe R CMD check
> error on the above (on CRAN and elsewhere) when testing my future
> package. The error always go away when retested. This far I've though
> this is due to port clashes (since the port is random selected in
> [11000:11999]) and accepted that it happens.  However, after
> discovering the above, it could be due to the worker launching "too
> soon".
>
>> sessionInfo()
> R version 3.4.3 (2017-11-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.4 LTS
>
> Matrix products: default
> BLAS: /usr/lib/atlas-base/atlas/libblas.so.3.0
> LAPACK: /usr/lib/atlas-base/atlas/liblapack.so.3.0
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.3


From henrik.bengtsson at gmail.com  Fri Mar  9 06:58:53 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 8 Mar 2018 21:58:53 -0800
Subject: [Rd] 
 parallel:::newPSOCKnode(): background worker fails immediately
 if socket on master is not set up in time (BUG?)
In-Reply-To: <CAFDcVCRMiVNVJeDsJdUH+jLeWJt3-cEiHm-+hTZPePt2WvskOA@mail.gmail.com>
References: <CAFDcVCTGR4Ft7XTJzXqr=jtDn18ZdJQ7n-NLRuoW1-=70PGXsQ@mail.gmail.com>
 <CAFDcVCRMiVNVJeDsJdUH+jLeWJt3-cEiHm-+hTZPePt2WvskOA@mail.gmail.com>
Message-ID: <CAFDcVCRg_m07wZuAeytck06XCv5FBRQxGYm2-eNpBD8zYoL8LQ@mail.gmail.com>

A solution is to have parallel:::.slaveRSOCK() attempt to connect
multiple times before failing, e.g.

    makeSOCKmaster <- function(master, port, timeout, useXDR, maxTries
= 10L, interval = 1.0) {
        port <- as.integer(port)
        for (i in seq_len(maxTries)) {
          con <- tryCatch({
            socketConnection(master, port = port, blocking = TRUE,
                                    open = "a+b", timeout = timeout)
          }, error = identity)
          if (inherits(con, "connection")) break
          Sys.sleep(interval)
        }
        if (inherits(con, "error")) stop(con)
        structure(list(con = con), class = if (useXDR)
            "SOCKnode"
        else "SOCK0node")
    }

One could set 'maxTries' and 'interval' via commandArgs() like what is
done for the other arguments.

I'm happy to submit an SVN patch if R core thinks this is an
acceptable solution.

/Henrik

On Thu, Mar 8, 2018 at 7:36 PM, Henrik Bengtsson
<henrik.bengtsson at gmail.com> wrote:
> I just noticed that parallel:::.slaveRSOCK() passes 'timeout' to
> socketConnection() as a character, i.e. there's a missing timeout <-
> as.integer(timeout), cf. port <- as.integer(port) and useXDR <-
> as.logical(value):
>
>> parallel:::.slaveRSOCK
> function ()
> {
>     makeSOCKmaster <- function(master, port, timeout, useXDR) {
>         port <- as.integer(port)
>         con <- socketConnection(master, port = port, blocking = TRUE,
>             open = "a+b", timeout = timeout)
>         structure(list(con = con), class = if (useXDR)
>             "SOCKnode"
>         else "SOCK0node")
>     }
>     master <- "localhost"
>     port <- NA_integer_
>     outfile <- Sys.getenv("R_SNOW_OUTFILE")
>     methods <- TRUE
>     useXDR <- TRUE
>     for (a in commandArgs(TRUE)) {
>         pos <- regexpr("=", a)
>         name <- substr(a, 1L, pos - 1L)
>         value <- substr(a, pos + 1L, nchar(a))
>         switch(name, MASTER = {
>             master <- value
>         }, PORT = {
>             port <- value
>         }, OUT = {
>             outfile <- value
>         }, TIMEOUT = {
>             timeout <- value
>         }, XDR = {
>             useXDR <- as.logical(value)
>         })
>     }
>     if (is.na(port))
>         stop("PORT must be specified")
>     sinkWorkerOutput(outfile)
>     msg <- sprintf("starting worker pid=%d on %s at %s\n", Sys.getpid(),
>         paste(master, port, sep = ":"), format(Sys.time(), "%H:%M:%OS3"))
>     cat(msg)
>     slaveLoop(makeSOCKmaster(master, port, timeout, useXDR))
> }
> <bytecode: 0x4bd4b58>
> <environment: namespace:parallel>
>
> Yet, fix that does *not* seem to change anything.
>
> /Henrik
>
> On Thu, Mar 8, 2018 at 7:05 PM, Henrik Bengtsson
> <henrik.bengtsson at gmail.com> wrote:
>> BACKGROUND:
>>
>> While troubleshooting random, occasionally occurring, errors from
>> parallel::makePSOCKcluster("localhost", port = 11000);
>>
>> Error in socketConnection("localhost", port = port, server = TRUE,
>> blocking = TRUE, :
>>     cannot open the connection
>>
>> I had another look at parallel:::newPSOCKnode(), which is used
>> internally to set up each background worker.  It is designed to, first
>> launch the background worker as:
>>
>>   system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
>> MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=TRUE',
>> wait = FALSE)
>>
>> which immediately tries to connect to a socket on localhost:11000 with
>> timeout.  Immediately after the master launched the above (without
>> waiting), it will set up the connection waiting for the connect from
>> the background worker:
>>
>>     con <- socketConnection("localhost", port = 11000, server = TRUE,
>>         blocking = TRUE, open = "a+b", timeout = timeout)
>>
>>
>> ISSUE:
>>
>> If we emulate the above process, and remove the OUT=/dev/null such
>> that we can see the output produces by the worker, as:
>>
>> setup <- function(delay = 0) {
>>   system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
>> MASTER=localhost PORT=11000 TIMEOUT=2592000 XDR=TRUE', wait = FALSE)
>>   Sys.sleep(delay)
>>   socketConnection("localhost", port = 11000, server = TRUE, blocking
>> = TRUE, open = "a+b", timeout = 20)
>> }
>>
>> doing:
>>
>>> con <- setup(0)
>> starting worker pid=24983 on localhost:11000 at 18:44:30.087
>>
>> will most likely work, but adding a delay:
>>
>>> con <- setup(5)
>> starting worker pid=25099 on localhost:11000 at 18:45:23.617
>> Warning in socketConnection(master, port = port, blocking = TRUE, open
>> = "a+b",  :
>>   localhost:11000 cannot be opened
>> Error in socketConnection(master, port = port, blocking = TRUE, open = "a+b",  :
>>   cannot open the connection
>> Calls: <Anonymous> ... doTryCatch -> recvData -> makeSOCKmaster ->
>> socketConnection
>>
>> will produce an *instant* error on the worker, and before master opens
>> the server socket.  Eventually, master will produce the originally
>> observed error:
>>
>> Error in socketConnection("localhost", port = 11000, server = TRUE,
>> blocking = TRUE,  :
>>   cannot open the connection
>>
>> In other words, if the master fails to setup socketConnection()
>> *before* the background workers attempts to connect, it all fails.
>> Such a delay may happen for instance when there is a large CPU load on
>> the test machine.
>>
>> Is this the above bug?
>>
>> /Henrik
>>
>> PS. The background is that I, very occasionally, observe R CMD check
>> error on the above (on CRAN and elsewhere) when testing my future
>> package. The error always go away when retested. This far I've though
>> this is due to port clashes (since the port is random selected in
>> [11000:11999]) and accepted that it happens.  However, after
>> discovering the above, it could be due to the worker launching "too
>> soon".
>>
>>> sessionInfo()
>> R version 3.4.3 (2017-11-30)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 16.04.4 LTS
>>
>> Matrix products: default
>> BLAS: /usr/lib/atlas-base/atlas/libblas.so.3.0
>> LAPACK: /usr/lib/atlas-base/atlas/liblapack.so.3.0
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.3


From dusa.adrian at unibuc.ro  Fri Mar  9 09:34:30 2018
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Fri, 9 Mar 2018 10:34:30 +0200
Subject: [Rd] importing namespaces from base packages
Message-ID: <CAJ=0CtCXxxGi9paHg6c6tQQJqbHt5GQHcZH5gPpkepEv9Pb56A@mail.gmail.com>

Dear All,

I understand the R CMD checks with only the base package attached,
everything else (including the other packages bundled with the base R)
should be imported and most importantly declared in the Imports field from
the DESCRIPTION file.

However, I do use functions from other packages than base (utils,
grDevices, stats, graphics), for which it is sufficient to declare
importFrom() in the NAMESPACE file.

For instance, it is not required to specify utils in the Imports: field
from DESCRIPTION, when using importFrom("utils", "packageDescription") in
NAMESPACE.

The opposite happens for importFrom("methods", "is"), which ends up in the
error: Namespace dependency not required: ?methods?

Is there a special reason for which package methods is treated differently
from all other packages bundled with the base R?

Thank you,
Adrian

--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr. 90-92
050663 Bucharest sector 5
Romania
https://adriandusa.eu

	[[alternative HTML version deleted]]


From luke-tierney at uiowa.edu  Fri Mar  9 13:37:01 2018
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 9 Mar 2018 06:37:01 -0600 (CST)
Subject: [Rd] 
 parallel:::newPSOCKnode(): background worker fails immediately
 if socket on master is not set up in time (BUG?)
In-Reply-To: <CAFDcVCRg_m07wZuAeytck06XCv5FBRQxGYm2-eNpBD8zYoL8LQ@mail.gmail.com>
References: <CAFDcVCTGR4Ft7XTJzXqr=jtDn18ZdJQ7n-NLRuoW1-=70PGXsQ@mail.gmail.com>
 <CAFDcVCRMiVNVJeDsJdUH+jLeWJt3-cEiHm-+hTZPePt2WvskOA@mail.gmail.com>
 <CAFDcVCRg_m07wZuAeytck06XCv5FBRQxGYm2-eNpBD8zYoL8LQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1803090632120.11361@luke-Latitude>

I'm happy to look at a patch that does this.  I'd start with a small
interval and increase it by 50%, say, on each try wit a max retry time
limit. This isn't eliminating the problem,only reducing the
probability, but still worth it. I had considered doing something like
this but it didn't seem necessary at the time. You don't want to retry
indefinitely since the connection could be failing because the master
died, and then you want the workers to die as well.

Best,

luke

On Fri, 9 Mar 2018, Henrik Bengtsson wrote:

> A solution is to have parallel:::.slaveRSOCK() attempt to connect
> multiple times before failing, e.g.
>
>    makeSOCKmaster <- function(master, port, timeout, useXDR, maxTries
> = 10L, interval = 1.0) {
>        port <- as.integer(port)
>        for (i in seq_len(maxTries)) {
>          con <- tryCatch({
>            socketConnection(master, port = port, blocking = TRUE,
>                                    open = "a+b", timeout = timeout)
>          }, error = identity)
>          if (inherits(con, "connection")) break
>          Sys.sleep(interval)
>        }
>        if (inherits(con, "error")) stop(con)
>        structure(list(con = con), class = if (useXDR)
>            "SOCKnode"
>        else "SOCK0node")
>    }
>
> One could set 'maxTries' and 'interval' via commandArgs() like what is
> done for the other arguments.
>
> I'm happy to submit an SVN patch if R core thinks this is an
> acceptable solution.
>
> /Henrik
>
> On Thu, Mar 8, 2018 at 7:36 PM, Henrik Bengtsson
> <henrik.bengtsson at gmail.com> wrote:
>> I just noticed that parallel:::.slaveRSOCK() passes 'timeout' to
>> socketConnection() as a character, i.e. there's a missing timeout <-
>> as.integer(timeout), cf. port <- as.integer(port) and useXDR <-
>> as.logical(value):
>>
>>> parallel:::.slaveRSOCK
>> function ()
>> {
>>     makeSOCKmaster <- function(master, port, timeout, useXDR) {
>>         port <- as.integer(port)
>>         con <- socketConnection(master, port = port, blocking = TRUE,
>>             open = "a+b", timeout = timeout)
>>         structure(list(con = con), class = if (useXDR)
>>             "SOCKnode"
>>         else "SOCK0node")
>>     }
>>     master <- "localhost"
>>     port <- NA_integer_
>>     outfile <- Sys.getenv("R_SNOW_OUTFILE")
>>     methods <- TRUE
>>     useXDR <- TRUE
>>     for (a in commandArgs(TRUE)) {
>>         pos <- regexpr("=", a)
>>         name <- substr(a, 1L, pos - 1L)
>>         value <- substr(a, pos + 1L, nchar(a))
>>         switch(name, MASTER = {
>>             master <- value
>>         }, PORT = {
>>             port <- value
>>         }, OUT = {
>>             outfile <- value
>>         }, TIMEOUT = {
>>             timeout <- value
>>         }, XDR = {
>>             useXDR <- as.logical(value)
>>         })
>>     }
>>     if (is.na(port))
>>         stop("PORT must be specified")
>>     sinkWorkerOutput(outfile)
>>     msg <- sprintf("starting worker pid=%d on %s at %s\n", Sys.getpid(),
>>         paste(master, port, sep = ":"), format(Sys.time(), "%H:%M:%OS3"))
>>     cat(msg)
>>     slaveLoop(makeSOCKmaster(master, port, timeout, useXDR))
>> }
>> <bytecode: 0x4bd4b58>
>> <environment: namespace:parallel>
>>
>> Yet, fix that does *not* seem to change anything.
>>
>> /Henrik
>>
>> On Thu, Mar 8, 2018 at 7:05 PM, Henrik Bengtsson
>> <henrik.bengtsson at gmail.com> wrote:
>>> BACKGROUND:
>>>
>>> While troubleshooting random, occasionally occurring, errors from
>>> parallel::makePSOCKcluster("localhost", port = 11000);
>>>
>>> Error in socketConnection("localhost", port = port, server = TRUE,
>>> blocking = TRUE, :
>>>     cannot open the connection
>>>
>>> I had another look at parallel:::newPSOCKnode(), which is used
>>> internally to set up each background worker.  It is designed to, first
>>> launch the background worker as:
>>>
>>>   system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
>>> MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=TRUE',
>>> wait = FALSE)
>>>
>>> which immediately tries to connect to a socket on localhost:11000 with
>>> timeout.  Immediately after the master launched the above (without
>>> waiting), it will set up the connection waiting for the connect from
>>> the background worker:
>>>
>>>     con <- socketConnection("localhost", port = 11000, server = TRUE,
>>>         blocking = TRUE, open = "a+b", timeout = timeout)
>>>
>>>
>>> ISSUE:
>>>
>>> If we emulate the above process, and remove the OUT=/dev/null such
>>> that we can see the output produces by the worker, as:
>>>
>>> setup <- function(delay = 0) {
>>>   system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
>>> MASTER=localhost PORT=11000 TIMEOUT=2592000 XDR=TRUE', wait = FALSE)
>>>   Sys.sleep(delay)
>>>   socketConnection("localhost", port = 11000, server = TRUE, blocking
>>> = TRUE, open = "a+b", timeout = 20)
>>> }
>>>
>>> doing:
>>>
>>>> con <- setup(0)
>>> starting worker pid=24983 on localhost:11000 at 18:44:30.087
>>>
>>> will most likely work, but adding a delay:
>>>
>>>> con <- setup(5)
>>> starting worker pid=25099 on localhost:11000 at 18:45:23.617
>>> Warning in socketConnection(master, port = port, blocking = TRUE, open
>>> = "a+b",  :
>>>   localhost:11000 cannot be opened
>>> Error in socketConnection(master, port = port, blocking = TRUE, open = "a+b",  :
>>>   cannot open the connection
>>> Calls: <Anonymous> ... doTryCatch -> recvData -> makeSOCKmaster ->
>>> socketConnection
>>>
>>> will produce an *instant* error on the worker, and before master opens
>>> the server socket.  Eventually, master will produce the originally
>>> observed error:
>>>
>>> Error in socketConnection("localhost", port = 11000, server = TRUE,
>>> blocking = TRUE,  :
>>>   cannot open the connection
>>>
>>> In other words, if the master fails to setup socketConnection()
>>> *before* the background workers attempts to connect, it all fails.
>>> Such a delay may happen for instance when there is a large CPU load on
>>> the test machine.
>>>
>>> Is this the above bug?
>>>
>>> /Henrik
>>>
>>> PS. The background is that I, very occasionally, observe R CMD check
>>> error on the above (on CRAN and elsewhere) when testing my future
>>> package. The error always go away when retested. This far I've though
>>> this is due to port clashes (since the port is random selected in
>>> [11000:11999]) and accepted that it happens.  However, after
>>> discovering the above, it could be due to the worker launching "too
>>> soon".
>>>
>>>> sessionInfo()
>>> R version 3.4.3 (2017-11-30)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 16.04.4 LTS
>>>
>>> Matrix products: default
>>> BLAS: /usr/lib/atlas-base/atlas/libblas.so.3.0
>>> LAPACK: /usr/lib/atlas-base/atlas/liblapack.so.3.0
>>>
>>> locale:
>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.3
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From suharto_anggono at yahoo.com  Sat Mar 10 02:23:21 2018
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 10 Mar 2018 01:23:21 +0000 (UTC)
Subject: [Rd] Inappropriate parens fix for Logic.Rd
References: <920363430.14541096.1520645001157.ref@mail.yahoo.com>
Message-ID: <920363430.14541096.1520645001157@mail.yahoo.com>

Logic.Rd is one of the files changed in r74363.

Before change:
  \item{x, y}{raw or logical or \sQuote{number-like} vectors (i.e., of types
    \code{\link{double}} (class \code{\link{numeric}}), \code{\link{integer}}
    and \code{\link{complex}})), or objects for

After change:
  \item{x, y}{raw or logical or \sQuote{number-like} vectors (i.e., of types
    \code{\link{double}} (class \code{\link{numeric}}, \code{\link{integer}}
    and \code{\link{complex}})), or objects for

Neither integer nor complex is double.
I think, it should be
  \item{x, y}{raw or logical or \sQuote{number-like} vectors (i.e., of types
    \code{\link{double}} (class \code{\link{numeric}}), \code{\link{integer}}
    and \code{\link{complex}}), or objects for


From henrik.bengtsson at gmail.com  Sat Mar 10 02:52:16 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 9 Mar 2018 17:52:16 -0800
Subject: [Rd] 
 parallel:::newPSOCKnode(): background worker fails immediately
 if socket on master is not set up in time (BUG?)
In-Reply-To: <alpine.DEB.2.20.1803090632120.11361@luke-Latitude>
References: <CAFDcVCTGR4Ft7XTJzXqr=jtDn18ZdJQ7n-NLRuoW1-=70PGXsQ@mail.gmail.com>
 <CAFDcVCRMiVNVJeDsJdUH+jLeWJt3-cEiHm-+hTZPePt2WvskOA@mail.gmail.com>
 <CAFDcVCRg_m07wZuAeytck06XCv5FBRQxGYm2-eNpBD8zYoL8LQ@mail.gmail.com>
 <alpine.DEB.2.20.1803090632120.11361@luke-Latitude>
Message-ID: <CAFDcVCRqAWF0HkL0BasD2--0fa=JZVBJ8SOn6MypmVVzUL+HdA@mail.gmail.com>

Great.

For the record of this thread, I've submitted patch PR17391
(https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17391).  I've
patched it against the latest R-devel on the SVN, passes 'make
check-all', and I've verified it works with the above tests.

/Henrik

On Fri, Mar 9, 2018 at 4:37 AM,  <luke-tierney at uiowa.edu> wrote:
> I'm happy to look at a patch that does this.  I'd start with a small
> interval and increase it by 50%, say, on each try wit a max retry time
> limit. This isn't eliminating the problem,only reducing the
> probability, but still worth it. I had considered doing something like
> this but it didn't seem necessary at the time. You don't want to retry
> indefinitely since the connection could be failing because the master
> died, and then you want the workers to die as well.
>
> Best,
>
> luke
>
>
> On Fri, 9 Mar 2018, Henrik Bengtsson wrote:
>
>> A solution is to have parallel:::.slaveRSOCK() attempt to connect
>> multiple times before failing, e.g.
>>
>>    makeSOCKmaster <- function(master, port, timeout, useXDR, maxTries
>> = 10L, interval = 1.0) {
>>        port <- as.integer(port)
>>        for (i in seq_len(maxTries)) {
>>          con <- tryCatch({
>>            socketConnection(master, port = port, blocking = TRUE,
>>                                    open = "a+b", timeout = timeout)
>>          }, error = identity)
>>          if (inherits(con, "connection")) break
>>          Sys.sleep(interval)
>>        }
>>        if (inherits(con, "error")) stop(con)
>>        structure(list(con = con), class = if (useXDR)
>>            "SOCKnode"
>>        else "SOCK0node")
>>    }
>>
>> One could set 'maxTries' and 'interval' via commandArgs() like what is
>> done for the other arguments.
>>
>> I'm happy to submit an SVN patch if R core thinks this is an
>> acceptable solution.
>>
>> /Henrik
>>
>> On Thu, Mar 8, 2018 at 7:36 PM, Henrik Bengtsson
>> <henrik.bengtsson at gmail.com> wrote:
>>>
>>> I just noticed that parallel:::.slaveRSOCK() passes 'timeout' to
>>> socketConnection() as a character, i.e. there's a missing timeout <-
>>> as.integer(timeout), cf. port <- as.integer(port) and useXDR <-
>>> as.logical(value):
>>>
>>>> parallel:::.slaveRSOCK
>>>
>>> function ()
>>> {
>>>     makeSOCKmaster <- function(master, port, timeout, useXDR) {
>>>         port <- as.integer(port)
>>>         con <- socketConnection(master, port = port, blocking = TRUE,
>>>             open = "a+b", timeout = timeout)
>>>         structure(list(con = con), class = if (useXDR)
>>>             "SOCKnode"
>>>         else "SOCK0node")
>>>     }
>>>     master <- "localhost"
>>>     port <- NA_integer_
>>>     outfile <- Sys.getenv("R_SNOW_OUTFILE")
>>>     methods <- TRUE
>>>     useXDR <- TRUE
>>>     for (a in commandArgs(TRUE)) {
>>>         pos <- regexpr("=", a)
>>>         name <- substr(a, 1L, pos - 1L)
>>>         value <- substr(a, pos + 1L, nchar(a))
>>>         switch(name, MASTER = {
>>>             master <- value
>>>         }, PORT = {
>>>             port <- value
>>>         }, OUT = {
>>>             outfile <- value
>>>         }, TIMEOUT = {
>>>             timeout <- value
>>>         }, XDR = {
>>>             useXDR <- as.logical(value)
>>>         })
>>>     }
>>>     if (is.na(port))
>>>         stop("PORT must be specified")
>>>     sinkWorkerOutput(outfile)
>>>     msg <- sprintf("starting worker pid=%d on %s at %s\n", Sys.getpid(),
>>>         paste(master, port, sep = ":"), format(Sys.time(), "%H:%M:%OS3"))
>>>     cat(msg)
>>>     slaveLoop(makeSOCKmaster(master, port, timeout, useXDR))
>>> }
>>> <bytecode: 0x4bd4b58>
>>> <environment: namespace:parallel>
>>>
>>> Yet, fix that does *not* seem to change anything.
>>>
>>> /Henrik
>>>
>>> On Thu, Mar 8, 2018 at 7:05 PM, Henrik Bengtsson
>>> <henrik.bengtsson at gmail.com> wrote:
>>>>
>>>> BACKGROUND:
>>>>
>>>> While troubleshooting random, occasionally occurring, errors from
>>>> parallel::makePSOCKcluster("localhost", port = 11000);
>>>>
>>>> Error in socketConnection("localhost", port = port, server = TRUE,
>>>> blocking = TRUE, :
>>>>     cannot open the connection
>>>>
>>>> I had another look at parallel:::newPSOCKnode(), which is used
>>>> internally to set up each background worker.  It is designed to, first
>>>> launch the background worker as:
>>>>
>>>>   system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
>>>> MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=TRUE',
>>>> wait = FALSE)
>>>>
>>>> which immediately tries to connect to a socket on localhost:11000 with
>>>> timeout.  Immediately after the master launched the above (without
>>>> waiting), it will set up the connection waiting for the connect from
>>>> the background worker:
>>>>
>>>>     con <- socketConnection("localhost", port = 11000, server = TRUE,
>>>>         blocking = TRUE, open = "a+b", timeout = timeout)
>>>>
>>>>
>>>> ISSUE:
>>>>
>>>> If we emulate the above process, and remove the OUT=/dev/null such
>>>> that we can see the output produces by the worker, as:
>>>>
>>>> setup <- function(delay = 0) {
>>>>   system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
>>>> MASTER=localhost PORT=11000 TIMEOUT=2592000 XDR=TRUE', wait = FALSE)
>>>>   Sys.sleep(delay)
>>>>   socketConnection("localhost", port = 11000, server = TRUE, blocking
>>>> = TRUE, open = "a+b", timeout = 20)
>>>> }
>>>>
>>>> doing:
>>>>
>>>>> con <- setup(0)
>>>>
>>>> starting worker pid=24983 on localhost:11000 at 18:44:30.087
>>>>
>>>> will most likely work, but adding a delay:
>>>>
>>>>> con <- setup(5)
>>>>
>>>> starting worker pid=25099 on localhost:11000 at 18:45:23.617
>>>> Warning in socketConnection(master, port = port, blocking = TRUE, open
>>>> = "a+b",  :
>>>>   localhost:11000 cannot be opened
>>>> Error in socketConnection(master, port = port, blocking = TRUE, open =
>>>> "a+b",  :
>>>>   cannot open the connection
>>>> Calls: <Anonymous> ... doTryCatch -> recvData -> makeSOCKmaster ->
>>>> socketConnection
>>>>
>>>> will produce an *instant* error on the worker, and before master opens
>>>> the server socket.  Eventually, master will produce the originally
>>>> observed error:
>>>>
>>>> Error in socketConnection("localhost", port = 11000, server = TRUE,
>>>> blocking = TRUE,  :
>>>>   cannot open the connection
>>>>
>>>> In other words, if the master fails to setup socketConnection()
>>>> *before* the background workers attempts to connect, it all fails.
>>>> Such a delay may happen for instance when there is a large CPU load on
>>>> the test machine.
>>>>
>>>> Is this the above bug?
>>>>
>>>> /Henrik
>>>>
>>>> PS. The background is that I, very occasionally, observe R CMD check
>>>> error on the above (on CRAN and elsewhere) when testing my future
>>>> package. The error always go away when retested. This far I've though
>>>> this is due to port clashes (since the port is random selected in
>>>> [11000:11999]) and accepted that it happens.  However, after
>>>> discovering the above, it could be due to the worker launching "too
>>>> soon".
>>>>
>>>>> sessionInfo()
>>>>
>>>> R version 3.4.3 (2017-11-30)
>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>> Running under: Ubuntu 16.04.4 LTS
>>>>
>>>> Matrix products: default
>>>> BLAS: /usr/lib/atlas-base/atlas/libblas.so.3.0
>>>> LAPACK: /usr/lib/atlas-base/atlas/liblapack.so.3.0
>>>>
>>>> locale:
>>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] compiler_3.4.3
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From maechler at stat.math.ethz.ch  Mon Mar 12 13:18:01 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 12 Mar 2018 13:18:01 +0100
Subject: [Rd] importing namespaces from base packages
In-Reply-To: <CAJ=0CtCXxxGi9paHg6c6tQQJqbHt5GQHcZH5gPpkepEv9Pb56A@mail.gmail.com>
References: <CAJ=0CtCXxxGi9paHg6c6tQQJqbHt5GQHcZH5gPpkepEv9Pb56A@mail.gmail.com>
Message-ID: <23206.28665.937751.614900@stat.math.ethz.ch>

>>>>> Adrian Du?a <dusa.adrian at unibuc.ro>
>>>>>     on Fri, 9 Mar 2018 10:34:30 +0200 writes:

    > Dear All,
    > I understand the R CMD checks with only the base package attached,
    > everything else (including the other packages bundled with the base R)
    > should be imported and most importantly declared in the Imports field from
    > the DESCRIPTION file.

    > However, I do use functions from other packages than base (utils,
    > grDevices, stats, graphics), for which it is sufficient to declare
    > importFrom() in the NAMESPACE file.

    > For instance, it is not required to specify utils in the Imports: field
    > from DESCRIPTION, when using importFrom("utils", "packageDescription") in
    > NAMESPACE.

Is that so?   Not according to my reading of the 'Writing R
Extensions' manual, nor according to what I have been doing in
all of my packages for ca. 2 years:

The rule I have in my mind is

 1) NAMESPACE Import(s|From) \
 ............................ <==>  DESCRIPTION -> 'Imports:'
 2) .. using "::" in  R code / 


If you really found that you did not have to import from say
'utils', I think this was a *un*lucky coincidence.
Even R's own  "stats" package has a line

  importFrom(utils, count.fields, flush.console, str, tail)

in its NAMESPACE.

    > The opposite happens for importFrom("methods", "is"), which ends up in the
    > error: Namespace dependency not required: ?methods?

    > Is there a special reason for which package methods is treated differently
    > from all other packages bundled with the base R?

    > Thank you,
    > Adrian

    > --
    > Adrian Dusa
    > University of Bucharest
    > Romanian Social Data Archive
    > Soseaua Panduri nr. 90-92
    > 050663 Bucharest sector 5
    > Romania
    > https://adriandusa.eu

There are places in the R source where it is treated specially,
indeed, part of 'methods' may be needed when it is neither
loaded nor attached (e.g., when R runs with only base, say, and
suddenly encounters an S4 object), and there still are
situations where 'methods' needs to be in the search() path and
not just loaded, but these cases should be unrelated to the
above DESCRIPTION-Imports vs NAMESPACE-Imports correspondence.

Martin Maechler
ETH Zurich & R Core Team


From dusa.adrian at unibuc.ro  Tue Mar 13 08:17:08 2018
From: dusa.adrian at unibuc.ro (=?UTF-8?B?QWRyaWFuIER1yJlh?=)
Date: Tue, 13 Mar 2018 09:17:08 +0200
Subject: [Rd] importing namespaces from base packages
In-Reply-To: <23206.28665.937751.614900@stat.math.ethz.ch>
References: <CAJ=0CtCXxxGi9paHg6c6tQQJqbHt5GQHcZH5gPpkepEv9Pb56A@mail.gmail.com>
 <23206.28665.937751.614900@stat.math.ethz.ch>
Message-ID: <CAJ=0CtBKN51Cbp2hjZyRjnsTBkygKcJfmrxTw6Q-ZVUWFWabGg@mail.gmail.com>

On Mon, Mar 12, 2018 at 2:18 PM, Martin Maechler <maechler at stat.math.ethz.ch>
wrote:
> [...]
> Is that so?   Not according to my reading of the 'Writing R
> Extensions' manual, nor according to what I have been doing in
> all of my packages for ca. 2 years:
>
> The rule I have in my mind is
>
>  1) NAMESPACE Import(s|From) \
>  ............................ <==>  DESCRIPTION -> 'Imports:'
>  2) .. using "::" in  R code /
>
>
> If you really found that you did not have to import from say
> 'utils', I think this was a *un*lucky coincidence.

Of course, the importFrom() is mandatory in NAMESPACE otherwise the package
does not pass the checks.
The question was related to the relation between the packages mentioned in
the NAMESPACE and the packages mentioned in the Imports: field from
DESCRIPTION.

For instance, the current version 3.1 of package QCA on CRAN mentions in
the DESCRIPTION:

Imports: venn (? 1.2), shiny, methods, fastdigest

while the NAMESPACE file has:

import(shiny)
import(venn)
import(fastdigest)
importFrom("utils", "packageDescription", "remove.packages",
"capture.output")
importFrom("stats", "glm", "predict", "quasibinomial", "binom.test",
"cutree", "dist", "hclust", "na.omit", "dbinom", "setNames")
importFrom("grDevices", "dev.cur", "dev.new", "dev.list")
importFrom("graphics", "abline", "axis", "box", "mtext", "par", "title",
"text")
importFrom("methods", "is")

There are functions from packages utils, stats, grDevices and graphics for
which the R checks do not require a specific entry in the Imports: field.
I suspect because all of these packages are part of the base R, but so is
package methods. The question is why is it not mandatory for those packages
to be mentioned in the Imports: field from DESCRIPTION, while removing
package methods from that field runs into an error, despite maintaining the
package in the NAMESPACE's importFrom().



> [...]
> There are places in the R source where it is treated specially,
> indeed, part of 'methods' may be needed when it is neither
> loaded nor attached (e.g., when R runs with only base, say, and
> suddenly encounters an S4 object), and there still are
> situations where 'methods' needs to be in the search() path and
> not just loaded, but these cases should be unrelated to the
> above DESCRIPTION-Imports vs NAMESPACE-Imports correspondence.

This is what I had expected myself, then the above behavior has to have
another explanation.
It is just a curiosity, there is naturally nothing wrong with maintaining
package methods in the Imports: field. Only odd why some base R packages
are treated differently than other base R packages, at the package checks
stage.

Thank you,
Adrian

--
Adrian Dusa
University of Bucharest
Romanian Social Data Archive
Soseaua Panduri nr. 90-92
050663 Bucharest sector 5
Romania
https://adriandusa.eu

	[[alternative HTML version deleted]]


From tomas.kalibera at gmail.com  Tue Mar 13 09:26:22 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Tue, 13 Mar 2018 09:26:22 +0100
Subject: [Rd] [parallel] fixes load balancing of parLapplyLB
In-Reply-To: <109bbbed255f49fbb6bac484cf753286@urzdommbx02.dom.uni-leipzig.de>
References: <a6e9c1ab509941489f0de6dcc1fac398@urzdommbx02.dom.uni-leipzig.de>
 <ee05a2d4382544cdb540665cd0ac3839@urzdommbx02.dom.uni-leipzig.de>
 <CAFDcVCRX82QZgs1BNzo-+PL92nULfG21CDpjDDKiPFhF2kH1Yg@mail.gmail.com>
 <1f1c808a24e9471784537dabde08d477@urzdommbx02.dom.uni-leipzig.de>
 <097719f7-da88-7a01-c4ec-3154328d6e58@gmail.com>
 <109bbbed255f49fbb6bac484cf753286@urzdommbx02.dom.uni-leipzig.de>
Message-ID: <b36d23df-7700-d521-3764-925f21e7060f@gmail.com>


Chunk size support has been added in R-devel 74353. Please let me know 
if you find any problem.

Thanks,
Tomas

On 03/01/2018 09:19 AM, Christian Krause wrote:
> Dear Tomas,
>
> Thanks for your commitment to fix this issue and also to add the chunk size as an argument. If you want our input, let us know ;)
>
> Best Regards
>
> On 02/26/2018 04:01 PM, Tomas Kalibera wrote:
>> Dear Christian and Henrik,
>>
>> thank you for spotting the problem and suggestions for a fix. We'll probably add a chunk.size argument to parLapplyLB and parLapply to follow OpenMP terminology, which has already been an inspiration for the present code (parLapply already implements static scheduling via internal function staticClusterApply, yet with a fixed chunk size; parLapplyLB already implements dynamic scheduling via internal function dynamicClusterApply, but with a fixed chunk size set to an unlucky value so that it behaves like static scheduling). The default chunk size for parallelLapplyLB will be set so that there is some dynamism in the schedule even by default. I am now testing a patch with these changes.
>>
>> Best
>> Tomas
>>
>>
>> On 02/20/2018 11:45 AM, Christian Krause wrote:
>>> Dear Henrik,
>>>
>>> The rationale is just that it is within these extremes and that it is really simple to calculate, without making any assumptions and knowing that it won't be perfect.
>>>
>>> The extremes A and B you are mentioning are special cases based on assumptions. Case A is based on the assumption that the function has a long runtime or varying runtime, then you are likely to get the best load balancing with really small chunks. Case B is based on the assumption that the function runtime is the same for each list element, i.e. where you don't actually need load balancing, i.e. just use `parLapply` without load balancing.
>>>
>>> This new default is **not the best one**. It's just a better one than we had before. There is no best one we can use as default because **we don't know the function runtime and how it varies**. The user needs to decide that because he/she knows the function. As mentioned before, I will write a patch that makes the chunk size an optional argument, so the user can decide because only he/she has all the information to choose the best chunk size, just like you did with the `future.scheduling` parameter.
>>>
>>> Best Regards
>>>
>>> On February 19, 2018 10:11:04 PM GMT+01:00, Henrik Bengtsson <henrik.bengtsson at gmail.com> wrote:
>>>> Hi, I'm trying to understand the rationale for your proposed amount of
>>>> splitting and more precisely why that one is THE one.
>>>>
>>>> If I put labels on your example numbers in one of your previous post:
>>>>
>>>> nbrOfElements <- 97
>>>> nbrOfWorkers <- 5
>>>>
>>>> With these, there are two extremes in how you can split up the
>>>> processing in chunks such that all workers are utilized:
>>>>
>>>> (A) Each worker, called multiple times, processes one element each
>>>> time:
>>>>
>>>>> nbrOfElements <- 97
>>>>> nbrOfWorkers <- 5
>>>>> nbrOfChunks <- nbrOfElements
>>>>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
>>>> [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>>>> [30] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>>>> [59] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1
>>>> [88] 1 1 1 1 1 1 1 1 1 1
>>>>
>>>>
>>>> (B) Each worker, called once, processes multiple element:
>>>>
>>>>> nbrOfElements <- 97
>>>>> nbrOfWorkers <- 5
>>>>> nbrOfChunks <- nbrOfWorkers
>>>>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
>>>> [1] 20 19 19 19 20
>>>>
>>>> I understand that neither of these two extremes may be the best when
>>>> it comes to orchestration overhead and load balancing. Instead, the
>>>> best might be somewhere in-between, e.g.
>>>>
>>>> (C) Each worker, called multiple times, processing multiple elements:
>>>>
>>>>> nbrOfElements <- 97
>>>>> nbrOfWorkers <- 5
>>>>> nbrOfChunks <- nbrOfElements / nbrOfWorkers
>>>>> sapply(parallel:::splitList(1:nbrOfElements, nbrOfChunks), length)
>>>> [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5
>>>>
>>>> However, there are multiple alternatives between the two extremes, e.g.
>>>>
>>>>> nbrOfChunks <- scale * nbrOfElements / nbrOfWorkers
>>>> So, is there a reason why you argue for scale = 1.0 to be the optimal?
>>>>
>>>> FYI, In future.apply::future_lapply(X, FUN, ...) there is a
>>>> 'future.scheduling' scale factor(*) argument where default
>>>> future.scheduling = 1 corresponds to (B) and future.scheduling = +Inf
>>>> to (A).? Using future.scheduling = 4 achieves the amount of
>>>> load-balancing you propose in (C).?? (*) Different definition from the
>>>> above 'scale'. (Disclaimer: I'm the author)
>>>>
>>>> /Henrik
>>>>
>>>> On Mon, Feb 19, 2018 at 10:21 AM, Christian Krause
>>>> <christian.krause at idiv.de> wrote:
>>>>> Dear R-Devel List,
>>>>>
>>>>> I have installed R 3.4.3 with the patch applied on our cluster and
>>>> ran a *real-world* job of one of our users to confirm that the patch
>>>> works to my satisfaction. Here are the results.
>>>>> The original was a series of jobs, all essentially doing the same
>>>> stuff using bootstrapped data, so for the original there is more data
>>>> and I show the arithmetic mean with standard deviation. The
>>>> confirmation with the patched R was only a single instance of that
>>>> series of jobs.
>>>>> ## Job Efficiency
>>>>>
>>>>> The job efficiency is defined as (this is what the `qacct-efficiency`
>>>> tool below does):
>>>>> ```
>>>>> efficiency = cputime / cores / wallclocktime * 100%
>>>>> ```
>>>>>
>>>>> In simpler words: how well did the job utilize its CPU cores. It
>>>> shows the percentage of time the job was actually doing stuff, as
>>>> opposed to the difference:
>>>>> ```
>>>>> wasted = 100% - efficiency
>>>>> ```
>>>>>
>>>>> ... which, essentially, tells us how much of the resources were
>>>> wasted, i.e. CPU cores just idling, without being used by anyone. We
>>>> care a lot about that because, for our scientific computing cluster,
>>>> wasted resources is like burning money.
>>>>> ### original
>>>>>
>>>>> This is the entire series from our job accounting database, filteres
>>>> the successful jobs, calculates efficiency and then shows the average
>>>> and standard deviation of the efficiency:
>>>>> ```
>>>>> $ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd
>>>>> n=945 ? 61.7276 ? 7.78719
>>>>> ```
>>>>>
>>>>> This is the entire series from our job accounting database, filteres
>>>> the successful jobs, calculates efficiency and does sort of a
>>>> histogram-like binning before calculation of mean and standard
>>>> deviation (to get a more detailed impression of the distribution when
>>>> standard deviation of the previous command is comparatively high):
>>>>> ```
>>>>> $ qacct -j 4433299 | qacct-success | qacct-efficiency | meansd-bin -w
>>>> 10 | sort -gk1 | column -t
>>>>> 10? -? 20? ->? n=3??? ?? 19.21666666666667?? ?? 0.9112811494447459
>>>>> 20? -? 30? ->? n=6??? ?? 26.418333333333333? ?? 2.665996374091058
>>>>> 30? -? 40? ->? n=12?? ?? 35.11583333333334?? ?? 2.8575783082671196
>>>>> 40? -? 50? ->? n=14?? ?? 45.35285714285715?? ?? 2.98623361591005
>>>>> 50? -? 60? ->? n=344? ?? 57.114593023255814? ?? 2.1922005551774415
>>>>> 60? -? 70? ->? n=453? ?? 64.29536423841049?? ?? 2.8334788433963856
>>>>> 70? -? 80? ->? n=108? ?? 72.95592592592598?? ?? 2.5219474143639276
>>>>> 80? -? 90? ->? n=5??? ?? 81.526????????????? ?? 1.2802265424525452
>>>>> ```
>>>>>
>>>>> I have attached an example graph from our monitoring system of a
>>>> single instance in my previous mail. There you can see that the load
>>>> balancing does not actually work, i.e. same as `parLapply`. This
>>>> reflects in the job efficiency.
>>>>> ### patch applied
>>>>>
>>>>> This is the single instance I used to confirm that the patch works:
>>>>>
>>>>> ```
>>>>> $ qacct -j 4562202 | qacct-efficiency
>>>>> 97.36
>>>>> ```
>>>>>
>>>>> The graph from our monitoring system is attached. As you can see, the
>>>> load balancing works to a satisfying degree and the efficiency is well
>>>> above 90% which was what I had hoped for :-)
>>>>> ## Additional Notes
>>>>>
>>>>> The list used in this jobs `parLapplyLB` is 5812 elements long. With
>>>> the `splitList`-chunking from the patch, you'll get 208 lists of about
>>>> 28 elements (208 chunks of size 28). The job ran on 28 CPU cores and
>>>> had a wallclock time of 120351.590 seconds, i.e. 33.43 hours. Thus, the
>>>> function we apply to our list takes about 580 seconds per list element,
>>>> i.e. about 10 minutes. I suppose, for that runtime, we would get even
>>>> better load balancing if we would reduce the chunk size even further,
>>>> maybe even down to 1, thus getting our efficiency even closer to 100%.
>>>>> Of course, for really short-running functions, a higher chunk size
>>>> may be more efficient because of the overhead. In our case, the
>>>> overhead is negligible and that is why the low chunk size works really
>>>> well. In contrast, for smallish lists with short-running functions, you
>>>> might not even need load balancing and `parLapply` suffices. It only
>>>> becomes an issue, when the runtime of the function is high and / or
>>>> varying.
>>>>> In our case, the entire runtime of the entire series of jobs was:
>>>>>
>>>>> ```
>>>>> $ qacct -j 4433299 | awk '$1 == "wallclock" { sum += $2 } END { print
>>>> sum, "seconds" }'
>>>>> 4.72439e+09 seconds
>>>>> ```
>>>>>
>>>>> Thats about 150 years on a single core or 7.5 years on a 20 core
>>>> server! Our user was constantly using about 500 cores, so this took
>>>> about 110 days. If you compare this to my 97% efficiency example, the
>>>> jobs could have been finished in 75 days instead ;-)
>>>>> ## Upcoming Patch
>>>>>
>>>>> If this patch gets applied to the R code base (and I hope it will
>>>> :-)) my colleague and I will submit another patch that adds the chunk
>>>> size as an optional parameter to all off the load balancing functions.
>>>> With that parameter, users of these functions *can* decide for
>>>> themselves which chunk size they prefer for their code. As mentioned
>>>> before, the most efficient chunk size depends on the used functions
>>>> runtime, which is the only thing R does not know and users really
>>>> should be allowed to specify explicitly. The default of this new
>>>> optional parameter would be the one we used here and this would make
>>>> that upcoming patch fully source-compatible.
>>>>> Best Regards
>>>>>
>>>>> On 02/12/2018 08:08 PM, Christian Krause wrote:
>>>>>> Dear R-Devel List,
>>>>>>
>>>>>> **TL;DR:** The function **parLapplyLB** of the parallel package has
>>>> [reportedly][1] (see also attached RRD output) not
>>>>>> been doing its job, i.e. not actually balancing the load. My
>>>> colleague Dirk Sarpe and I found the cause of the problem
>>>>>> and we also have a patch to fix it (attached). A similar fix has
>>>> also been provided [here][2].
>>>>>> [1]:
>>>> https://stackoverflow.com/questions/38230831/why-does-parlapplylb-not-actually-balance-load
>>>>>> [2]: https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16792
>>>>>>
>>>>>>
>>>>>> ## The Call Chain
>>>>>>
>>>>>> First, we traced the relevant R function calls through the code,
>>>> beginning with `parLapplyLB`:
>>>>>> 1.? **parLapplyLB:** clusterApply.R:177, calls **splitList**, then
>>>> **clusterApplyLB**
>>>>>> 2.? **splitList:** clusterApply.R:157
>>>>>> 3.? **clusterApplyLB:** clusterApply.R:87, calls
>>>> **dynamicClusterApply**
>>>>>> 4.? **dynamicClusterApply:** clusterApply.R:39
>>>>>>
>>>>>>
>>>>>> ## splitList
>>>>>>
>>>>>> We used both our whiteboard and an R session to manually *run* a few
>>>> examples. We were using lists of 100 elements and 5
>>>>>> workers. First, lets take a look at **splitList**:
>>>>>>
>>>>>> ```r
>>>>>>> sapply(parallel:::splitList(1:100, 5), length)
>>>>>> [1] 20 20 20 20 20
>>>>>>
>>>>>>> sapply(parallel:::splitList(1:97, 5), length)
>>>>>> [1] 20 19 19 19 20
>>>>>>
>>>>>>> sapply(parallel:::splitList(1:97, 20), length)
>>>>>>  ? [1] 5 5 5 5 4 5 5 5 5 5 4 5 5 5 5 4 5 5 5 5
>>>>>> ```
>>>>>>
>>>>>> As we can see in the examples, the work is distributed as equally as
>>>> possible.
>>>>>> ## dynamicClusterApply
>>>>>>
>>>>>> **dynamicClusterApply** works this way (simplified):
>>>>>>
>>>>>> 1.? it first gives a chunk to each worker
>>>>>> 2.? once a worker comes back with the result, it is given the next
>>>> chunk
>>>>>> **This is the important part:** As long as there are **more** chunks
>>>> than workers, there will be load balancing. If
>>>>>> there are fewer chunks than workers, each worker will get **at most
>>>> one chunk** and there is **no** load balancing.
>>>>>> ## parLapplyLB
>>>>>>
>>>>>> This is how **parLapplyLB** splits the input list (with a bit of
>>>> refactoring, for readability):
>>>>>> ```r
>>>>>> parLapplyLB <- function(cl = NULL, X, fun, ...)
>>>>>> {
>>>>>>  ???? cl <- defaultCluster(cl)
>>>>>>
>>>>>>  ???? chunks <- splitList(X, length(cl))
>>>>>>
>>>>>>  ???? do.call(c,
>>>>>>  ???????????? clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>>>>>>  ???????????? quote = TRUE)
>>>>>> }
>>>>>> ```
>>>>>>
>>>>>> For our examples, the chunks have these sizes:
>>>>>>
>>>>>> ```r
>>>>>>> sapply(parallel:::splitList(1:100, 5), length)
>>>>>> [1] 20 20 20 20 20
>>>>>> ```
>>>>>>
>>>>>> There we have it: 5 chunks. 5 workers. With this work distribution,
>>>> there can't possibly be any load balancing, because
>>>>>> each worker is given a single chunk and then it stops working
>>>> because there are no more chunks.
>>>>>> Instead, **parLapplyLB** should look like this (patch is attached):
>>>>>>
>>>>>> ```r
>>>>>> parLapplyLB <- function(cl = NULL, X, fun, ...)
>>>>>> {
>>>>>>  ???? cl <- defaultCluster(cl)
>>>>>>
>>>>>>  ???? chunkSize <- max(length(cl), ceiling(length(X) / length(cl)))
>>>>>>
>>>>>>  ???? chunks <- splitList(X, chunkSize)
>>>>>>
>>>>>>  ???? do.call(c,
>>>>>>  ???????????? clusterApplyLB(cl, x = chunks, fun = lapply, fun, ...),
>>>>>>  ???????????? quote = TRUE)
>>>>>> }
>>>>>> ```
>>>>>>
>>>>>> Examples with a cluster of 5 workers:
>>>>>>
>>>>>> ```r
>>>>>> # length(cl) < length(X)
>>>>>>> sapply(parallel:::splitList(1:100, ceiling(100 / 5)), length)
>>>>>>  ? [1] 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5 5
>>>>>>
>>>>>> # length(cl) >= length(X)
>>>>>>> sapply(parallel:::splitList(1:4, 4), length)
>>>>>> [1] 1 1 1 1
>>>>>> # one worker idles here, but we can't do better than that
>>>>>> ```
>>>>>>
>>>>>> With this patch, the number of chunks is larger than the number of
>>>> workers, if possible at all, and then load balancing
>>>>>> should work.
>>>>>>
>>>>>> Best Regards
>>>>>>
>>>>>>
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>>
>>>>> -- 
>>>>> Christian Krause
>>>>>
>>>>> Scientific Computing Administration and Support
>>>>>
>>>>>
>>>> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>>> Email: christian.krause at idiv.de
>>>>>
>>>>> Office: BioCity Leipzig 5e, Room 3.201.3
>>>>>
>>>>> Phone: +49 341 97 33144
>>>>>
>>>>>
>>>> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>>> German Centre for Integrative Biodiversity Research (iDiv)
>>>> Halle-Jena-Leipzig
>>>>> Deutscher Platz 5e
>>>>>
>>>>> 04103 Leipzig
>>>>>
>>>>> Germany
>>>>>
>>>>>
>>>> ------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
>>>>> iDiv is a research centre of the DFG ? Deutsche
>>>> Forschungsgemeinschaft
>>>>> iDiv ist eine zentrale Einrichtung der Universit?t Leipzig im Sinne
>>>> des ? 92 Abs. 1 S?chsHSFG und wird zusammen mit der
>>>> Martin-Luther-Universit?t Halle-Wittenberg und der
>>>> Friedrich-Schiller-Universit?t Jena betrieben sowie in Kooperation mit
>>>> dem Helmholtz-Zentrum f?r Umweltforschung GmbH ? UFZ. Beteiligte
>>>> Kooperationspartner sind die folgenden au?eruniversit?ren
>>>> Forschungseinrichtungen: das Helmholtz-Zentrum f?r Umweltforschung GmbH
>>>> - UFZ, das Max-Planck-Institut f?r Biogeochemie (MPI BGC), das
>>>> Max-Planck-Institut f?r chemische ?kologie (MPI CE), das
>>>> Max-Planck-Institut f?r evolution?re Anthropologie (MPI EVA), das
>>>> Leibniz-Institut Deutsche Sammlung von Mikroorganismen und Zellkulturen
>>>> (DSMZ), das Leibniz-Institut f?r Pflanzenbiochemie (IPB), das
>>>> Leibniz-Institut f?r Pflanzengenetik und Kulturpflanzenforschung (IPK)
>>>> und das Leibniz-Institut Senckenberg Museum f?r Naturkunde G?rlitz
>>>> (SMNG). USt-IdNr. DE 141510383
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>


From maechler at stat.math.ethz.ch  Tue Mar 13 12:47:28 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 13 Mar 2018 12:47:28 +0100
Subject: [Rd] importing namespaces from base packages
In-Reply-To: <CAJ=0CtBKN51Cbp2hjZyRjnsTBkygKcJfmrxTw6Q-ZVUWFWabGg@mail.gmail.com>
References: <CAJ=0CtCXxxGi9paHg6c6tQQJqbHt5GQHcZH5gPpkepEv9Pb56A@mail.gmail.com>
 <23206.28665.937751.614900@stat.math.ethz.ch>
 <CAJ=0CtBKN51Cbp2hjZyRjnsTBkygKcJfmrxTw6Q-ZVUWFWabGg@mail.gmail.com>
Message-ID: <23207.47696.939928.601943@stat.math.ethz.ch>

>>>>> Adrian Du?a <dusa.adrian at unibuc.ro>
>>>>>     on Tue, 13 Mar 2018 09:17:08 +0200 writes:

    > On Mon, Mar 12, 2018 at 2:18 PM, Martin Maechler <maechler at stat.math.ethz.ch>
    > wrote:
    >> [...]
    >> Is that so?   Not according to my reading of the 'Writing R
    >> Extensions' manual, nor according to what I have been doing in
    >> all of my packages for ca. 2 years:
    >> 
    >> The rule I have in my mind is
    >> 
    >> 1) NAMESPACE Import(s|From) \
    >> ............................ <==>  DESCRIPTION -> 'Imports:'
    >> 2) .. using "::" in  R code /
    >> 
    >> 
    >> If you really found that you did not have to import from say
    >> 'utils', I think this was a *un*lucky coincidence.

    > Of course, the importFrom() is mandatory in NAMESPACE otherwise the package
    > does not pass the checks.
    > The question was related to the relation between the packages mentioned in
    > the NAMESPACE and the packages mentioned in the Imports: field from
    > DESCRIPTION.

    > For instance, the current version 3.1 of package QCA on CRAN mentions in
    > the DESCRIPTION:

    > Imports: venn (? 1.2), shiny, methods, fastdigest

    > while the NAMESPACE file has:

    > import(shiny)
    > import(venn)
    > import(fastdigest)
    > importFrom("utils", "packageDescription", "remove.packages",
    > "capture.output")
    > importFrom("stats", "glm", "predict", "quasibinomial", "binom.test",
    > "cutree", "dist", "hclust", "na.omit", "dbinom", "setNames")
    > importFrom("grDevices", "dev.cur", "dev.new", "dev.list")
    > importFrom("graphics", "abline", "axis", "box", "mtext", "par", "title",
    > "text")
    > importFrom("methods", "is")

    > There are functions from packages utils, stats, grDevices and graphics for
    > which the R checks do not require a specific entry in the Imports: field.
    > I suspect because all of these packages are part of the base R, but so is
    > package methods. The question is why is it not mandatory for those packages
    > to be mentioned in the Imports: field from DESCRIPTION, while removing
    > package methods from that field runs into an error, despite maintaining the
    > package in the NAMESPACE's importFrom().


Thank you, Adrian,  for clarification of your question.
As a matter of fact, I was not aware of what you showed above,
and personally I think I do add every package/namespace mentioned in
NAMESPACE to the DESCRIPTION's  "Imports:" field.

AFAIK the above phenomenon is not documented, and rather the
docs would imply that this phenomenon might go away -- I for one
would vote for more consistency here ..

Martin

    >> [...]
    >> There are places in the R source where it is treated specially,
    >> indeed, part of 'methods' may be needed when it is neither
    >> loaded nor attached (e.g., when R runs with only base, say, and
    >> suddenly encounters an S4 object), and there still are
    >> situations where 'methods' needs to be in the search() path and
    >> not just loaded, but these cases should be unrelated to the
    >> above DESCRIPTION-Imports vs NAMESPACE-Imports correspondence.

    > This is what I had expected myself, then the above behavior has to have
    > another explanation.
    > It is just a curiosity, there is naturally nothing wrong with maintaining
    > package methods in the Imports: field. Only odd why some base R packages
    > are treated differently than other base R packages, at the package checks
    > stage.

    > Thank you,
    > Adrian

    > --
    > Adrian Dusa
    > University of Bucharest
    > Romanian Social Data Archive
    > Soseaua Panduri nr. 90-92
    > 050663 Bucharest sector 5
    > Romania
    > https://adriandusa.eu

    > [[alternative HTML version deleted]]


From jari.oksanen at oulu.fi  Tue Mar 13 13:36:53 2018
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Tue, 13 Mar 2018 14:36:53 +0200
Subject: [Rd] importing namespaces from base packages
In-Reply-To: <23207.47696.939928.601943@stat.math.ethz.ch>
References: <CAJ=0CtCXxxGi9paHg6c6tQQJqbHt5GQHcZH5gPpkepEv9Pb56A@mail.gmail.com>
 <23206.28665.937751.614900@stat.math.ethz.ch>
 <CAJ=0CtBKN51Cbp2hjZyRjnsTBkygKcJfmrxTw6Q-ZVUWFWabGg@mail.gmail.com>
 <23207.47696.939928.601943@stat.math.ethz.ch>
Message-ID: <f1bf10e9-676e-55ba-f972-709c56c79a65@oulu.fi>

It seems that they are defined in tools/R/check.R. For instance, line 
363-364 says:

     ## The default set of packages here are as they are because
     ## .get_S3_generics_as_seen_from_package needs utils,graphics,stats

and then on lines 368 (Windows) and 377 (other OS) it has:
     "R_DEFAULT_PACKAGES=utils,grDevices,graphics,stats"

So these pass R CMD check and are an "industrial standard". Changing 
this will be break half of CRAN packages.

Cheers, Jari Oksanen

On 13/03/18 13:47, Martin Maechler wrote:
>>>>>> Adrian Du?a <dusa.adrian at unibuc.ro>
>>>>>>      on Tue, 13 Mar 2018 09:17:08 +0200 writes:
> 
>      > On Mon, Mar 12, 2018 at 2:18 PM, Martin Maechler <maechler at stat.math.ethz.ch>
>      > wrote:
>      >> [...]
>      >> Is that so?   Not according to my reading of the 'Writing R
>      >> Extensions' manual, nor according to what I have been doing in
>      >> all of my packages for ca. 2 years:
>      >>
>      >> The rule I have in my mind is
>      >>
>      >> 1) NAMESPACE Import(s|From) \
>      >> ............................ <==>  DESCRIPTION -> 'Imports:'
>      >> 2) .. using "::" in  R code /
>      >>
>      >>
>      >> If you really found that you did not have to import from say
>      >> 'utils', I think this was a *un*lucky coincidence.
> 
>      > Of course, the importFrom() is mandatory in NAMESPACE otherwise the package
>      > does not pass the checks.
>      > The question was related to the relation between the packages mentioned in
>      > the NAMESPACE and the packages mentioned in the Imports: field from
>      > DESCRIPTION.
> 
>      > For instance, the current version 3.1 of package QCA on CRAN mentions in
>      > the DESCRIPTION:
> 
>      > Imports: venn (? 1.2), shiny, methods, fastdigest
> 
>      > while the NAMESPACE file has:
> 
>      > import(shiny)
>      > import(venn)
>      > import(fastdigest)
>      > importFrom("utils", "packageDescription", "remove.packages",
>      > "capture.output")
>      > importFrom("stats", "glm", "predict", "quasibinomial", "binom.test",
>      > "cutree", "dist", "hclust", "na.omit", "dbinom", "setNames")
>      > importFrom("grDevices", "dev.cur", "dev.new", "dev.list")
>      > importFrom("graphics", "abline", "axis", "box", "mtext", "par", "title",
>      > "text")
>      > importFrom("methods", "is")
> 
>      > There are functions from packages utils, stats, grDevices and graphics for
>      > which the R checks do not require a specific entry in the Imports: field.
>      > I suspect because all of these packages are part of the base R, but so is
>      > package methods. The question is why is it not mandatory for those packages
>      > to be mentioned in the Imports: field from DESCRIPTION, while removing
>      > package methods from that field runs into an error, despite maintaining the
>      > package in the NAMESPACE's importFrom().
> 
> 
> Thank you, Adrian,  for clarification of your question.
> As a matter of fact, I was not aware of what you showed above,
> and personally I think I do add every package/namespace mentioned in
> NAMESPACE to the DESCRIPTION's  "Imports:" field.
> 
> AFAIK the above phenomenon is not documented, and rather the
> docs would imply that this phenomenon might go away -- I for one
> would vote for more consistency here ..
> 
> Martin
> 
>      >> [...]
>      >> There are places in the R source where it is treated specially,
>      >> indeed, part of 'methods' may be needed when it is neither
>      >> loaded nor attached (e.g., when R runs with only base, say, and
>      >> suddenly encounters an S4 object), and there still are
>      >> situations where 'methods' needs to be in the search() path and
>      >> not just loaded, but these cases should be unrelated to the
>      >> above DESCRIPTION-Imports vs NAMESPACE-Imports correspondence.
> 
>      > This is what I had expected myself, then the above behavior has to have
>      > another explanation.
>      > It is just a curiosity, there is naturally nothing wrong with maintaining
>      > package methods in the Imports: field. Only odd why some base R packages
>      > are treated differently than other base R packages, at the package checks
>      > stage.
> 
>      > Thank you,
>      > Adrian
> 
>      > --
>      > Adrian Dusa
>      > University of Bucharest
>      > Romanian Social Data Archive
>      > Soseaua Panduri nr. 90-92
>      > 050663 Bucharest sector 5
>      > Romania
>      > https://adriandusa.eu
> 
>      > [[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From dutangc at gmail.com  Tue Mar 13 17:29:00 2018
From: dutangc at gmail.com (Christophe DUTANG)
Date: Tue, 13 Mar 2018 17:29:00 +0100
Subject: [Rd] 64-bit integer type warning on windows
Message-ID: <9C767F91-8EE1-4657-BDE0-639AB6757B06@gmail.com>

Dear list,

During the last two months, I spent a lot of time trying to remove the following warnings of my package randtoolbox:

congruRand.c:180:3: warning: ISO C does not support the 'I64' ms_scanf length modifier [-Wformat=]
   sscanf(params[0], "%" PRIu64 "\n", &inp_mod);

Please see https://www.r-project.org/nosvn/R.check/r-devel-windows-ix86+x86_64/randtoolbox-00install.html 

The warning is raised by the option -pedantic added when checking the package by R-devel. This warning is due to the use of the macro PRIu64. Note that this warning does not show up when I use PRIu64 with printf via Rprintf in other parts of the file congruRand.c. 

My first reaction to look at https://msdn.microsoft.com/fr-fr/library/f9ezhzhs(v=vs.110).aspx is useless, because R on windows uses Mingw-W64 integer types and not the MS version. 

Then, I tried to find information in such as Write Portable Code by Brian Hook and C11 (http://www.open-std.org/jtc1/sc22/wg14/www/docs/n1570.pdf).

They do recommend to use the macro SCNu64 (reserved for scanf family) rather than PRIu64 reserved for printf family functions. 

Unfortunately when I check the package with R-devel, I still have the warning.

On GitHub, there are a version of mingw64 sources : https://github.com/Alexpux/mingw-w64/ . It is explicitly written that SCNu64 is I64u, see line 210 of https://github.com/Alexpux/mingw-w64/blob/master/mingw-w64-headers/crt/inttypes.h 

So, I was wondering if this warning was removable at all? Does anyone encounter this issue?

Any help is appreciated.

Thanks in advance, Christophe

PS: latest version of randtoolbox source code is here https://r-forge.r-project.org/scm/viewvc.php/pkg/randtoolbox/?root=rmetrics
------------------------------------------------------------
Christophe Dutang
CEREMADE, Univ. Paris Dauphine, France
Web : http://dutangc.free.fr


From jtelleria.rproject at gmail.com  Wed Mar 14 12:34:49 2018
From: jtelleria.rproject at gmail.com (Juan Telleria Ruiz de Aguirre)
Date: Wed, 14 Mar 2018 12:34:49 +0100
Subject: [Rd] 64-bit integer type warning on windows
In-Reply-To: <9C767F91-8EE1-4657-BDE0-639AB6757B06@gmail.com>
References: <9C767F91-8EE1-4657-BDE0-639AB6757B06@gmail.com>
Message-ID: <CAJXDcw1DA5m4XW_pSbO78ak-4d-33aeM-wjOtVNLJD4bD-c6Rw@mail.gmail.com>

It does not answer direcly your question, but have you tried "bit64"
CRAN package :)

https://cran.r-project.org/web/packages/bit64/index.html


From edd at debian.org  Wed Mar 14 13:07:12 2018
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 14 Mar 2018 07:07:12 -0500
Subject: [Rd] 64-bit integer type warning on windows
In-Reply-To: <9C767F91-8EE1-4657-BDE0-639AB6757B06@gmail.com>
References: <9C767F91-8EE1-4657-BDE0-639AB6757B06@gmail.com>
Message-ID: <23209.4208.683103.472053@rob.eddelbuettel.com>


On 13 March 2018 at 17:29, Christophe DUTANG wrote:
| So, I was wondering if this warning was removable at all? Does anyone encounter this issue?

That is a pretty old topic.

Did you look into Writing R Extensions?  The first mention is

   * Do be very careful with passing arguments between R, C and FORTRAN
     code.  In particular, 'long' in C will be 32-bit on some R
     platforms (including 64-bit Windows), but 64-bit on most modern
     Unix and Linux platforms.  It is rather unlikely that the use of
     'long' in C code has been thought through: if you need a longer
     type than 'int' you should use a configure test for a C99/C++11
     type such as 'int_fast64_t' (and failing that, 'long long' (8)) and
     typedef your own type to be 'long' or 'long long', or use another
     suitable type (such as 'size_t').

     It is not safe to assume that 'long' and pointer types are the same
     size, and they are not on 64-bit Windows.  If you need to convert
     pointers to and from integers use the C99/C++11 integer types
     'intptr_t' and 'uintptr_t' (which are defined in the header
     '<stdint.h>' and are not required to be implemented by the C99
     standard but are used in C code by R itself).

     Note that 'integer' in FORTRAN corresponds to 'int' in C on all R
     platforms.

   [...]
   
   (8) but note that 'long long' is not a standard C++98 type, and C++
   compilers set up for strict checking will reject it.

so with C++11 you get by: simply make your package use 'CXX_STD = CXX11'.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From greg at datarobot.com  Wed Mar 14 13:24:27 2018
From: greg at datarobot.com (Gregory Michaelson)
Date: Wed, 14 Mar 2018 13:24:27 +0100
Subject: [Rd] truncation/rounding bug with write.csv
Message-ID: <CA+CvkJ_SeWvh07TNTUfUt+Rdj1RKgLzeaak9P+DmnS9_-djYDg@mail.gmail.com>

Hello, I have looked on https://www.r-project.org/bugs.html , but it seems
that this is the only way to do it.

The issue is that the precision used by write.csv is on consistant for big
files.  See the following code:

First I create a large dataframe filled with random uniform values.  Then I
write it to .csv and print out the first and last lines.


df = data.frame(replicate(100, runif(1000000, 0,1)))

write.csv(df, "temp.csv")
system('tail -n1 temp.csv')
system('head -n2 temp.csv')


If you run this, you will note that the precision for the first line is
different from the preision of the last line.  I'm not sure what is
Controlling this, but in the code that led me to this bug, I was only
getting 3 decimal Points by the end of the file.

if you use the write functionality in readr, then you get consistent
precision:

readr::write_csv(df, "temp2.csv")
system('tail -n1 temp2.csv')
system('head -n2 temp2.csv')

 I hope that this ishelpful.  If this is not the proper way to submit the
bug, please let me know.


-- 

Greg

	[[alternative HTML version deleted]]


From edd at debian.org  Wed Mar 14 13:53:54 2018
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 14 Mar 2018 07:53:54 -0500
Subject: [Rd] truncation/rounding bug with write.csv
In-Reply-To: <CA+CvkJ_SeWvh07TNTUfUt+Rdj1RKgLzeaak9P+DmnS9_-djYDg@mail.gmail.com>
References: <CA+CvkJ_SeWvh07TNTUfUt+Rdj1RKgLzeaak9P+DmnS9_-djYDg@mail.gmail.com>
Message-ID: <23209.7010.634867.342504@rob.eddelbuettel.com>


What OS are you on?  On Ubuntu 17.10 with R 3.4.3 all seems well (see
below for your example, I just added a setwd()).

[ That said, I long held a (apparently minority) view that csv is for all
intends and purposes a less-than-ideal format.  If you have that much data,
you do generally not want to serialize it back and forth as that is slow, and
may drop precision.  The rds format is great for R alone; we now have C code
to read it from other apps (in the librdata repo by Evan Miller).  Different
portable serializations work too (protocol buffer, msgpack, ...), there are
databases and on and on... ]

Dirk


R> df <- data.frame(replicate(100, runif(1000000, 0,1)))
R> setwd("/tmp")
R> write.csv(df, "temp.csv")
R> system('tail -n1 temp.csv')
"1000000",0.11496100993827,0.740764639340341,0.519190795486793,0.736045523779467,0.537115448853001,0.769496953347698,0.102257401449606,0.437617724528536,0.173321532085538,0.351960731903091,0.397348914295435,0.496789071243256,0.463006566744298,0.573105450021103,0.575196429155767,0.821617329493165,0.112913676071912,0.187580146361142,0.121353451395407,0.576333721866831,0.00763232703320682,0.468676633667201,0.451408475637436,0.0172415724955499,0.946199159137905,0.439950440311804,0.109224532730877,0.657066411571577,0.0524766123853624,0.54859598656185,0.94473168021068,0.500153199071065,0.636756601976231,0.221365773351863,0.620196332456544,0.559639401268214,0.198483835440129,0.397874651942402,0.710652963491157,0.317212327616289,0.239299293374643,0.0606942125596106,0.165786643279716,0.667431530542672,0.436631754040718,0.812185280025005,0.374252707697451,0.421187321422622,0.730321826180443,0.904493971262127,0.399387824581936,0.650714065413922,0.594219180056825,0.147960299625993,0.941945064114407,0.357223904458806,0.275038427906111,0.191008436959237,0.957893384154886,0.211530723143369,0.680650093592703,0.503884038887918,0.754094189498574,0.74776051659137,0.673691919771954,0.236221367260441,0.825558929471299,0.21071959589608,0.246618688805029,0.686810691142455,0.0247942050918937,0.572868114337325,0.494058627169579,0.684360746992752,0.0139967589639127,0.626861660508439,0.417218193877488,0.410173830809072,0.390906651504338,0.477168896235526,0.382211019750684,0.597674581920728,0.198329919017851,0.0684413285925984,0.450342149706557,0.133007253985852,0.755873151356354,0.372862737858668,0.762442974606529,0.582133987685665,0.692048883531243,0.259269661735743,0.147847984684631,0.635266482364386,0.320955650880933,0.00151186063885689,0.446474697208032,0.0673662247136235,0.791947861900553,0.0973296447191387
R> system('head -n2 temp.csv')
"","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12","X13","X14","X15","X16","X17","X18","X19","X20","X21","X22","X23","X24","X25","X26","X27","X28","X29","X30","X31","X32","X33","X34","X35","X36","X37","X38","X39","X40","X41","X42","X43","X44","X45","X46","X47","X48","X49","X50","X51","X52","X53","X54","X55","X56","X57","X58","X59","X60","X61","X62","X63","X64","X65","X66","X67","X68","X69","X70","X71","X72","X73","X74","X75","X76","X77","X78","X79","X80","X81","X82","X83","X84","X85","X86","X87","X88","X89","X90","X91","X92","X93","X94","X95","X96","X97","X98","X99","X100"
"1",0.995067856274545,0.0237177284434438,0.839840568602085,0.99880409357138,0.455015312181786,0.967688028467819,0.191194181796163,0.903533136472106,0.570170691236854,0.86230118968524,0.23530788696371,0.30707904486917,0.256274404237047,0.369592409580946,0.989929250674322,0.50812312704511,0.806819133926183,0.536566868191585,0.0863138805143535,0.294523851014674,0.676951135974377,0.195627561537549,0.261776751372963,0.383222601376474,0.578275503357872,0.79082652577199,0.19860127940774,0.0204593606758863,0.659964868798852,0.42379029514268,0.69516694964841,0.0594558380544186,0.124592808773741,0.289328144863248,0.524508266709745,0.84306427766569,0.317027662880719,0.273440480465069,0.111866136547178,0.217484838794917,0.354757327819243,0.973936082562432,0.673076402861625,0.300948366522789,0.219195493729785,0.912278874544427,0.276768424082547,0.959344451315701,0.500720858341083,0.431024399353191,0.814444699790329,0.0738761406391859,0.600137831410393,0.639816240407526,0.405302967177704,0.941259450744838,0.190415472723544,0.0382565588224679,0.486769351176918,0.127647049957886,0.558708024444059,0.686994878342375,0.176803215174004,0.794697789475322,0.59406904829666,0.0897431457415223,0.196549082174897,0.0750515828840435,0.736311340238899,0.00494878669269383,0.383522965712473,0.960385771468282,0.101023471681401,0.209177070530131,0.798869548132643,0.147874428424984,0.187238642480224,0.148522146046162,0.32379064662382,0.620601811446249,0.201180462958291,0.179565666476265,0.466121524339542,0.245493365218863,0.980698639061302,0.342919659335166,0.387780519668013,0.393966492731124,0.148554262006655,0.521724705817178,0.722740866011009,0.105151653522626,0.461909410310909,0.905382365221158,0.0736293855588883,0.636923864483833,0.540197744267061,0.425208077067509,0.666353516280651,0.584139186656103
R> 

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org

From jorismeys at gmail.com  Wed Mar 14 16:47:45 2018
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 14 Mar 2018 16:47:45 +0100
Subject: [Rd] truncation/rounding bug with write.csv
In-Reply-To: <23209.7010.634867.342504@rob.eddelbuettel.com>
References: <CA+CvkJ_SeWvh07TNTUfUt+Rdj1RKgLzeaak9P+DmnS9_-djYDg@mail.gmail.com>
 <23209.7010.634867.342504@rob.eddelbuettel.com>
Message-ID: <CAO1zAVb9YD5eCD1TvQNxqFdOLi9tv=QMJAJGN4StPvyRF25aJw@mail.gmail.com>

To my surprise, I can confirm on Windows 10 using R 3.4.3 . As tail is not
recognized by Windows cmd, I replaced with:

system('powershell -nologo "& "Get-Content -Path temp.csv -Tail 1')

The last line shows only 7 digits after the decimal, whereas the first have
15 digits after the decimal. I agree with Dirk though, 1.6Gb csv files are
not the best way to work with datasets.

Cheers
Joris



On Wed, Mar 14, 2018 at 1:53 PM, Dirk Eddelbuettel <edd at debian.org> wrote:

>
> What OS are you on?  On Ubuntu 17.10 with R 3.4.3 all seems well (see
> below for your example, I just added a setwd()).
>
> [ That said, I long held a (apparently minority) view that csv is for all
> intends and purposes a less-than-ideal format.  If you have that much data,
> you do generally not want to serialize it back and forth as that is slow,
> and
> may drop precision.  The rds format is great for R alone; we now have C
> code
> to read it from other apps (in the librdata repo by Evan Miller).
> Different
> portable serializations work too (protocol buffer, msgpack, ...), there are
> databases and on and on... ]
>
> Dirk
>
>
> R> df <- data.frame(replicate(100, runif(1000000, 0,1)))
> R> setwd("/tmp")
> R> write.csv(df, "temp.csv")
> R> system('tail -n1 temp.csv')
> "1000000",0.11496100993827,0.740764639340341,0.519190795486793,0.
> 736045523779467,0.537115448853001,0.769496953347698,0.102257401449606,0.
> 437617724528536,0.173321532085538,0.351960731903091,0.397348914295435,0.
> 496789071243256,0.463006566744298,0.573105450021103,0.575196429155767,0.
> 821617329493165,0.112913676071912,0.187580146361142,0.121353451395407,0.
> 576333721866831,0.00763232703320682,0.468676633667201,0.451408475637436,0.
> 0172415724955499,0.946199159137905,0.439950440311804,0.109224532730877,0.
> 657066411571577,0.0524766123853624,0.54859598656185,0.94473168021068,0.
> 500153199071065,0.636756601976231,0.221365773351863,0.620196332456544,0.
> 559639401268214,0.198483835440129,0.397874651942402,0.710652963491157,0.
> 317212327616289,0.239299293374643,0.0606942125596106,0.165786643279716,0.
> 667431530542672,0.436631754040718,0.812185280025005,0.374252707697451,0.
> 421187321422622,0.730321826180443,0.904493971262127,0.399387824581936,0.
> 650714065413922,0.594219180056825,0.147960299625993,0.941945064114407,0.
> 357223904458806,0.275038427906111,0.191008436959237,0.957893384154886,0.
> 211530723143369,0.680650093592703,0.503884038887918,0.754094189498574,0.
> 74776051659137,0.673691919771954,0.236221367260441,0.825558929471299,0.
> 21071959589608,0.246618688805029,0.686810691142455,0.0247942050918937,0.
> 572868114337325,0.494058627169579,0.684360746992752,0.0139967589639127,0.
> 626861660508439,0.417218193877488,0.410173830809072,0.390906651504338,0.
> 477168896235526,0.382211019750684,0.597674581920728,0.198329919017851,0.
> 0684413285925984,0.450342149706557,0.133007253985852,0.755873151356354,0.
> 372862737858668,0.762442974606529,0.582133987685665,0.692048883531243,0.
> 259269661735743,0.147847984684631,0.635266482364386,0.320955650880933,0.
> 00151186063885689,0.446474697208032,0.0673662247136235,0.
> 791947861900553,0.0973296447191387
> R> system('head -n2 temp.csv')
> "","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11"
> ,"X12","X13","X14","X15","X16","X17","X18","X19","X20","X21"
> ,"X22","X23","X24","X25","X26","X27","X28","X29","X30","X31"
> ,"X32","X33","X34","X35","X36","X37","X38","X39","X40","X41"
> ,"X42","X43","X44","X45","X46","X47","X48","X49","X50","X51"
> ,"X52","X53","X54","X55","X56","X57","X58","X59","X60","X61"
> ,"X62","X63","X64","X65","X66","X67","X68","X69","X70","X71"
> ,"X72","X73","X74","X75","X76","X77","X78","X79","X80","X81"
> ,"X82","X83","X84","X85","X86","X87","X88","X89","X90","X91"
> ,"X92","X93","X94","X95","X96","X97","X98","X99","X100"
> "1",0.995067856274545,0.0237177284434438,0.839840568602085,0.
> 99880409357138,0.455015312181786,0.967688028467819,0.191194181796163,0.
> 903533136472106,0.570170691236854,0.86230118968524,0.23530788696371,0.
> 30707904486917,0.256274404237047,0.369592409580946,0.989929250674322,0.
> 50812312704511,0.806819133926183,0.536566868191585,0.0863138805143535,0.
> 294523851014674,0.676951135974377,0.195627561537549,0.261776751372963,0.
> 383222601376474,0.578275503357872,0.79082652577199,0.19860127940774,0.
> 0204593606758863,0.659964868798852,0.42379029514268,0.69516694964841,0.
> 0594558380544186,0.124592808773741,0.289328144863248,0.524508266709745,0.
> 84306427766569,0.317027662880719,0.273440480465069,0.111866136547178,0.
> 217484838794917,0.354757327819243,0.973936082562432,0.673076402861625,0.
> 300948366522789,0.219195493729785,0.912278874544427,0.276768424082547,0.
> 959344451315701,0.500720858341083,0.431024399353191,0.814444699790329,0.
> 0738761406391859,0.600137831410393,0.639816240407526,0.405302967177704,0.
> 941259450744838,0.190415472723544,0.0382565588224679,0.486769351176918,0.
> 127647049957886,0.558708024444059,0.686994878342375,0.176803215174004,0.
> 794697789475322,0.59406904829666,0.0897431457415223,0.196549082174897,0.
> 0750515828840435,0.736311340238899,0.00494878669269383,0.
> 383522965712473,0.960385771468282,0.101023471681401,0.209177070530131,0.
> 798869548132643,0.147874428424984,0.187238642480224,0.148522146046162,0.
> 32379064662382,0.620601811446249,0.201180462958291,0.179565666476265,0.
> 466121524339542,0.245493365218863,0.980698639061302,0.342919659335166,0.
> 387780519668013,0.393966492731124,0.148554262006655,0.521724705817178,0.
> 722740866011009,0.105151653522626,0.461909410310909,0.905382365221158,0.
> 0736293855588883,0.636923864483833,0.540197744267061,0.425208077067509,0.
> 666353516280651,0.584139186656103
> R>
>
> --
> http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Department of Data Analysis and Mathematical Modelling
Ghent University
Coupure Links 653, B-9000 Gent (Belgium)
<https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>

-----------
Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From Florian_Schwendinger at gmx.at  Wed Mar 14 16:50:59 2018
From: Florian_Schwendinger at gmx.at (Florian Schwendinger)
Date: Wed, 14 Mar 2018 16:50:59 +0100
Subject: [Rd] clusterApply arguments
Message-ID: <trinity-9abb96df-40b2-4e2d-a112-1f2e8a032353-1521042659731@3c-app-gmx-bs70>

Hi!

I recognized that the argument matching of clusterApply (and therefore parLapply) goes wrong when one of the arguments of the function is called "c". In this case, the argument "c" is used as cluster and the functions give the following error message "Error in checkCluster(cl) : not a valid cluster".

Of course, "c" is for many reasons an unfortunate argument name and this can be easily fixed by the user side. 

See below for a small example.

library(parallel)

clu <- makeCluster(2, "PSOCK")

fun <- function(x0, x1) (x0 + x1)
clusterApply(clu, x = 1:2, fun = fun, x1 = 1) ## OK
parLapply(cl = clu, X = 1:2, fun = fun, x1 = 1) #OK


fun <- function(b, c) (b + c)
clusterApply(clu, x = 1:2, fun = fun, c = 1) ## Error
clusterApply(cl = clu, x = 1:2, fun = fun, c = 1) ## OK 
parLapply(cl = clu, X = 1:2, fun = fun, c = 1) ## Error

stopCluster(clu)


I used "R version 3.4.3 Patched (2018-01-07 r74099".


Best regards,
Florian


From greg at datarobot.com  Wed Mar 14 17:02:41 2018
From: greg at datarobot.com (Gregory Michaelson)
Date: Wed, 14 Mar 2018 17:02:41 +0100
Subject: [Rd] truncation/rounding bug with write.csv
In-Reply-To: <CAO1zAVb9YD5eCD1TvQNxqFdOLi9tv=QMJAJGN4StPvyRF25aJw@mail.gmail.com>
References: <CA+CvkJ_SeWvh07TNTUfUt+Rdj1RKgLzeaak9P+DmnS9_-djYDg@mail.gmail.com>
 <23209.7010.634867.342504@rob.eddelbuettel.com>
 <CAO1zAVb9YD5eCD1TvQNxqFdOLi9tv=QMJAJGN4StPvyRF25aJw@mail.gmail.com>
Message-ID: <43D7D9A2-4579-4780-B87C-11D5642D96D4@datarobot.com>

I ran this code in RStudio Server on a linux machine, but I don?t know the version offhand.  I will try to get it tomorrow.  Thanks.

Thanks,
Greg Michaelson
www.datarobot.com
704-981-1118




> On Mar 14, 2018, at 4:47 PM, Joris Meys <jorismeys at gmail.com> wrote:
> 
> To my surprise, I can confirm on Windows 10 using R 3.4.3 . As tail is not recognized by Windows cmd, I replaced with:
> 
> system('powershell -nologo "& "Get-Content -Path temp.csv -Tail 1')
> 
> The last line shows only 7 digits after the decimal, whereas the first have 15 digits after the decimal. I agree with Dirk though, 1.6Gb csv files are not the best way to work with datasets.
> 
> Cheers
> Joris
> 
> 
> 
> On Wed, Mar 14, 2018 at 1:53 PM, Dirk Eddelbuettel <edd at debian.org <mailto:edd at debian.org>> wrote:
> 
> What OS are you on?  On Ubuntu 17.10 with R 3.4.3 all seems well (see
> below for your example, I just added a setwd()).
> 
> [ That said, I long held a (apparently minority) view that csv is for all
> intends and purposes a less-than-ideal format.  If you have that much data,
> you do generally not want to serialize it back and forth as that is slow, and
> may drop precision.  The rds format is great for R alone; we now have C code
> to read it from other apps (in the librdata repo by Evan Miller).  Different
> portable serializations work too (protocol buffer, msgpack, ...), there are
> databases and on and on... ]
> 
> Dirk
> 
> 
> R> df <- data.frame(replicate(100, runif(1000000, 0,1)))
> R> setwd("/tmp")
> R> write.csv(df, "temp.csv")
> R> system('tail -n1 temp.csv')
> "1000000",0.11496100993827,0.740764639340341,0.519190795486793,0.736045523779467,0.537115448853001,0.769496953347698,0.102257401449606,0.437617724528536,0.173321532085538,0.351960731903091,0.397348914295435,0.496789071243256,0.463006566744298,0.573105450021103,0.575196429155767,0.821617329493165,0.112913676071912,0.187580146361142,0.121353451395407,0.576333721866831,0.00763232703320682,0.468676633667201,0.451408475637436,0.0172415724955499,0.946199159137905,0.439950440311804,0.109224532730877,0.657066411571577,0.0524766123853624,0.54859598656185,0.94473168021068,0.500153199071065,0.636756601976231,0.221365773351863,0.620196332456544,0.559639401268214,0.198483835440129,0.397874651942402,0.710652963491157,0.317212327616289,0.239299293374643,0.0606942125596106,0.165786643279716,0.667431530542672,0.436631754040718,0.812185280025005,0.374252707697451,0.421187321422622,0.730321826180443,0.904493971262127,0.399387824581936,0.650714065413922,0.594219180056825,0.147960299625993,0.941945064114407,0.357223904458806,0.275038427906111,0.191008436959237,0.957893384154886,0.211530723143369,0.680650093592703,0.503884038887918,0.754094189498574,0.74776051659137,0.673691919771954,0.236221367260441,0.825558929471299,0.21071959589608,0.246618688805029,0.686810691142455,0.0247942050918937,0.572868114337325,0.494058627169579,0.684360746992752,0.0139967589639127,0.626861660508439,0.417218193877488,0.410173830809072,0.390906651504338,0.477168896235526,0.382211019750684,0.597674581920728,0.198329919017851,0.0684413285925984,0.450342149706557,0.133007253985852,0.755873151356354,0.372862737858668,0.762442974606529,0.582133987685665,0.692048883531243,0.259269661735743,0.147847984684631,0.635266482364386,0.320955650880933,0.00151186063885689,0.446474697208032,0.0673662247136235,0.791947861900553,0.0973296447191387
> R> system('head -n2 temp.csv')
> "","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12","X13","X14","X15","X16","X17","X18","X19","X20","X21","X22","X23","X24","X25","X26","X27","X28","X29","X30","X31","X32","X33","X34","X35","X36","X37","X38","X39","X40","X41","X42","X43","X44","X45","X46","X47","X48","X49","X50","X51","X52","X53","X54","X55","X56","X57","X58","X59","X60","X61","X62","X63","X64","X65","X66","X67","X68","X69","X70","X71","X72","X73","X74","X75","X76","X77","X78","X79","X80","X81","X82","X83","X84","X85","X86","X87","X88","X89","X90","X91","X92","X93","X94","X95","X96","X97","X98","X99","X100"
> "1",0.995067856274545,0.0237177284434438,0.839840568602085,0.99880409357138,0.455015312181786,0.967688028467819,0.191194181796163,0.903533136472106,0.570170691236854,0.86230118968524,0.23530788696371,0.30707904486917,0.256274404237047,0.369592409580946,0.989929250674322,0.50812312704511,0.806819133926183,0.536566868191585,0.0863138805143535,0.294523851014674,0.676951135974377,0.195627561537549,0.261776751372963,0.383222601376474,0.578275503357872,0.79082652577199,0.19860127940774,0.0204593606758863,0.659964868798852,0.42379029514268,0.69516694964841,0.0594558380544186,0.124592808773741,0.289328144863248,0.524508266709745,0.84306427766569,0.317027662880719,0.273440480465069,0.111866136547178,0.217484838794917,0.354757327819243,0.973936082562432,0.673076402861625,0.300948366522789,0.219195493729785,0.912278874544427,0.276768424082547,0.959344451315701,0.500720858341083,0.431024399353191,0.814444699790329,0.0738761406391859,0.600137831410393,0.639816240407526,0.405302967177704,0.941259450744838,0.190415472723544,0.0382565588224679,0.486769351176918,0.127647049957886,0.558708024444059,0.686994878342375,0.176803215174004,0.794697789475322,0.59406904829666,0.0897431457415223,0.196549082174897,0.0750515828840435,0.736311340238899,0.00494878669269383,0.383522965712473,0.960385771468282,0.101023471681401,0.209177070530131,0.798869548132643,0.147874428424984,0.187238642480224,0.148522146046162,0.32379064662382,0.620601811446249,0.201180462958291,0.179565666476265,0.466121524339542,0.245493365218863,0.980698639061302,0.342919659335166,0.387780519668013,0.393966492731124,0.148554262006655,0.521724705817178,0.722740866011009,0.105151653522626,0.461909410310909,0.905382365221158,0.0736293855588883,0.636923864483833,0.540197744267061,0.425208077067509,0.666353516280651,0.584139186656103
> R>
> 
> --
> http://dirk.eddelbuettel.com <http://dirk.eddelbuettel.com/> | @eddelbuettel | edd at debian.org <mailto:edd at debian.org>
> ______________________________________________
> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel <https://stat.ethz.ch/mailman/listinfo/r-devel>
> 
> 
> 
> -- 
> Joris Meys
> Statistical consultant
> 
> Department of Data Analysis and Mathematical Modelling
> Ghent University
> Coupure Links 653, B-9000 Gent (Belgium)
>  <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
> 
> -----------
> Biowiskundedagen 2017-2018
> http://www.biowiskundedagen.ugent.be/ <http://www.biowiskundedagen.ugent.be/>
> 
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php <http://helpdesk.ugent.be/e-maildisclaimer.php>

	[[alternative HTML version deleted]]


From georgi.boshnakov at manchester.ac.uk  Wed Mar 14 19:04:46 2018
From: georgi.boshnakov at manchester.ac.uk (Georgi Boshnakov)
Date: Wed, 14 Mar 2018 18:04:46 +0000
Subject: [Rd] punctuation in utils::cite()
Message-ID: <438D2EC9EAFE5946B2D5864670EA468E018F65313A@MBXP01.ds.man.ac.uk>

Hi,

I wonder if the following is a design decision in the default bib style  for utils::cite().

Create a bibentry object:

> bibs <- bibtex::read.bib(package = "tools")
> bibs

Murdoch D (2009). "Parsing Rd files." <URL:
http://developer.r-project.org/parseRd.pdf>.

When an entry is cited with with a text to include with argument `after', I would expect a comma after the year, but both textual and parenthesised citation include only a space delimiter:

> cite("murdoch:2009", bib = bibs, after = "section 2", textual = TRUE)
[1] "Murdoch (2009 section 2)"

> cite("murdoch:2009", bib = bibs, after = "section 2")
[1] "(Murdoch 2009 section 2)"


Is this intended?  Including the comma in `after' doesn't help, since the space is before it:

> cite("murdoch:2009", bib = bibs, after = ", section 2", textual = TRUE)
[1] "Murdoch (2009 , section 2)"

> cite("murdoch:2009", bib = bibs, after = ", section 2")
[1] "(Murdoch 2009 , section 2)"


Georgi Boshnakov


	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Wed Mar 14 19:05:58 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Wed, 14 Mar 2018 11:05:58 -0700
Subject: [Rd] clusterApply arguments
In-Reply-To: <trinity-9abb96df-40b2-4e2d-a112-1f2e8a032353-1521042659731@3c-app-gmx-bs70>
References: <trinity-9abb96df-40b2-4e2d-a112-1f2e8a032353-1521042659731@3c-app-gmx-bs70>
Message-ID: <CAFDcVCRUoLVcr7ByUE0eABt+n5Tjj_RTZjsO6iVpbih0b8wxuw@mail.gmail.com>

This is nothing specific to parallel::clusterApply() per se. It is the
default behavior of R where it allows for partial argument names.  I
don't think there's much that can be done here except always using
fully named arguments to the "apply" function itself as you show.

You can "alert" yourself when there's a mistake by using:

options(warnPartialMatchArgs = TRUE)

e.g.

> clusterApply(clu, x = 1:2, fun = fun, c = 1) ## Error
Warning in clusterApply(clu, x = 1:2, fun = fun, c = 1) :
  partial argument match of 'c' to 'cl'
Error in checkCluster(cl) : not a valid cluster

It's still only a warning, but an informative one.

/Henrik

On Wed, Mar 14, 2018 at 8:50 AM, Florian Schwendinger
<Florian_Schwendinger at gmx.at> wrote:
> Hi!
>
> I recognized that the argument matching of clusterApply (and therefore parLapply) goes wrong when one of the arguments of the function is called "c". In this case, the argument "c" is used as cluster and the functions give the following error message "Error in checkCluster(cl) : not a valid cluster".
>
> Of course, "c" is for many reasons an unfortunate argument name and this can be easily fixed by the user side.
>
> See below for a small example.
>
> library(parallel)
>
> clu <- makeCluster(2, "PSOCK")
>
> fun <- function(x0, x1) (x0 + x1)
> clusterApply(clu, x = 1:2, fun = fun, x1 = 1) ## OK
> parLapply(cl = clu, X = 1:2, fun = fun, x1 = 1) #OK
>
>
> fun <- function(b, c) (b + c)
> clusterApply(clu, x = 1:2, fun = fun, c = 1) ## Error
> clusterApply(cl = clu, x = 1:2, fun = fun, c = 1) ## OK
> parLapply(cl = clu, X = 1:2, fun = fun, c = 1) ## Error
>
> stopCluster(clu)
>
>
> I used "R version 3.4.3 Patched (2018-01-07 r74099".
>
>
> Best regards,
> Florian
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From istazahn at gmail.com  Wed Mar 14 19:32:23 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Wed, 14 Mar 2018 14:32:23 -0400
Subject: [Rd] truncation/rounding bug with write.csv
In-Reply-To: <43D7D9A2-4579-4780-B87C-11D5642D96D4@datarobot.com>
References: <CA+CvkJ_SeWvh07TNTUfUt+Rdj1RKgLzeaak9P+DmnS9_-djYDg@mail.gmail.com>
 <23209.7010.634867.342504@rob.eddelbuettel.com>
 <CAO1zAVb9YD5eCD1TvQNxqFdOLi9tv=QMJAJGN4StPvyRF25aJw@mail.gmail.com>
 <43D7D9A2-4579-4780-B87C-11D5642D96D4@datarobot.com>
Message-ID: <CA+vqiLEu2zL8kvg-DHnYZG2qQ9SzhZKWd6K_a=+xD-BBt6wF+w@mail.gmail.com>

I don't see the issue here. It would be helpful if people would report
their sessionInfo() when reporting whether or not they see this issue.
Mine is

> sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Arch Linux

Matrix products: default
BLAS/LAPACK: /usr/lib/libopenblas_haswellp-r0.2.20.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.3 rmsfact_0.0.3  cowsay_0.5.0   fortunes_1.5-4

On Wed, Mar 14, 2018 at 12:02 PM, Gregory Michaelson <greg at datarobot.com> wrote:
> I ran this code in RStudio Server on a linux machine, but I don?t know the version offhand.  I will try to get it tomorrow.  Thanks.
>
> Thanks,
> Greg Michaelson
> www.datarobot.com
> 704-981-1118
>
>
>
>
>> On Mar 14, 2018, at 4:47 PM, Joris Meys <jorismeys at gmail.com> wrote:
>>
>> To my surprise, I can confirm on Windows 10 using R 3.4.3 . As tail is not recognized by Windows cmd, I replaced with:
>>
>> system('powershell -nologo "& "Get-Content -Path temp.csv -Tail 1')
>>
>> The last line shows only 7 digits after the decimal, whereas the first have 15 digits after the decimal. I agree with Dirk though, 1.6Gb csv files are not the best way to work with datasets.
>>
>> Cheers
>> Joris
>>
>>
>>
>> On Wed, Mar 14, 2018 at 1:53 PM, Dirk Eddelbuettel <edd at debian.org <mailto:edd at debian.org>> wrote:
>>
>> What OS are you on?  On Ubuntu 17.10 with R 3.4.3 all seems well (see
>> below for your example, I just added a setwd()).
>>
>> [ That said, I long held a (apparently minority) view that csv is for all
>> intends and purposes a less-than-ideal format.  If you have that much data,
>> you do generally not want to serialize it back and forth as that is slow, and
>> may drop precision.  The rds format is great for R alone; we now have C code
>> to read it from other apps (in the librdata repo by Evan Miller).  Different
>> portable serializations work too (protocol buffer, msgpack, ...), there are
>> databases and on and on... ]
>>
>> Dirk
>>
>>
>> R> df <- data.frame(replicate(100, runif(1000000, 0,1)))
>> R> setwd("/tmp")
>> R> write.csv(df, "temp.csv")
>> R> system('tail -n1 temp.csv')
>> "1000000",0.11496100993827,0.740764639340341,0.519190795486793,0.736045523779467,0.537115448853001,0.769496953347698,0.102257401449606,0.437617724528536,0.173321532085538,0.351960731903091,0.397348914295435,0.496789071243256,0.463006566744298,0.573105450021103,0.575196429155767,0.821617329493165,0.112913676071912,0.187580146361142,0.121353451395407,0.576333721866831,0.00763232703320682,0.468676633667201,0.451408475637436,0.0172415724955499,0.946199159137905,0.439950440311804,0.109224532730877,0.657066411571577,0.0524766123853624,0.54859598656185,0.94473168021068,0.500153199071065,0.636756601976231,0.221365773351863,0.620196332456544,0.559639401268214,0.198483835440129,0.397874651942402,0.710652963491157,0.317212327616289,0.239299293374643,0.0606942125596106,0.165786643279716,0.667431530542672,0.436631754040718,0.812185280025005,0.374252707697451,0.421187321422622,0.730321826180443,0.904493971262127,0.399387824581936,0.650714065413922,0.594219180056825,0.147960299625993,0.941945064114407,0.357223904458806,0.275038427906111,0.191008436959237,0.957893384154886,0.211530723143369,0.680650093592703,0.503884038887918,0.754094189498574,0.74776051659137,0.673691919771954,0.236221367260441,0.825558929471299,0.21071959589608,0.246618688805029,0.686810691142455,0.0247942050918937,0.572868114337325,0.494058627169579,0.684360746992752,0.0139967589639127,0.626861660508439,0.417218193877488,0.410173830809072,0.390906651504338,0.477168896235526,0.382211019750684,0.597674581920728,0.198329919017851,0.0684413285925984,0.450342149706557,0.133007253985852,0.755873151356354,0.372862737858668,0.762442974606529,0.582133987685665,0.692048883531243,0.259269661735743,0.147847984684631,0.635266482364386,0.320955650880933,0.00151186063885689,0.446474697208032,0.0673662247136235,0.791947861900553,0.0973296447191387
>> R> system('head -n2 temp.csv')
>> "","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12","X13","X14","X15","X16","X17","X18","X19","X20","X21","X22","X23","X24","X25","X26","X27","X28","X29","X30","X31","X32","X33","X34","X35","X36","X37","X38","X39","X40","X41","X42","X43","X44","X45","X46","X47","X48","X49","X50","X51","X52","X53","X54","X55","X56","X57","X58","X59","X60","X61","X62","X63","X64","X65","X66","X67","X68","X69","X70","X71","X72","X73","X74","X75","X76","X77","X78","X79","X80","X81","X82","X83","X84","X85","X86","X87","X88","X89","X90","X91","X92","X93","X94","X95","X96","X97","X98","X99","X100"
>> "1",0.995067856274545,0.0237177284434438,0.839840568602085,0.99880409357138,0.455015312181786,0.967688028467819,0.191194181796163,0.903533136472106,0.570170691236854,0.86230118968524,0.23530788696371,0.30707904486917,0.256274404237047,0.369592409580946,0.989929250674322,0.50812312704511,0.806819133926183,0.536566868191585,0.0863138805143535,0.294523851014674,0.676951135974377,0.195627561537549,0.261776751372963,0.383222601376474,0.578275503357872,0.79082652577199,0.19860127940774,0.0204593606758863,0.659964868798852,0.42379029514268,0.69516694964841,0.0594558380544186,0.124592808773741,0.289328144863248,0.524508266709745,0.84306427766569,0.317027662880719,0.273440480465069,0.111866136547178,0.217484838794917,0.354757327819243,0.973936082562432,0.673076402861625,0.300948366522789,0.219195493729785,0.912278874544427,0.276768424082547,0.959344451315701,0.500720858341083,0.431024399353191,0.814444699790329,0.0738761406391859,0.600137831410393,0.639816240407526,0.405302967177704,0.941259450744838,0.190415472723544,0.0382565588224679,0.486769351176918,0.127647049957886,0.558708024444059,0.686994878342375,0.176803215174004,0.794697789475322,0.59406904829666,0.0897431457415223,0.196549082174897,0.0750515828840435,0.736311340238899,0.00494878669269383,0.383522965712473,0.960385771468282,0.101023471681401,0.209177070530131,0.798869548132643,0.147874428424984,0.187238642480224,0.148522146046162,0.32379064662382,0.620601811446249,0.201180462958291,0.179565666476265,0.466121524339542,0.245493365218863,0.980698639061302,0.342919659335166,0.387780519668013,0.393966492731124,0.148554262006655,0.521724705817178,0.722740866011009,0.105151653522626,0.461909410310909,0.905382365221158,0.0736293855588883,0.636923864483833,0.540197744267061,0.425208077067509,0.666353516280651,0.584139186656103
>> R>
>>
>> --
>> http://dirk.eddelbuettel.com <http://dirk.eddelbuettel.com/> | @eddelbuettel | edd at debian.org <mailto:edd at debian.org>
>> ______________________________________________
>> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel <https://stat.ethz.ch/mailman/listinfo/r-devel>
>>
>>
>>
>> --
>> Joris Meys
>> Statistical consultant
>>
>> Department of Data Analysis and Mathematical Modelling
>> Ghent University
>> Coupure Links 653, B-9000 Gent (Belgium)
>>  <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
>>
>> -----------
>> Biowiskundedagen 2017-2018
>> http://www.biowiskundedagen.ugent.be/ <http://www.biowiskundedagen.ugent.be/>
>>
>> -------------------------------
>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php <http://helpdesk.ugent.be/e-maildisclaimer.php>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Wed Mar 14 20:05:31 2018
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 14 Mar 2018 20:05:31 +0100
Subject: [Rd] truncation/rounding bug with write.csv
In-Reply-To: <CA+vqiLEu2zL8kvg-DHnYZG2qQ9SzhZKWd6K_a=+xD-BBt6wF+w@mail.gmail.com>
References: <CA+CvkJ_SeWvh07TNTUfUt+Rdj1RKgLzeaak9P+DmnS9_-djYDg@mail.gmail.com>
 <23209.7010.634867.342504@rob.eddelbuettel.com>
 <CAO1zAVb9YD5eCD1TvQNxqFdOLi9tv=QMJAJGN4StPvyRF25aJw@mail.gmail.com>
 <43D7D9A2-4579-4780-B87C-11D5642D96D4@datarobot.com>
 <CA+vqiLEu2zL8kvg-DHnYZG2qQ9SzhZKWd6K_a=+xD-BBt6wF+w@mail.gmail.com>
Message-ID: <CAO1zAVZMQHv6BgngfDKen97pFqq6pcQizhC5iuQ7ZrhxznEhsw@mail.gmail.com>

My apologies for not including sessionInfo(), and I'm a bit angry at myself
for that. Retrying in a fresh session of R, I get different results. More
specifically, I get the expected result where accuracy is the same in the
first and the last line. As I didn't include my sessionInfo() in my
previous mail, I can't figure out why I now have a different result. So I'm
positive I've seen the behaviour described by Gregory, but I can't
reproduce consistently.

Results and session Info below.

Cheers
Joris

df = data.frame(replicate(100, runif(1000000, 0,1)))
write.csv(df, "temp.csv")

> system('head -n2 temp.csv')
"","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11","X12","X13","X14","X15","X16","X17","X18","X19","X20","X21","X22","X23","X24","X25","X26","X27","X28","X29","X30","X31","X32","X33","X34","X35","X36","X37","X38","X39","X40","X41","X42","X43","X44","X45","X46","X47","X48","X49","X50","X51","X52","X53","X54","X55","X56","X57","X58","X59","X60","X61","X62","X63","X64","X65","X66","X67","X68","X69","X70","X71","X72","X73","X74","X75","X76","X77","X78","X79","X80","X81","X82","X83","X84","X85","X86","X87","X88","X89","X90","X91","X92","X93","X94","X95","X96","X97","X98","X99","X100"
"1",0.278388975420967,0.370451691094786,0.717217007186264,0.116161955753341,0.144262576242909,0.937281515449286,0.373484081588686,0.955863541224971,0.826917823404074,0.821003203978762,0.592950115678832,0.0627794633619487,0.815737818833441,0.0805139308795333,0.238502083579078,0.509200588334352,0.73775092815049,0.868772336747497,0.0352788285817951,0.96509046619758,0.403636189643294,0.435718205757439,0.0162769011221826,0.597037401981652,0.504837732296437,0.206882111029699,0.883217994589359,0.548339378088713,0.294472687412053,0.996299823047593,0.84715538774617,0.206719091162086,0.936834576772526,0.439650829415768,0.48171737533994,0.847850588615984,0.168411831371486,0.74452265072614,0.148969533387572,0.410039864480495,0.778313281945884,0.432499173562974,0.512454774230719,0.16644035698846,0.82063413807191,0.978053349768743,0.99700310616754,0.874686364317313,0.796479270327836,0.816980117466301,0.274035695008934,0.00785374757833779,0.678476774599403,0.660274159396067,0.184961069142446,0.681200950173661,0.611048432299867,0.73395977425389,0.209964233217761,0.310086127603427,0.975754244253039,0.125808657845482,0.015794032253325,0.526331929024309,0.531722096726298,0.59097072808072,0.815139955608174,0.529103851644322,0.183188699418679,0.910278890514746,0.237709420500323,0.752752122003585,0.14534721034579,0.00572531204670668,0.222574554383755,0.895228188252077,0.899962505558506,0.987743409816176,0.592631630599499,0.948386731324717,0.86595072131604,0.0715177122037858,0.0426598901394755,0.336731978459284,0.641609625890851,0.949697833275422,0.26424896903336,0.528028564760461,0.562290757661685,0.653207891387865,0.513830083655193,0.818740799557418,0.86044091056101,0.790382120991126,0.227793522411957,0.580261130817235,0.181467723799869,0.295633365400136,0.548259064555168,0.833231552969664
> system('powershell -nologo & Get-Content -Path temp.csv -Tail 1')
"1000000",0.946863592602313,0.656343327835202,0.627083137864247,0.482342466711998,0.337082419078797,0.424337374512106,0.626660786569118,0.870844106189907,0.78627574048005,0.0107703430112451,0.50574235082604,0.182688802946359,0.29385484661907,0.0441680049989372,0.375604564556852,0.895043386844918,0.510951161850244,0.865806604968384,0.0833957826253027,0.100834607845172,0.139034334337339,0.854574690107256,0.121182460337877,0.86904955166392,0.616418665507808,0.616997531382367,0.325345175806433,0.487117795739323,0.00973135000094771,0.304118999978527,0.0132197963539511,0.654607841046527,0.896146323531866,0.358923224499449,0.968490360304713,0.757937406655401,0.926832290366292,0.863271801266819,0.325824091676623,0.140821835258976,0.550571520347148,0.645497811725363,0.545551799703389,0.440615838393569,0.296690225601196,0.838868388207629,0.488215223187581,0.512655091006309,0.764586469857022,0.156665422255173,0.109298826660961,0.660329486243427,0.220234925625846,0.192423258908093,0.672684306278825,0.239764124620706,0.754978574579582,0.636799369007349,0.240582759492099,0.458807958755642,0.196174292825162,0.477994701592252,0.725636600283906,0.473409370519221,0.741089153569192,0.906417449470609,0.540478575974703,0.360421892022714,0.933905930491164,0.631188633851707,0.416520888684317,0.485372453462332,0.700725849252194,0.186034456361085,0.903570784721524,0.0693298415280879,0.261779377236962,0.128776200115681,0.0801852298900485,0.665786169003695,0.144309232477099,0.485807131510228,0.0646850543562323,0.909404250094667,0.848976222565398,0.862456669798121,0.949187902035192,0.240288577275351,0.177118748193607,0.0833796421065927,0.0747064722236246,0.107194342184812,0.774909492349252,0.424547733273357,0.848057812545449,0.913047505775467,0.134580536745489,0.904593974584714,0.90503191947937,0.386907825712115

> sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows >= 8 x64 (build 9200)

Matrix products: default

locale:
[1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252
LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.3 tools_3.4.3    yaml_2.1.18

On Wed, Mar 14, 2018 at 7:32 PM, Ista Zahn <istazahn at gmail.com> wrote:

> I don't see the issue here. It would be helpful if people would report
> their sessionInfo() when reporting whether or not they see this issue.
> Mine is
>
> > sessionInfo()
> R version 3.4.3 (2017-11-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Arch Linux
>
> Matrix products: default
> BLAS/LAPACK: /usr/lib/libopenblas_haswellp-r0.2.20.so
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.3 rmsfact_0.0.3  cowsay_0.5.0   fortunes_1.5-4
>
> On Wed, Mar 14, 2018 at 12:02 PM, Gregory Michaelson <greg at datarobot.com>
> wrote:
> > I ran this code in RStudio Server on a linux machine, but I don?t know
> the version offhand.  I will try to get it tomorrow.  Thanks.
> >
> > Thanks,
> > Greg Michaelson
> > www.datarobot.com
> > 704-981-1118
> >
> >
> >
> >
> >> On Mar 14, 2018, at 4:47 PM, Joris Meys <jorismeys at gmail.com> wrote:
> >>
> >> To my surprise, I can confirm on Windows 10 using R 3.4.3 . As tail is
> not recognized by Windows cmd, I replaced with:
> >>
> >> system('powershell -nologo "& "Get-Content -Path temp.csv -Tail 1')
> >>
> >> The last line shows only 7 digits after the decimal, whereas the first
> have 15 digits after the decimal. I agree with Dirk though, 1.6Gb csv files
> are not the best way to work with datasets.
> >>
> >> Cheers
> >> Joris
> >>
> >>
> >>
> >> On Wed, Mar 14, 2018 at 1:53 PM, Dirk Eddelbuettel <edd at debian.org
> <mailto:edd at debian.org>> wrote:
> >>
> >> What OS are you on?  On Ubuntu 17.10 with R 3.4.3 all seems well (see
> >> below for your example, I just added a setwd()).
> >>
> >> [ That said, I long held a (apparently minority) view that csv is for
> all
> >> intends and purposes a less-than-ideal format.  If you have that much
> data,
> >> you do generally not want to serialize it back and forth as that is
> slow, and
> >> may drop precision.  The rds format is great for R alone; we now have C
> code
> >> to read it from other apps (in the librdata repo by Evan Miller).
> Different
> >> portable serializations work too (protocol buffer, msgpack, ...), there
> are
> >> databases and on and on... ]
> >>
> >> Dirk
> >>
> >>
> >> R> df <- data.frame(replicate(100, runif(1000000, 0,1)))
> >> R> setwd("/tmp")
> >> R> write.csv(df, "temp.csv")
> >> R> system('tail -n1 temp.csv')
> >> "1000000",0.11496100993827,0.740764639340341,0.519190795486793,0.
> 736045523779467,0.537115448853001,0.769496953347698,0.102257401449606,0.
> 437617724528536,0.173321532085538,0.351960731903091,0.397348914295435,0.
> 496789071243256,0.463006566744298,0.573105450021103,0.575196429155767,0.
> 821617329493165,0.112913676071912,0.187580146361142,0.121353451395407,0.
> 576333721866831,0.00763232703320682,0.468676633667201,0.451408475637436,0.
> 0172415724955499,0.946199159137905,0.439950440311804,0.109224532730877,0.
> 657066411571577,0.0524766123853624,0.54859598656185,0.94473168021068,0.
> 500153199071065,0.636756601976231,0.221365773351863,0.620196332456544,0.
> 559639401268214,0.198483835440129,0.397874651942402,0.710652963491157,0.
> 317212327616289,0.239299293374643,0.0606942125596106,0.165786643279716,0.
> 667431530542672,0.436631754040718,0.812185280025005,0.374252707697451,0.
> 421187321422622,0.730321826180443,0.904493971262127,0.399387824581936,0.
> 650714065413922,0.594219180056825,0.147960299625993,0.941945064114407,0.
> 357223904458806,0.275038427906111,0.191008436959237,0.957893384154886,0.
> 211530723143369,0.680650093592703,0.503884038887918,0.754094189498574,0.
> 74776051659137,0.673691919771954,0.236221367260441,0.825558929471299,0.
> 21071959589608,0.246618688805029,0.686810691142455,0.0247942050918937,0.
> 572868114337325,0.494058627169579,0.684360746992752,0.0139967589639127,0.
> 626861660508439,0.417218193877488,0.410173830809072,0.390906651504338,0.
> 477168896235526,0.382211019750684,0.597674581920728,0.198329919017851,0.
> 0684413285925984,0.450342149706557,0.133007253985852,0.755873151356354,0.
> 372862737858668,0.762442974606529,0.582133987685665,0.692048883531243,0.
> 259269661735743,0.147847984684631,0.635266482364386,0.320955650880933,0.
> 00151186063885689,0.446474697208032,0.0673662247136235,0.
> 791947861900553,0.0973296447191387
> >> R> system('head -n2 temp.csv')
> >> "","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11"
> ,"X12","X13","X14","X15","X16","X17","X18","X19","X20","X21"
> ,"X22","X23","X24","X25","X26","X27","X28","X29","X30","X31"
> ,"X32","X33","X34","X35","X36","X37","X38","X39","X40","X41"
> ,"X42","X43","X44","X45","X46","X47","X48","X49","X50","X51"
> ,"X52","X53","X54","X55","X56","X57","X58","X59","X60","X61"
> ,"X62","X63","X64","X65","X66","X67","X68","X69","X70","X71"
> ,"X72","X73","X74","X75","X76","X77","X78","X79","X80","X81"
> ,"X82","X83","X84","X85","X86","X87","X88","X89","X90","X91"
> ,"X92","X93","X94","X95","X96","X97","X98","X99","X100"
> >> "1",0.995067856274545,0.0237177284434438,0.839840568602085,0.
> 99880409357138,0.455015312181786,0.967688028467819,0.191194181796163,0.
> 903533136472106,0.570170691236854,0.86230118968524,0.23530788696371,0.
> 30707904486917,0.256274404237047,0.369592409580946,0.989929250674322,0.
> 50812312704511,0.806819133926183,0.536566868191585,0.0863138805143535,0.
> 294523851014674,0.676951135974377,0.195627561537549,0.261776751372963,0.
> 383222601376474,0.578275503357872,0.79082652577199,0.19860127940774,0.
> 0204593606758863,0.659964868798852,0.42379029514268,0.69516694964841,0.
> 0594558380544186,0.124592808773741,0.289328144863248,0.524508266709745,0.
> 84306427766569,0.317027662880719,0.273440480465069,0.111866136547178,0.
> 217484838794917,0.354757327819243,0.973936082562432,0.673076402861625,0.
> 300948366522789,0.219195493729785,0.912278874544427,0.276768424082547,0.
> 959344451315701,0.500720858341083,0.431024399353191,0.814444699790329,0.
> 0738761406391859,0.600137831410393,0.639816240407526,0.405302967177704,0.
> 941259450744838,0.190415472723544,0.0382565588224679,0.486769351176918,0.
> 127647049957886,0.558708024444059,0.686994878342375,0.176803215174004,0.
> 794697789475322,0.59406904829666,0.0897431457415223,0.196549082174897,0.
> 0750515828840435,0.736311340238899,0.00494878669269383,0.
> 383522965712473,0.960385771468282,0.101023471681401,0.209177070530131,0.
> 798869548132643,0.147874428424984,0.187238642480224,0.148522146046162,0.
> 32379064662382,0.620601811446249,0.201180462958291,0.179565666476265,0.
> 466121524339542,0.245493365218863,0.980698639061302,0.342919659335166,0.
> 387780519668013,0.393966492731124,0.148554262006655,0.521724705817178,0.
> 722740866011009,0.105151653522626,0.461909410310909,0.905382365221158,0.
> 0736293855588883,0.636923864483833,0.540197744267061,0.425208077067509,0.
> 666353516280651,0.584139186656103
> >> R>
> >>
> >> --
> >> http://dirk.eddelbuettel.com <http://dirk.eddelbuettel.com/> |
> @eddelbuettel | edd at debian.org <mailto:edd at debian.org>
> >> ______________________________________________
> >> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel <
> https://stat.ethz.ch/mailman/listinfo/r-devel>
> >>
> >>
> >>
> >> --
> >> Joris Meys
> >> Statistical consultant
> >>
> >> Department of Data Analysis and Mathematical Modelling
> >> Ghent University
> >> Coupure Links 653, B-9000 Gent (Belgium)
> >>  <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-
> 9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
> >>
> >> -----------
> >> Biowiskundedagen 2017-2018
> >> http://www.biowiskundedagen.ugent.be/ <http://www.biowiskundedagen.
> ugent.be/>
> >>
> >> -------------------------------
> >> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php <
> http://helpdesk.ugent.be/e-maildisclaimer.php>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Department of Data Analysis and Mathematical Modelling
Ghent University
Coupure Links 653, B-9000 Gent (Belgium)
<https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>

-----------
Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From FlorianSchwendinger at gmx.at  Thu Mar 15 11:39:14 2018
From: FlorianSchwendinger at gmx.at (FlorianSchwendinger at gmx.at)
Date: Thu, 15 Mar 2018 11:39:14 +0100
Subject: [Rd] clusterApply arguments
In-Reply-To: <CAFDcVCRUoLVcr7ByUE0eABt+n5Tjj_RTZjsO6iVpbih0b8wxuw@mail.gmail.com>
References: <trinity-9abb96df-40b2-4e2d-a112-1f2e8a032353-1521042659731@3c-app-gmx-bs70>
 <CAFDcVCRUoLVcr7ByUE0eABt+n5Tjj_RTZjsO6iVpbih0b8wxuw@mail.gmail.com>
Message-ID: <trinity-a8e04674-7da0-43cc-86cf-9e9d4189ecb4-1521110354065@3c-app-gmx-bs25>

Thank you for your answer!
I agree with you except for the 3 (Error) example and 
I realize now I should have started with that in the explanation.

>From my point of view 
parLapply(cl = clu, X = 1:2, fun = fun, c = 1) 
shouldn't give an error.

This could be easily avoided by using all the argument
names in the custerApply call of parLapply which means changing,

parLapply <- function(cl = NULL, X, fun, ...)  {
    cl <- defaultCluster(cl)
    do.call(c, clusterApply(cl, x = splitList(X, length(cl)), 
            fun = lapply, fun, ...), quote = TRUE)
}

to 

parLapply <- function (cl = NULL, X, fun, ...)  {
    cl <- defaultCluster(cl)
    do.call(c, clusterApply(cl = cl, x = splitList(X, length(cl)), 
            fun = lapply, fun, ...), quote = TRUE)
}

.

Best regards,
Florian

?

Gesendet:?Mittwoch, 14. M?rz 2018 um 19:05 Uhr
Von:?"Henrik Bengtsson" <henrik.bengtsson at gmail.com>
An:?"Florian Schwendinger" <Florian_Schwendinger at gmx.at>
Cc:?fschwend at wu.ac.at, R-devel <r-devel at r-project.org>
Betreff:?Re: [Rd] clusterApply arguments
This is nothing specific to parallel::clusterApply() per se. It is the
default behavior of R where it allows for partial argument names. I
don't think there's much that can be done here except always using
fully named arguments to the "apply" function itself as you show.

You can "alert" yourself when there's a mistake by using:

options(warnPartialMatchArgs = TRUE)

e.g.

> clusterApply(clu, x = 1:2, fun = fun, c = 1) ## Error
Warning in clusterApply(clu, x = 1:2, fun = fun, c = 1) :
partial argument match of 'c' to 'cl'
Error in checkCluster(cl) : not a valid cluster

It's still only a warning, but an informative one.

/Henrik

On Wed, Mar 14, 2018 at 8:50 AM, Florian Schwendinger
<Florian_Schwendinger at gmx.at> wrote:
> Hi!
>
> I recognized that the argument matching of clusterApply (and therefore parLapply) goes wrong when one of the arguments of the function is called "c". In this case, the argument "c" is used as cluster and the functions give the following error message "Error in checkCluster(cl) : not a valid cluster".
>
> Of course, "c" is for many reasons an unfortunate argument name and this can be easily fixed by the user side.
>
> See below for a small example.
>
> library(parallel)
>
> clu <- makeCluster(2, "PSOCK")
>
> fun <- function(x0, x1) (x0 + x1)
> clusterApply(clu, x = 1:2, fun = fun, x1 = 1) ## OK
> parLapply(cl = clu, X = 1:2, fun = fun, x1 = 1) #OK
>
>
> fun <- function(b, c) (b + c)
> clusterApply(clu, x = 1:2, fun = fun, c = 1) ## Error
> clusterApply(cl = clu, x = 1:2, fun = fun, c = 1) ## OK
> parLapply(cl = clu, X = 1:2, fun = fun, c = 1) ## Error
>
> stopCluster(clu)
>
>
> I used "R version 3.4.3 Patched (2018-01-07 r74099".
>
>
> Best regards,
> Florian
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel[https://stat.ethz.ch/mailman/listinfo/r-devel]
?
?


From greg at datarobot.com  Thu Mar 15 11:57:11 2018
From: greg at datarobot.com (Gregory Michaelson)
Date: Thu, 15 Mar 2018 11:57:11 +0100
Subject: [Rd] truncation/rounding bug with write.csv
In-Reply-To: <CAO1zAVZMQHv6BgngfDKen97pFqq6pcQizhC5iuQ7ZrhxznEhsw@mail.gmail.com>
References: <CA+CvkJ_SeWvh07TNTUfUt+Rdj1RKgLzeaak9P+DmnS9_-djYDg@mail.gmail.com>
 <23209.7010.634867.342504@rob.eddelbuettel.com>
 <CAO1zAVb9YD5eCD1TvQNxqFdOLi9tv=QMJAJGN4StPvyRF25aJw@mail.gmail.com>
 <43D7D9A2-4579-4780-B87C-11D5642D96D4@datarobot.com>
 <CA+vqiLEu2zL8kvg-DHnYZG2qQ9SzhZKWd6K_a=+xD-BBt6wF+w@mail.gmail.com>
 <CAO1zAVZMQHv6BgngfDKen97pFqq6pcQizhC5iuQ7ZrhxznEhsw@mail.gmail.com>
Message-ID: <CA+CvkJ_1Xpcak_S50n6hst81yPoYnmXeg6a95UQt3x-9Tw2AEg@mail.gmail.com>

So, I come in this morning, and I also find that the behavior is not
Happening any longer as well.  Perhaps it has to do with Memory utilization
and some built-in safeguards to avoid Memory Problems by truncating the
numerics?  It's extermely frustrating that it I can no longer make this
happen.

On Wed, Mar 14, 2018 at 8:05 PM, Joris Meys <jorismeys at gmail.com> wrote:

> My apologies for not including sessionInfo(), and I'm a bit angry at
> myself for that. Retrying in a fresh session of R, I get different results.
> More specifically, I get the expected result where accuracy is the same in
> the first and the last line. As I didn't include my sessionInfo() in my
> previous mail, I can't figure out why I now have a different result. So I'm
> positive I've seen the behaviour described by Gregory, but I can't
> reproduce consistently.
>
> Results and session Info below.
>
> Cheers
> Joris
>
> df = data.frame(replicate(100, runif(1000000, 0,1)))
> write.csv(df, "temp.csv")
>
> > system('head -n2 temp.csv')
> "","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11"
> ,"X12","X13","X14","X15","X16","X17","X18","X19","X20","X21"
> ,"X22","X23","X24","X25","X26","X27","X28","X29","X30","X31"
> ,"X32","X33","X34","X35","X36","X37","X38","X39","X40","X41"
> ,"X42","X43","X44","X45","X46","X47","X48","X49","X50","X51"
> ,"X52","X53","X54","X55","X56","X57","X58","X59","X60","X61"
> ,"X62","X63","X64","X65","X66","X67","X68","X69","X70","X71"
> ,"X72","X73","X74","X75","X76","X77","X78","X79","X80","X81"
> ,"X82","X83","X84","X85","X86","X87","X88","X89","X90","X91"
> ,"X92","X93","X94","X95","X96","X97","X98","X99","X100"
> "1",0.278388975420967,0.370451691094786,0.717217007186264,0.
> 116161955753341,0.144262576242909,0.937281515449286,0.373484081588686,0.
> 955863541224971,0.826917823404074,0.821003203978762,0.592950115678832,0.
> 0627794633619487,0.815737818833441,0.0805139308795333,0.238502083579078,0.
> 509200588334352,0.73775092815049,0.868772336747497,0.0352788285817951,0.
> 96509046619758,0.403636189643294,0.435718205757439,0.0162769011221826,0.
> 597037401981652,0.504837732296437,0.206882111029699,0.883217994589359,0.
> 548339378088713,0.294472687412053,0.996299823047593,0.84715538774617,0.
> 206719091162086,0.936834576772526,0.439650829415768,0.48171737533994,0.
> 847850588615984,0.168411831371486,0.74452265072614,0.148969533387572,0.
> 410039864480495,0.778313281945884,0.432499173562974,0.512454774230719,0.
> 16644035698846,0.82063413807191,0.978053349768743,0.99700310616754,0.
> 874686364317313,0.796479270327836,0.816980117466301,0.274035695008934,0.
> 00785374757833779,0.678476774599403,0.660274159396067,0.184961069142446,0.
> 681200950173661,0.611048432299867,0.73395977425389,0.209964233217761,0.
> 310086127603427,0.975754244253039,0.125808657845482,0.015794032253325,0.
> 526331929024309,0.531722096726298,0.59097072808072,0.815139955608174,0.
> 529103851644322,0.183188699418679,0.910278890514746,0.237709420500323,0.
> 752752122003585,0.14534721034579,0.00572531204670668,0.222574554383755,0.
> 895228188252077,0.899962505558506,0.987743409816176,0.592631630599499,0.
> 948386731324717,0.86595072131604,0.0715177122037858,0.0426598901394755,0.
> 336731978459284,0.641609625890851,0.949697833275422,0.26424896903336,0.
> 528028564760461,0.562290757661685,0.653207891387865,0.513830083655193,0.
> 818740799557418,0.86044091056101,0.790382120991126,0.227793522411957,0.
> 580261130817235,0.181467723799869,0.295633365400136,0.548259064555168,0.
> 833231552969664
> > system('powershell -nologo & Get-Content -Path temp.csv -Tail 1')
> "1000000",0.946863592602313,0.656343327835202,0.627083137864247,0.
> 482342466711998,0.337082419078797,0.424337374512106,0.626660786569118,0.
> 870844106189907,0.78627574048005,0.0107703430112451,0.50574235082604,0.
> 182688802946359,0.29385484661907,0.0441680049989372,0.375604564556852,0.
> 895043386844918,0.510951161850244,0.865806604968384,0.0833957826253027,0.
> 100834607845172,0.139034334337339,0.854574690107256,0.121182460337877,0.
> 86904955166392,0.616418665507808,0.616997531382367,0.325345175806433,0.
> 487117795739323,0.00973135000094771,0.304118999978527,0.
> 0132197963539511,0.654607841046527,0.896146323531866,0.358923224499449,0.
> 968490360304713,0.757937406655401,0.926832290366292,0.863271801266819,0.
> 325824091676623,0.140821835258976,0.550571520347148,0.645497811725363,0.
> 545551799703389,0.440615838393569,0.296690225601196,0.838868388207629,0.
> 488215223187581,0.512655091006309,0.764586469857022,0.156665422255173,0.
> 109298826660961,0.660329486243427,0.220234925625846,0.192423258908093,0.
> 672684306278825,0.239764124620706,0.754978574579582,0.636799369007349,0.
> 240582759492099,0.458807958755642,0.196174292825162,0.477994701592252,0.
> 725636600283906,0.473409370519221,0.741089153569192,0.906417449470609,0.
> 540478575974703,0.360421892022714,0.933905930491164,0.631188633851707,0.
> 416520888684317,0.485372453462332,0.700725849252194,0.186034456361085,0.
> 903570784721524,0.0693298415280879,0.261779377236962,0.128776200115681,0.
> 0801852298900485,0.665786169003695,0.144309232477099,0.485807131510228,0.
> 0646850543562323,0.909404250094667,0.848976222565398,0.862456669798121,0.
> 949187902035192,0.240288577275351,0.177118748193607,0.0833796421065927,0.
> 0747064722236246,0.107194342184812,0.774909492349252,0.424547733273357,0.
> 848057812545449,0.913047505775467,0.134580536745489,0.904593974584714,0.
> 90503191947937,0.386907825712115
>
> > sessionInfo()
> R version 3.4.3 (2017-11-30)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows >= 8 x64 (build 9200)
>
> Matrix products: default
>
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252  LC_CTYPE=English_United
> Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252 LC_NUMERIC=C
>
> [5] LC_TIME=English_United Kingdom.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.3 tools_3.4.3    yaml_2.1.18
>
> On Wed, Mar 14, 2018 at 7:32 PM, Ista Zahn <istazahn at gmail.com> wrote:
>
>> I don't see the issue here. It would be helpful if people would report
>> their sessionInfo() when reporting whether or not they see this issue.
>> Mine is
>>
>> > sessionInfo()
>> R version 3.4.3 (2017-11-30)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Arch Linux
>>
>> Matrix products: default
>> BLAS/LAPACK: /usr/lib/libopenblas_haswellp-r0.2.20.so
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.3 rmsfact_0.0.3  cowsay_0.5.0   fortunes_1.5-4
>>
>> On Wed, Mar 14, 2018 at 12:02 PM, Gregory Michaelson <greg at datarobot.com>
>> wrote:
>> > I ran this code in RStudio Server on a linux machine, but I don?t know
>> the version offhand.  I will try to get it tomorrow.  Thanks.
>> >
>> > Thanks,
>> > Greg Michaelson
>> > www.datarobot.com
>> > 704-981-1118
>> >
>> >
>> >
>> >
>> >> On Mar 14, 2018, at 4:47 PM, Joris Meys <jorismeys at gmail.com> wrote:
>> >>
>> >> To my surprise, I can confirm on Windows 10 using R 3.4.3 . As tail is
>> not recognized by Windows cmd, I replaced with:
>> >>
>> >> system('powershell -nologo "& "Get-Content -Path temp.csv -Tail 1')
>> >>
>> >> The last line shows only 7 digits after the decimal, whereas the first
>> have 15 digits after the decimal. I agree with Dirk though, 1.6Gb csv files
>> are not the best way to work with datasets.
>> >>
>> >> Cheers
>> >> Joris
>> >>
>> >>
>> >>
>> >> On Wed, Mar 14, 2018 at 1:53 PM, Dirk Eddelbuettel <edd at debian.org
>> <mailto:edd at debian.org>> wrote:
>> >>
>> >> What OS are you on?  On Ubuntu 17.10 with R 3.4.3 all seems well (see
>> >> below for your example, I just added a setwd()).
>> >>
>> >> [ That said, I long held a (apparently minority) view that csv is for
>> all
>> >> intends and purposes a less-than-ideal format.  If you have that much
>> data,
>> >> you do generally not want to serialize it back and forth as that is
>> slow, and
>> >> may drop precision.  The rds format is great for R alone; we now have
>> C code
>> >> to read it from other apps (in the librdata repo by Evan Miller).
>> Different
>> >> portable serializations work too (protocol buffer, msgpack, ...),
>> there are
>> >> databases and on and on... ]
>> >>
>> >> Dirk
>> >>
>> >>
>> >> R> df <- data.frame(replicate(100, runif(1000000, 0,1)))
>> >> R> setwd("/tmp")
>> >> R> write.csv(df, "temp.csv")
>> >> R> system('tail -n1 temp.csv')
>> >> "1000000",0.11496100993827 <+49%206100%20993827>,0.7
>> 40764639340341,0.519190795486793,0.736045523779467,0.5371154
>> 48853001,0.769496953347698,0.102257401449606,0.4376177245285
>> 36,0.173321532085538,0.351960731903091,0.397348914295435,0.4
>> 96789071243256,0.463006566744298,0.573105450021103,0.5751964
>> 29155767,0.821617329493165,0.112913676071912,0.1875801463611
>> 42,0.121353451395407,0.576333721866831,0.00763232703320682,
>> 0.468676633667201,0.451408475637436,0.0172415724955499,0.946
>> 199159137905,0.439950440311804,0.109224532730877,0.657066411
>> 571577,0.0524766123853624,0.54859598656185,0.94473168021068,
>> 0.500153199071065,0.636756601976231,0.221365773351863,0.6201
>> 96332456544,0.559639401268214,0.198483835440129,0.3978746519
>> 42402,0.710652963491157,0.317212327616289,0.239299293374643,
>> 0.0606942125596106,0.165786643279716,0.667431530542672,0.436
>> 631754040718,0.812185280025005,0.374252707697451,0.421187321
>> 422622,0.730321826180443,0.904493971262127,0.399387824581936
>> ,0.650714065413922,0.594219180056825,0.147960299625993,0.941
>> 945064114407,0.357223904458806,0.275038427906111,0.191008436
>> 959237,0.957893384154886,0.211530723143369,0.680650093592703
>> ,0.503884038887918,0.754094189498574,0.74776051659137,0.6736
>> 91919771954,0.236221367260441,0.825558929471299,0.2107195958
>> 9608,0.246618688805029,0.686810691142455,0.0247942050918937,
>> 0.572868114337325,0.494058627169579,0.684360746992752,0.0139
>> 967589639127,0.626861660508439,0.417218193877488,0.410173830
>> 809072,0.390906651504338,0.477168896235526,0.382211019750684
>> ,0.597674581920728,0.198329919017851,0.0684413285925984,0.45
>> 0342149706557,0.133007253985852,0.755873151356354,0.37286273
>> 7858668,0.762442974606529,0.582133987685665,0.69204888353124
>> 3,0.259269661735743,0.147847984684631,0.635266482364386,0.32
>> 0955650880933,0.00151186063885689,0.446474697208032,0.067366
>> 2247136235,0.791947861900553,0.0973296447191387
>> >> R> system('head -n2 temp.csv')
>> >> "","X1","X2","X3","X4","X5","X6","X7","X8","X9","X10","X11",
>> "X12","X13","X14","X15","X16","X17","X18","X19","X20","X21",
>> "X22","X23","X24","X25","X26","X27","X28","X29","X30","X31",
>> "X32","X33","X34","X35","X36","X37","X38","X39","X40","X41",
>> "X42","X43","X44","X45","X46","X47","X48","X49","X50","X51",
>> "X52","X53","X54","X55","X56","X57","X58","X59","X60","X61",
>> "X62","X63","X64","X65","X66","X67","X68","X69","X70","X71",
>> "X72","X73","X74","X75","X76","X77","X78","X79","X80","X81",
>> "X82","X83","X84","X85","X86","X87","X88","X89","X90","X91",
>> "X92","X93","X94","X95","X96","X97","X98","X99","X100"
>> >> "1",0.995067856274545,0.0237177284434438,0.839840568602085,
>> 0.99880409357138,0.455015312181786,0.967688028467819,0.19119
>> 4181796163,0.903533136472106,0.570170691236854,0.8623011896
>> 8524,0.23530788696371,0.30707904486917,0.256274404237047,0.3
>> 69592409580946,0.989929250674322,0.50812312704511,0.80681913
>> 3926183,0.536566868191585,0.0863138805143535,0.2945238510146
>> 74,0.676951135974377,0.195627561537549,0.261776751372963,0.3
>> 83222601376474,0.578275503357872,0.79082652577199,0.19860127
>> 940774,0.0204593606758863,0.659964868798852,0.42379029514268
>> ,0.69516694964841,0.0594558380544186,0.124592808773741,0.289
>> 328144863248,0.524508266709745,0.84306427766569,0.3170276628
>> 80719,0.273440480465069,0.111866136547178,0.217484838794917,
>> 0.354757327819243,0.973936082562432,0.673076402861625,0.3009
>> 48366522789,0.219195493729785,0.912278874544427,0.2767684240
>> 82547,0.959344451315701,0.500720858341083,0.431024399353191,
>> 0.814444699790329,0.0738761406391859,0.600137831410393,0.639
>> 816240407526,0.405302967177704,0.941259450744838,0.190415472
>> 723544,0.0382565588224679,0.486769351176918,0.12764704995788
>> 6,0.558708024444059,0.686994878342375,0.176803215174004,0.79
>> 4697789475322,0.59406904829666,0.0897431457415223,0.19654908
>> 2174897,0.0750515828840435,0.736311340238899,0.0049487866926
>> 9383,0.383522965712473,0.960385771468282,0.101023471681401,
>> 0.209177070530131,0.798869548132643,0.147874428424984,0.1872
>> 38642480224,0.148522146046162,0.32379064662382,0.62060181144
>> 6249,0.201180462958291,0.179565666476265,0.466121524339542,
>> 0.245493365218863,0.980698639061302,0.342919659335166,0.3877
>> 80519668013,0.393966492731124,0.148554262006655,0.5217247058
>> 17178,0.722740866011009,0.105151653522626,0.461909410310909,
>> 0.905382365221158,0.0736293855588883,0.636923864483833,0.540
>> 197744267061,0.425208077067509,0.666353516280651,0.584139186656103
>> >> R>
>> >>
>> >> --
>> >> http://dirk.eddelbuettel.com <http://dirk.eddelbuettel.com/> |
>> @eddelbuettel | edd at debian.org <mailto:edd at debian.org>
>> >> ______________________________________________
>> >> R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>> >> https://stat.ethz.ch/mailman/listinfo/r-devel <
>> https://stat.ethz.ch/mailman/listinfo/r-devel>
>> >>
>> >>
>> >>
>> >> --
>> >> Joris Meys
>> >> Statistical consultant
>> >>
>> >> Department of Data Analysis and Mathematical Modelling
>> >> Ghent University
>> >> Coupure Links 653, B-9000 Gent (Belgium
>> <https://maps.google.com/?q=Coupure+Links+653,+B-9000+Gent+(Belgium&entry=gmail&source=g>
>> )
>> >>  <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+
>> Gent,%C2%A0Belgium&entry=gmail&source=g>
>> >>
>> >> -----------
>> >> Biowiskundedagen 2017-2018
>> >> http://www.biowiskundedagen.ugent.be/ <http://www.biowiskundedagen.u
>> gent.be/>
>> >>
>> >> -------------------------------
>> >> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php <
>> http://helpdesk.ugent.be/e-maildisclaimer.php>
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Department of Data Analysis and Mathematical Modelling
> Ghent University
> Coupure Links 653, B-9000 Gent (Belgium)
>
> <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
>
> -----------
> Biowiskundedagen 2017-2018
> http://www.biowiskundedagen.ugent.be/
>
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>



-- 
Greg

	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Thu Mar 15 17:25:20 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Thu, 15 Mar 2018 09:25:20 -0700
Subject: [Rd] clusterApply arguments
In-Reply-To: <trinity-a8e04674-7da0-43cc-86cf-9e9d4189ecb4-1521110354065@3c-app-gmx-bs25>
References: <trinity-9abb96df-40b2-4e2d-a112-1f2e8a032353-1521042659731@3c-app-gmx-bs70>
 <CAFDcVCRUoLVcr7ByUE0eABt+n5Tjj_RTZjsO6iVpbih0b8wxuw@mail.gmail.com>
 <trinity-a8e04674-7da0-43cc-86cf-9e9d4189ecb4-1521110354065@3c-app-gmx-bs25>
Message-ID: <CAFDcVCTdERGnFHWsx4hr5DVfsvhVV9o3EzMVKrb9NJ6CKu7=Mg@mail.gmail.com>

On Thu, Mar 15, 2018 at 3:39 AM,  <FlorianSchwendinger at gmx.at> wrote:
> Thank you for your answer!
> I agree with you except for the 3 (Error) example and
> I realize now I should have started with that in the explanation.
>
> From my point of view
> parLapply(cl = clu, X = 1:2, fun = fun, c = 1)
> shouldn't give an error.
>
> This could be easily avoided by using all the argument
> names in the custerApply call of parLapply which means changing,
>
> parLapply <- function(cl = NULL, X, fun, ...)  {
>     cl <- defaultCluster(cl)
>     do.call(c, clusterApply(cl, x = splitList(X, length(cl)),
>             fun = lapply, fun, ...), quote = TRUE)
> }
>
> to
>
> parLapply <- function (cl = NULL, X, fun, ...)  {
>     cl <- defaultCluster(cl)
>     do.call(c, clusterApply(cl = cl, x = splitList(X, length(cl)),
>             fun = lapply, fun, ...), quote = TRUE)
> }

Oh... sorry I missed that point.  Yes, I agree, this should be a
trivial fix to the 'parallel' package.

/Henrik

>
> .
>
> Best regards,
> Florian
>
>
>
> Gesendet: Mittwoch, 14. M?rz 2018 um 19:05 Uhr
> Von: "Henrik Bengtsson" <henrik.bengtsson at gmail.com>
> An: "Florian Schwendinger" <Florian_Schwendinger at gmx.at>
> Cc: fschwend at wu.ac.at, R-devel <r-devel at r-project.org>
> Betreff: Re: [Rd] clusterApply arguments
> This is nothing specific to parallel::clusterApply() per se. It is the
> default behavior of R where it allows for partial argument names. I
> don't think there's much that can be done here except always using
> fully named arguments to the "apply" function itself as you show.
>
> You can "alert" yourself when there's a mistake by using:
>
> options(warnPartialMatchArgs = TRUE)
>
> e.g.
>
>> clusterApply(clu, x = 1:2, fun = fun, c = 1) ## Error
> Warning in clusterApply(clu, x = 1:2, fun = fun, c = 1) :
> partial argument match of 'c' to 'cl'
> Error in checkCluster(cl) : not a valid cluster
>
> It's still only a warning, but an informative one.
>
> /Henrik
>
> On Wed, Mar 14, 2018 at 8:50 AM, Florian Schwendinger
> <Florian_Schwendinger at gmx.at> wrote:
>> Hi!
>>
>> I recognized that the argument matching of clusterApply (and therefore parLapply) goes wrong when one of the arguments of the function is called "c". In this case, the argument "c" is used as cluster and the functions give the following error message "Error in checkCluster(cl) : not a valid cluster".
>>
>> Of course, "c" is for many reasons an unfortunate argument name and this can be easily fixed by the user side.
>>
>> See below for a small example.
>>
>> library(parallel)
>>
>> clu <- makeCluster(2, "PSOCK")
>>
>> fun <- function(x0, x1) (x0 + x1)
>> clusterApply(clu, x = 1:2, fun = fun, x1 = 1) ## OK
>> parLapply(cl = clu, X = 1:2, fun = fun, x1 = 1) #OK
>>
>>
>> fun <- function(b, c) (b + c)
>> clusterApply(clu, x = 1:2, fun = fun, c = 1) ## Error
>> clusterApply(cl = clu, x = 1:2, fun = fun, c = 1) ## OK
>> parLapply(cl = clu, X = 1:2, fun = fun, c = 1) ## Error
>>
>> stopCluster(clu)
>>
>>
>> I used "R version 3.4.3 Patched (2018-01-07 r74099".
>>
>>
>> Best regards,
>> Florian
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel[https://stat.ethz.ch/mailman/listinfo/r-devel]
>
>


From tomas.kalibera at gmail.com  Thu Mar 15 20:57:00 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 15 Mar 2018 20:57:00 +0100
Subject: [Rd] clusterApply arguments
In-Reply-To: <CAFDcVCTdERGnFHWsx4hr5DVfsvhVV9o3EzMVKrb9NJ6CKu7=Mg@mail.gmail.com>
References: <trinity-9abb96df-40b2-4e2d-a112-1f2e8a032353-1521042659731@3c-app-gmx-bs70>
 <CAFDcVCRUoLVcr7ByUE0eABt+n5Tjj_RTZjsO6iVpbih0b8wxuw@mail.gmail.com>
 <trinity-a8e04674-7da0-43cc-86cf-9e9d4189ecb4-1521110354065@3c-app-gmx-bs25>
 <CAFDcVCTdERGnFHWsx4hr5DVfsvhVV9o3EzMVKrb9NJ6CKu7=Mg@mail.gmail.com>
Message-ID: <0870b4c1-d7ac-29a9-8215-671bac51c26d@gmail.com>

On 03/15/2018 05:25 PM, Henrik Bengtsson wrote:
> On Thu, Mar 15, 2018 at 3:39 AM,  <FlorianSchwendinger at gmx.at> wrote:
>> Thank you for your answer!
>> I agree with you except for the 3 (Error) example and
>> I realize now I should have started with that in the explanation.
>>
>>  From my point of view
>> parLapply(cl = clu, X = 1:2, fun = fun, c = 1)
>> shouldn't give an error.
>>
>> This could be easily avoided by using all the argument
>> names in the custerApply call of parLapply which means changing,
>>
>> parLapply <- function(cl = NULL, X, fun, ...)  {
>>      cl <- defaultCluster(cl)
>>      do.call(c, clusterApply(cl, x = splitList(X, length(cl)),
>>              fun = lapply, fun, ...), quote = TRUE)
>> }
>>
>> to
>>
>> parLapply <- function (cl = NULL, X, fun, ...)  {
>>      cl <- defaultCluster(cl)
>>      do.call(c, clusterApply(cl = cl, x = splitList(X, length(cl)),
>>              fun = lapply, fun, ...), quote = TRUE)
>> }
> Oh... sorry I missed that point.  Yes, I agree, this should be a
> trivial fix to the 'parallel' package.
>
> /Henrik
Yes, thanks for the report, I am testing a fix for this (and other 
missing argument names in calls involving ...) in parallel.
Tomas
>
>> .
>>
>> Best regards,
>> Florian
>>
>>
>>
>> Gesendet: Mittwoch, 14. M?rz 2018 um 19:05 Uhr
>> Von: "Henrik Bengtsson" <henrik.bengtsson at gmail.com>
>> An: "Florian Schwendinger" <Florian_Schwendinger at gmx.at>
>> Cc: fschwend at wu.ac.at, R-devel <r-devel at r-project.org>
>> Betreff: Re: [Rd] clusterApply arguments
>> This is nothing specific to parallel::clusterApply() per se. It is the
>> default behavior of R where it allows for partial argument names. I
>> don't think there's much that can be done here except always using
>> fully named arguments to the "apply" function itself as you show.
>>
>> You can "alert" yourself when there's a mistake by using:
>>
>> options(warnPartialMatchArgs = TRUE)
>>
>> e.g.
>>
>>> clusterApply(clu, x = 1:2, fun = fun, c = 1) ## Error
>> Warning in clusterApply(clu, x = 1:2, fun = fun, c = 1) :
>> partial argument match of 'c' to 'cl'
>> Error in checkCluster(cl) : not a valid cluster
>>
>> It's still only a warning, but an informative one.
>>
>> /Henrik
>>
>> On Wed, Mar 14, 2018 at 8:50 AM, Florian Schwendinger
>> <Florian_Schwendinger at gmx.at> wrote:
>>> Hi!
>>>
>>> I recognized that the argument matching of clusterApply (and therefore parLapply) goes wrong when one of the arguments of the function is called "c". In this case, the argument "c" is used as cluster and the functions give the following error message "Error in checkCluster(cl) : not a valid cluster".
>>>
>>> Of course, "c" is for many reasons an unfortunate argument name and this can be easily fixed by the user side.
>>>
>>> See below for a small example.
>>>
>>> library(parallel)
>>>
>>> clu <- makeCluster(2, "PSOCK")
>>>
>>> fun <- function(x0, x1) (x0 + x1)
>>> clusterApply(clu, x = 1:2, fun = fun, x1 = 1) ## OK
>>> parLapply(cl = clu, X = 1:2, fun = fun, x1 = 1) #OK
>>>
>>>
>>> fun <- function(b, c) (b + c)
>>> clusterApply(clu, x = 1:2, fun = fun, c = 1) ## Error
>>> clusterApply(cl = clu, x = 1:2, fun = fun, c = 1) ## OK
>>> parLapply(cl = clu, X = 1:2, fun = fun, c = 1) ## Error
>>>
>>> stopCluster(clu)
>>>
>>>
>>> I used "R version 3.4.3 Patched (2018-01-07 r74099".
>>>
>>>
>>> Best regards,
>>> Florian
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel[https://stat.ethz.ch/mailman/listinfo/r-devel]
>>
>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From davidhughjones at gmail.com  Thu Mar 15 21:02:31 2018
From: davidhughjones at gmail.com (David Hugh-Jones)
Date: Thu, 15 Mar 2018 20:02:31 +0000
Subject: [Rd] speeding up R compilation
Message-ID: <CAARY7kjbr9OiP3WmZ5Z+fGY2Q=vQtnAe=+pwUd-ookZ6ExyQcw@mail.gmail.com>

Hello all,

First, a small advert for this:
https://hughjonesd.shinyapps.io/rcheology/
which lists functions in core R going back to 3.0.1.

Second, I'm trying to extend this back to 2.0.0. That involves building
many versions of R from source on a Docker image of Debian Sarge. (Shades
 of 2006, when the Linux desktop was around the corner, just as soon as I'd
finished compiling this *^&%* software...)

This is obviously quite slow. Do list members have any suggestions for how
to maximize compilation speed of (old) R sources?

Currently I'm doing:

 CFLAGS="-O0 -pipe" FFLAGS=-O0 ./configure --with-recommended-packages=no \
      --with-libpng=no --with-libjpeg=no \
      --with-tcl-config=/usr/lib/tcl8.4/tclConfig.sh \
      --with-tk-config=/usr/lib/tk8.4/tkConfig.sh --with-tcl-tk=yes
 make -j4

Cheers,
David

	[[alternative HTML version deleted]]


From mark.vanderloo at gmail.com  Fri Mar 16 10:21:23 2018
From: mark.vanderloo at gmail.com (Mark van der Loo)
Date: Fri, 16 Mar 2018 09:21:23 +0000
Subject: [Rd] Apparent bug in behavior of formulas with '-' operator for lm
Message-ID: <CAOKDuOj7iXPkGZXyRXPmZocRYFw8VUD2sttS2tQGoZ+QEvSGtw@mail.gmail.com>

Dear R-developers,

In the 'lm' documentation, the '-' operator is only specified to be used
with -1 (to remove the intercept from the model).

However, the documentation also refers to the 'formula' help file, which
indicates that it is possible to subtract any term. Indeed, the following
works with no problems (the period '.' stands for 'all terms except the
lhs'):

d <- data.frame(x=rnorm(6), y=rnorm(6), z=letters[1:2])
m <- lm(x ~ . -z, data=d)
p <- predict(m,newdata=d)

Now, if I change 'z' so that it has only unique values, and I introduce an
NA in the predicted variable, the following happens:

d <- data.frame(x=rnorm(6),y=rnorm(6),z=letters[1:6])
d$x[1] <- NA
m <- lm(x ~ . -z, data=d)
p <- predict(m, newdata=d)
Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
object$xlevels) : factor z has new levels a

It seems a bug to me, although one could argue that 'lm's documentation
does not allow one to expect that the '-' operator should work generally.

If it is a bug I'm happy to report it to bugzilla.

Thanks for all your efforts,
Mark

ps: I was not able to test this on R3.4.4 yet, but the NEWS does not
mention fixes related to 'lm' or 'predict'.


> sessionInfo()
R version 3.4.3 (2017-11-30)
Platform: x86_64-pc-linux-gnu (64-bit)
Running under: Ubuntu 16.04.4 LTS

Matrix products: default
BLAS: /usr/lib/libblas/libblas.so.3.6.0
LAPACK: /usr/lib/lapack/liblapack.so.3.6.0

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 LC_TIME=nl_NL.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=nl_NL.UTF-8    LC_MESSAGES=en_US.UTF-8
LC_PAPER=nl_NL.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
 LC_MEASUREMENT=nl_NL.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.3 tools_3.4.3    yaml_2.1.16

	[[alternative HTML version deleted]]


From jorismeys at gmail.com  Fri Mar 16 13:03:32 2018
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 16 Mar 2018 13:03:32 +0100
Subject: [Rd] 
 Apparent bug in behavior of formulas with '-' operator for lm
In-Reply-To: <CAOKDuOj7iXPkGZXyRXPmZocRYFw8VUD2sttS2tQGoZ+QEvSGtw@mail.gmail.com>
References: <CAOKDuOj7iXPkGZXyRXPmZocRYFw8VUD2sttS2tQGoZ+QEvSGtw@mail.gmail.com>
Message-ID: <CAO1zAVbeb9QkVQUPZZGBtceqFWsCfGzb+hNu-swOqXbTxbqpDg@mail.gmail.com>

It's not a bug per se. It's the effect of removing all observations linked
to a certain level in your data frame. So the output of lm() doesn't
contain a coefficient for level a of z, but your new data contains that
level a. With a small addition, this works again:

d <- data.frame(x=rnorm(12),y=rnorm(12),z=rep(letters[1:6],2))
d$x[1] <- NA
m <- lm(x ~ . -z, data=d)
p <- predict(m, newdata=d)

This is linked to another discussion earlier on stackoverflow :
https://stackoverflow.com/questions/48461980/prediction-in-r-glmm
which lead to an update to lme4 : https://github.com/lme4/lme4/issues/452

The point being that factors in your newdata should have the same levels as
factors in the original data that was used to fit the model. If you add
levels to these factors, it's impossible to use that model to predict for
these new data.

Cheers
Joris

On Fri, Mar 16, 2018 at 10:21 AM, Mark van der Loo <mark.vanderloo at gmail.com
> wrote:

> Dear R-developers,
>
> In the 'lm' documentation, the '-' operator is only specified to be used
> with -1 (to remove the intercept from the model).
>
> However, the documentation also refers to the 'formula' help file, which
> indicates that it is possible to subtract any term. Indeed, the following
> works with no problems (the period '.' stands for 'all terms except the
> lhs'):
>
> d <- data.frame(x=rnorm(6), y=rnorm(6), z=letters[1:2])
> m <- lm(x ~ . -z, data=d)
> p <- predict(m,newdata=d)
>
> Now, if I change 'z' so that it has only unique values, and I introduce an
> NA in the predicted variable, the following happens:
>
> d <- data.frame(x=rnorm(6),y=rnorm(6),z=letters[1:6])
> d$x[1] <- NA
> m <- lm(x ~ . -z, data=d)
> p <- predict(m, newdata=d)
> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
> object$xlevels) : factor z has new levels a
>
> It seems a bug to me, although one could argue that 'lm's documentation
> does not allow one to expect that the '-' operator should work generally.
>
> If it is a bug I'm happy to report it to bugzilla.
>
> Thanks for all your efforts,
> Mark
>
> ps: I was not able to test this on R3.4.4 yet, but the NEWS does not
> mention fixes related to 'lm' or 'predict'.
>
>
> > sessionInfo()
> R version 3.4.3 (2017-11-30)
> Platform: x86_64-pc-linux-gnu (64-bit)
> Running under: Ubuntu 16.04.4 LTS
>
> Matrix products: default
> BLAS: /usr/lib/libblas/libblas.so.3.6.0
> LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  LC_TIME=nl_NL.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=nl_NL.UTF-8    LC_MESSAGES=en_US.UTF-8
> LC_PAPER=nl_NL.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>  LC_MEASUREMENT=nl_NL.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.3 tools_3.4.3    yaml_2.1.16
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Joris Meys
Statistical consultant

Department of Data Analysis and Mathematical Modelling
Ghent University
Coupure Links 653, B-9000 Gent (Belgium)
<https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>

-----------
Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From mark.vanderloo at gmail.com  Fri Mar 16 13:09:08 2018
From: mark.vanderloo at gmail.com (Mark van der Loo)
Date: Fri, 16 Mar 2018 12:09:08 +0000
Subject: [Rd] 
 Apparent bug in behavior of formulas with '-' operator for lm
In-Reply-To: <CAO1zAVbeb9QkVQUPZZGBtceqFWsCfGzb+hNu-swOqXbTxbqpDg@mail.gmail.com>
References: <CAOKDuOj7iXPkGZXyRXPmZocRYFw8VUD2sttS2tQGoZ+QEvSGtw@mail.gmail.com>
 <CAO1zAVbeb9QkVQUPZZGBtceqFWsCfGzb+hNu-swOqXbTxbqpDg@mail.gmail.com>
Message-ID: <CAOKDuOhDiG2hfcoZ+TnK5f8jYpbrJ4K9prrurQG+WqgtVXTLCg@mail.gmail.com>

Joris, the point is that 'z' is NOT used as a predictor in the model.
Therefore it should not affect predictions. Also, I find it suspicious that
the error only occurs when the response variable conitains missings and 'z'
is unique (I have tested several other cases to confirm this).

-Mark

Op vr 16 mrt. 2018 om 13:03 schreef Joris Meys <jorismeys at gmail.com>:

> It's not a bug per se. It's the effect of removing all observations linked
> to a certain level in your data frame. So the output of lm() doesn't
> contain a coefficient for level a of z, but your new data contains that
> level a. With a small addition, this works again:
>
> d <- data.frame(x=rnorm(12),y=rnorm(12),z=rep(letters[1:6],2))
>
> d$x[1] <- NA
> m <- lm(x ~ . -z, data=d)
> p <- predict(m, newdata=d)
>
> This is linked to another discussion earlier on stackoverflow :
> https://stackoverflow.com/questions/48461980/prediction-in-r-glmm
> which lead to an update to lme4 : https://github.com/lme4/lme4/issues/452
>
> The point being that factors in your newdata should have the same levels
> as factors in the original data that was used to fit the model. If you add
> levels to these factors, it's impossible to use that model to predict for
> these new data.
>
> Cheers
> Joris
>
> On Fri, Mar 16, 2018 at 10:21 AM, Mark van der Loo <
> mark.vanderloo at gmail.com> wrote:
>
>> Dear R-developers,
>>
>> In the 'lm' documentation, the '-' operator is only specified to be used
>> with -1 (to remove the intercept from the model).
>>
>> However, the documentation also refers to the 'formula' help file, which
>> indicates that it is possible to subtract any term. Indeed, the following
>> works with no problems (the period '.' stands for 'all terms except the
>> lhs'):
>>
>> d <- data.frame(x=rnorm(6), y=rnorm(6), z=letters[1:2])
>> m <- lm(x ~ . -z, data=d)
>> p <- predict(m,newdata=d)
>>
>> Now, if I change 'z' so that it has only unique values, and I introduce an
>> NA in the predicted variable, the following happens:
>>
>> d <- data.frame(x=rnorm(6),y=rnorm(6),z=letters[1:6])
>> d$x[1] <- NA
>> m <- lm(x ~ . -z, data=d)
>> p <- predict(m, newdata=d)
>> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev =
>> object$xlevels) : factor z has new levels a
>>
>> It seems a bug to me, although one could argue that 'lm's documentation
>> does not allow one to expect that the '-' operator should work generally.
>>
>> If it is a bug I'm happy to report it to bugzilla.
>>
>> Thanks for all your efforts,
>> Mark
>>
>> ps: I was not able to test this on R3.4.4 yet, but the NEWS does not
>> mention fixes related to 'lm' or 'predict'.
>>
>>
>> > sessionInfo()
>> R version 3.4.3 (2017-11-30)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>> Running under: Ubuntu 16.04.4 LTS
>>
>> Matrix products: default
>> BLAS: /usr/lib/libblas/libblas.so.3.6.0
>> LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>>
>> locale:
>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>  LC_TIME=nl_NL.UTF-8        LC_COLLATE=en_US.UTF-8
>>  [5] LC_MONETARY=nl_NL.UTF-8    LC_MESSAGES=en_US.UTF-8
>> LC_PAPER=nl_NL.UTF-8       LC_NAME=C
>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>  LC_MEASUREMENT=nl_NL.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.3 tools_3.4.3    yaml_2.1.16
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Department of Data Analysis and Mathematical Modelling
> Ghent University
> Coupure Links 653, B-9000 Gent (Belgium)
>
> <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
>
> -----------
> Biowiskundedagen 2017-2018
> http://www.biowiskundedagen.ugent.be/
>
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>

	[[alternative HTML version deleted]]


From jorismeys at gmail.com  Fri Mar 16 13:22:45 2018
From: jorismeys at gmail.com (Joris Meys)
Date: Fri, 16 Mar 2018 13:22:45 +0100
Subject: [Rd] 
 Apparent bug in behavior of formulas with '-' operator for lm
In-Reply-To: <CAOKDuOhDiG2hfcoZ+TnK5f8jYpbrJ4K9prrurQG+WqgtVXTLCg@mail.gmail.com>
References: <CAOKDuOj7iXPkGZXyRXPmZocRYFw8VUD2sttS2tQGoZ+QEvSGtw@mail.gmail.com>
 <CAO1zAVbeb9QkVQUPZZGBtceqFWsCfGzb+hNu-swOqXbTxbqpDg@mail.gmail.com>
 <CAOKDuOhDiG2hfcoZ+TnK5f8jYpbrJ4K9prrurQG+WqgtVXTLCg@mail.gmail.com>
Message-ID: <CAO1zAVa74omJFP4ZM01Q5afAY889VmHX1_CpNTAqXJrjDcTHTg@mail.gmail.com>

Technically it is used as a predictor in the model. The information is
contained in terms :

> terms(x ~ . - z, data = d)
x ~ (y + z) - z
attr(,"variables")
list(x, y, z)
attr(,"factors")
  y
x 0
y 1
z 0
attr(,"term.labels")
[1] "y"
attr(,"order")
[1] 1
attr(,"intercept")
[1] 1
attr(,"response")
[1] 1
attr(,".Environment")

And the model.frame contains it :

> head(model.frame(x ~ . - z, data = d))
            x          y z
2 -0.06022984 -0.4483109 b
3  1.25293390  0.2687065 c
4 -1.11811090  0.8016076 d
5 -0.75521720 -0.7484931 e
6  0.93037156  0.4128456 f
7  1.32052028 -1.6609043 a

It is at the construction of the model.matrix that z disappears, but the
contrasts information for z is still attached :

> attr(model.matrix(x ~ . - z, data = d),"contrasts")
$z
[1] "contr.treatment"

As you can see from the error you printed, it is model.frame() complaining
about it. In this case it wouldn't be necessary, but it is documented
behaviour of model.frame. Which is why I didn't say "this is not a bug",
but "this is not a bug per se". Meaning that this is not optimal behaviour
and might not what you expect, but it follows the documentation of the
underlying functions.

Solving it would require a bypass of model.frame() to construct the correct
model,matrix for the new predictions, and that's far from trivial as
model.matrix() itself depends on model.frame().

Cheers
Joris





On Fri, Mar 16, 2018 at 1:09 PM, Mark van der Loo <mark.vanderloo at gmail.com>
wrote:

> Joris, the point is that 'z' is NOT used as a predictor in the model.
> Therefore it should not affect predictions. Also, I find it suspicious that
> the error only occurs when the response variable conitains missings and 'z'
> is unique (I have tested several other cases to confirm this).
>
> -Mark
>
> Op vr 16 mrt. 2018 om 13:03 schreef Joris Meys <jorismeys at gmail.com>:
>
>> It's not a bug per se. It's the effect of removing all observations
>> linked to a certain level in your data frame. So the output of lm() doesn't
>> contain a coefficient for level a of z, but your new data contains that
>> level a. With a small addition, this works again:
>>
>> d <- data.frame(x=rnorm(12),y=rnorm(12),z=rep(letters[1:6],2))
>>
>> d$x[1] <- NA
>> m <- lm(x ~ . -z, data=d)
>> p <- predict(m, newdata=d)
>>
>> This is linked to another discussion earlier on stackoverflow :
>> https://stackoverflow.com/questions/48461980/prediction-in-r-glmm
>> which lead to an update to lme4 : https://github.com/lme4/lme4/issues/452
>>
>> The point being that factors in your newdata should have the same levels
>> as factors in the original data that was used to fit the model. If you add
>> levels to these factors, it's impossible to use that model to predict for
>> these new data.
>>
>> Cheers
>> Joris
>>
>> On Fri, Mar 16, 2018 at 10:21 AM, Mark van der Loo <
>> mark.vanderloo at gmail.com> wrote:
>>
>>> Dear R-developers,
>>>
>>> In the 'lm' documentation, the '-' operator is only specified to be used
>>> with -1 (to remove the intercept from the model).
>>>
>>> However, the documentation also refers to the 'formula' help file, which
>>> indicates that it is possible to subtract any term. Indeed, the following
>>> works with no problems (the period '.' stands for 'all terms except the
>>> lhs'):
>>>
>>> d <- data.frame(x=rnorm(6), y=rnorm(6), z=letters[1:2])
>>> m <- lm(x ~ . -z, data=d)
>>> p <- predict(m,newdata=d)
>>>
>>> Now, if I change 'z' so that it has only unique values, and I introduce
>>> an
>>> NA in the predicted variable, the following happens:
>>>
>>> d <- data.frame(x=rnorm(6),y=rnorm(6),z=letters[1:6])
>>> d$x[1] <- NA
>>> m <- lm(x ~ . -z, data=d)
>>> p <- predict(m, newdata=d)
>>> Error in model.frame.default(Terms, newdata, na.action = na.action, xlev
>>> =
>>> object$xlevels) : factor z has new levels a
>>>
>>> It seems a bug to me, although one could argue that 'lm's documentation
>>> does not allow one to expect that the '-' operator should work generally.
>>>
>>> If it is a bug I'm happy to report it to bugzilla.
>>>
>>> Thanks for all your efforts,
>>> Mark
>>>
>>> ps: I was not able to test this on R3.4.4 yet, but the NEWS does not
>>> mention fixes related to 'lm' or 'predict'.
>>>
>>>
>>> > sessionInfo()
>>> R version 3.4.3 (2017-11-30)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> Running under: Ubuntu 16.04.4 LTS
>>>
>>> Matrix products: default
>>> BLAS: /usr/lib/libblas/libblas.so.3.6.0
>>> LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>>>
>>> locale:
>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>  LC_TIME=nl_NL.UTF-8        LC_COLLATE=en_US.UTF-8
>>>  [5] LC_MONETARY=nl_NL.UTF-8    LC_MESSAGES=en_US.UTF-8
>>> LC_PAPER=nl_NL.UTF-8       LC_NAME=C
>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>  LC_MEASUREMENT=nl_NL.UTF-8 LC_IDENTIFICATION=C
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.3 tools_3.4.3    yaml_2.1.16
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>>
>> --
>> Joris Meys
>> Statistical consultant
>>
>> Department of Data Analysis and Mathematical Modelling
>> Ghent University
>> Coupure Links 653, B-9000 Gent (Belgium)
>>
>> <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
>>
>> -----------
>> Biowiskundedagen 2017-2018
>> http://www.biowiskundedagen.ugent.be/
>>
>> -------------------------------
>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>
>


-- 
Joris Meys
Statistical consultant

Department of Data Analysis and Mathematical Modelling
Ghent University
Coupure Links 653, B-9000 Gent (Belgium)
<https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>

-----------
Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From mark.vanderloo at gmail.com  Fri Mar 16 14:21:17 2018
From: mark.vanderloo at gmail.com (Mark van der Loo)
Date: Fri, 16 Mar 2018 13:21:17 +0000
Subject: [Rd] 
 Apparent bug in behavior of formulas with '-' operator for lm
In-Reply-To: <CAO1zAVa74omJFP4ZM01Q5afAY889VmHX1_CpNTAqXJrjDcTHTg@mail.gmail.com>
References: <CAOKDuOj7iXPkGZXyRXPmZocRYFw8VUD2sttS2tQGoZ+QEvSGtw@mail.gmail.com>
 <CAO1zAVbeb9QkVQUPZZGBtceqFWsCfGzb+hNu-swOqXbTxbqpDg@mail.gmail.com>
 <CAOKDuOhDiG2hfcoZ+TnK5f8jYpbrJ4K9prrurQG+WqgtVXTLCg@mail.gmail.com>
 <CAO1zAVa74omJFP4ZM01Q5afAY889VmHX1_CpNTAqXJrjDcTHTg@mail.gmail.com>
Message-ID: <CAOKDuOjrcQh6AL1+dVuD00_Y0x_ubTEGqBuB4jwRwYZYK_Uc6g@mail.gmail.com>

Thanks, Joris,

This clarifies at least where exactly it comes from. I still find the
high-level behavior of 'predict' very counter-intuitive as the estimated
model contains no coefficients in 'z', but I think we agree on that.

I am not sure how much trouble it would be to improve this behavior, but
perhaps one of the core authors can have a look at it.

Best,
Mark




Op vr 16 mrt. 2018 om 13:22 schreef Joris Meys <jorismeys at gmail.com>:

> Technically it is used as a predictor in the model. The information is
> contained in terms :
>
> > terms(x ~ . - z, data = d)
> x ~ (y + z) - z
> attr(,"variables")
> list(x, y, z)
> attr(,"factors")
>   y
> x 0
> y 1
> z 0
> attr(,"term.labels")
> [1] "y"
> attr(,"order")
> [1] 1
> attr(,"intercept")
> [1] 1
> attr(,"response")
> [1] 1
> attr(,".Environment")
>
> And the model.frame contains it :
>
> > head(model.frame(x ~ . - z, data = d))
>             x          y z
> 2 -0.06022984 -0.4483109 b
> 3  1.25293390  0.2687065 c
> 4 -1.11811090  0.8016076 d
> 5 -0.75521720 -0.7484931 e
> 6  0.93037156  0.4128456 f
> 7  1.32052028 -1.6609043 a
>
> It is at the construction of the model.matrix that z disappears, but the
> contrasts information for z is still attached :
>
> > attr(model.matrix(x ~ . - z, data = d),"contrasts")
> $z
> [1] "contr.treatment"
>
> As you can see from the error you printed, it is model.frame() complaining
> about it. In this case it wouldn't be necessary, but it is documented
> behaviour of model.frame. Which is why I didn't say "this is not a bug",
> but "this is not a bug per se". Meaning that this is not optimal behaviour
> and might not what you expect, but it follows the documentation of the
> underlying functions.
>
> Solving it would require a bypass of model.frame() to construct the
> correct model,matrix for the new predictions, and that's far from trivial
> as model.matrix() itself depends on model.frame().
>
> Cheers
> Joris
>
>
>
>
>
> On Fri, Mar 16, 2018 at 1:09 PM, Mark van der Loo <
> mark.vanderloo at gmail.com> wrote:
>
>> Joris, the point is that 'z' is NOT used as a predictor in the model.
>> Therefore it should not affect predictions. Also, I find it suspicious that
>> the error only occurs when the response variable conitains missings and 'z'
>> is unique (I have tested several other cases to confirm this).
>>
>> -Mark
>>
>> Op vr 16 mrt. 2018 om 13:03 schreef Joris Meys <jorismeys at gmail.com>:
>>
>>> It's not a bug per se. It's the effect of removing all observations
>>> linked to a certain level in your data frame. So the output of lm() doesn't
>>> contain a coefficient for level a of z, but your new data contains that
>>> level a. With a small addition, this works again:
>>>
>>> d <- data.frame(x=rnorm(12),y=rnorm(12),z=rep(letters[1:6],2))
>>>
>>> d$x[1] <- NA
>>> m <- lm(x ~ . -z, data=d)
>>> p <- predict(m, newdata=d)
>>>
>>> This is linked to another discussion earlier on stackoverflow :
>>> https://stackoverflow.com/questions/48461980/prediction-in-r-glmm
>>> which lead to an update to lme4 :
>>> https://github.com/lme4/lme4/issues/452
>>>
>>> The point being that factors in your newdata should have the same levels
>>> as factors in the original data that was used to fit the model. If you add
>>> levels to these factors, it's impossible to use that model to predict for
>>> these new data.
>>>
>>> Cheers
>>> Joris
>>>
>>> On Fri, Mar 16, 2018 at 10:21 AM, Mark van der Loo <
>>> mark.vanderloo at gmail.com> wrote:
>>>
>>>> Dear R-developers,
>>>>
>>>> In the 'lm' documentation, the '-' operator is only specified to be used
>>>> with -1 (to remove the intercept from the model).
>>>>
>>>> However, the documentation also refers to the 'formula' help file, which
>>>> indicates that it is possible to subtract any term. Indeed, the
>>>> following
>>>> works with no problems (the period '.' stands for 'all terms except the
>>>> lhs'):
>>>>
>>>> d <- data.frame(x=rnorm(6), y=rnorm(6), z=letters[1:2])
>>>> m <- lm(x ~ . -z, data=d)
>>>> p <- predict(m,newdata=d)
>>>>
>>>> Now, if I change 'z' so that it has only unique values, and I introduce
>>>> an
>>>> NA in the predicted variable, the following happens:
>>>>
>>>> d <- data.frame(x=rnorm(6),y=rnorm(6),z=letters[1:6])
>>>> d$x[1] <- NA
>>>> m <- lm(x ~ . -z, data=d)
>>>> p <- predict(m, newdata=d)
>>>> Error in model.frame.default(Terms, newdata, na.action = na.action,
>>>> xlev =
>>>> object$xlevels) : factor z has new levels a
>>>>
>>>> It seems a bug to me, although one could argue that 'lm's documentation
>>>> does not allow one to expect that the '-' operator should work
>>>> generally.
>>>>
>>>> If it is a bug I'm happy to report it to bugzilla.
>>>>
>>>> Thanks for all your efforts,
>>>> Mark
>>>>
>>>> ps: I was not able to test this on R3.4.4 yet, but the NEWS does not
>>>> mention fixes related to 'lm' or 'predict'.
>>>>
>>>>
>>>> > sessionInfo()
>>>> R version 3.4.3 (2017-11-30)
>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>> Running under: Ubuntu 16.04.4 LTS
>>>>
>>>> Matrix products: default
>>>> BLAS: /usr/lib/libblas/libblas.so.3.6.0
>>>> LAPACK: /usr/lib/lapack/liblapack.so.3.6.0
>>>>
>>>> locale:
>>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>>  LC_TIME=nl_NL.UTF-8        LC_COLLATE=en_US.UTF-8
>>>>  [5] LC_MONETARY=nl_NL.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>> LC_PAPER=nl_NL.UTF-8       LC_NAME=C
>>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>>  LC_MEASUREMENT=nl_NL.UTF-8 LC_IDENTIFICATION=C
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] compiler_3.4.3 tools_3.4.3    yaml_2.1.16
>>>>
>>>>         [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>>
>>>
>>> --
>>> Joris Meys
>>> Statistical consultant
>>>
>>> Department of Data Analysis and Mathematical Modelling
>>> Ghent University
>>> Coupure Links 653, B-9000 Gent (Belgium)
>>>
>>> <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
>>>
>>> -----------
>>> Biowiskundedagen 2017-2018
>>> http://www.biowiskundedagen.ugent.be/
>>>
>>> -------------------------------
>>> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>>>
>>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Department of Data Analysis and Mathematical Modelling
> Ghent University
> Coupure Links 653, B-9000 Gent (Belgium)
>
> <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
>
> -----------
> Biowiskundedagen 2017-2018
> http://www.biowiskundedagen.ugent.be/
>
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>

	[[alternative HTML version deleted]]


From pchausse at uwaterloo.ca  Fri Mar 16 15:58:35 2018
From: pchausse at uwaterloo.ca (Pierre Chausse)
Date: Fri, 16 Mar 2018 10:58:35 -0400
Subject: [Rd] Discrepancy: R sum() VS C or Fortran sum
Message-ID: <1885e1e6-374f-21c0-4ea3-5aa2e8587ac2@mailservices.uwaterloo.ca>

Hi all,

I found a discrepancy between the sum() in R and either a sum done in C 
or Fortran for vector of just 5 elements. The difference is very small, 
but this is a very small part of a much larger numerical problem in 
which first and second derivatives are computed numerically. This is 
part of a numerical method course I am teaching in which I want to 
compare speeds of R versus Fortran (We solve a general equilibrium 
problem all numerically, if you want to know). Because of this 
discrepancy, the Jacobian and Hessian in R versus in Fortran are quite 
different, which results in the Newton method producing a different 
solution (for a given stopping rule). Since the solution computed in 
Fortran is almost identical to the analytical solution, I suspect that 
the sum in Fortran may be more accurate (That's just a guess).  Most of 
the time the sum produces identical results, but for some numbers, it is 
different. The following example, shows what happens:

set.seed(12233)
n <- 5
a <- runif(n,1,5)
e <- runif(n, 5*(1:n),10*(1:n))
s <- runif(1, 1.2, 4)
p <- runif(5, 3, 10)
x <- c(e[-5], (sum(e*p)-sum(e[-5]*p[-5]))/p[5])
u <- a^(1/s)*x^((s-1)/s)
dyn.load("sumF.so")

u[1] <- u[1]+.0001 ### If we do not add .0001, all differences are 0
s1 <- sum(u)
s2 <- .Fortran("sumf", as.double(u), as.integer(n), sf1=double(1),
                sf2=double(1))[3:4]
s3 <- .C("sumc", as.double(u), as.integer(n), sC=double(1))[[3]]

s1-s2[[1]] ## R versus compiler sum() (Fortran)

[1] -7.105427e-15

s1-s2[[2]] ## R versus manual sum (Fortran

[1] -7.105427e-15

s1-s3 ## R Versus manual sum in C

[1] -7.105427e-15

s2[[2]]-s2[[1]] ## manual sum versus compiler sum() (Fortran)

[1] 0

s3-s2[[2]] ## Fortran versus C

[1] 0

My sumf and sumc are

       subroutine sumf(x, n, sx1, sx2)
       integer i, n
       double precision x(n), sx1, sx2
       sx1 = sum(x)
       sx2 = 0.0d0
       do i=1,n
          sx2 = sx2+x(i)
       end do
       end

void sumc(double *x, int *n, double *sum)
{
   int i;
   double sum1 = 0.0;
   for (i=0; i< *n; i++) {
     sum1 += x[i];
   }
   *sum = sum1;
}

Can that be a bug?  Thanks.

-- 
Pierre Chauss?
Assistant Professor
Department of Economics
University of Waterloo


From sdirkse at gams.com  Fri Mar 16 16:29:16 2018
From: sdirkse at gams.com (Steven Dirkse)
Date: Fri, 16 Mar 2018 11:29:16 -0400
Subject: [Rd] Discrepancy: R sum() VS C or Fortran sum
In-Reply-To: <1885e1e6-374f-21c0-4ea3-5aa2e8587ac2@mailservices.uwaterloo.ca>
References: <1885e1e6-374f-21c0-4ea3-5aa2e8587ac2@mailservices.uwaterloo.ca>
Message-ID: <CAHiA-Z=EXk2dQ1U4f5Rf0KsoanBxyknKtgZFnW0n7rm8YiE0jw@mail.gmail.com>

Pierre,

It's comforting to think that the same simple summation loop implemented in
R, C, and Fortran would give bit-wise identical results, but that isn't the
case in practice.  Floating-point results depend on lots of things: the
chip used, the compiler used, the optimization flags, etc.  For example, in
the unlikely event that you run this on a 32-bit machine, you have the
messy 80-bit internal precision used by the double precision hardware on
the 32-bit platform to consider.  This is enough to derail the "bit-wise
equivalence train" right away.  There are plenty of other such issues that
can rise up and play a role.

Of course, there may be something about R's double precision evaluation
that is wrong, but IMHO a failure to be bit-wise identical with a
computation done elsewhere isn't enough to say a bug has been turfed up.
IMHO it's not unusual for computations to differ by the least significant
bit or two.  If that is enough to derail your computations for the
Jacobians and Hessians, that is at least a teachable moment for your
numerical methods class you have.

BTW, are you using finite difference techniques for the derivatives or
computational derivatives?  The latter techniques are not so sensitive to
round-off errors: I would expect them to be as accurate as symbolic
derivatives.

HTH,

-Steve

On Fri, Mar 16, 2018 at 10:58 AM, Pierre Chausse <pchausse at uwaterloo.ca>
wrote:

> Hi all,
>
> I found a discrepancy between the sum() in R and either a sum done in C or
> Fortran for vector of just 5 elements. The difference is very small, but
> this is a very small part of a much larger numerical problem in which first
> and second derivatives are computed numerically. This is part of a
> numerical method course I am teaching in which I want to compare speeds of
> R versus Fortran (We solve a general equilibrium problem all numerically,
> if you want to know). Because of this discrepancy, the Jacobian and Hessian
> in R versus in Fortran are quite different, which results in the Newton
> method producing a different solution (for a given stopping rule). Since
> the solution computed in Fortran is almost identical to the analytical
> solution, I suspect that the sum in Fortran may be more accurate (That's
> just a guess).  Most of the time the sum produces identical results, but
> for some numbers, it is different. The following example, shows what
> happens:
>
> set.seed(12233)
> n <- 5
> a <- runif(n,1,5)
> e <- runif(n, 5*(1:n),10*(1:n))
> s <- runif(1, 1.2, 4)
> p <- runif(5, 3, 10)
> x <- c(e[-5], (sum(e*p)-sum(e[-5]*p[-5]))/p[5])
> u <- a^(1/s)*x^((s-1)/s)
> dyn.load("sumF.so")
>
> u[1] <- u[1]+.0001 ### If we do not add .0001, all differences are 0
> s1 <- sum(u)
> s2 <- .Fortran("sumf", as.double(u), as.integer(n), sf1=double(1),
>                sf2=double(1))[3:4]
> s3 <- .C("sumc", as.double(u), as.integer(n), sC=double(1))[[3]]
>
> s1-s2[[1]] ## R versus compiler sum() (Fortran)
>
> [1] -7.105427e-15
>
> s1-s2[[2]] ## R versus manual sum (Fortran
>
> [1] -7.105427e-15
>
> s1-s3 ## R Versus manual sum in C
>
> [1] -7.105427e-15
>
> s2[[2]]-s2[[1]] ## manual sum versus compiler sum() (Fortran)
>
> [1] 0
>
> s3-s2[[2]] ## Fortran versus C
>
> [1] 0
>
> My sumf and sumc are
>
>       subroutine sumf(x, n, sx1, sx2)
>       integer i, n
>       double precision x(n), sx1, sx2
>       sx1 = sum(x)
>       sx2 = 0.0d0
>       do i=1,n
>          sx2 = sx2+x(i)
>       end do
>       end
>
> void sumc(double *x, int *n, double *sum)
> {
>   int i;
>   double sum1 = 0.0;
>   for (i=0; i< *n; i++) {
>     sum1 += x[i];
>   }
>   *sum = sum1;
> }
>
> Can that be a bug?  Thanks.
>
> --
> Pierre Chauss?
> Assistant Professor
> Department of Economics
> University of Waterloo
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Steven Dirkse, Ph.D.
GAMS Development Corp.
office: 202.342.0180

	[[alternative HTML version deleted]]


From luke-tierney at uiowa.edu  Fri Mar 16 16:37:03 2018
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 16 Mar 2018 10:37:03 -0500 (CDT)
Subject: [Rd] Discrepancy: R sum() VS C or Fortran sum
In-Reply-To: <1885e1e6-374f-21c0-4ea3-5aa2e8587ac2@mailservices.uwaterloo.ca>
References: <1885e1e6-374f-21c0-4ea3-5aa2e8587ac2@mailservices.uwaterloo.ca>
Message-ID: <alpine.DEB.2.20.1803161026280.4709@luke-Latitude>

Install the gmp package, run your code, and then try this:

bu <- gmp::as.bigq(u)
bs4 <- bu[1] + bu[2] + bu[3] + bu[4] + bu[5]
s4 <- as.double(bs4)
s1 - s4
##  [1] 0
s2[[2]] - s4
##  [1] 7.105427e-15
s3 - s4
##  [1] 7.105427e-15
identical(s1, s4)
##  [1] TRUE

`bs4` is the exact sum of the binary rationals in your `u` vector;
`s4` is the closest double precision to this exact sum.

Looking at the C source code for sum() will show you that it makes
some extra efforts to get a more accurate sum than your simple
version.

Best,

luke

On Fri, 16 Mar 2018, Pierre Chausse wrote:

> Hi all,
>
> I found a discrepancy between the sum() in R and either a sum done in C or 
> Fortran for vector of just 5 elements. The difference is very small, but this 
> is a very small part of a much larger numerical problem in which first and 
> second derivatives are computed numerically. This is part of a numerical 
> method course I am teaching in which I want to compare speeds of R versus 
> Fortran (We solve a general equilibrium problem all numerically, if you want 
> to know). Because of this discrepancy, the Jacobian and Hessian in R versus 
> in Fortran are quite different, which results in the Newton method producing 
> a different solution (for a given stopping rule). Since the solution computed 
> in Fortran is almost identical to the analytical solution, I suspect that the 
> sum in Fortran may be more accurate (That's just a guess).  Most of the time 
> the sum produces identical results, but for some numbers, it is different. 
> The following example, shows what happens:
>
> set.seed(12233)
> n <- 5
> a <- runif(n,1,5)
> e <- runif(n, 5*(1:n),10*(1:n))
> s <- runif(1, 1.2, 4)
> p <- runif(5, 3, 10)
> x <- c(e[-5], (sum(e*p)-sum(e[-5]*p[-5]))/p[5])
> u <- a^(1/s)*x^((s-1)/s)
> dyn.load("sumF.so")
>
> u[1] <- u[1]+.0001 ### If we do not add .0001, all differences are 0
> s1 <- sum(u)
> s2 <- .Fortran("sumf", as.double(u), as.integer(n), sf1=double(1),
>               sf2=double(1))[3:4]
> s3 <- .C("sumc", as.double(u), as.integer(n), sC=double(1))[[3]]
>
> s1-s2[[1]] ## R versus compiler sum() (Fortran)
>
> [1] -7.105427e-15
>
> s1-s2[[2]] ## R versus manual sum (Fortran
>
> [1] -7.105427e-15
>
> s1-s3 ## R Versus manual sum in C
>
> [1] -7.105427e-15
>
> s2[[2]]-s2[[1]] ## manual sum versus compiler sum() (Fortran)
>
> [1] 0
>
> s3-s2[[2]] ## Fortran versus C
>
> [1] 0
>
> My sumf and sumc are
>
>      subroutine sumf(x, n, sx1, sx2)
>      integer i, n
>      double precision x(n), sx1, sx2
>      sx1 = sum(x)
>      sx2 = 0.0d0
>      do i=1,n
>         sx2 = sx2+x(i)
>      end do
>      end
>
> void sumc(double *x, int *n, double *sum)
> {
>  int i;
>  double sum1 = 0.0;
>  for (i=0; i< *n; i++) {
>    sum1 += x[i];
>  }
>  *sum = sum1;
> }
>
> Can that be a bug?  Thanks.
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From luke-tierney at uiowa.edu  Fri Mar 16 16:56:43 2018
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Fri, 16 Mar 2018 10:56:43 -0500 (CDT)
Subject: [Rd] 
 parallel:::newPSOCKnode(): background worker fails immediately
 if socket on master is not set up in time (BUG?)
In-Reply-To: <CAFDcVCRqAWF0HkL0BasD2--0fa=JZVBJ8SOn6MypmVVzUL+HdA@mail.gmail.com>
References: <CAFDcVCTGR4Ft7XTJzXqr=jtDn18ZdJQ7n-NLRuoW1-=70PGXsQ@mail.gmail.com>
 <CAFDcVCRMiVNVJeDsJdUH+jLeWJt3-cEiHm-+hTZPePt2WvskOA@mail.gmail.com>
 <CAFDcVCRg_m07wZuAeytck06XCv5FBRQxGYm2-eNpBD8zYoL8LQ@mail.gmail.com>
 <alpine.DEB.2.20.1803090632120.11361@luke-Latitude>
 <CAFDcVCRqAWF0HkL0BasD2--0fa=JZVBJ8SOn6MypmVVzUL+HdA@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1803161056140.4709@luke-Latitude>

Thanks. Fix committed to R-devel in r74417.

Best,

luke

On Sat, 10 Mar 2018, Henrik Bengtsson wrote:

> Great.
>
> For the record of this thread, I've submitted patch PR17391
> (https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17391).  I've
> patched it against the latest R-devel on the SVN, passes 'make
> check-all', and I've verified it works with the above tests.
>
> /Henrik
>
> On Fri, Mar 9, 2018 at 4:37 AM,  <luke-tierney at uiowa.edu> wrote:
>> I'm happy to look at a patch that does this.  I'd start with a small
>> interval and increase it by 50%, say, on each try wit a max retry time
>> limit. This isn't eliminating the problem,only reducing the
>> probability, but still worth it. I had considered doing something like
>> this but it didn't seem necessary at the time. You don't want to retry
>> indefinitely since the connection could be failing because the master
>> died, and then you want the workers to die as well.
>>
>> Best,
>>
>> luke
>>
>>
>> On Fri, 9 Mar 2018, Henrik Bengtsson wrote:
>>
>>> A solution is to have parallel:::.slaveRSOCK() attempt to connect
>>> multiple times before failing, e.g.
>>>
>>>    makeSOCKmaster <- function(master, port, timeout, useXDR, maxTries
>>> = 10L, interval = 1.0) {
>>>        port <- as.integer(port)
>>>        for (i in seq_len(maxTries)) {
>>>          con <- tryCatch({
>>>            socketConnection(master, port = port, blocking = TRUE,
>>>                                    open = "a+b", timeout = timeout)
>>>          }, error = identity)
>>>          if (inherits(con, "connection")) break
>>>          Sys.sleep(interval)
>>>        }
>>>        if (inherits(con, "error")) stop(con)
>>>        structure(list(con = con), class = if (useXDR)
>>>            "SOCKnode"
>>>        else "SOCK0node")
>>>    }
>>>
>>> One could set 'maxTries' and 'interval' via commandArgs() like what is
>>> done for the other arguments.
>>>
>>> I'm happy to submit an SVN patch if R core thinks this is an
>>> acceptable solution.
>>>
>>> /Henrik
>>>
>>> On Thu, Mar 8, 2018 at 7:36 PM, Henrik Bengtsson
>>> <henrik.bengtsson at gmail.com> wrote:
>>>>
>>>> I just noticed that parallel:::.slaveRSOCK() passes 'timeout' to
>>>> socketConnection() as a character, i.e. there's a missing timeout <-
>>>> as.integer(timeout), cf. port <- as.integer(port) and useXDR <-
>>>> as.logical(value):
>>>>
>>>>> parallel:::.slaveRSOCK
>>>>
>>>> function ()
>>>> {
>>>>     makeSOCKmaster <- function(master, port, timeout, useXDR) {
>>>>         port <- as.integer(port)
>>>>         con <- socketConnection(master, port = port, blocking = TRUE,
>>>>             open = "a+b", timeout = timeout)
>>>>         structure(list(con = con), class = if (useXDR)
>>>>             "SOCKnode"
>>>>         else "SOCK0node")
>>>>     }
>>>>     master <- "localhost"
>>>>     port <- NA_integer_
>>>>     outfile <- Sys.getenv("R_SNOW_OUTFILE")
>>>>     methods <- TRUE
>>>>     useXDR <- TRUE
>>>>     for (a in commandArgs(TRUE)) {
>>>>         pos <- regexpr("=", a)
>>>>         name <- substr(a, 1L, pos - 1L)
>>>>         value <- substr(a, pos + 1L, nchar(a))
>>>>         switch(name, MASTER = {
>>>>             master <- value
>>>>         }, PORT = {
>>>>             port <- value
>>>>         }, OUT = {
>>>>             outfile <- value
>>>>         }, TIMEOUT = {
>>>>             timeout <- value
>>>>         }, XDR = {
>>>>             useXDR <- as.logical(value)
>>>>         })
>>>>     }
>>>>     if (is.na(port))
>>>>         stop("PORT must be specified")
>>>>     sinkWorkerOutput(outfile)
>>>>     msg <- sprintf("starting worker pid=%d on %s at %s\n", Sys.getpid(),
>>>>         paste(master, port, sep = ":"), format(Sys.time(), "%H:%M:%OS3"))
>>>>     cat(msg)
>>>>     slaveLoop(makeSOCKmaster(master, port, timeout, useXDR))
>>>> }
>>>> <bytecode: 0x4bd4b58>
>>>> <environment: namespace:parallel>
>>>>
>>>> Yet, fix that does *not* seem to change anything.
>>>>
>>>> /Henrik
>>>>
>>>> On Thu, Mar 8, 2018 at 7:05 PM, Henrik Bengtsson
>>>> <henrik.bengtsson at gmail.com> wrote:
>>>>>
>>>>> BACKGROUND:
>>>>>
>>>>> While troubleshooting random, occasionally occurring, errors from
>>>>> parallel::makePSOCKcluster("localhost", port = 11000);
>>>>>
>>>>> Error in socketConnection("localhost", port = port, server = TRUE,
>>>>> blocking = TRUE, :
>>>>>     cannot open the connection
>>>>>
>>>>> I had another look at parallel:::newPSOCKnode(), which is used
>>>>> internally to set up each background worker.  It is designed to, first
>>>>> launch the background worker as:
>>>>>
>>>>>   system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
>>>>> MASTER=localhost PORT=11000 OUT=/dev/null TIMEOUT=2592000 XDR=TRUE',
>>>>> wait = FALSE)
>>>>>
>>>>> which immediately tries to connect to a socket on localhost:11000 with
>>>>> timeout.  Immediately after the master launched the above (without
>>>>> waiting), it will set up the connection waiting for the connect from
>>>>> the background worker:
>>>>>
>>>>>     con <- socketConnection("localhost", port = 11000, server = TRUE,
>>>>>         blocking = TRUE, open = "a+b", timeout = timeout)
>>>>>
>>>>>
>>>>> ISSUE:
>>>>>
>>>>> If we emulate the above process, and remove the OUT=/dev/null such
>>>>> that we can see the output produces by the worker, as:
>>>>>
>>>>> setup <- function(delay = 0) {
>>>>>   system('R --slave --no-restore -e "parallel:::.slaveRSOCK()" --args
>>>>> MASTER=localhost PORT=11000 TIMEOUT=2592000 XDR=TRUE', wait = FALSE)
>>>>>   Sys.sleep(delay)
>>>>>   socketConnection("localhost", port = 11000, server = TRUE, blocking
>>>>> = TRUE, open = "a+b", timeout = 20)
>>>>> }
>>>>>
>>>>> doing:
>>>>>
>>>>>> con <- setup(0)
>>>>>
>>>>> starting worker pid=24983 on localhost:11000 at 18:44:30.087
>>>>>
>>>>> will most likely work, but adding a delay:
>>>>>
>>>>>> con <- setup(5)
>>>>>
>>>>> starting worker pid=25099 on localhost:11000 at 18:45:23.617
>>>>> Warning in socketConnection(master, port = port, blocking = TRUE, open
>>>>> = "a+b",  :
>>>>>   localhost:11000 cannot be opened
>>>>> Error in socketConnection(master, port = port, blocking = TRUE, open =
>>>>> "a+b",  :
>>>>>   cannot open the connection
>>>>> Calls: <Anonymous> ... doTryCatch -> recvData -> makeSOCKmaster ->
>>>>> socketConnection
>>>>>
>>>>> will produce an *instant* error on the worker, and before master opens
>>>>> the server socket.  Eventually, master will produce the originally
>>>>> observed error:
>>>>>
>>>>> Error in socketConnection("localhost", port = 11000, server = TRUE,
>>>>> blocking = TRUE,  :
>>>>>   cannot open the connection
>>>>>
>>>>> In other words, if the master fails to setup socketConnection()
>>>>> *before* the background workers attempts to connect, it all fails.
>>>>> Such a delay may happen for instance when there is a large CPU load on
>>>>> the test machine.
>>>>>
>>>>> Is this the above bug?
>>>>>
>>>>> /Henrik
>>>>>
>>>>> PS. The background is that I, very occasionally, observe R CMD check
>>>>> error on the above (on CRAN and elsewhere) when testing my future
>>>>> package. The error always go away when retested. This far I've though
>>>>> this is due to port clashes (since the port is random selected in
>>>>> [11000:11999]) and accepted that it happens.  However, after
>>>>> discovering the above, it could be due to the worker launching "too
>>>>> soon".
>>>>>
>>>>>> sessionInfo()
>>>>>
>>>>> R version 3.4.3 (2017-11-30)
>>>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>>>> Running under: Ubuntu 16.04.4 LTS
>>>>>
>>>>> Matrix products: default
>>>>> BLAS: /usr/lib/atlas-base/atlas/libblas.so.3.0
>>>>> LAPACK: /usr/lib/atlas-base/atlas/liblapack.so.3.0
>>>>>
>>>>> locale:
>>>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>>>>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>>>>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>>>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>>>>
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>
>>>>> loaded via a namespace (and not attached):
>>>>> [1] compiler_3.4.3
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>> --
>> Luke Tierney
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>    Actuarial Science
>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From davidhughjones at gmail.com  Fri Mar 16 17:10:23 2018
From: davidhughjones at gmail.com (David Hugh-Jones)
Date: Fri, 16 Mar 2018 16:10:23 +0000
Subject: [Rd] cat(fill=N)
Message-ID: <CAARY7ki-sZKdhFaknTh5pDOWTLumw==RiVs0Wi2BDGkOSLUuhA@mail.gmail.com>

Hi all,

I expect I'm getting something wrong, but

cat("foo bar baz foo bar baz foo bar baz", fill = 10)

should be broken into lines of width 10, whereas I get:

> cat("foo bar baz foo bar baz foo bar baz", fill = 10)

foo bar baz foo bar baz foo bar baz

This is on R 3.4.3, but I don't see mentions of it fixed in 3.4.4 or
r-devel NEWS.

Cheers,
David

	[[alternative HTML version deleted]]


From sokol at insa-toulouse.fr  Fri Mar 16 17:19:13 2018
From: sokol at insa-toulouse.fr (Serguei Sokol)
Date: Fri, 16 Mar 2018 17:19:13 +0100
Subject: [Rd] cat(fill=N)
In-Reply-To: <CAARY7ki-sZKdhFaknTh5pDOWTLumw==RiVs0Wi2BDGkOSLUuhA@mail.gmail.com>
References: <CAARY7ki-sZKdhFaknTh5pDOWTLumw==RiVs0Wi2BDGkOSLUuhA@mail.gmail.com>
Message-ID: <d18f4888-7279-580c-ec50-f59b49c59418@insa-toulouse.fr>

Le 16/03/2018 ? 17:10, David Hugh-Jones a ?crit?:
> Hi all,
>
> I expect I'm getting something wrong, but
>
> cat("foo bar baz foo bar baz foo bar baz", fill = 10)
>
> should be broken into lines of width 10, whereas I get:
>
>> cat("foo bar baz foo bar baz foo bar baz", fill = 10)
> foo bar baz foo bar baz foo bar baz
On the other side, if I do
 > cat(strsplit("foo bar baz foo bar baz foo bar baz", " ")[[1]], fill = 10)
I get the expected result:

foo bar
baz foo
bar baz
foo bar
baz

Which suggest that cat() doesn't break elements of submitted character vector
put put enough of them to fill the requested width.

Serguei.

>
> This is on R 3.4.3, but I don't see mentions of it fixed in 3.4.4 or
> r-devel NEWS.
>
> Cheers,
> David
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From davidhughjones at gmail.com  Fri Mar 16 17:26:15 2018
From: davidhughjones at gmail.com (David Hugh-Jones)
Date: Fri, 16 Mar 2018 16:26:15 +0000
Subject: [Rd] cat(fill=N)
In-Reply-To: <d18f4888-7279-580c-ec50-f59b49c59418@insa-toulouse.fr>
References: <CAARY7ki-sZKdhFaknTh5pDOWTLumw==RiVs0Wi2BDGkOSLUuhA@mail.gmail.com>
 <d18f4888-7279-580c-ec50-f59b49c59418@insa-toulouse.fr>
Message-ID: <CAARY7khs_tTj5BoP58u-bBYx-gDPQMzv04yRZ4nEESe_67pGdg@mail.gmail.com>

Agreed. Perhaps this is a documentation issue:

    fill: a logical or (positive) numeric controlling how the output is
          broken into successive lines.  If ?FALSE? (default), only
          newlines created explicitly by ?"\n"? are printed.
          Otherwise, the output is broken into lines with print width
          equal to the option ?width? if ?fill? is ?TRUE?, or the value
          of ?fill? if this is numeric.  Non-positive ?fill? values are
          ignored, with a warning.

could add "Newlines are only printed between elements of x, not within
elements".

But I think the behaviour I expected is more intuitive. The natural use
case is to
limit line length, and if so, that should apply globally not just between
elements.


On 16 March 2018 at 16:19, Serguei Sokol <sokol at insa-toulouse.fr> wrote:

> Le 16/03/2018 ? 17:10, David Hugh-Jones a ?crit :
>
>> Hi all,
>>
>> I expect I'm getting something wrong, but
>>
>> cat("foo bar baz foo bar baz foo bar baz", fill = 10)
>>
>> should be broken into lines of width 10, whereas I get:
>>
>> cat("foo bar baz foo bar baz foo bar baz", fill = 10)
>>>
>> foo bar baz foo bar baz foo bar baz
>>
> On the other side, if I do
> > cat(strsplit("foo bar baz foo bar baz foo bar baz", " ")[[1]], fill = 10)
> I get the expected result:
>
> foo bar
> baz foo
> bar baz
> foo bar
> baz
>
> Which suggest that cat() doesn't break elements of submitted character
> vector
> put put enough of them to fill the requested width.
>
> Serguei.
>
>
>> This is on R 3.4.3, but I don't see mentions of it fixed in 3.4.4 or
>> r-devel NEWS.
>>
>> Cheers,
>> David
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>

	[[alternative HTML version deleted]]


From pchausse at uwaterloo.ca  Fri Mar 16 18:08:07 2018
From: pchausse at uwaterloo.ca (Pierre Chausse)
Date: Fri, 16 Mar 2018 13:08:07 -0400
Subject: [Rd] Discrepancy: R sum() VS C or Fortran sum
In-Reply-To: <alpine.DEB.2.20.1803161026280.4709@luke-Latitude>
References: <1885e1e6-374f-21c0-4ea3-5aa2e8587ac2@mailservices.uwaterloo.ca>
 <alpine.DEB.2.20.1803161026280.4709@luke-Latitude>
Message-ID: <db62a096-8f21-fe1c-e34e-b31f538e0a60@mailservices.uwaterloo.ca>

My simple functions were to compare the result with the gfortran 
compiler sum() function.  I thought that the Fortran sum could not be 
less precise than R. I was wrong. I am impressed. The R sum does in fact 
match the result if we use the Kahan algorithm.

P.

I am glad to see that R sum() is more accurate than the gfortran 
compiler sum.

On 16/03/18 11:37 AM, luke-tierney at uiowa.edu wrote:
> Install the gmp package, run your code, and then try this:
>
> bu <- gmp::as.bigq(u)
> bs4 <- bu[1] + bu[2] + bu[3] + bu[4] + bu[5]
> s4 <- as.double(bs4)
> s1 - s4
> ##  [1] 0
> s2[[2]] - s4
> ##  [1] 7.105427e-15
> s3 - s4
> ##  [1] 7.105427e-15
> identical(s1, s4)
> ##  [1] TRUE
>
> `bs4` is the exact sum of the binary rationals in your `u` vector;
> `s4` is the closest double precision to this exact sum.
>
> Looking at the C source code for sum() will show you that it makes
> some extra efforts to get a more accurate sum than your simple
> version.
>
> Best,
>
> luke
>
> On Fri, 16 Mar 2018, Pierre Chausse wrote:
>
>> Hi all,
>>
>> I found a discrepancy between the sum() in R and either a sum done in 
>> C or Fortran for vector of just 5 elements. The difference is very 
>> small, but this is a very small part of a much larger numerical 
>> problem in which first and second derivatives are computed 
>> numerically. This is part of a numerical method course I am teaching 
>> in which I want to compare speeds of R versus Fortran (We solve a 
>> general equilibrium problem all numerically, if you want to know). 
>> Because of this discrepancy, the Jacobian and Hessian in R versus in 
>> Fortran are quite different, which results in the Newton method 
>> producing a different solution (for a given stopping rule). Since the 
>> solution computed in Fortran is almost identical to the analytical 
>> solution, I suspect that the sum in Fortran may be more accurate 
>> (That's just a guess).  Most of the time the sum produces identical 
>> results, but for some numbers, it is different. The following 
>> example, shows what happens:
>>
>> set.seed(12233)
>> n <- 5
>> a <- runif(n,1,5)
>> e <- runif(n, 5*(1:n),10*(1:n))
>> s <- runif(1, 1.2, 4)
>> p <- runif(5, 3, 10)
>> x <- c(e[-5], (sum(e*p)-sum(e[-5]*p[-5]))/p[5])
>> u <- a^(1/s)*x^((s-1)/s)
>> dyn.load("sumF.so")
>>
>> u[1] <- u[1]+.0001 ### If we do not add .0001, all differences are 0
>> s1 <- sum(u)
>> s2 <- .Fortran("sumf", as.double(u), as.integer(n), sf1=double(1),
>>               sf2=double(1))[3:4]
>> s3 <- .C("sumc", as.double(u), as.integer(n), sC=double(1))[[3]]
>>
>> s1-s2[[1]] ## R versus compiler sum() (Fortran)
>>
>> [1] -7.105427e-15
>>
>> s1-s2[[2]] ## R versus manual sum (Fortran
>>
>> [1] -7.105427e-15
>>
>> s1-s3 ## R Versus manual sum in C
>>
>> [1] -7.105427e-15
>>
>> s2[[2]]-s2[[1]] ## manual sum versus compiler sum() (Fortran)
>>
>> [1] 0
>>
>> s3-s2[[2]] ## Fortran versus C
>>
>> [1] 0
>>
>> My sumf and sumc are
>>
>>      subroutine sumf(x, n, sx1, sx2)
>>      integer i, n
>>      double precision x(n), sx1, sx2
>>      sx1 = sum(x)
>>      sx2 = 0.0d0
>>      do i=1,n
>>         sx2 = sx2+x(i)
>>      end do
>>      end
>>
>> void sumc(double *x, int *n, double *sum)
>> {
>>  int i;
>>  double sum1 = 0.0;
>>  for (i=0; i< *n; i++) {
>>    sum1 += x[i];
>>  }
>>  *sum = sum1;
>> }
>>
>> Can that be a bug?  Thanks.
>>
>>
>

-- 
Pierre Chauss?
Assistant Professor
Department of Economics
University of Waterloo


From ccberry at ucsd.edu  Fri Mar 16 18:13:43 2018
From: ccberry at ucsd.edu (Berry, Charles)
Date: Fri, 16 Mar 2018 17:13:43 +0000
Subject: [Rd] cat(fill=N)
In-Reply-To: <d18f4888-7279-580c-ec50-f59b49c59418@insa-toulouse.fr>
References: <CAARY7ki-sZKdhFaknTh5pDOWTLumw==RiVs0Wi2BDGkOSLUuhA@mail.gmail.com>
 <d18f4888-7279-580c-ec50-f59b49c59418@insa-toulouse.fr>
Message-ID: <5667085D-732F-4BEB-8FB7-1A2A21CA4022@ucsd.edu>



> On Mar 16, 2018, at 9:19 AM, Serguei Sokol <sokol at insa-toulouse.fr> wrote:
> 
> Le 16/03/2018 ? 17:10, David Hugh-Jones a ?crit :
>> Hi all,
>> 
>> I expect I'm getting something wrong, but
>> 
>> cat("foo bar baz foo bar baz foo bar baz", fill = 10)
>> 
>> should be broken into lines of width 10, whereas I get:
>> 
>>> cat("foo bar baz foo bar baz foo bar baz", fill = 10)
>> foo bar baz foo bar baz foo bar baz
> On the other side, if I do
> > cat(strsplit("foo bar baz foo bar baz foo bar baz", " ")[[1]], fill = 10)
> I get the expected result:
> 
> foo bar
> baz foo
> bar baz
> foo bar
> baz
> 
> Which suggest that cat() doesn't break elements of submitted character vector
> put put enough of them to fill the requested width.

Also, see ?strwrap, which honors word boundaries

> cat(strwrap("foo bar baz foo bar baz foo bar baz", width = 10),fill=10)
foo bar 
baz foo 
bar baz 
foo bar 
baz
> 

HTH,

Chuck

From tomas.kalibera at gmail.com  Fri Mar 16 18:34:39 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Fri, 16 Mar 2018 18:34:39 +0100
Subject: [Rd] Discrepancy: R sum() VS C or Fortran sum
In-Reply-To: <db62a096-8f21-fe1c-e34e-b31f538e0a60@mailservices.uwaterloo.ca>
References: <1885e1e6-374f-21c0-4ea3-5aa2e8587ac2@mailservices.uwaterloo.ca>
 <alpine.DEB.2.20.1803161026280.4709@luke-Latitude>
 <db62a096-8f21-fe1c-e34e-b31f538e0a60@mailservices.uwaterloo.ca>
Message-ID: <f555e482-dc84-84d5-76b0-49925e8ff653@gmail.com>

R uses long double type for the accumulator (on platforms where it is 
available). This is also mentioned in ?sum:

"Where possible extended-precision accumulators are used, typically well 
supported with C99 and newer, but possibly platform-dependent."

Tomas

On 03/16/2018 06:08 PM, Pierre Chausse wrote:
> My simple functions were to compare the result with the gfortran 
> compiler sum() function.? I thought that the Fortran sum could not be 
> less precise than R. I was wrong. I am impressed. The R sum does in 
> fact match the result if we use the Kahan algorithm.
>
> P.
>
> I am glad to see that R sum() is more accurate than the gfortran 
> compiler sum.
>
> On 16/03/18 11:37 AM, luke-tierney at uiowa.edu wrote:
>> Install the gmp package, run your code, and then try this:
>>
>> bu <- gmp::as.bigq(u)
>> bs4 <- bu[1] + bu[2] + bu[3] + bu[4] + bu[5]
>> s4 <- as.double(bs4)
>> s1 - s4
>> ##? [1] 0
>> s2[[2]] - s4
>> ##? [1] 7.105427e-15
>> s3 - s4
>> ##? [1] 7.105427e-15
>> identical(s1, s4)
>> ##? [1] TRUE
>>
>> `bs4` is the exact sum of the binary rationals in your `u` vector;
>> `s4` is the closest double precision to this exact sum.
>>
>> Looking at the C source code for sum() will show you that it makes
>> some extra efforts to get a more accurate sum than your simple
>> version.
>>
>> Best,
>>
>> luke
>>
>> On Fri, 16 Mar 2018, Pierre Chausse wrote:
>>
>>> Hi all,
>>>
>>> I found a discrepancy between the sum() in R and either a sum done 
>>> in C or Fortran for vector of just 5 elements. The difference is 
>>> very small, but this is a very small part of a much larger numerical 
>>> problem in which first and second derivatives are computed 
>>> numerically. This is part of a numerical method course I am teaching 
>>> in which I want to compare speeds of R versus Fortran (We solve a 
>>> general equilibrium problem all numerically, if you want to know). 
>>> Because of this discrepancy, the Jacobian and Hessian in R versus in 
>>> Fortran are quite different, which results in the Newton method 
>>> producing a different solution (for a given stopping rule). Since 
>>> the solution computed in Fortran is almost identical to the 
>>> analytical solution, I suspect that the sum in Fortran may be more 
>>> accurate (That's just a guess).? Most of the time the sum produces 
>>> identical results, but for some numbers, it is different. The 
>>> following example, shows what happens:
>>>
>>> set.seed(12233)
>>> n <- 5
>>> a <- runif(n,1,5)
>>> e <- runif(n, 5*(1:n),10*(1:n))
>>> s <- runif(1, 1.2, 4)
>>> p <- runif(5, 3, 10)
>>> x <- c(e[-5], (sum(e*p)-sum(e[-5]*p[-5]))/p[5])
>>> u <- a^(1/s)*x^((s-1)/s)
>>> dyn.load("sumF.so")
>>>
>>> u[1] <- u[1]+.0001 ### If we do not add .0001, all differences are 0
>>> s1 <- sum(u)
>>> s2 <- .Fortran("sumf", as.double(u), as.integer(n), sf1=double(1),
>>> ????????????? sf2=double(1))[3:4]
>>> s3 <- .C("sumc", as.double(u), as.integer(n), sC=double(1))[[3]]
>>>
>>> s1-s2[[1]] ## R versus compiler sum() (Fortran)
>>>
>>> [1] -7.105427e-15
>>>
>>> s1-s2[[2]] ## R versus manual sum (Fortran
>>>
>>> [1] -7.105427e-15
>>>
>>> s1-s3 ## R Versus manual sum in C
>>>
>>> [1] -7.105427e-15
>>>
>>> s2[[2]]-s2[[1]] ## manual sum versus compiler sum() (Fortran)
>>>
>>> [1] 0
>>>
>>> s3-s2[[2]] ## Fortran versus C
>>>
>>> [1] 0
>>>
>>> My sumf and sumc are
>>>
>>> ???? subroutine sumf(x, n, sx1, sx2)
>>> ???? integer i, n
>>> ???? double precision x(n), sx1, sx2
>>> ???? sx1 = sum(x)
>>> ???? sx2 = 0.0d0
>>> ???? do i=1,n
>>> ??????? sx2 = sx2+x(i)
>>> ???? end do
>>> ???? end
>>>
>>> void sumc(double *x, int *n, double *sum)
>>> {
>>> ?int i;
>>> ?double sum1 = 0.0;
>>> ?for (i=0; i< *n; i++) {
>>> ?? sum1 += x[i];
>>> ?}
>>> ?*sum = sum1;
>>> }
>>>
>>> Can that be a bug?? Thanks.
>>>
>>>
>>
>


From tomas.kalibera at gmail.com  Fri Mar 16 18:36:28 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Fri, 16 Mar 2018 18:36:28 +0100
Subject: [Rd] clusterApply arguments
In-Reply-To: <0870b4c1-d7ac-29a9-8215-671bac51c26d@gmail.com>
References: <trinity-9abb96df-40b2-4e2d-a112-1f2e8a032353-1521042659731@3c-app-gmx-bs70>
 <CAFDcVCRUoLVcr7ByUE0eABt+n5Tjj_RTZjsO6iVpbih0b8wxuw@mail.gmail.com>
 <trinity-a8e04674-7da0-43cc-86cf-9e9d4189ecb4-1521110354065@3c-app-gmx-bs25>
 <CAFDcVCTdERGnFHWsx4hr5DVfsvhVV9o3EzMVKrb9NJ6CKu7=Mg@mail.gmail.com>
 <0870b4c1-d7ac-29a9-8215-671bac51c26d@gmail.com>
Message-ID: <a02e404f-e6fb-d047-156c-43883abc2b8c@gmail.com>

Fixed in R-devel (74418).
Tomas

On 03/15/2018 08:57 PM, Tomas Kalibera wrote:
> On 03/15/2018 05:25 PM, Henrik Bengtsson wrote:
>> On Thu, Mar 15, 2018 at 3:39 AM, <FlorianSchwendinger at gmx.at> wrote:
>>> Thank you for your answer!
>>> I agree with you except for the 3 (Error) example and
>>> I realize now I should have started with that in the explanation.
>>>
>>> ?From my point of view
>>> parLapply(cl = clu, X = 1:2, fun = fun, c = 1)
>>> shouldn't give an error.
>>>
>>> This could be easily avoided by using all the argument
>>> names in the custerApply call of parLapply which means changing,
>>>
>>> parLapply <- function(cl = NULL, X, fun, ...)? {
>>> ???? cl <- defaultCluster(cl)
>>> ???? do.call(c, clusterApply(cl, x = splitList(X, length(cl)),
>>> ???????????? fun = lapply, fun, ...), quote = TRUE)
>>> }
>>>
>>> to
>>>
>>> parLapply <- function (cl = NULL, X, fun, ...)? {
>>> ???? cl <- defaultCluster(cl)
>>> ???? do.call(c, clusterApply(cl = cl, x = splitList(X, length(cl)),
>>> ???????????? fun = lapply, fun, ...), quote = TRUE)
>>> }
>> Oh... sorry I missed that point.? Yes, I agree, this should be a
>> trivial fix to the 'parallel' package.
>>
>> /Henrik
> Yes, thanks for the report, I am testing a fix for this (and other 
> missing argument names in calls involving ...) in parallel.
> Tomas
>>
>>> .
>>>
>>> Best regards,
>>> Florian
>>>
>>>
>>>
>>> Gesendet: Mittwoch, 14. M?rz 2018 um 19:05 Uhr
>>> Von: "Henrik Bengtsson" <henrik.bengtsson at gmail.com>
>>> An: "Florian Schwendinger" <Florian_Schwendinger at gmx.at>
>>> Cc: fschwend at wu.ac.at, R-devel <r-devel at r-project.org>
>>> Betreff: Re: [Rd] clusterApply arguments
>>> This is nothing specific to parallel::clusterApply() per se. It is the
>>> default behavior of R where it allows for partial argument names. I
>>> don't think there's much that can be done here except always using
>>> fully named arguments to the "apply" function itself as you show.
>>>
>>> You can "alert" yourself when there's a mistake by using:
>>>
>>> options(warnPartialMatchArgs = TRUE)
>>>
>>> e.g.
>>>
>>>> clusterApply(clu, x = 1:2, fun = fun, c = 1) ## Error
>>> Warning in clusterApply(clu, x = 1:2, fun = fun, c = 1) :
>>> partial argument match of 'c' to 'cl'
>>> Error in checkCluster(cl) : not a valid cluster
>>>
>>> It's still only a warning, but an informative one.
>>>
>>> /Henrik
>>>
>>> On Wed, Mar 14, 2018 at 8:50 AM, Florian Schwendinger
>>> <Florian_Schwendinger at gmx.at> wrote:
>>>> Hi!
>>>>
>>>> I recognized that the argument matching of clusterApply (and 
>>>> therefore parLapply) goes wrong when one of the arguments of the 
>>>> function is called "c". In this case, the argument "c" is used as 
>>>> cluster and the functions give the following error message "Error 
>>>> in checkCluster(cl) : not a valid cluster".
>>>>
>>>> Of course, "c" is for many reasons an unfortunate argument name and 
>>>> this can be easily fixed by the user side.
>>>>
>>>> See below for a small example.
>>>>
>>>> library(parallel)
>>>>
>>>> clu <- makeCluster(2, "PSOCK")
>>>>
>>>> fun <- function(x0, x1) (x0 + x1)
>>>> clusterApply(clu, x = 1:2, fun = fun, x1 = 1) ## OK
>>>> parLapply(cl = clu, X = 1:2, fun = fun, x1 = 1) #OK
>>>>
>>>>
>>>> fun <- function(b, c) (b + c)
>>>> clusterApply(clu, x = 1:2, fun = fun, c = 1) ## Error
>>>> clusterApply(cl = clu, x = 1:2, fun = fun, c = 1) ## OK
>>>> parLapply(cl = clu, X = 1:2, fun = fun, c = 1) ## Error
>>>>
>>>> stopCluster(clu)
>>>>
>>>>
>>>> I used "R version 3.4.3 Patched (2018-01-07 r74099".
>>>>
>>>>
>>>> Best regards,
>>>> Florian
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel[https://stat.ethz.ch/mailman/listinfo/r-devel] 
>>>
>>>
>>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From suharto_anggono at yahoo.com  Sat Mar 17 12:53:28 2018
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 17 Mar 2018 11:53:28 +0000 (UTC)
Subject: [Rd] Inappropriate parens fix for Logic.Rd
References: <2041498083.2278320.1521287608494.ref@mail.yahoo.com>
Message-ID: <2041498083.2278320.1521287608494@mail.yahoo.com>

Logic.Rd has been changed again in r74377. After change:
? \item{x, y}{raw or logical or \sQuote{number-like} vectors (i.e., of
? ? types \code{\link{double}} (class \code{\link{numeric}},
? ? \code{\link{integer}}) and \code{\link{complex}}), or objects for

It is still inappropriate. As I said before, integer is not double.

Right: numeric includes double and integer
Wrong: double includes numeric and integer

The text mentions "type" and "class". I believe that, in the text, originally, "type" refers to what is returned by typeof() and "class" refers to what is returned by class() in R.
When typeof(x) is "double", class(x) is "numeric".
When typeof(x) is "integer", class(x) is "integer".

--------------------------------------------

> wrote:

 Subject: Inappropriate parens fix for Logic.Rd
 To: r-devel at r-project.org
 Date: Saturday, 10 March, 2018, 8:23 AM

Logic.Rd is one of the files changed in r74363.

Before change:
? \item{x, y}{raw or logical or \sQuote{number-like} vectors (i.e., of types
? ? \code{\link{double}} (class \code{\link{numeric}}), \code{\link{integer}}
? ? and \code{\link{complex}})), or objects for

After change:
? \item{x, y}{raw or logical or \sQuote{number-like} vectors (i.e., of types
? ? \code{\link{double}} (class \code{\link{numeric}}, \code{\link{integer}}
? ? and \code{\link{complex}})), or objects for

Neither integer nor complex is double.
I think, it should be
? \item{x, y}{raw or logical or \sQuote{number-like} vectors (i.e., of types
? ? \code{\link{double}} (class \code{\link{numeric}}), \code{\link{integer}}
? ? and \code{\link{complex}}), or objects for


From maechler at stat.math.ethz.ch  Sat Mar 17 20:07:23 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 17 Mar 2018 20:07:23 +0100
Subject: [Rd] Inappropriate parens fix for Logic.Rd
In-Reply-To: <2041498083.2278320.1521287608494@mail.yahoo.com>
References: <2041498083.2278320.1521287608494.ref@mail.yahoo.com>
 <2041498083.2278320.1521287608494@mail.yahoo.com>
Message-ID: <23213.26475.932097.285583@stat.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
>>>>>     on Sat, 17 Mar 2018 11:53:28 +0000 writes:

    > Logic.Rd has been changed again in r74377. After change: ?
    > \item{x, y}{raw or logical or \sQuote{number-like} vectors
    > (i.e., of ? ? types \code{\link{double}} (class
    > \code{\link{numeric}}, ? ? \code{\link{integer}}) and
    > \code{\link{complex}}), or objects for

    > It is still inappropriate. As I said before, integer is
    > not double.

    > Right: numeric includes double and integer Wrong: double
    > includes numeric and integer

    > The text mentions "type" and "class". I believe that, in
    > the text, originally, "type" refers to what is returned by
    > typeof() and "class" refers to what is returned by class()
    > in R.  When typeof(x) is "double", class(x) is "numeric".
    > When typeof(x) is "integer", class(x) is "integer".

It's amazing that we've not done better .. I've tried again now.

Thank you Suharto!
Martin


From marlin- at gmx.cn  Sun Mar 18 15:07:43 2018
From: marlin- at gmx.cn (Jialin Ma)
Date: Sun, 18 Mar 2018 22:07:43 +0800
Subject: [Rd] `@<-` modify its argument when slot is externalptr
Message-ID: <1521382063.7888.5.camel@gmx.cn>

Dear all,

I am confused about the inconsistent behaviors of `@<-` operator when
used in different ways. Consider the following example:

  library(inline)
  
  # Function to generate an externalptr object with random address
  new_extptr <- cfunction(c(), '
    SEXP val = PROTECT(ScalarLogical(1));
    SEXP out = PROTECT(R_MakeExternalPtr(&val, R_NilValue, val));
    UNPROTECT(2);
    return(out);
  ')

  setClass("S4ClassHoldingExtptr", contains = "externalptr")

  subs_extptr_1 <- function(x) {
    x at .xData <- new_extptr()
    x
  }

  subs_extptr_2 <- function(x) {
    x <- `@<-`(x, ".xData", new_extptr())
    x
  }

I expect functions "subs_extptr_1" and "subs_extptr_2" should be
semantically identical. (is it right?)

But it seems that "subs_extptr_2" will modify its argument while
"subs_extptr_1" won't.

  x <- new("S4ClassHoldingExtptr", new_extptr())
  y <- x
  y
   # An object of class "S4ClassHoldingExtptr"
   # <pointer: 0x7ffc60971eb0>
  
  subs_extptr_1(x)
   # An object of class "S4ClassHoldingExtptr"
   # <pointer: 0x7ffc60974250>
  x
   # An object of class "S4ClassHoldingExtptr"
   # <pointer: 0x7ffc60971eb0>
  y
   # An object of class "S4ClassHoldingExtptr"
   # <pointer: 0x7ffc60971eb0>

As shown above, "subs_extptr_1" will not modify x or y.

  subs_extptr_2(x)
   # An object of class "S4ClassHoldingExtptr"
   # <pointer: 0x7ffc60973f30>
  x
   # An object of class "S4ClassHoldingExtptr"
   # <pointer: 0x7ffc60973f30>
  y
   # An object of class "S4ClassHoldingExtptr"
   # <pointer: 0x7ffc60973f30>

However, "subs_extptr_2" will modify both x and y.

Is this behavior expected?

Thanks,
Jialin


> sessionInfo()
R version 3.4.1 (2017-06-30)
Platform: x86_64-suse-linux-gnu (64-bit)
Running under: openSUSE Tumbleweed

Matrix products: default
BLAS: /usr/lib64/R/lib/libRblas.so
LAPACK: /usr/lib64/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-
8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8       
 [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-
8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-
8       LC_NAME=C                  LC_ADDRESS=C              
[10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices
utils     datasets  methods   base     

other attached packages:
[1] inline_0.3.14 magrittr_1.5 

loaded via a namespace (and not attached):
[1] compiler_3.4.1 tools_3.4.1    yaml_2.1.18    ulimit_0.0-3


From luke-tierney at uiowa.edu  Sun Mar 18 15:54:44 2018
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sun, 18 Mar 2018 09:54:44 -0500 (CDT)
Subject: [Rd] `@<-` modify its argument when slot is externalptr
In-Reply-To: <1521382063.7888.5.camel@gmx.cn>
References: <1521382063.7888.5.camel@gmx.cn>
Message-ID: <alpine.DEB.2.20.1803180933350.4709@luke-Latitude>

On Sun, 18 Mar 2018, Jialin Ma wrote:

> Dear all,
>
> I am confused about the inconsistent behaviors of `@<-` operator when
> used in different ways. Consider the following example:
>
>  library(inline)
>
>  # Function to generate an externalptr object with random address
>  new_extptr <- cfunction(c(), '
>    SEXP val = PROTECT(ScalarLogical(1));
>    SEXP out = PROTECT(R_MakeExternalPtr(&val, R_NilValue, val));
>    UNPROTECT(2);
>    return(out);
>  ')
>
>  setClass("S4ClassHoldingExtptr", contains = "externalptr")
>
>  subs_extptr_1 <- function(x) {
>    x at .xData <- new_extptr()
>    x
>  }
>
>  subs_extptr_2 <- function(x) {
>    x <- `@<-`(x, ".xData", new_extptr())
>    x
>  }
>
> I expect functions "subs_extptr_1" and "subs_extptr_2" should be
> semantically identical. (is it right?)

No. The are similar but not identical. It is not a good idea to call
replacement functions directly and should be avoided. Doing so may need
to become a runtime error or at least a warning in the future.

Nevertheless, this is a bug in the implementation @<-.A simpler example is

x <- setClass("foo", slots = "bar")
x <- new("foo", bar = 1)
y <- x
y at bar
##  [1] 1
`@<-`(x, bar, 2)
y at bar
##  [1] 2

Will be fixed soon in R-devel.

Best,

luke

> x <- setClass("foo", slots = "bar")
> x <- new("foo", bar = 1)
> y <- x
> `@<-`(x, bar, 2)
An object of class "foo"
Slot "bar":
[1] 2

> x
An object of class "foo"
Slot "bar":
[1] 2

> x$bar
Error in x$bar : $ operator not defined for this S4 class
> x at bar
[1] 2

> But it seems that "subs_extptr_2" will modify its argument while
> "subs_extptr_1" won't.
>
>  x <- new("S4ClassHoldingExtptr", new_extptr())
>  y <- x
>  y
>   # An object of class "S4ClassHoldingExtptr"
>   # <pointer: 0x7ffc60971eb0>
>
>  subs_extptr_1(x)
>   # An object of class "S4ClassHoldingExtptr"
>   # <pointer: 0x7ffc60974250>
>  x
>   # An object of class "S4ClassHoldingExtptr"
>   # <pointer: 0x7ffc60971eb0>
>  y
>   # An object of class "S4ClassHoldingExtptr"
>   # <pointer: 0x7ffc60971eb0>
>
> As shown above, "subs_extptr_1" will not modify x or y.
>
>  subs_extptr_2(x)
>   # An object of class "S4ClassHoldingExtptr"
>   # <pointer: 0x7ffc60973f30>
>  x
>   # An object of class "S4ClassHoldingExtptr"
>   # <pointer: 0x7ffc60973f30>
>  y
>   # An object of class "S4ClassHoldingExtptr"
>   # <pointer: 0x7ffc60973f30>
>
> However, "subs_extptr_2" will modify both x and y.
>
> Is this behavior expected?
>
> Thanks,
> Jialin
>
>
>> sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-suse-linux-gnu (64-bit)
> Running under: openSUSE Tumbleweed
>
> Matrix products: default
> BLAS: /usr/lib64/R/lib/libRblas.so
> LAPACK: /usr/lib64/R/lib/libRlapack.so
>
> locale:
> [1] LC_CTYPE=en_US.UTF-
> 8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8
> [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-
> 8    LC_MESSAGES=en_US.UTF-8
> [7] LC_PAPER=en_US.UTF-
> 8       LC_NAME=C                  LC_ADDRESS=C
> [10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
> LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices
> utils     datasets  methods   base
>
> other attached packages:
> [1] inline_0.3.14 magrittr_1.5
>
> loaded via a namespace (and not attached):
> [1] compiler_3.4.1 tools_3.4.1    yaml_2.1.18    ulimit_0.0-3
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From lukas.stadler at oracle.com  Sun Mar 18 17:48:46 2018
From: lukas.stadler at oracle.com (Lukas Stadler)
Date: Sun, 18 Mar 2018 17:48:46 +0100
Subject: [Rd] `@<-` modify its argument when slot is externalptr
In-Reply-To: <alpine.DEB.2.20.1803180933350.4709@luke-Latitude>
References: <1521382063.7888.5.camel@gmx.cn>
 <alpine.DEB.2.20.1803180933350.4709@luke-Latitude>
Message-ID: <7866BD9C-7445-4416-88AB-4CCA4CC0FBBE@oracle.com>


> On 18.03.2018, at 15:54, luke-tierney at uiowa.edu wrote:
> 
> x <- setClass("foo", slots = "bar")
> x <- new("foo", bar = 1)
> y <- x
> y at bar
> ##  [1] 1
> `@<-`(x, bar, 2)
> y at bar
> ##  [1] 2
> 
> Will be fixed soon in R-devel.
> 

I always assumed that this behavior is intentional, in order to make S4 "initialize" work efficiently.

- Lukas
	[[alternative HTML version deleted]]


From henrik.bengtsson at gmail.com  Sun Mar 18 21:53:20 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Sun, 18 Mar 2018 13:53:20 -0700
Subject: [Rd] BUG: tools::pskill() returns incorrect values or non-initated
 garbage values [PATCH]
Message-ID: <CAFDcVCSwdcMOMcUknbBPjLyhzAZ9mG4TT2m0Bh25rG9RkZyx8w@mail.gmail.com>

For the record, I've just filed the following bug report with a patch
to https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17395:

tools::pskill() returns either random garbage or incorrect values,
because the internal ps_kill() (a) it does not initiate the returned
logical, and (b) it assigns the logical returned the 0/-1 value of C's
kill().

# Example 1: returns garbage due to non-initiated allocation

> as.integer(tools::pskill(0))
[1] 44764824
> as.integer(tools::pskill(0))
[1] 41609736
> as.integer(tools::pskill(0))
[1] 45003984


# Example 2: returns 0 in success and -1 on failure

> p <- parallel::mcparallel({ Sys.sleep(3600); 42L })
> res <- tools::pskill(pid = p$pid, signal = tools::SIGKILL)
> as.integer(res)
[1] 0

> p <- parallel::mcparallel({ Sys.sleep(3600); 42L })
> res <- tools::pskill(pid = p$pid, signal = -1) ## invalid signal
> as.integer(res)
[1] -1

/Henrik


From marlin- at gmx.cn  Mon Mar 19 07:23:51 2018
From: marlin- at gmx.cn (Jialin Ma)
Date: Mon, 19 Mar 2018 14:23:51 +0800
Subject: [Rd] `@<-` modify its argument when slot is externalptr
In-Reply-To: <alpine.DEB.2.20.1803180933350.4709@luke-Latitude>
References: <1521382063.7888.5.camel@gmx.cn>
 <alpine.DEB.2.20.1803180933350.4709@luke-Latitude>
Message-ID: <1521440631.12678.1.camel@gmx.cn>

Hi Luke,

Thanks a lot for the explanation. I also noted that `@<-` will not
modify the argument when the slot is ".Data". For example

setClass("foo", contains = "numeric")
x <- new("foo", 2)
y <- x
y
# An object of class "foo"
# [1] 2

`@<-`(x, .Data, 42)
# An object of class "foo"
# [1] 42
x
# An object of class "foo"
# [1] 2
y
# An object of class "foo"
# [1] 2

Best regards,
Jialin


On Sun, 2018-03-18 at 09:54 -0500, luke-tierney at uiowa.edu wrote:
> On Sun, 18 Mar 2018, Jialin Ma wrote:
> 
> > Dear all,
> > 
> > I am confused about the inconsistent behaviors of `@<-` operator
> > when
> > used in different ways. Consider the following example:
> > 
> >  library(inline)
> > 
> >  # Function to generate an externalptr object with random address
> >  new_extptr <- cfunction(c(), '
> >    SEXP val = PROTECT(ScalarLogical(1));
> >    SEXP out = PROTECT(R_MakeExternalPtr(&val, R_NilValue, val));
> >    UNPROTECT(2);
> >    return(out);
> >  ')
> > 
> >  setClass("S4ClassHoldingExtptr", contains = "externalptr")
> > 
> >  subs_extptr_1 <- function(x) {
> >    x at .xData <- new_extptr()
> >    x
> >  }
> > 
> >  subs_extptr_2 <- function(x) {
> >    x <- `@<-`(x, ".xData", new_extptr())
> >    x
> >  }
> > 
> > I expect functions "subs_extptr_1" and "subs_extptr_2" should be
> > semantically identical. (is it right?)
> 
> No. The are similar but not identical. It is not a good idea to call
> replacement functions directly and should be avoided. Doing so may
> need
> to become a runtime error or at least a warning in the future.
> 
> Nevertheless, this is a bug in the implementation @<-.A simpler
> example is
> 
> x <- setClass("foo", slots = "bar")
> x <- new("foo", bar = 1)
> y <- x
> y at bar
> ##  [1] 1
> `@<-`(x, bar, 2)
> y at bar
> ##  [1] 2
> 
> Will be fixed soon in R-devel.
> 
> Best,
> 
> luke
> 
> > x <- setClass("foo", slots = "bar")
> > x <- new("foo", bar = 1)
> > y <- x
> > `@<-`(x, bar, 2)
> 
> An object of class "foo"
> Slot "bar":
> [1] 2
> 
> > x
> 
> An object of class "foo"
> Slot "bar":
> [1] 2
> 
> > x$bar
> 
> Error in x$bar : $ operator not defined for this S4 class
> > x at bar
> 
> [1] 2
> 
> > But it seems that "subs_extptr_2" will modify its argument while
> > "subs_extptr_1" won't.
> > 
> >  x <- new("S4ClassHoldingExtptr", new_extptr())
> >  y <- x
> >  y
> >   # An object of class "S4ClassHoldingExtptr"
> >   # <pointer: 0x7ffc60971eb0>
> > 
> >  subs_extptr_1(x)
> >   # An object of class "S4ClassHoldingExtptr"
> >   # <pointer: 0x7ffc60974250>
> >  x
> >   # An object of class "S4ClassHoldingExtptr"
> >   # <pointer: 0x7ffc60971eb0>
> >  y
> >   # An object of class "S4ClassHoldingExtptr"
> >   # <pointer: 0x7ffc60971eb0>
> > 
> > As shown above, "subs_extptr_1" will not modify x or y.
> > 
> >  subs_extptr_2(x)
> >   # An object of class "S4ClassHoldingExtptr"
> >   # <pointer: 0x7ffc60973f30>
> >  x
> >   # An object of class "S4ClassHoldingExtptr"
> >   # <pointer: 0x7ffc60973f30>
> >  y
> >   # An object of class "S4ClassHoldingExtptr"
> >   # <pointer: 0x7ffc60973f30>
> > 
> > However, "subs_extptr_2" will modify both x and y.
> > 
> > Is this behavior expected?
> > 
> > Thanks,
> > Jialin
> > 
> > 
> > > sessionInfo()
> > 
> > R version 3.4.1 (2017-06-30)
> > Platform: x86_64-suse-linux-gnu (64-bit)
> > Running under: openSUSE Tumbleweed
> > 
> > Matrix products: default
> > BLAS: /usr/lib64/R/lib/libRblas.so
> > LAPACK: /usr/lib64/R/lib/libRlapack.so
> > 
> > locale:
> > [1] LC_CTYPE=en_US.UTF-
> > 8       LC_NUMERIC=C               LC_TIME=en_US.UTF-8
> > [4] LC_COLLATE=en_US.UTF-8     LC_MONETARY=en_US.UTF-
> > 8    LC_MESSAGES=en_US.UTF-8
> > [7] LC_PAPER=en_US.UTF-
> > 8       LC_NAME=C                  LC_ADDRESS=C
> > [10] LC_TELEPHONE=C             LC_MEASUREMENT=en_US.UTF-8
> > LC_IDENTIFICATION=C
> > 
> > attached base packages:
> > [1] stats     graphics  grDevices
> > utils     datasets  methods   base
> > 
> > other attached packages:
> > [1] inline_0.3.14 magrittr_1.5
> > 
> > loaded via a namespace (and not attached):
> > [1] compiler_3.4.1 tools_3.4.1    yaml_2.1.18    ulimit_0.0-3
> > 
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> > 
> 
>


From steuer at hsu-hh.de  Mon Mar 19 14:23:32 2018
From: steuer at hsu-hh.de (Detlef Steuer)
Date: Mon, 19 Mar 2018 14:23:32 +0100
Subject: [Rd] Inconsistency, may be bug in read.delim ?
Message-ID: <20180319142332.3934f83e@gaia>

Dear friends,

I stumbled into beheaviour of read.delim which I would consider a bug
or at least an inconsistency that should be improved upon.

Recently we had to work with data that used "", two double quotes, as
symbol to start and end character input.

Essentially the data looked like this

data.csv
========
V1, V2, V3
""data"", 3, """" 

The last sequence of """" indicating a missing.

One obvious solution to read in this data is using some gsub(),
but that's not the point I want to make.

Consider this case we found during tests:

test.csv
========
V1, V2, V3, V4
"""", """", 3, ""

and read it with 
> read.delim("test.csv", sep=",", header=TRUE, na.strings="\"")  

you get the following

  V1 V2 V3 V4
1 NA  "  3 NA  

(and a warning)

I would have assumed to get some error message or at
least the same result for both appearances of """" in the
input file.
(the setting na.strings="\"" turned out to be working for
 a colleague and his specific data, while I think it shouldn't)

My main concern is the different interpretation for the two """"
sequences.

Real bug? Minor inconsistency? I don't know.

All the best
Detlef


-- 
'People who say "I have nothing to hide" misunderstand the purpose of
surveillance. It was never about privacy. It's about power.' E. Snowden


From bbolker at gmail.com  Mon Mar 19 16:57:34 2018
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 19 Mar 2018 11:57:34 -0400
Subject: [Rd] trivial typo in man/pretty.Rd
Message-ID: <68c2afa9-989d-7f3c-cf7e-c12ad3a8781b@gmail.com>

  patch against recent SVN ...
  as far as I can tell this trivial typo has been there for 20 years:

https://github.com/wch/r-source/blame/ba7920a99fb2fb62b89e404e65f8b132ed4c150a/src/library/base/man/pretty.Rd

===================================================================
--- pretty.Rd	(revision 74426)
+++ pretty.Rd	(working copy)
@@ -21,8 +21,8 @@
   \item{min.n}{nonnegative integer giving the \emph{minimal} number of
     intervals.  If \code{min.n == 0}, \code{pretty(.)} may return a
     single value.}
-  \item{shrink.sml}{positive numeric
-    by a which a default scale is shrunk in the case when
+  \item{shrink.sml}{positive numeric factor
+    by which a default scale is shrunk in the case when
     \code{range(x)} is very small (usually 0).}
   \item{high.u.bias}{non-negative numeric, typically \eqn{> 1}.
     The interval unit is determined as \{1,2,5,10\} times \code{b}, a


From tomas.kalibera at gmail.com  Mon Mar 19 20:20:40 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Mon, 19 Mar 2018 20:20:40 +0100
Subject: [Rd] 
 BUG: tools::pskill() returns incorrect values or non-initated
 garbage values [PATCH]
In-Reply-To: <CAFDcVCSwdcMOMcUknbBPjLyhzAZ9mG4TT2m0Bh25rG9RkZyx8w@mail.gmail.com>
References: <CAFDcVCSwdcMOMcUknbBPjLyhzAZ9mG4TT2m0Bh25rG9RkZyx8w@mail.gmail.com>
Message-ID: <662014f4-65f6-2873-d6c3-9c303e333240@gmail.com>

Thanks for spotting this, fixed in R-devel (including the Windows version).
Tomas


On 03/18/2018 09:53 PM, Henrik Bengtsson wrote:
> For the record, I've just filed the following bug report with a patch
> to https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=17395:
>
> tools::pskill() returns either random garbage or incorrect values,
> because the internal ps_kill() (a) it does not initiate the returned
> logical, and (b) it assigns the logical returned the 0/-1 value of C's
> kill().
>
> # Example 1: returns garbage due to non-initiated allocation
>
>> as.integer(tools::pskill(0))
> [1] 44764824
>> as.integer(tools::pskill(0))
> [1] 41609736
>> as.integer(tools::pskill(0))
> [1] 45003984
>
>
> # Example 2: returns 0 in success and -1 on failure
>
>> p <- parallel::mcparallel({ Sys.sleep(3600); 42L })
>> res <- tools::pskill(pid = p$pid, signal = tools::SIGKILL)
>> as.integer(res)
> [1] 0
>
>> p <- parallel::mcparallel({ Sys.sleep(3600); 42L })
>> res <- tools::pskill(pid = p$pid, signal = -1) ## invalid signal
>> as.integer(res)
> [1] -1
>
> /Henrik
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Tue Mar 20 10:49:01 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Tue, 20 Mar 2018 10:49:01 +0100
Subject: [Rd] trivial typo in man/pretty.Rd
In-Reply-To: <68c2afa9-989d-7f3c-cf7e-c12ad3a8781b@gmail.com>
References: <68c2afa9-989d-7f3c-cf7e-c12ad3a8781b@gmail.com>
Message-ID: <23216.55565.395394.58750@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Mon, 19 Mar 2018 11:57:34 -0400 writes:

    > patch against recent SVN ...
    > as far as I can tell this trivial typo has been there for 20 years:

    > https://github.com/wch/r-source/blame/ba7920a99fb2fb62b89e404e65f8b132ed4c150a/src/library/base/man/pretty.Rd

indeed, 20 years and 2 weeks today:  then it's good to fix it
finally.

Thank you Ben!
Martin

    > ===================================================================
    > --- pretty.Rd	(revision 74426)
    > +++ pretty.Rd	(working copy)
    > @@ -21,8 +21,8 @@
    > \item{min.n}{nonnegative integer giving the \emph{minimal} number of
    > intervals.  If \code{min.n == 0}, \code{pretty(.)} may return a
    > single value.}
    > -  \item{shrink.sml}{positive numeric
    > -    by a which a default scale is shrunk in the case when
    > +  \item{shrink.sml}{positive numeric factor
    > +    by which a default scale is shrunk in the case when
    > \code{range(x)} is very small (usually 0).}
    > \item{high.u.bias}{non-negative numeric, typically \eqn{> 1}.
    > The interval unit is determined as \{1,2,5,10\} times \code{b}, a


From pd.mes at cbs.dk  Tue Mar 20 18:34:10 2018
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Tue, 20 Mar 2018 17:34:10 +0000
Subject: [Rd] R 3.5.0 scheduled for April 23
Message-ID: <120ED611-56F6-4465-998D-DAAF2CA5FA0C@cbs.dk>

Full schedule available on developer.r-project.org (pending auto-update from SVN)

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From henrik.bengtsson at gmail.com  Tue Mar 20 22:11:40 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 20 Mar 2018 14:11:40 -0700
Subject: [Rd] WISH: Sys.setlocale() to return value invisibly
Message-ID: <CAFDcVCTagHrsOwbAdF+08mAv5j3Dc6Ou50YC0iUVP+g92YuS2w@mail.gmail.com>

Contrary to, say, Sys.setenv(), Sys.setlocale() returns it's value
visibly.  This means that if you for instance add:

Sys.setlocale("LC_COLLATE", "C")

to your .Rprofile file, it will print:

[1] "C"

at startup. The workaround is to wrap the call in invisible(), but I'd
argue that any "setter" function should return invisibly.

Some more details:

> withVisible(Sys.setlocale("LC_COLLATE", "C"))
$value
[1] "C"

$visible
[1] TRUE

> withVisible(Sys.setenv(FOO = "C"))
$value
[1] TRUE

$visible
[1] FALSE

/Henrik


From henrik.bengtsson at gmail.com  Tue Mar 20 22:27:58 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Tue, 20 Mar 2018 14:27:58 -0700
Subject: [Rd] sink(con,
 type = "message"): what is the reason why 'message' sinks
 cannot be stacked?
Message-ID: <CAFDcVCSpYOihfdxy6cr5cX3_jXj8fKcCUqr2jcH-hwd5mNgf9A@mail.gmail.com>

In ?sink we can read:

  "Sink-ing the messages stream should be done only with great care.
For that stream file must be an already open connection, and there is
no stack of connections."

and:

  "Do not sink the messages stream unless you understand the source
code implementing it and hence the pitfalls."

Does anyone know the background/reason for this?  Is it a design
decision, or is it just that it was complicated/is not-yet
implemented?  If the latter, I could add it to my to-do list looking
into how stacked message sinks could be supported.


Because of the limitation of only active "message" sink, it is more or
less impossible to reliably capture stderr in package code, or at
least not unconditionally, e.g.

if (sink.number("message") - 2L == 0) {
  sink(con, type = "message")
  ...
} else {
  # Do something else not relying on 'message' sinks
}

Any code/package that does not acknowledge the above, will hijack any
existing message sink.

/Henrik


From hugh.parsonage at gmail.com  Wed Mar 21 13:07:20 2018
From: hugh.parsonage at gmail.com (Hugh Parsonage)
Date: Wed, 21 Mar 2018 23:07:20 +1100
Subject: [Rd] Proposal to reduce check times by skipping GitHub pulls and
 issues URL checks
Message-ID: <CAJmOi+Mm3LzNKeyca+-GYi4p1HGfPwLko8kDXYdvpfHQJRPqpA@mail.gmail.com>

When a package is submitted to CRAN, part of the quality control
process is to ensure any URLs in the package point are valid. While
this requirement is sound, it can add considerably to check times
since each URL takes around a second to check.

There are around 70,000 URLs on CRAN that are checked currently, of
which around 12,000 have a github.com domain (by far the most common
domain, the next most common being doi.org with < 3000). I propose the
QC process be slightly weakened to skip checks of URLs that point to a
pull request or issue of a repository, provided the repository URL
itself has been checked. This patch would skip around 5000 URLs.

I claim that this would not actually weaken the quality control
process in practice. While this patch would skip invalid URLs like
https://github.com/<repo>/<package>/9999999999999, I think it is much
more likely that a URL would point to the wrong issue or pull request,
rather than one which does not exist. Since the current QC doesn't
check whether a valid link is the intended page, my proposal would not
be a real change in this regard.

The patch should not affect the QC of packages with no github.com URLs at all.

This change was motivated by a recent somewhat regrettable change to
the data.table package. That particular package had over 500 such URLs
in its NEWS file that took so long to check it choked the R CMD check
process. As a result, the NEWS file was split, which avoided the
checks but makes it harder to navigate historical changes.


Best,


Hugh Parsonage.
Grattan Institute

From tomas.kalibera at gmail.com  Wed Mar 21 16:57:18 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Wed, 21 Mar 2018 16:57:18 +0100
Subject: [Rd] Inconsistency, may be bug in read.delim ?
In-Reply-To: <20180319142332.3934f83e@gaia>
References: <20180319142332.3934f83e@gaia>
Message-ID: <9ad7cd64-bd09-018b-9f5f-ea84500d414d@gmail.com>

On 03/19/2018 02:23 PM, Detlef Steuer wrote:
> Dear friends,
>
> I stumbled into beheaviour of read.delim which I would consider a bug
> or at least an inconsistency that should be improved upon.
>
> Recently we had to work with data that used "", two double quotes, as
> symbol to start and end character input.
>
> Essentially the data looked like this
>
> data.csv
> ========
> V1, V2, V3
> ""data"", 3, """"
>
> The last sequence of """" indicating a missing.
After processing the quotes, this is internally parsed as

data 3 "

Which I think is correct; in particular, """" represents single quote. 
This is correct and it conforms to RFC 4180. "" in contrast represents 
an empty string.

Based on my reading of RFC4180, ""data"" is not a valid field, but not 
every CSV file follows that RFC, and R supports this pattern as expected 
in your data. So you should be fine here.

> One obvious solution to read in this data is using some gsub(),
> but that's not the point I want to make.
>
> Consider this case we found during tests:
>
> test.csv
> ========
> V1, V2, V3, V4
> """", """", 3, ""
>
> and read it with
>> read.delim("test.csv", sep=",", header=TRUE, na.strings="\"")
After processing the quotes, this is internally parsed as
" " 3 <empty_string>

which is again I think correct (and conforms to RFC 4180)

> you get the following
>
>    V1 V2 V3 V4
> 1 NA  "  3 NA
>
> (and a warning)

I do not get the warning on my system. The reason why the second " is 
not translated to NA by na.strings is white space after the comma in the 
CSV file, this works more consistently:

 > read.delim("test.csv", sep=",", header=TRUE, na.strings="\"", 
strip.white=TRUE)
 ? V1 V2 V3 V4
1 NA NA? 3 NA

If one needed to differentiate between " and <empty_string>, then it 
might be necessary to run without the na.strings argument.

Best
Tomas

> I would have assumed to get some error message or at
> least the same result for both appearances of """" in the
> input file.
> (the setting na.strings="\"" turned out to be working for
>   a colleague and his specific data, while I think it shouldn't)
>
> My main concern is the different interpretation for the two """"
> sequences.
>
> Real bug? Minor inconsistency? I don't know.
>
> All the best
> Detlef
>
>


From maechler at stat.math.ethz.ch  Thu Mar 22 16:43:50 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 22 Mar 2018 16:43:50 +0100
Subject: [Rd] [R-pkg-devel] Warning: rBind is deprecated
In-Reply-To: <485E4908-A0C9-4C99-8AFC-B99339B04188@revelle.net>
References: <83D4DC35-EE2D-48D6-A6F9-44FF234FAA00@revelle.net>
 <CAERMt4dntjpby7ffNg=890VZCTsRF71KtY_D2Nm4K7Fkw0Ra=A@mail.gmail.com>
 <CAO1zAVZY9Lnn6CH2QnG2Myjx=cBv2ywZZ7CMgWZae4C3zykxvw@mail.gmail.com>
 <9F8993B9-3905-4DEE-91B2-1EF8D408AFF0@revelle.net>
 <CAJuCY5za0LskCNC-UDV5NHznoLHi1_q2P49Ae+rGdJS1eqZHnA@mail.gmail.com>
 <485E4908-A0C9-4C99-8AFC-B99339B04188@revelle.net>
Message-ID: <23219.53046.123634.779153@stat.math.ethz.ch>

>From a small thread over at the 'R-package-devel' mailing list,

this now goes to the R-devel mailing list
(CC'ing the original R-package-devel very exceptionally). 

Note that I, as maintainer("Matrix") had introduced rBind() and
cBind() to be used for Matrix package matrices as substitute for
rbind() and cbind() because back then it was not reasonably
possible to provide S4 methods for these.

But for almost three years now, they have been deprecated,
unfortunately *not* with a warning [which was a lapsus of mine].
The help page for these has started, for a long time now, as

| cBind                  package:Matrix                  R Documentation
| 
| Versions of 'cbind' and 'rbind' recursively built on cbind2/rbind2
| 
| Description:
| 
|      The base functions ?cbind? and ?rbind? are defined for an
|      arbitrary number of arguments and hence have the first formal
|      argument ?...?.  For that reason, in the past S4 methods could
|      easily be defined for binding together matrices inheriting from
|      ?Matrix?.
| 
|      For that reason, ?cbind2? and ?rbind2? have been provided for
|      binding together _two_ matrices, and we have defined methods for
|      these and the ?'Matrix'?-matrices.
| 
|      Before R version 3.2.0 (April 2015), we have needed a substitute
|      for _S4-enabled_ versions of ?cbind? and ?rbind?, and provided
|      ?cBind? and ?rBind? with identical syntax and semantic in order to
|      bind together multiple matrices (?"matrix"? or ?"Matrix"? and
|      vectors.  With R version 3.2.0 and newer, ?cBind? and ?rBind? are
|      _deprecated_ and produce a deprecation warning (via
|      ?.Deprecated?), and your code should start using ?cbind()? and
|      ?rbind()? instead.

and finally, the next version of Matrix, which will be the
(recommended, hence bundled) Matrix package for R version 3.5.0
will produce warnings -- only once per session -- whenever
cBind() or rBind() are still used. 

This currently is true e.g., for lme4 and also for another
several dozens of CRAN packages, and unknown but probably
non-zero number of bioconductor packages.

There are even two CRAN packages which in their tests turn every
warning into an error and these packages will even fail their 'R
CMD check' in about a month when R 3.5.0 will appear.

Please package authors, do update the source of your packages:

a) replace  cBind() by cbind()  and rBind() by rbind()
b) Ensure that your package depends on at least R 3.2.0,
   i.e. possibly add a
      'Depends: R (>= 3.2.0)'
   to your DESCRIPTION file.

Of course feel free to comment / ask
privately or here {R-devel only} if necessary.

With best regards,

Martin Maechler
ETH Zurich


From rmh at temple.edu  Fri Mar 23 03:28:08 2018
From: rmh at temple.edu (Richard M. Heiberger)
Date: Thu, 22 Mar 2018 22:28:08 -0400
Subject: [Rd] inappropriate warning in latticeExtra
Message-ID: <CAGx1TMCADAAvL0wa6hyHSuRtrrpU1qFNvPpsaorRAtm6P0roaw@mail.gmail.com>

The warning message in the last line of this email is incorrect.
This is behavior which Duncan Murdoch labeled a bug in
   https://stat.ethz.ch/pipermail/r-help/2017-December/450494.html

This is a fresh install of R-devel (2018-03-21 r74436)




R Under development (unstable) (2018-03-21 r74436) -- "Unsuffered Consequences"
Copyright (C) 2018 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)

R is free software and comes with ABSOLUTELY NO WARRANTY.
You are welcome to redistribute it under certain conditions.
Type 'license()' or 'licence()' for distribution details.

  Natural language support but running in an English locale

R is a collaborative project with many contributors.
Type 'contributors()' for more information and
'citation()' on how to cite R or R packages in publications.

Type 'demo()' for some demos, 'help()' for on-line help, or
'help.start()' for an HTML browser interface to help.
Type 'q()' to quit R.

> library(latticeExtra)
Error in library(latticeExtra) :
  there is no package called ?latticeExtra?
> install.packages("latticeExtra")
Warning in install.packages("latticeExtra") :
  'lib = "C:/Program Files/R/R-devel/library"' is not writable
--- Please select a CRAN mirror for use in this session ---
also installing the dependency ?RColorBrewer?

Warning: unable to access index for repository
http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.5:
  cannot open URL
'http://www.stats.ox.ac.uk/pub/RWin/bin/windows/contrib/3.5/PACKAGES'
trying URL 'https://cran.wu.ac.at/bin/windows/contrib/3.5/RColorBrewer_1.1-2.zip'
Content type 'application/zip' length 55444 bytes (54 KB)
downloaded 54 KB

trying URL 'https://cran.wu.ac.at/bin/windows/contrib/3.5/latticeExtra_0.6-28.zip'
Content type 'application/zip' length 2191524 bytes (2.1 MB)
downloaded 2.1 MB

package ?RColorBrewer? successfully unpacked and MD5 sums checked
package ?latticeExtra? successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\rmh.DESKTOP-60G4CCO\AppData\Local\Temp\RtmpqA7Rqg\downloaded_packages
> library(latticeExtra)
Loading required package: lattice
Loading required package: RColorBrewer
> a <- xyplot(1 ~ 1)
> c(a,a)
Warning message:
In formals(fun) : argument is not a function
>


From rpruim at calvin.edu  Fri Mar 23 14:29:07 2018
From: rpruim at calvin.edu (Randall Pruim)
Date: Fri, 23 Mar 2018 13:29:07 +0000
Subject: [Rd] aggregate() naming -- bug or feature
Message-ID: <9187C1DA-5061-4ABD-9D7C-D536BB134BD6@calvin.edu>

In the examples below, the first loses the name attached by foo(), the second retains names attached by bar().  Is this an intentional difference?  I?d prefer that the names be retained in both cases.

foo <- function(x) { c(mean = base::mean(x)) }
bar <- function(x) { c(mean = base::mean(x), sd = stats::sd(x))}
aggregate(iris$Sepal.Length, by = list(iris$Species), FUN = foo)
#>      Group.1     x
#> 1     setosa 5.006
#> 2 versicolor 5.936
#> 3  virginica 6.588
aggregate(iris$Sepal.Length, by = list(iris$Species), FUN = bar)
#>      Group.1    x.mean      x.sd
#> 1     setosa 5.0060000 0.3524897
#> 2 versicolor 5.9360000 0.5161711
#> 3  virginica 6.5880000 0.6358796

?rjp


	[[alternative HTML version deleted]]


From ruipbarradas at sapo.pt  Fri Mar 23 23:43:57 2018
From: ruipbarradas at sapo.pt (Rui Barradas)
Date: Fri, 23 Mar 2018 22:43:57 +0000
Subject: [Rd] aggregate() naming -- bug or feature
In-Reply-To: <9187C1DA-5061-4ABD-9D7C-D536BB134BD6@calvin.edu>
References: <9187C1DA-5061-4ABD-9D7C-D536BB134BD6@calvin.edu>
Message-ID: <031f02b9-a6eb-cc2b-7c7b-286dc5b7bf68@sapo.pt>

Hello,

Not exactly an answer but here it goes.
If you use the formula interface the names will be retained. If fact, 
this is even better than those names assigned by bar.


aggregate(Sepal.Length ~ Species, data = iris, FUN = foo)
#     Species Sepal.Length
#1     setosa        5.006
#2 versicolor        5.936
#3  virginica        6.588


Hope this helps,

Rui Barradas

On 3/23/2018 1:29 PM, Randall Pruim wrote:
> In the examples below, the first loses the name attached by foo(), the second retains names attached by bar().  Is this an intentional difference?  I?d prefer that the names be retained in both cases.
> 
> foo <- function(x) { c(mean = base::mean(x)) }
> bar <- function(x) { c(mean = base::mean(x), sd = stats::sd(x))}
> aggregate(iris$Sepal.Length, by = list(iris$Species), FUN = foo)
> #>      Group.1     x
> #> 1     setosa 5.006
> #> 2 versicolor 5.936
> #> 3  virginica 6.588
> aggregate(iris$Sepal.Length, by = list(iris$Species), FUN = bar)
> #>      Group.1    x.mean      x.sd
> #> 1     setosa 5.0060000 0.3524897
> #> 2 versicolor 5.9360000 0.5161711
> #> 3  virginica 6.5880000 0.6358796
> 
> ?rjp
> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From muschellij2 at gmail.com  Fri Mar 23 23:51:39 2018
From: muschellij2 at gmail.com (John Muschelli)
Date: Fri, 23 Mar 2018 18:51:39 -0400
Subject: [Rd] Integrate erros on certain functions
Message-ID: <CAFsq6G9i7MD+JHmwdfu88RjD3WmUq79faVUJv2JWb4FbYbasAg@mail.gmail.com>

In the help for ?integrate:

>When integrating over infinite intervals do so explicitly, rather than
just using a large number as the endpoint. This increases the chance of a
correct answer ? any function whose integral over an infinite interval is
finite must be near zero for most of that interval.

I understand that and there are examples such as:

## a slowly-convergent integral
integrand <- function(x) {1/((x+1)*sqrt(x))}
integrate(integrand, lower = 0, upper = Inf)

## don't do this if you really want the integral from 0 to Inf
integrate(integrand, lower = 0, upper = 1000000, stop.on.error = FALSE)
#> failed with message ?the integral is probably divergent?

which gives an error message if stop.on.error = FALSE. But what happens on
something like the function below:
integrate(function(x) exp(-x), lower = 0, upper =Inf)
#> 1 with absolute error < 5.7e-05
integrate(function(x) exp(-x), lower = 0, upper =13000)
#> 2.819306e-05 with absolute error < 5.6e-05

*integrate(function(x) exp(-x), lower = 0, upper =13000, stop.on.error =
FALSE)#> 2.819306e-05 with absolute error < 5.6e-05*

I'm not sure this is a bug or misuse of the function, but I would assume
the last integrate to give an error if stop.on.error = FALSE.

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Fri Mar 23 23:57:05 2018
From: istazahn at gmail.com (Ista Zahn)
Date: Fri, 23 Mar 2018 18:57:05 -0400
Subject: [Rd] aggregate() naming -- bug or feature
In-Reply-To: <031f02b9-a6eb-cc2b-7c7b-286dc5b7bf68@sapo.pt>
References: <9187C1DA-5061-4ABD-9D7C-D536BB134BD6@calvin.edu>
 <031f02b9-a6eb-cc2b-7c7b-286dc5b7bf68@sapo.pt>
Message-ID: <CA+vqiLHze0icMj=M8RL7TtEXWdP7QUkMYNpimCn=6b_Dfv=_yA@mail.gmail.com>

On Fri, Mar 23, 2018 at 6:43 PM, Rui Barradas <ruipbarradas at sapo.pt> wrote:
> Hello,
>
> Not exactly an answer but here it goes.
> If you use the formula interface the names will be retained.

Also if you pass named arguments:

aggregate(iris["Sepal.Length"], by = iris["Species"], FUN = foo)
#      Species Sepal.Length
# 1     setosa        5.006
# 2 versicolor        5.936
# 3  virginica        6.588

If fact, this
> is even better than those names assigned by bar.
>
>
> aggregate(Sepal.Length ~ Species, data = iris, FUN = foo)
> #     Species Sepal.Length
> #1     setosa        5.006
> #2 versicolor        5.936
> #3  virginica        6.588
>
>
> Hope this helps,
>
> Rui Barradas
>
>
> On 3/23/2018 1:29 PM, Randall Pruim wrote:
>>
>> In the examples below, the first loses the name attached by foo(), the
>> second retains names attached by bar().  Is this an intentional difference?
>> I?d prefer that the names be retained in both cases.
>>
>> foo <- function(x) { c(mean = base::mean(x)) }
>> bar <- function(x) { c(mean = base::mean(x), sd = stats::sd(x))}
>> aggregate(iris$Sepal.Length, by = list(iris$Species), FUN = foo)
>> #>      Group.1     x
>> #> 1     setosa 5.006
>> #> 2 versicolor 5.936
>> #> 3  virginica 6.588
>> aggregate(iris$Sepal.Length, by = list(iris$Species), FUN = bar)
>> #>      Group.1    x.mean      x.sd
>> #> 1     setosa 5.0060000 0.3524897
>> #> 2 versicolor 5.9360000 0.5161711
>> #> 3  virginica 6.5880000 0.6358796
>>
>> ?rjp
>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From rpruim at calvin.edu  Sat Mar 24 00:20:39 2018
From: rpruim at calvin.edu (Randall Pruim)
Date: Fri, 23 Mar 2018 23:20:39 +0000
Subject: [Rd] aggregate() naming -- bug or feature
In-Reply-To: <CA+vqiLHze0icMj=M8RL7TtEXWdP7QUkMYNpimCn=6b_Dfv=_yA@mail.gmail.com>
References: <9187C1DA-5061-4ABD-9D7C-D536BB134BD6@calvin.edu>
 <031f02b9-a6eb-cc2b-7c7b-286dc5b7bf68@sapo.pt>
 <CA+vqiLHze0icMj=M8RL7TtEXWdP7QUkMYNpimCn=6b_Dfv=_yA@mail.gmail.com>
Message-ID: <892793DF-BA84-4EF9-8C8D-AC6503250801@calvin.edu>


Thanks.

I?m aware of the other syntax.  My example was just to illustrate the issue minimally, not to indicate how I am using aggregate().  In my application, aggregate() will be called within another function, and the information passed to aggregate() is columns of a matrix returned by model.frame().

For now, I?ve written by own local version of aggregate() with a few tweaks to retain the names I want.

But my question remains: Is this a bug or a feature?

?rjp


On Mar 23, 2018, at 6:57 PM, Ista Zahn <istazahn at gmail.com<mailto:istazahn at gmail.com>> wrote:

On Fri, Mar 23, 2018 at 6:43 PM, Rui Barradas <ruipbarradas at sapo.pt<mailto:ruipbarradas at sapo.pt>> wrote:
Hello,

Not exactly an answer but here it goes.
If you use the formula interface the names will be retained.

Also if you pass named arguments:

aggregate(iris["Sepal.Length"], by = iris["Species"], FUN = foo)
#      Species Sepal.Length
# 1     setosa        5.006
# 2 versicolor        5.936
# 3  virginica        6.588

If fact, this
is even better than those names assigned by bar.


aggregate(Sepal.Length ~ Species, data = iris, FUN = foo)
#     Species Sepal.Length
#1     setosa        5.006
#2 versicolor        5.936
#3  virginica        6.588


Hope this helps,

Rui Barradas


On 3/23/2018 1:29 PM, Randall Pruim wrote:

In the examples below, the first loses the name attached by foo(), the
second retains names attached by bar().  Is this an intentional difference?
I?d prefer that the names be retained in both cases.

foo <- function(x) { c(mean = base::mean(x)) }
bar <- function(x) { c(mean = base::mean(x), sd = stats::sd(x))}
aggregate(iris$Sepal.Length, by = list(iris$Species), FUN = foo)
#>      Group.1     x
#> 1     setosa 5.006
#> 2 versicolor 5.936
#> 3  virginica 6.588
aggregate(iris$Sepal.Length, by = list(iris$Species), FUN = bar)
#>      Group.1    x.mean      x.sd
#> 1     setosa 5.0060000 0.3524897
#> 2 versicolor 5.9360000 0.5161711
#> 3  virginica 6.5880000 0.6358796

?rjp


       [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwIFaQ&c=4rZ6NPIETe-LE5i2KBR4rw&r=S6U-baLhvGcJ7iUQX_KZ6K2om1TTOeUI_-mjRpTrm00&m=wR-DoggMzZ5fX3PJlgbTQe2njoPJ03CTiimaCc_OHe0&s=rehyeJZBteb4wYmKFPvE74AzY4Nm__6Cm4h2q4xfXnk&e=


______________________________________________
R-devel at r-project.org<mailto:R-devel at r-project.org> mailing list
https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwIFaQ&c=4rZ6NPIETe-LE5i2KBR4rw&r=S6U-baLhvGcJ7iUQX_KZ6K2om1TTOeUI_-mjRpTrm00&m=wR-DoggMzZ5fX3PJlgbTQe2njoPJ03CTiimaCc_OHe0&s=rehyeJZBteb4wYmKFPvE74AzY4Nm__6Cm4h2q4xfXnk&e=


	[[alternative HTML version deleted]]


From suharto_anggono at yahoo.com  Sat Mar 24 01:52:02 2018
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Sat, 24 Mar 2018 00:52:02 +0000 (UTC)
Subject: [Rd] Function 'factor' issues
References: <1131771521.6262200.1521852722948.ref@mail.yahoo.com>
Message-ID: <1131771521.6262200.1521852722948@mail.yahoo.com>

I am trying once again.

By just changing
f <- match(xlevs[f], nlevs)
to
f <- match(xlevs, nlevs)[f]
, function 'factor' in R devel could be made more consistent and back-compatible. Why not picking it?

--------------------------------------------
On Sat, 25/11/17, Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com> wrote:

 Subject: Re: [Rd] Function 'factor' issues
 To: r-devel at r-project.org
 Date: Saturday, 25 November, 2017, 6:03 PM

>From commits to R devel, I saw attempts to speed up subsetting and 'match', and to cache results of conversion of small nonnegative integers to character string. That's good.

I am sorry for pushing, still.

Is the partial new behavior of function 'factor' with respect to NA really worthy?

match(xlevs, nlevs)[f]? looks nice, too.

- Using
f <- match(xlevs, nlevs)[f]
instead of
f <- match(xlevs[f], nlevs)
for remapping
- Remapping only if length(nlevs) differs from length(xlevs)
Applying changes similar to above to function 'levels<-.factor' will not change 'levels<-.factor' result at all. So, the corresponding part of functions 'factor' and 'levels<-.factor' can be kept in sync.

--------------------------------------------
On Sun, 22/10/17, Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com> wrote:

Subject: Re: [Rd] Function 'factor' issues
To: r-devel at r-project.org
Date: Sunday, 22 October, 2017, 6:43 AM

My idea (like in https://bugs.r-project.org/bugzilla/attachment.cgi?id=1540 ):
- For remapping, use
f <- match(xlevs, nlevs)[f]
instead of
f <- match(xlevs[f], nlevs)
(I have mentioned it).
- Remap only if length(nlevs) differs from length(xlevs) .


[snip]

--------------------------------------------
On Wed, 18/10/17, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

Subject: Re: [Rd] Function 'factor' issues

Cc: r-devel at r-project.org
Date: Wednesday, 18 October, 2017, 11:54 PM

>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
>>>>>? ? on Sun, 15 Oct 2017 16:03:48 +0000 writes:


? ? > In R devel, function 'factor' has been changed, allowing and merging duplicated 'labels'.

Indeed.? That had been asked for and discussed a bit on this
list from June 14 to June 23, starting at
? https://stat.ethz.ch/pipermail/r-devel/2017-June/074451.html

? ? > Issue 1: Handling of specified 'labels' without duplicates is slower than before.
? ? > Example:
? ? > x <- rep(1:26, 40000)
? ? > system.time(factor(x, levels=1:26, labels=letters))

? ? > Function 'factor' is already rather slow because of conversion to character. Please don't add slowdown.

Indeed, I doo see a ~ 20%? performance loss for the example
above, and I may get to look into this.
However, in R-devel there have been important internal
changes (ALTREP additions) some of which are currently giving
some performance losses in some cases (but they have the
potential to give big performance _gains_ e.g. for simple
indexing into large vectors which may apply here !).
For factor(), these C level "ALTREP" changes may not be the reason at
all for the slow down;
I may find time to investigate further.

{{ For the ALTREP-change slowdowns I've noticed in some
? indexing/subset operations, we'll definitely have time to look into
? before R-devel is going to be released next spring... and as mentioned,
? these operations may even become considerably faster *thanks*
? to ALTREP ... }}

? ? > Issue 2: While default 'labels' is 'levels', not specifying 'labels' may be different from specifying 'labels' to be the same as 'levels'.

? ? > Example 1:
? ? > as.integer(factor(c(NA,2,3), levels = c(2, NA), exclude = NULL))
? ? > is different from
? ? > as.integer(factor(c(NA,2,3), levels = c(2, NA), labels = c(2, NA), exclude = NULL))

You are right.? But this is not so exceptional and part of the new feature of
'labels' allowing to "fix up" things in such cases.? While it
would be nice if this was not the case the same phenomenon
happens in other functions as well because of lazy evaluation.
I think I had noticed that already and at the time found
"not easy" to work around.
(There are many aspects about changing such important base functions:
1. not breaking back compatibility ((unless in rare
? ? border cases, where we are sure it's worth))
2. Keeping code relatively transparent
3. Keep the semantics "simple" to document and as intuitive as possible
)

? ? > File reg-tests-1d.R indicates that 'factor' behavior with NA is slightly changed, for the better. NA entry (because it is unmatched to 'levels' argument or is in 'exclude') is absorbed into NA in "levels" attribute (comes from 'labels' argument), if any. The issue is that it happens only when 'labels' is specified.

I'm not sure anymore, but I think I had noticed that also in
June, considered to change it and found that such a changed
factor() would be too different from what it has "always been".
So, yes, IIRC, this current behavior is on purpose, if only for back compatibility.


? ? > Function 'factor' could use match(xlevs, nlevs)[f]. It doesn't match NA to NA level. When 'f' is long enough, longer than 'xlevs', it is faster than match(xlevs[f], nlevs).

? ? > Example 2:
? ? > With
? ? > levs <- c("A","A")? ,
? ? > factor(levs, levels=levs)
? ? > gives error, but
? ? > factor(levs, levels=levs, labels=levs)
? ? > doesn't.

yes, again that is a consequence of what you said above (before
'Example 1')

? ? > Note: In theory, if function 'factor' merged duplicated 'labels' in all cases, at least in
? ? > factor(c(sqrt(2)^2, 2))? ,
? ? > function 'factor' could do matching on original 'x' (without conversion to character), as in R before version 2.10.0. If function 'factor' did it,
? ? > factor(c(sqrt(2)^2, 2), levels = c(sqrt(2)^2, 2), labels = c("sqrt(2)^2", "2"))
? ? > could take sqrt(2)^2 and 2 as distinct.

Well, that may be interesting.. but I doubt if that's somewhere
we should go, easily, because? factor() has been documented to do
what it does now (with very slightly rounding such numbers via as.character(.))
and hence such a change would typically lead to much work for
too many people.

I do see that indeed the? as.character(.) inside factor() takes
most of the CPU time used in largish factor() examples [as your
first], and indeed, for the case of integer 'x', we really could
be much faster in factor construction.? 

[snip]


From jorismeys at gmail.com  Sat Mar 24 11:16:51 2018
From: jorismeys at gmail.com (Joris Meys)
Date: Sat, 24 Mar 2018 11:16:51 +0100
Subject: [Rd] Possible bug: file.exists() always returns TRUE for prn.us.txt
Message-ID: <CAO1zAVYDDRwJfhm+Mzab-dLQVxi_7JsLwdpEsVFatT22brM0Xg@mail.gmail.com>

Dear all,

while preparing some exercises I came across some highly surprising
behaviour of file.exists(). The specific value "prn.us.txt" always returns
TRUE, even though that file is nowhere to be found on my system.

In a fresh R session 3.4.4 installed on Windows 10:

> grep("prn.us.txt", dir(recursive = TRUE))
integer(0)
> file.exists("prn.us.txt")
[1] TRUE
> file.exists("pnr.us.txt")
[1] FALSE
> file.exists("prn\\.us\\.txt")
[1] FALSE

> sessionInfo()
R version 3.4.4 (2018-03-15)
Platform: x86_64-w64-mingw32/x64 (64-bit)
Running under: Windows 10 x64 (build 16299)

Matrix products: default

locale:
[1] LC_COLLATE=English_United Kingdom.1252
[2] LC_CTYPE=English_United Kingdom.1252
[3] LC_MONETARY=English_United Kingdom.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United Kingdom.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.4.4

This also happens in 3.4.3, 3.4.2 and 3.4.1 . It is confirmed by Roman
Lustrik on his system as well :
https://twitter.com/romunov/status/977486929380995072

I suspect this is a bug, or I must be missing something completely.

Cheers
Joris

-- 
Joris Meys
Statistical consultant

Department of Data Analysis and Mathematical Modelling
Ghent University
Coupure Links 653, B-9000 Gent (Belgium)
<https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>

-----------
Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat Mar 24 11:36:19 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 24 Mar 2018 06:36:19 -0400
Subject: [Rd] 
 Possible bug: file.exists() always returns TRUE for prn.us.txt
In-Reply-To: <CAO1zAVYDDRwJfhm+Mzab-dLQVxi_7JsLwdpEsVFatT22brM0Xg@mail.gmail.com>
References: <CAO1zAVYDDRwJfhm+Mzab-dLQVxi_7JsLwdpEsVFatT22brM0Xg@mail.gmail.com>
Message-ID: <61d7402a-728b-3dec-c6bf-d503bc9f2b4a@gmail.com>

On 24/03/2018 6:16 AM, Joris Meys wrote:
> Dear all,
> 
> while preparing some exercises I came across some highly surprising
> behaviour of file.exists(). The specific value "prn.us.txt" always returns
> TRUE, even though that file is nowhere to be found on my system.

That's a Windows "bug", not an R bug.  Any name starting "prn" (upper or 
lowercase), followed by an extension (i.e. a dot and characters) is 
taken to be the DOS printer device.  According to Writing R Extensions, 
names starting with "?con?, ?prn?, ?aux?, ?clock$?, ?nul?, ?com1? to 
?com9?, and ?lpt1? to ?lpt9' (possibly followed by extensions) are also 
bad.  You can Google "PRN filename in Windows" to find lots of people 
confused by this.  One page I get is

https://msdn.microsoft.com/en-us/library/aa365247(VS.85).aspx

but there's no guarantee that will work five minutes from now.

Duncan Murdoch

> 
> In a fresh R session 3.4.4 installed on Windows 10:
> 
>> grep("prn.us.txt", dir(recursive = TRUE))
> integer(0)
>> file.exists("prn.us.txt")
> [1] TRUE
>> file.exists("pnr.us.txt")
> [1] FALSE
>> file.exists("prn\\.us\\.txt")
> [1] FALSE
> 
>> sessionInfo()
> R version 3.4.4 (2018-03-15)
> Platform: x86_64-w64-mingw32/x64 (64-bit)
> Running under: Windows 10 x64 (build 16299)
> 
> Matrix products: default
> 
> locale:
> [1] LC_COLLATE=English_United Kingdom.1252
> [2] LC_CTYPE=English_United Kingdom.1252
> [3] LC_MONETARY=English_United Kingdom.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United Kingdom.1252
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.4.4
> 
> This also happens in 3.4.3, 3.4.2 and 3.4.1 . It is confirmed by Roman
> Lustrik on his system as well :
> https://twitter.com/romunov/status/977486929380995072
> 
> I suspect this is a bug, or I must be missing something completely.
> 
> Cheers
> Joris
>


From jorismeys at gmail.com  Sat Mar 24 11:38:02 2018
From: jorismeys at gmail.com (Joris Meys)
Date: Sat, 24 Mar 2018 11:38:02 +0100
Subject: [Rd] 
 Possible bug: file.exists() always returns TRUE for prn.us.txt
In-Reply-To: <61d7402a-728b-3dec-c6bf-d503bc9f2b4a@gmail.com>
References: <CAO1zAVYDDRwJfhm+Mzab-dLQVxi_7JsLwdpEsVFatT22brM0Xg@mail.gmail.com>
 <61d7402a-728b-3dec-c6bf-d503bc9f2b4a@gmail.com>
Message-ID: <CAO1zAVZ3hEGckYfv3zdnQ45GL9jogB0SF3RoWZab4JLbQXLOhA@mail.gmail.com>

Thank you. I was just replying my own message with the same information.
Sorry for not doing the research properly before filing.

Cheers
Joris

On Sat, Mar 24, 2018 at 11:36 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 24/03/2018 6:16 AM, Joris Meys wrote:
>
>> Dear all,
>>
>> while preparing some exercises I came across some highly surprising
>> behaviour of file.exists(). The specific value "prn.us.txt" always returns
>> TRUE, even though that file is nowhere to be found on my system.
>>
>
> That's a Windows "bug", not an R bug.  Any name starting "prn" (upper or
> lowercase), followed by an extension (i.e. a dot and characters) is taken
> to be the DOS printer device.  According to Writing R Extensions, names
> starting with "?con?, ?prn?, ?aux?, ?clock$?, ?nul?, ?com1? to ?com9?, and
> ?lpt1? to ?lpt9' (possibly followed by extensions) are also bad.  You can
> Google "PRN filename in Windows" to find lots of people confused by this.
> One page I get is
>
> https://msdn.microsoft.com/en-us/library/aa365247(VS.85).aspx
>
> but there's no guarantee that will work five minutes from now.
>
> Duncan Murdoch
>
>
>
>> In a fresh R session 3.4.4 installed on Windows 10:
>>
>> grep("prn.us.txt", dir(recursive = TRUE))
>>>
>> integer(0)
>>
>>> file.exists("prn.us.txt")
>>>
>> [1] TRUE
>>
>>> file.exists("pnr.us.txt")
>>>
>> [1] FALSE
>>
>>> file.exists("prn\\.us\\.txt")
>>>
>> [1] FALSE
>>
>> sessionInfo()
>>>
>> R version 3.4.4 (2018-03-15)
>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>> Running under: Windows 10 x64 (build 16299)
>>
>> Matrix products: default
>>
>> locale:
>> [1] LC_COLLATE=English_United Kingdom.1252
>> [2] LC_CTYPE=English_United Kingdom.1252
>> [3] LC_MONETARY=English_United Kingdom.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United Kingdom.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] compiler_3.4.4
>>
>> This also happens in 3.4.3, 3.4.2 and 3.4.1 . It is confirmed by Roman
>> Lustrik on his system as well :
>> https://twitter.com/romunov/status/977486929380995072
>>
>> I suspect this is a bug, or I must be missing something completely.
>>
>> Cheers
>> Joris
>>
>>
>


-- 
Joris Meys
Statistical consultant

Department of Data Analysis and Mathematical Modelling
Ghent University
Coupure Links 653, B-9000 Gent (Belgium)
<https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>

-----------
Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From jorismeys at gmail.com  Sat Mar 24 11:46:23 2018
From: jorismeys at gmail.com (Joris Meys)
Date: Sat, 24 Mar 2018 11:46:23 +0100
Subject: [Rd] 
 Possible bug: file.exists() always returns TRUE for prn.us.txt
In-Reply-To: <CAO1zAVZ3hEGckYfv3zdnQ45GL9jogB0SF3RoWZab4JLbQXLOhA@mail.gmail.com>
References: <CAO1zAVYDDRwJfhm+Mzab-dLQVxi_7JsLwdpEsVFatT22brM0Xg@mail.gmail.com>
 <61d7402a-728b-3dec-c6bf-d503bc9f2b4a@gmail.com>
 <CAO1zAVZ3hEGckYfv3zdnQ45GL9jogB0SF3RoWZab4JLbQXLOhA@mail.gmail.com>
Message-ID: <CAO1zAVZk-be_kVmkP6qZ7ho0FNw+HkMpGqykNmwhnCnT14db5A@mail.gmail.com>

Sorry for coming back at this, but would it make sense to have
file.exists() return FALSE when it only finds one of these device names?
Using backslashes to escape the dots makes file.exists() return the correct
result. I got caught by this when I created file names based on a set of
stock market tickers, so I can imagine this could happen to other people
too.

Cheers
Joris

On Sat, Mar 24, 2018 at 11:38 AM, Joris Meys <jorismeys at gmail.com> wrote:

> Thank you. I was just replying my own message with the same information.
> Sorry for not doing the research properly before filing.
>
> Cheers
> Joris
>
> On Sat, Mar 24, 2018 at 11:36 AM, Duncan Murdoch <murdoch.duncan at gmail.com
> > wrote:
>
>> On 24/03/2018 6:16 AM, Joris Meys wrote:
>>
>>> Dear all,
>>>
>>> while preparing some exercises I came across some highly surprising
>>> behaviour of file.exists(). The specific value "prn.us.txt" always
>>> returns
>>> TRUE, even though that file is nowhere to be found on my system.
>>>
>>
>> That's a Windows "bug", not an R bug.  Any name starting "prn" (upper or
>> lowercase), followed by an extension (i.e. a dot and characters) is taken
>> to be the DOS printer device.  According to Writing R Extensions, names
>> starting with "?con?, ?prn?, ?aux?, ?clock$?, ?nul?, ?com1? to ?com9?, and
>> ?lpt1? to ?lpt9' (possibly followed by extensions) are also bad.  You can
>> Google "PRN filename in Windows" to find lots of people confused by this.
>> One page I get is
>>
>> https://msdn.microsoft.com/en-us/library/aa365247(VS.85).aspx
>>
>> but there's no guarantee that will work five minutes from now.
>>
>> Duncan Murdoch
>>
>>
>>
>>> In a fresh R session 3.4.4 installed on Windows 10:
>>>
>>> grep("prn.us.txt", dir(recursive = TRUE))
>>>>
>>> integer(0)
>>>
>>>> file.exists("prn.us.txt")
>>>>
>>> [1] TRUE
>>>
>>>> file.exists("pnr.us.txt")
>>>>
>>> [1] FALSE
>>>
>>>> file.exists("prn\\.us\\.txt")
>>>>
>>> [1] FALSE
>>>
>>> sessionInfo()
>>>>
>>> R version 3.4.4 (2018-03-15)
>>> Platform: x86_64-w64-mingw32/x64 (64-bit)
>>> Running under: Windows 10 x64 (build 16299)
>>>
>>> Matrix products: default
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United Kingdom.1252
>>> [2] LC_CTYPE=English_United Kingdom.1252
>>> [3] LC_MONETARY=English_United Kingdom.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United Kingdom.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> loaded via a namespace (and not attached):
>>> [1] compiler_3.4.4
>>>
>>> This also happens in 3.4.3, 3.4.2 and 3.4.1 . It is confirmed by Roman
>>> Lustrik on his system as well :
>>> https://twitter.com/romunov/status/977486929380995072
>>>
>>> I suspect this is a bug, or I must be missing something completely.
>>>
>>> Cheers
>>> Joris
>>>
>>>
>>
>
>
> --
> Joris Meys
> Statistical consultant
>
> Department of Data Analysis and Mathematical Modelling
> Ghent University
> Coupure Links 653, B-9000 Gent (Belgium)
>
> <https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>
>
> -----------
> Biowiskundedagen 2017-2018
> http://www.biowiskundedagen.ugent.be/
>
> -------------------------------
> Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php
>



-- 
Joris Meys
Statistical consultant

Department of Data Analysis and Mathematical Modelling
Ghent University
Coupure Links 653, B-9000 Gent (Belgium)
<https://maps.google.com/?q=Coupure+links+653,%C2%A0B-9000+Gent,%C2%A0Belgium&entry=gmail&source=g>

-----------
Biowiskundedagen 2017-2018
http://www.biowiskundedagen.ugent.be/

-------------------------------
Disclaimer : http://helpdesk.ugent.be/e-maildisclaimer.php

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Sat Mar 24 20:23:20 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Sat, 24 Mar 2018 20:23:20 +0100
Subject: [Rd] Function 'factor' issues
In-Reply-To: <1131771521.6262200.1521852722948@mail.yahoo.com>
References: <1131771521.6262200.1521852722948.ref@mail.yahoo.com>
 <1131771521.6262200.1521852722948@mail.yahoo.com>
Message-ID: <23222.42408.949577.534683@stat.math.ethz.ch>

>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
>>>>>     on Sat, 24 Mar 2018 00:52:02 +0000 writes:

    > I am trying once again.

    > By just changing
    > f <- match(xlevs[f], nlevs)
    > to
    > f <- match(xlevs, nlevs)[f]
    > , function 'factor' in R devel could be made more consistent and back-compatible. Why not picking it?

Thank you for persevering,

I'll have a hard look...  You have been right before ;-)
So I will check this small change for both  `factor`  and `levels<-.factor`

Martin

    > --------------------------------------------
    > On Sat, 25/11/17, Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com> wrote:

    > Subject: Re: [Rd] Function 'factor' issues
    > To: r-devel at r-project.org
    > Date: Saturday, 25 November, 2017, 6:03 PM

    >> From commits to R devel, I saw attempts to speed up subsetting and 'match', and to cache results of conversion of small nonnegative integers to character string. That's good.

    > I am sorry for pushing, still.

    > Is the partial new behavior of function 'factor' with respect to NA really worthy?

    > match(xlevs, nlevs)[f]? looks nice, too.

    > - Using
    > f <- match(xlevs, nlevs)[f]
    > instead of
    > f <- match(xlevs[f], nlevs)
    > for remapping
    > - Remapping only if length(nlevs) differs from length(xlevs)
    > Applying changes similar to above to function 'levels<-.factor' will not change 'levels<-.factor' result at all. So, the corresponding part of functions 'factor' and 'levels<-.factor' can be kept in sync.

    > --------------------------------------------
    > On Sun, 22/10/17, Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com> wrote:

    > Subject: Re: [Rd] Function 'factor' issues
    > To: r-devel at r-project.org
    > Date: Sunday, 22 October, 2017, 6:43 AM

    > My idea (like in https://bugs.r-project.org/bugzilla/attachment.cgi?id=1540 ):
    > - For remapping, use
    > f <- match(xlevs, nlevs)[f]
    > instead of
    > f <- match(xlevs[f], nlevs)
    > (I have mentioned it).
    > - Remap only if length(nlevs) differs from length(xlevs) .


    > [snip]

    > --------------------------------------------
    > On Wed, 18/10/17, Martin Maechler <maechler at stat.math.ethz.ch> wrote:

    > Subject: Re: [Rd] Function 'factor' issues

    > Cc: r-devel at r-project.org
    > Date: Wednesday, 18 October, 2017, 11:54 PM

>>>>> Suharto Anggono Suharto Anggono via R-devel <r-devel at r-project.org>
    >>>>>> ? ? on Sun, 15 Oct 2017 16:03:48 +0000 writes:


    > ? ? > In R devel, function 'factor' has been changed, allowing and merging duplicated 'labels'.

    > Indeed.? That had been asked for and discussed a bit on this
    > list from June 14 to June 23, starting at
    > ? https://stat.ethz.ch/pipermail/r-devel/2017-June/074451.html

    > ? ? > Issue 1: Handling of specified 'labels' without duplicates is slower than before.
    > ? ? > Example:
    > ? ? > x <- rep(1:26, 40000)
    > ? ? > system.time(factor(x, levels=1:26, labels=letters))

    > ? ? > Function 'factor' is already rather slow because of conversion to character. Please don't add slowdown.

    > Indeed, I doo see a ~ 20%? performance loss for the example
    > above, and I may get to look into this.
    > However, in R-devel there have been important internal
    > changes (ALTREP additions) some of which are currently giving
    > some performance losses in some cases (but they have the
    > potential to give big performance _gains_ e.g. for simple
    > indexing into large vectors which may apply here !).
    > For factor(), these C level "ALTREP" changes may not be the reason at
    > all for the slow down;
    > I may find time to investigate further.

    > {{ For the ALTREP-change slowdowns I've noticed in some
    > ? indexing/subset operations, we'll definitely have time to look into
    > ? before R-devel is going to be released next spring... and as mentioned,
    > ? these operations may even become considerably faster *thanks*
    > ? to ALTREP ... }}

    > ? ? > Issue 2: While default 'labels' is 'levels', not specifying 'labels' may be different from specifying 'labels' to be the same as 'levels'.

    > ? ? > Example 1:
    > ? ? > as.integer(factor(c(NA,2,3), levels = c(2, NA), exclude = NULL))
    > ? ? > is different from
    > ? ? > as.integer(factor(c(NA,2,3), levels = c(2, NA), labels = c(2, NA), exclude = NULL))

    > You are right.? But this is not so exceptional and part of the new feature of
    > 'labels' allowing to "fix up" things in such cases.? While it
    > would be nice if this was not the case the same phenomenon
    > happens in other functions as well because of lazy evaluation.
    > I think I had noticed that already and at the time found
    > "not easy" to work around.
    > (There are many aspects about changing such important base functions:
    > 1. not breaking back compatibility ((unless in rare
    > ? ? border cases, where we are sure it's worth))
    > 2. Keeping code relatively transparent
    > 3. Keep the semantics "simple" to document and as intuitive as possible
    > )

    > ? ? > File reg-tests-1d.R indicates that 'factor' behavior with NA is slightly changed, for the better. NA entry (because it is unmatched to 'levels' argument or is in 'exclude') is absorbed into NA in "levels" attribute (comes from 'labels' argument), if any. The issue is that it happens only when 'labels' is specified.

    > I'm not sure anymore, but I think I had noticed that also in
    > June, considered to change it and found that such a changed
    > factor() would be too different from what it has "always been".
    > So, yes, IIRC, this current behavior is on purpose, if only for back compatibility.


    > ? ? > Function 'factor' could use match(xlevs, nlevs)[f]. It doesn't match NA to NA level. When 'f' is long enough, longer than 'xlevs', it is faster than match(xlevs[f], nlevs).

    > ? ? > Example 2:
    > ? ? > With
    > ? ? > levs <- c("A","A")? ,
    > ? ? > factor(levs, levels=levs)
    > ? ? > gives error, but
    > ? ? > factor(levs, levels=levs, labels=levs)
    > ? ? > doesn't.

    > yes, again that is a consequence of what you said above (before
    > 'Example 1')

    > ? ? > Note: In theory, if function 'factor' merged duplicated 'labels' in all cases, at least in
    > ? ? > factor(c(sqrt(2)^2, 2))? ,
    > ? ? > function 'factor' could do matching on original 'x' (without conversion to character), as in R before version 2.10.0. If function 'factor' did it,
    > ? ? > factor(c(sqrt(2)^2, 2), levels = c(sqrt(2)^2, 2), labels = c("sqrt(2)^2", "2"))
    > ? ? > could take sqrt(2)^2 and 2 as distinct.

    > Well, that may be interesting.. but I doubt if that's somewhere
    > we should go, easily, because? factor() has been documented to do
    > what it does now (with very slightly rounding such numbers via as.character(.))
    > and hence such a change would typically lead to much work for
    > too many people.

    > I do see that indeed the? as.character(.) inside factor() takes
    > most of the CPU time used in largish factor() examples [as your
    > first], and indeed, for the case of integer 'x', we really could
    > be much faster in factor construction.? 

    > [snip]

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From lukemolson at yahoo.com  Sat Mar 24 21:08:33 2018
From: lukemolson at yahoo.com (lmo)
Date: Sat, 24 Mar 2018 20:08:33 +0000 (UTC)
Subject: [Rd] aggregate() naming -- bug or feature
References: <1099191693.397761.1521922113450.ref@mail.yahoo.com>
Message-ID: <1099191693.397761.1521922113450@mail.yahoo.com>

Be aware that the object that aggregate returns with bar() is more complicated than you think.
str(aggregate(iris$Sepal.Length, by = list(iris$Species), FUN = bar))
'data.frame':?? ?3 obs. of? 2 variables:
?$ Group.1: Factor w/ 3 levels "setosa","versicolor",..: 1 2 3
?$ x????? : num [1:3, 1:2] 5.006 5.936 6.588 0.352 0.516 ...
? ..- attr(*, "dimnames")=List of 2
? .. ..$ : NULL
? .. ..$ : chr? "mean" "sd"
So you get a two column data.frame whose second column is a matrix.

	[[alternative HTML version deleted]]


From jpnolan at american.edu  Sun Mar 25 00:29:06 2018
From: jpnolan at american.edu (John P. Nolan)
Date: Sat, 24 Mar 2018 23:29:06 +0000
Subject: [Rd] Integrate erros on certain functions
In-Reply-To: <CAFsq6G9i7MD+JHmwdfu88RjD3WmUq79faVUJv2JWb4FbYbasAg@mail.gmail.com>
References: <CAFsq6G9i7MD+JHmwdfu88RjD3WmUq79faVUJv2JWb4FbYbasAg@mail.gmail.com>
Message-ID: <CY4PR06MB32884A3106B075807C8D911EC6AF0@CY4PR06MB3288.namprd06.prod.outlook.com>

Dear John,

Two issues.  First, the default action is stop.on.error=TRUE, so anytime the integrate function can determine an error, it will stop.  It doesn't detect an error, so no error is produced (whether you set stop.on.error=TRUE or FALSE).

The second issue is the real problem:  what automatic numerical integration can do or not do.  When the upper bound is Inf, integrate (which is based on the QUADPACK fortran code) does a change of variable to make the region of integration be a finite interval, then tries to evaluate that transformed integral.  When the upper bound is a large finite number, integrate tries to evaluate the integral directly.  In this case, the integrand is evaluated at multiple x values in the interval [0,13000].   Those x values are large, and the resulting function values are very near 0.  You can verify this by putting some trace statements into your integrand function, e.g. 

> f1 <- function( x ) { y <- exp(-x); print( rbind(x,y) ); return(y) }
> integrate( f1, lower = 0, upper =13000)

The quadrature rule "sees" an integrand near 0 and returns a value for the integral near 0.  It does not detect an error, so it does not report anything to you.  It does not know how the integrand function behaves on regions where it does not evaluate it.  This is a well-known problem in numerical integration: there is no way the integrate function can know what region to focus on in a general problem.  Using an upper bound=Inf does not guarantee that you will get the correct value, but sometimes it works.  

Hope this helps. 

John

??????????????????????????????..
John P. Nolan
Math/Stat Dept., American University
106J Myers Hall, 4400 Massachusetts Ave, NW, Washington, DC 20016-8050
Phone: 202-885-3140   E-mail:  jpnolan at american.edu
Web:   http://fs2.american.edu/jpnolan/www/





-----Original Message-----
From: R-devel <r-devel-bounces at r-project.org> On Behalf Of John Muschelli
Sent: Friday, March 23, 2018 6:52 PM
To: r-devel at r-project.org
Subject: [Rd] Integrate erros on certain functions

In the help for ?integrate:

>When integrating over infinite intervals do so explicitly, rather than
just using a large number as the endpoint. This increases the chance of a correct answer ? any function whose integral over an infinite interval is finite must be near zero for most of that interval.

I understand that and there are examples such as:

## a slowly-convergent integral
integrand <- function(x) {1/((x+1)*sqrt(x))} integrate(integrand, lower = 0, upper = Inf)

## don't do this if you really want the integral from 0 to Inf integrate(integrand, lower = 0, upper = 1000000, stop.on.error = FALSE) #> failed with message ?the integral is probably divergent?

which gives an error message if stop.on.error = FALSE. But what happens on something like the function below:
integrate(function(x) exp(-x), lower = 0, upper =Inf) #> 1 with absolute error < 5.7e-05
integrate(function(x) exp(-x), lower = 0, upper =13000) #> 2.819306e-05 with absolute error < 5.6e-05

*integrate(function(x) exp(-x), lower = 0, upper =13000, stop.on.error = FALSE)#> 2.819306e-05 with absolute error < 5.6e-05*

I'm not sure this is a bug or misuse of the function, but I would assume the last integrate to give an error if stop.on.error = FALSE.

	[[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://urldefense.proofpoint.com/v2/url?u=https-3A__stat.ethz.ch_mailman_listinfo_r-2Ddevel&d=DwIFaQ&c=U0G0XJAMhEk_X0GAGzCL7Q&r=7rQvU8hscCTWlvO-F5wI2-2eTiW40XI5qUKda0AnbG0&m=iA2KskSHO_cMznVT31Amx5mIJ0-cQurEM9ItQz-WwvU&s=_A2zZDw5gLetKaZqbPZMpJFqO8B1-kPT2T__T73CM-I&e=

From rpruim at calvin.edu  Sun Mar 25 15:56:22 2018
From: rpruim at calvin.edu (Randall Pruim)
Date: Sun, 25 Mar 2018 13:56:22 +0000
Subject: [Rd] R-devel Digest, Vol 181, Issue 22
In-Reply-To: <mailman.46825.3.1521972002.2726.r-devel@r-project.org>
References: <mailman.46825.3.1521972002.2726.r-devel@r-project.org>
Message-ID: <7E076BB3-671E-4561-9E74-7DCBF3B15AA7@calvin.edu>

Thanks.

I am fully aware of what aggregate() returnes, and I can post-process this into the form I want ? if the names are available.

But for foo, the returned object is both different in structure and loses the name altogether:

foo <- function(x) { c(mean = base::mean(x)) }
str(aggregate(iris$Sepal.Length, by = list(iris$Species), FUN = foo))
## 'data.frame': 3 obs. of  2 variables:
##  $ Group.1: Factor w/ 3 levels "setosa","versicolor",..: 1 2 3
##  $ x      : num  5.01 5.94 6.59

If $x were $mean, or if $x were a matrix with one column named ?mean?, then I would not have had to write a custom aggregate.

For anyone interested, I?m doing this to create a function that can compute (multiple, group-wise) summary statistics easily, and return them in a tidy data frame with one row for each group.  Naming depends on whether ? arguments are named and on some optional arguments.  Here is an example.

args(df_stats)
## function (formula, data, ..., drop = TRUE, fargs = list(), sep = "_",
##     format = c("wide", "long"), groups = NULL, long_names = TRUE,
##     nice_names = FALSE, na.action = "na.warn")

df_stats(Sepal.Length ~ Species, data = iris, mean, sd, R = range, Q = quantile)
##      Species mean_Sepal.Length sd_Sepal.Length R_1 R_2 Q_0% Q_25% Q_50% Q_75% Q_100%
## 1     setosa             5.006       0.3524897 4.3 5.8  4.3 4.800   5.0   5.2    5.8
## 2 versicolor             5.936       0.5161711 4.9 7.0  4.9 5.600   5.9   6.3    7.0
## 3  virginica             6.588       0.6358796 4.9 7.9  4.9 6.225   6.5   6.9    7.9

As I?ve said, I solved my problem by creating a slightly modified version of aggregate().  But it made me wonder whether this is a bug or a feature in aggregate().

?rjp


On Mar 25, 2018, at 6:00 AM, r-devel-request at r-project.org<mailto:r-devel-request at r-project.org> wrote:

Date: Sat, 24 Mar 2018 20:08:33 +0000 (UTC)
From: lmo <lukemolson at yahoo.com<mailto:lukemolson at yahoo.com>>
To: "R-devel at r-project.org<mailto:R-devel at r-project.org>" <R-devel at r-project.org<mailto:R-devel at r-project.org>>
Subject: [Rd] aggregate() naming -- bug or feature
Message-ID: <1099191693.397761.1521922113450 at mail.yahoo.com<mailto:1099191693.397761.1521922113450 at mail.yahoo.com>>
Content-Type: text/plain; charset="utf-8"

Be aware that the object that aggregate returns with bar() is more complicated than you think.
str(aggregate(iris$Sepal.Length, by = list(iris$Species), FUN = bar))
'data.frame':    3 obs. of  2 variables:
 $ Group.1: Factor w/ 3 levels "setosa","versicolor",..: 1 2 3
 $ x      : num [1:3, 1:2] 5.006 5.936 6.588 0.352 0.516 ...
  ..- attr(*, "dimnames")=List of 2
  .. ..$ : NULL
  .. ..$ : chr  "mean" "sd"
So you get a two column data.frame whose second column is a matrix.


	[[alternative HTML version deleted]]


From steuer at hsu-hh.de  Sun Mar 25 19:00:35 2018
From: steuer at hsu-hh.de (Detlef Steuer)
Date: Sun, 25 Mar 2018 19:00:35 +0200
Subject: [Rd] Workflow for translations?
Message-ID: <20180325190035.047492a9@linux-h0yu.fritz.box>

Hi friends,

what happend to the "call for translation" that was a clear
signal to start working on an update for transations in former times?

What is the supposed workflow for translations at the moment?
Did I miss some policy change there? Can I read it up somewhere?

All the best
Detlef


From katrin.leinweber at uni-konstanz.de  Sun Mar 25 19:04:34 2018
From: katrin.leinweber at uni-konstanz.de (Katrin Leinweber)
Date: Sun, 25 Mar 2018 19:04:34 +0200
Subject: [Rd] Suggesting patch to link DOIs against secure resolver
Message-ID: <6558a286-9d12-54dd-5d11-66b90e86bc9f@uni-konstanz.de>

Dear Madams and Sirs,

because the DOI foundation recommends a new, secure resolver [1], I
wanted to suggest the attached patch. It

a) updates a static DOI link in the docu,
b) the code chunks that generate new ones, and
c) a reg-ex that detects DOI links.

Hopefully, my first venture into SVN & patch files was done correctly.
My apologies, if there is anything amiss. In that case, I'll be happy to
update the patch according to your advice.

Thank you, and kind regards,
Katrin Leinweber


[1]: https://www.doi.org/doi_handbook/3_Resolution.html#3.8
[2]: https://github.com/parklab/nozzle/pull/27


PS: I left jss.cls untouched, because I emailed an equivalent patch to
the JSS team already, and presume that their update will trickle down in
due time.

PPS: Through RSiteSearch("DOI resolver") I also found instances of
dx.doi.org in Nozzle.R1, to which I had submitted a PR already [2].


-------------- next part --------------
An embedded and charset-unspecified text was scrubbed...
Name: patch.diff
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20180325/27c97f3f/attachment.ksh>

From lawrence.michael at gene.com  Mon Mar 26 01:58:42 2018
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Sun, 25 Mar 2018 16:58:42 -0700
Subject: [Rd] Workflow for translations?
In-Reply-To: <20180325190035.047492a9@linux-h0yu.fritz.box>
References: <20180325190035.047492a9@linux-h0yu.fritz.box>
Message-ID: <CAOQ5NycE9T80EcyzGyXp9jdHvTZJyFD4UuWHouvq0MdOTaYJmg@mail.gmail.com>

Hi Detlef,

Sorry, this is something that I have been supposed to be doing. I will send
out a call soon.

Michael

On Sun, Mar 25, 2018 at 10:00 AM, Detlef Steuer <steuer at hsu-hh.de> wrote:

> Hi friends,
>
> what happend to the "call for translation" that was a clear
> signal to start working on an update for transations in former times?
>
> What is the supposed workflow for translations at the moment?
> Did I miss some policy change there? Can I read it up somewhere?
>
> All the best
> Detlef
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From baptiste.auguie at gmail.com  Mon Mar 26 07:49:09 2018
From: baptiste.auguie at gmail.com (Baptiste Auguie)
Date: Mon, 26 Mar 2018 18:49:09 +1300
Subject: [Rd] =?utf-8?q?R_Lapack_=E2=80=93_why_a_subset=3F?=
Message-ID: <CANLFJPp0nvu1MQPQa6Qw0D+Tqb7Z228FZWZQKDtWf8Vr_snX1A@mail.gmail.com>

Hi,

Why doesn't R include a full Lapack but only a subset?

My cda package (now archived) relying on RcppArmadillo has broken multiple
times on CRAN over the past few years following updates in the underlying
Armadillo library, Every time it follows the same pattern: Armadillo adds a
function to solve a specialised linear system more efficiently, and the
corresponding Lapack routine is not included in the R Lapack subset used on
CRAN, causing breakage. The workaround so far has been an unhappy
compromise with Armadillo developers, adding a "crippled lapack" flag in
the RcppArmadillo configure script, that triggers the use of alternative
(suboptimal) routines and passes CRAN checks. Most RcppArmadillo-dependent
packages don't see the problem; mine seems to be the only one using complex
linear algebra. Two years ago a large number of Lapack routines were added*
to R, and this nicely solved the issue for a while. Unfortunately the same
problem resurfaced last year, with another missing Lapack routine, and my
package is now archived (though it works fine with an external Lapack).
More generally, this workaround is not satisfying for various reasons, and
so I want to ask: why does R ship only a subset of Lapack in the first
place?

Best regards,

baptiste

* Relevant commit at
https://github.com/wch/r-source/commit/98acd96f22eb795a933879c0d3f740e802855473

	[[alternative HTML version deleted]]


From maechler at stat.math.ethz.ch  Mon Mar 26 13:22:45 2018
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 26 Mar 2018 13:22:45 +0200
Subject: [Rd] Suggesting patch to link DOIs against secure resolver
In-Reply-To: <6558a286-9d12-54dd-5d11-66b90e86bc9f@uni-konstanz.de>
References: <6558a286-9d12-54dd-5d11-66b90e86bc9f@uni-konstanz.de>
Message-ID: <23224.55301.758997.58172@stat.math.ethz.ch>

>>>>> Katrin Leinweber <katrin.leinweber at uni-konstanz.de>
>>>>>     on Sun, 25 Mar 2018 19:04:34 +0200 writes:

    > Dear Madams and Sirs,
    > because the DOI foundation recommends a new, secure resolver [1], I
    > wanted to suggest the attached patch. It

    > a) updates a static DOI link in the docu,
    > b) the code chunks that generate new ones, and
    > c) a reg-ex that detects DOI links.

    > Hopefully, my first venture into SVN & patch files was done correctly.
    > My apologies, if there is anything amiss. In that case, I'll be happy to
    > update the patch according to your advice.

Thank you very much, Katrin!
The patch looks perfect to me: It is minimal and well motivated
including references.

I have committed it to R-devel -- which for a dozen of hours now
is aiming for a version of R which will not be released soonish.

If nothing adverse appears from the change, we'd also plan to
back port this patch to what is now called  "R 3.5.0 alpha",
the alpha pre-release version of R 3.5.0 which is due in four weeks.

    > Thank you, and kind regards,
    > Katrin Leinweber


    > [1]: https://www.doi.org/doi_handbook/3_Resolution.html#3.8
    > [2]: https://github.com/parklab/nozzle/pull/27


    > PS: I left jss.cls untouched, because I emailed an equivalent patch to
    > the JSS team already, and presume that their update will trickle down in
    > due time.

    > PPS: Through RSiteSearch("DOI resolver") I also found instances of
    > dx.doi.org in Nozzle.R1, to which I had submitted a PR already [2].

Both decisions make much sense to me.

    > x[DELETED ATTACHMENT external: KLeinweber-DOI_patch.diff, plain text]


From mikko.korpela at maanmittauslaitos.fi  Mon Mar 26 15:22:58 2018
From: mikko.korpela at maanmittauslaitos.fi (Korpela Mikko (MML))
Date: Mon, 26 Mar 2018 13:22:58 +0000
Subject: [Rd] Typo in src/extra/tzone/registryTZ.c
Message-ID: <3fc01e1a09e04b55bfc1718064596c7d@C119S212VM016.msvyvi.vaha.local>

I stumbled upon a typo in a time zone name: Irtutsk should be Irkutsk.
A patch is attached. I also checked that this is the only bug of its
kind in this file, i.e., all the other Olson time zones occurring in
the file can also be found in Unicode Common Locale Data Repository.

- Mikko Korpela

Index: src/extra/tzone/registryTZ.c
===================================================================
--- src/extra/tzone/registryTZ.c        (revision 74465)
+++ src/extra/tzone/registryTZ.c        (working copy)
@@ -303,7 +303,7 @@
     { L"Russia Time Zone 4", "Asia/Yekaterinburg" },
     { L"Russia Time Zone 5", "Asia/Novosibirsk" },
     { L"Russia Time Zone 6", "Asia/Krasnoyarsk" },
-    { L"Russia Time Zone 7", "Asia/Irtutsk" },
+    { L"Russia Time Zone 7", "Asia/Irkutsk" },
     { L"Russia Time Zone 8", "Asia/Yakutsk" },
     { L"Russia Time Zone 9", "Asia/Magadan" },
     { L"Russia Time Zone 10", "Asia/Srednekolymsk" },


From pd.mes at cbs.dk  Mon Mar 26 16:24:32 2018
From: pd.mes at cbs.dk (Peter Dalgaard)
Date: Mon, 26 Mar 2018 14:24:32 +0000
Subject: [Rd] =?windows-1252?q?R_Lapack_=96_why_a_subset=3F?=
In-Reply-To: <CANLFJPp0nvu1MQPQa6Qw0D+Tqb7Z228FZWZQKDtWf8Vr_snX1A@mail.gmail.com>
References: <CANLFJPp0nvu1MQPQa6Qw0D+Tqb7Z228FZWZQKDtWf8Vr_snX1A@mail.gmail.com>
Message-ID: <EBD08220-AD8A-49E6-90BE-90BEAE053AD6@cbs.dk>

I'm not too happy with this either, but I believe the reason is that there would be a significant extra maintenance burden consisting of things that is not being used by R itself. In particular, complex math routines are little used and have historically caused a number of issues with correct argument and return-value passing. 

Notice that it is a bit of a can of worms involving matching up C and Fortran compilers, OS versions, routines being and not being present in current LAPACK, which may differ from the system-supplied one, etc.

-pd

> On 26 Mar 2018, at 07:49 , Baptiste Auguie <baptiste.auguie at gmail.com> wrote:
> 
> Hi,
> 
> Why doesn't R include a full Lapack but only a subset?
> 
> My cda package (now archived) relying on RcppArmadillo has broken multiple
> times on CRAN over the past few years following updates in the underlying
> Armadillo library, Every time it follows the same pattern: Armadillo adds a
> function to solve a specialised linear system more efficiently, and the
> corresponding Lapack routine is not included in the R Lapack subset used on
> CRAN, causing breakage. The workaround so far has been an unhappy
> compromise with Armadillo developers, adding a "crippled lapack" flag in
> the RcppArmadillo configure script, that triggers the use of alternative
> (suboptimal) routines and passes CRAN checks. Most RcppArmadillo-dependent
> packages don't see the problem; mine seems to be the only one using complex
> linear algebra. Two years ago a large number of Lapack routines were added*
> to R, and this nicely solved the issue for a while. Unfortunately the same
> problem resurfaced last year, with another missing Lapack routine, and my
> package is now archived (though it works fine with an external Lapack).
> More generally, this workaround is not satisfying for various reasons, and
> so I want to ask: why does R ship only a subset of Lapack in the first
> place?
> 
> Best regards,
> 
> baptiste
> 
> * Relevant commit at
> https://github.com/wch/r-source/commit/98acd96f22eb795a933879c0d3f740e802855473
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From keith.ohara at nyu.edu  Mon Mar 26 16:59:37 2018
From: keith.ohara at nyu.edu (Keith O'Hara)
Date: Mon, 26 Mar 2018 10:59:37 -0400
Subject: [Rd] =?utf-8?q?R_Lapack_=E2=80=93_why_a_subset=3F?=
In-Reply-To: <EBD08220-AD8A-49E6-90BE-90BEAE053AD6@cbs.dk>
References: <CANLFJPp0nvu1MQPQa6Qw0D+Tqb7Z228FZWZQKDtWf8Vr_snX1A@mail.gmail.com>
 <EBD08220-AD8A-49E6-90BE-90BEAE053AD6@cbs.dk>
Message-ID: <C4870C82-2C89-4089-BA56-0A3B87258FF0@nyu.edu>

Peter, 

Is there not already a significant maintenance burden from cherry-picking routines? From my own experience (https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16482 <https://bugs.r-project.org/bugzilla/show_bug.cgi?id=16482>) this is a painful process. And while users may not call these complex routines directly, R is often used as a front-end for libraries that do, so Rlapack-related linking errors are arising more and more.

Is the cost really so high as to preclude adding the remaining Lapack routines to Rlapack? 

Best,
Keith

> On Mar 26, 2018, at 10:24 AM, Peter Dalgaard via R-devel <r-devel at r-project.org> wrote:
> 
> I'm not too happy with this either, but I believe the reason is that there would be a significant extra maintenance burden consisting of things that is not being used by R itself. In particular, complex math routines are little used and have historically caused a number of issues with correct argument and return-value passing. 
> 
> Notice that it is a bit of a can of worms involving matching up C and Fortran compilers, OS versions, routines being and not being present in current LAPACK, which may differ from the system-supplied one, etc.
> 
> -pd
> 
>> On 26 Mar 2018, at 07:49 , Baptiste Auguie <baptiste.auguie at gmail.com> wrote:
>> 
>> Hi,
>> 
>> Why doesn't R include a full Lapack but only a subset?
>> 
>> My cda package (now archived) relying on RcppArmadillo has broken multiple
>> times on CRAN over the past few years following updates in the underlying
>> Armadillo library, Every time it follows the same pattern: Armadillo adds a
>> function to solve a specialised linear system more efficiently, and the
>> corresponding Lapack routine is not included in the R Lapack subset used on
>> CRAN, causing breakage. The workaround so far has been an unhappy
>> compromise with Armadillo developers, adding a "crippled lapack" flag in
>> the RcppArmadillo configure script, that triggers the use of alternative
>> (suboptimal) routines and passes CRAN checks. Most RcppArmadillo-dependent
>> packages don't see the problem; mine seems to be the only one using complex
>> linear algebra. Two years ago a large number of Lapack routines were added*
>> to R, and this nicely solved the issue for a while. Unfortunately the same
>> problem resurfaced last year, with another missing Lapack routine, and my
>> package is now archived (though it works fine with an external Lapack).
>> More generally, this workaround is not satisfying for various reasons, and
>> so I want to ask: why does R ship only a subset of Lapack in the first
>> place?
>> 
>> Best regards,
>> 
>> baptiste
>> 
>> * Relevant commit at
>> https://github.com/wch/r-source/commit/98acd96f22eb795a933879c0d3f740e802855473
>> 
>> 	[[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


	[[alternative HTML version deleted]]


From jtelleria.rproject at gmail.com  Mon Mar 26 17:40:36 2018
From: jtelleria.rproject at gmail.com (Juan Telleria Ruiz de Aguirre)
Date: Mon, 26 Mar 2018 17:40:36 +0200
Subject: [Rd] =?utf-8?q?R_Lapack_=E2=80=93_why_a_subset=3F?=
In-Reply-To: <C4870C82-2C89-4089-BA56-0A3B87258FF0@nyu.edu>
References: <CANLFJPp0nvu1MQPQa6Qw0D+Tqb7Z228FZWZQKDtWf8Vr_snX1A@mail.gmail.com>
 <EBD08220-AD8A-49E6-90BE-90BEAE053AD6@cbs.dk>
 <C4870C82-2C89-4089-BA56-0A3B87258FF0@nyu.edu>
Message-ID: <CAJXDcw1jRPk6XV39azJ=PXd98iur9nszWy7r-S93q-XGq-XoFw@mail.gmail.com>

> Is the cost really so high as to preclude adding the remaining Lapack routines to Rlapack?

Updating Lapack Libraries shall not break compatibility, and rather
provide bug fixes I guess.

> the reason is that there would be a significant extra maintenance burden consisting of things that is not being used by R itself.

I agree with Keith O'Hara when she says that *"R is often used as a
front-end for libraries that do, so Rlapack-related linking errors are
arising more and more"*.

Maybe we could propose R-Core some SVN patches by ourselves for
R-alpha that update LAPLACK libraries and see how it looks like... :S

> http://www.netlib.org/lapack/archives/

> https://github.com/wch/r-source/tree/trunk/src/modules/lapack

And in SVN:

> svn checkout https://svn.r-project.org/R/trunk/ R-devel
> svn update
> svn diff > patch.diff


From katrin.leinweber at uni-konstanz.de  Mon Mar 26 21:32:27 2018
From: katrin.leinweber at uni-konstanz.de (Katrin Leinweber)
Date: Mon, 26 Mar 2018 21:32:27 +0200
Subject: [Rd] Suggesting patch to link DOIs against secure resolver
In-Reply-To: <23224.55301.758997.58172@stat.math.ethz.ch>
References: <6558a286-9d12-54dd-5d11-66b90e86bc9f@uni-konstanz.de>
 <23224.55301.758997.58172@stat.math.ethz.ch>
Message-ID: <eb296e34-5157-bfb1-260c-fc27e4e5c22d@uni-konstanz.de>

Thank you, Martin. I feel very warmly welcomed to this ML :-)
Happy Easter holidays, everyone and kind regards,

Katrin


From i.ucar86 at gmail.com  Mon Mar 26 23:46:03 2018
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Mon, 26 Mar 2018 23:46:03 +0200
Subject: [Rd] Objects not gc'ed due to caching (?) in R's S3 dispatch
 mechanism
Message-ID: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>

Hi,

I initially opened an issue in the R6 repo because my issue was with
an R6 object. But Winston (thanks!) further simplified my example, and
it turns out that the issue (whether a feature or a bug is yet to be
seen) had to do with S3 dispatching.

The following example, by Winston, depicts the issue:

print.foo <- function(x, ...) {
  cat("print.foo called\n")
  invisible(x)
}

new_foo <- function() {
  e <- new.env()
  reg.finalizer(e, function(e) message("Finalizer called"))
  class(e) <- "foo"
  e
}

new_foo()
gc() # still in .Last.value
gc() # nothing

I would expect that the second call to gc() should free 'e', but it's
not. However, if we call now *any* S3 method, then the object can be
finally gc'ed:

print(1)
gc() # Finalizer called

So the hypothesis is that there is some kind of caching (?) mechanism
going on. Intended behaviour or not, this is something that was
introduced between R 3.2.3 and 3.3.2 (the first succeeds; from the
second on, the example fails as described above).

Regards,
I?aki

PS: Further discussion and examples in https://github.com/r-lib/R6/issues/140


From winstonchang1 at gmail.com  Tue Mar 27 05:49:33 2018
From: winstonchang1 at gmail.com (Winston Chang)
Date: Mon, 26 Mar 2018 22:49:33 -0500
Subject: [Rd] Objects not gc'ed due to caching (?) in R's S3 dispatch
 mechanism
In-Reply-To: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>
References: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>
Message-ID: <CAFOpNVFsNiQgy2pf2kWahx9NAQGYAmYz400hvkwG+FZs5P3WGA@mail.gmail.com>

I'd like to emphasize that although I?aki's example uses print(), it
also happens with other S3 generics. Please note that each of the
following examples might need to be run in a clean R session to work.

===========
Here's an example that doesn't use S3 dispatch. The finalizer runs correctly.

ident <- function(x) invisible(x)

env_with_finalizer <- function() {
  reg.finalizer(environment(), function(e) message("Finalizer called"))
  environment()
}

ident(env_with_finalizer())
gc() # Still in .Last.value
gc() # Finalizer called


===========
Here's an example that uses S3. In this case, the finalizer doesn't run.

ident <- function(x) UseMethod("ident")
ident.default <- function(x) invisible(x)

env_with_finalizer <- function() {
  reg.finalizer(environment(), function(e) message("Finalizer called"))
  environment()
}

ident(env_with_finalizer())
gc()
gc() # Nothing

However, if the S3 generic is called with another object, the
finalizer will run on the next GC:

ident(1)
gc() # Finalizer called

===========

This example is the same as the previous one, except that, at the end,
instead of calling the same S3 generic on a different object (that is,
ident(1)), it calls a _different_ S3 generic on a different object
(mean(1)).

ident <- function(x) UseMethod("ident")
ident.default <- function(x) invisible(x)

env_with_finalizer <- function() {
  reg.finalizer(environment(), function(e) message("Finalizer called"))
  environment()
}

ident(env_with_finalizer())
gc()
gc() # Nothing

# Call a different S3 generic
mean(1)
gc() # Finalizer called


-Winston

On Mon, Mar 26, 2018 at 4:46 PM, I?aki ?car <i.ucar86 at gmail.com> wrote:
> Hi,
>
> I initially opened an issue in the R6 repo because my issue was with
> an R6 object. But Winston (thanks!) further simplified my example, and
> it turns out that the issue (whether a feature or a bug is yet to be
> seen) had to do with S3 dispatching.
>
> The following example, by Winston, depicts the issue:
>
> print.foo <- function(x, ...) {
>   cat("print.foo called\n")
>   invisible(x)
> }
>
> new_foo <- function() {
>   e <- new.env()
>   reg.finalizer(e, function(e) message("Finalizer called"))
>   class(e) <- "foo"
>   e
> }
>
> new_foo()
> gc() # still in .Last.value
> gc() # nothing
>
> I would expect that the second call to gc() should free 'e', but it's
> not. However, if we call now *any* S3 method, then the object can be
> finally gc'ed:
>
> print(1)
> gc() # Finalizer called
>
> So the hypothesis is that there is some kind of caching (?) mechanism
> going on. Intended behaviour or not, this is something that was
> introduced between R 3.2.3 and 3.3.2 (the first succeeds; from the
> second on, the example fails as described above).
>
> Regards,
> I?aki
>
> PS: Further discussion and examples in https://github.com/r-lib/R6/issues/140
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From luke-tierney at uiowa.edu  Tue Mar 27 06:02:55 2018
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 26 Mar 2018 23:02:55 -0500 (CDT)
Subject: [Rd] Objects not gc'ed due to caching (?) in R's S3 dispatch
 mechanism
In-Reply-To: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>
References: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>
Message-ID: <alpine.DEB.2.20.1803262247070.4709@luke-Latitude>

This has nothing to do with printing or dispatch per se. It is the
result of an internal register (R_ReturnedValue) being protected. It
gets rewritten whenever there is a jump, e.g. by an explicit return
call. So a simplified example is

new_foo <- function() {
   e <- new.env()
     reg.finalizer(e, function(e) message("Finalizer called"))
       e
       }

bar <- function(x) return(x)

bar(new_foo())
gc() # still in .Last.value
gc() # nothing

UseMethod essentially does a return call so you see the effect there.

The R_ReturnedValue register could probably be safely cleared in more
places but it isn't clear exactly where. As things stand it will be
cleared on the next use of a non-local transfer of control, and those
happen frequently enough that I'm not convinced this is worth
addressing, at least not at this point in the release cycle.

Best,

luke

On Mon, 26 Mar 2018, I?aki ?car wrote:

> Hi,
>
> I initially opened an issue in the R6 repo because my issue was with
> an R6 object. But Winston (thanks!) further simplified my example, and
> it turns out that the issue (whether a feature or a bug is yet to be
> seen) had to do with S3 dispatching.
>
> The following example, by Winston, depicts the issue:
>
> print.foo <- function(x, ...) {
>  cat("print.foo called\n")
>  invisible(x)
> }
>
> new_foo <- function() {
>  e <- new.env()
>  reg.finalizer(e, function(e) message("Finalizer called"))
>  class(e) <- "foo"
>  e
> }
>
> new_foo()
> gc() # still in .Last.value
> gc() # nothing
>
> I would expect that the second call to gc() should free 'e', but it's
> not. However, if we call now *any* S3 method, then the object can be
> finally gc'ed:
>
> print(1)
> gc() # Finalizer called
>
> So the hypothesis is that there is some kind of caching (?) mechanism
> going on. Intended behaviour or not, this is something that was
> introduced between R 3.2.3 and 3.3.2 (the first succeeds; from the
> second on, the example fails as described above).
>
> Regards,
> I?aki
>
> PS: Further discussion and examples in https://github.com/r-lib/R6/issues/140
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From i.ucar86 at gmail.com  Tue Mar 27 09:51:23 2018
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Tue, 27 Mar 2018 09:51:23 +0200
Subject: [Rd] Objects not gc'ed due to caching (?) in R's S3 dispatch
 mechanism
In-Reply-To: <alpine.DEB.2.20.1803262247070.4709@luke-Latitude>
References: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>
 <alpine.DEB.2.20.1803262247070.4709@luke-Latitude>
Message-ID: <CALEXWq2aX2fXdm1e8veOxhXUS4+42Uqwx1Dtm9xbmpTs5cDNMQ@mail.gmail.com>

2018-03-27 6:02 GMT+02:00  <luke-tierney at uiowa.edu>:
> This has nothing to do with printing or dispatch per se. It is the
> result of an internal register (R_ReturnedValue) being protected. It
> gets rewritten whenever there is a jump, e.g. by an explicit return
> call. So a simplified example is
>
> new_foo <- function() {
>   e <- new.env()
>     reg.finalizer(e, function(e) message("Finalizer called"))
>       e
>       }
>
> bar <- function(x) return(x)
>
> bar(new_foo())
> gc() # still in .Last.value
> gc() # nothing
>
> UseMethod essentially does a return call so you see the effect there.

Understood. Thanks for the explanation, Luke.

> The R_ReturnedValue register could probably be safely cleared in more
> places but it isn't clear exactly where. As things stand it will be
> cleared on the next use of a non-local transfer of control, and those
> happen frequently enough that I'm not convinced this is worth
> addressing, at least not at this point in the release cycle.

I barely know the R internals, and I'm sure there's a good reason
behind this change (R 3.2.3 does not show this behaviour), but IMHO
it's, at the very least, confusing. When .Last.value is cleared, that
object loses the last reference, and I'd expect it to be eligible for
gc.

In my case, I was using an object that internally generates a bunch of
data. I discovered this because I was benchmarking the execution, and
I was running out of memory because the memory wasn't been freed as it
was supposed to. So I spent half of the day on this because I thought
I had a memory leak. :-\ (Not blaming anyone here, of course; just
making a case to show that this may be worth addressing at some
point). :-)

Regards,
I?aki

>
> Best,
>
> luke
>


From tomas.kalibera at gmail.com  Tue Mar 27 11:11:26 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Tue, 27 Mar 2018 11:11:26 +0200
Subject: [Rd] Objects not gc'ed due to caching (?) in R's S3 dispatch
 mechanism
In-Reply-To: <CALEXWq2aX2fXdm1e8veOxhXUS4+42Uqwx1Dtm9xbmpTs5cDNMQ@mail.gmail.com>
References: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>
 <alpine.DEB.2.20.1803262247070.4709@luke-Latitude>
 <CALEXWq2aX2fXdm1e8veOxhXUS4+42Uqwx1Dtm9xbmpTs5cDNMQ@mail.gmail.com>
Message-ID: <d2bb4286-2f57-844c-9349-7e171ac6a1cd@gmail.com>

On 03/27/2018 09:51 AM, I?aki ?car wrote:
> 2018-03-27 6:02 GMT+02:00  <luke-tierney at uiowa.edu>:
>> This has nothing to do with printing or dispatch per se. It is the
>> result of an internal register (R_ReturnedValue) being protected. It
>> gets rewritten whenever there is a jump, e.g. by an explicit return
>> call. So a simplified example is
>>
>> new_foo <- function() {
>>    e <- new.env()
>>      reg.finalizer(e, function(e) message("Finalizer called"))
>>        e
>>        }
>>
>> bar <- function(x) return(x)
>>
>> bar(new_foo())
>> gc() # still in .Last.value
>> gc() # nothing
>>
>> UseMethod essentially does a return call so you see the effect there.
> Understood. Thanks for the explanation, Luke.
>
>> The R_ReturnedValue register could probably be safely cleared in more
>> places but it isn't clear exactly where. As things stand it will be
>> cleared on the next use of a non-local transfer of control, and those
>> happen frequently enough that I'm not convinced this is worth
>> addressing, at least not at this point in the release cycle.
> I barely know the R internals, and I'm sure there's a good reason
> behind this change (R 3.2.3 does not show this behaviour), but IMHO
> it's, at the very least, confusing. When .Last.value is cleared, that
> object loses the last reference, and I'd expect it to be eligible for
> gc.
>
> In my case, I was using an object that internally generates a bunch of
> data. I discovered this because I was benchmarking the execution, and
> I was running out of memory because the memory wasn't been freed as it
> was supposed to. So I spent half of the day on this because I thought
> I had a memory leak. :-\ (Not blaming anyone here, of course; just
> making a case to show that this may be worth addressing at some
> point). :-)
 From the perspective of the R user/programmer/package developer, please 
do not make any assumptions on when finalizers will be run, only that 
they indeed won't be run when the object is still alive. Similarly, it 
is not good to make any assumptions that "gc()" will actually run a 
collection (and a particular type of collection, that it will be 
immediately, etc). Such guarantees would too much restrict the design 
space and potential optimizations on the R internals side - and for this 
reason are typically not given in other managed languages, either. I've 
seen R examples where most time had been wasted tracing live objects 
because explicit "gc()" had been run in a tight loop. Note in Java for 
instance, an explicit call to gc() had been eventually turned into a 
hint only.

Once you start debugging when objects are collected, you are debugging R 
internals - and surprises/changes between svn versions/etc should be 
expected as well as changes in behavior caused very indirectly by code 
changes somewhere else. I work on R internals and spend most of my time 
debugging - that is unfortunately normal when you work on a language 
runtime. Indeed, the runtime should try not to keep references to 
objects for too long, but it remains to be seen whether and for what 
cost this could be fixed with R_ReturnedValue.

Best
Tomas

>
> Regards,
> I?aki
>
>> Best,
>>
>> luke
>>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From i.ucar86 at gmail.com  Tue Mar 27 11:53:58 2018
From: i.ucar86 at gmail.com (=?UTF-8?B?ScOxYWtpIMOaY2Fy?=)
Date: Tue, 27 Mar 2018 11:53:58 +0200
Subject: [Rd] Objects not gc'ed due to caching (?) in R's S3 dispatch
 mechanism
In-Reply-To: <d2bb4286-2f57-844c-9349-7e171ac6a1cd@gmail.com>
References: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>
 <alpine.DEB.2.20.1803262247070.4709@luke-Latitude>
 <CALEXWq2aX2fXdm1e8veOxhXUS4+42Uqwx1Dtm9xbmpTs5cDNMQ@mail.gmail.com>
 <d2bb4286-2f57-844c-9349-7e171ac6a1cd@gmail.com>
Message-ID: <CALEXWq2ato=5gTnTJXqU-QWqpPwwKRXXfr4ck3feLPdxoMwsFw@mail.gmail.com>

2018-03-27 11:11 GMT+02:00 Tomas Kalibera <tomas.kalibera at gmail.com>:
> On 03/27/2018 09:51 AM, I?aki ?car wrote:
>>
>> 2018-03-27 6:02 GMT+02:00  <luke-tierney at uiowa.edu>:
>>>
>>> This has nothing to do with printing or dispatch per se. It is the
>>> result of an internal register (R_ReturnedValue) being protected. It
>>> gets rewritten whenever there is a jump, e.g. by an explicit return
>>> call. So a simplified example is
>>>
>>> new_foo <- function() {
>>>    e <- new.env()
>>>      reg.finalizer(e, function(e) message("Finalizer called"))
>>>        e
>>>        }
>>>
>>> bar <- function(x) return(x)
>>>
>>> bar(new_foo())
>>> gc() # still in .Last.value
>>> gc() # nothing
>>>
>>> UseMethod essentially does a return call so you see the effect there.
>>
>> Understood. Thanks for the explanation, Luke.
>>
>>> The R_ReturnedValue register could probably be safely cleared in more
>>> places but it isn't clear exactly where. As things stand it will be
>>> cleared on the next use of a non-local transfer of control, and those
>>> happen frequently enough that I'm not convinced this is worth
>>> addressing, at least not at this point in the release cycle.
>>
>> I barely know the R internals, and I'm sure there's a good reason
>> behind this change (R 3.2.3 does not show this behaviour), but IMHO
>> it's, at the very least, confusing. When .Last.value is cleared, that
>> object loses the last reference, and I'd expect it to be eligible for
>> gc.
>>
>> In my case, I was using an object that internally generates a bunch of
>> data. I discovered this because I was benchmarking the execution, and
>> I was running out of memory because the memory wasn't been freed as it
>> was supposed to. So I spent half of the day on this because I thought
>> I had a memory leak. :-\ (Not blaming anyone here, of course; just
>> making a case to show that this may be worth addressing at some
>> point). :-)
>
> From the perspective of the R user/programmer/package developer, please do
> not make any assumptions on when finalizers will be run, only that they
> indeed won't be run when the object is still alive. Similarly, it is not
> good to make any assumptions that "gc()" will actually run a collection (and
> a particular type of collection, that it will be immediately, etc). Such
> guarantees would too much restrict the design space and potential
> optimizations on the R internals side - and for this reason are typically
> not given in other managed languages, either. I've seen R examples where
> most time had been wasted tracing live objects because explicit "gc()" had
> been run in a tight loop. Note in Java for instance, an explicit call to
> gc() had been eventually turned into a hint only.
>
> Once you start debugging when objects are collected, you are debugging R
> internals - and surprises/changes between svn versions/etc should be
> expected as well as changes in behavior caused very indirectly by code
> changes somewhere else. I work on R internals and spend most of my time
> debugging - that is unfortunately normal when you work on a language
> runtime. Indeed, the runtime should try not to keep references to objects
> for too long, but it remains to be seen whether and for what cost this could
> be fixed with R_ReturnedValue.

To be precise, I was not debugging *when* objects were collected, I
was debugging *whether* objects were collected. And for that, I
necessarily need some hint about the *when*.

But I think that's another discussion. My point is that, as an R user
and package developer, I expect consistency, and currently

new_foo <- function() {
  e <- new.env()
  reg.finalizer(e, function(e) message("Finalizer called"))
  e
}

bar <- function(x) return(x)

bar(new_foo())
gc() # still in .Last.value
gc() # nothing

behaves differently than

new_foo <- function() {
  e <- new.env()
  reg.finalizer(e, function(e) message("Finalizer called"))
  e
}

bar <- function(x) x

bar(new_foo())
gc() # still in .Last.value
gc() # Finalizer called!

And such a difference is not explained (AFAIK) in the documentation.
At least the help page for 'return' does not make me think that I
should not expect exactly the same behaviour if I write (or not) an
explicit 'return'.

Regards,
I?aki

>
> Best
> Tomas
>


From tomas.kalibera at gmail.com  Tue Mar 27 12:16:28 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Tue, 27 Mar 2018 12:16:28 +0200
Subject: [Rd] Objects not gc'ed due to caching (?) in R's S3 dispatch
 mechanism
In-Reply-To: <CALEXWq2ato=5gTnTJXqU-QWqpPwwKRXXfr4ck3feLPdxoMwsFw@mail.gmail.com>
References: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>
 <alpine.DEB.2.20.1803262247070.4709@luke-Latitude>
 <CALEXWq2aX2fXdm1e8veOxhXUS4+42Uqwx1Dtm9xbmpTs5cDNMQ@mail.gmail.com>
 <d2bb4286-2f57-844c-9349-7e171ac6a1cd@gmail.com>
 <CALEXWq2ato=5gTnTJXqU-QWqpPwwKRXXfr4ck3feLPdxoMwsFw@mail.gmail.com>
Message-ID: <41296a94-6e9f-4f2f-d220-7292831aba43@gmail.com>

On 03/27/2018 11:53 AM, I?aki ?car wrote:
> 2018-03-27 11:11 GMT+02:00 Tomas Kalibera <tomas.kalibera at gmail.com>:
>> On 03/27/2018 09:51 AM, I?aki ?car wrote:
>>> 2018-03-27 6:02 GMT+02:00  <luke-tierney at uiowa.edu>:
>>>> This has nothing to do with printing or dispatch per se. It is the
>>>> result of an internal register (R_ReturnedValue) being protected. It
>>>> gets rewritten whenever there is a jump, e.g. by an explicit return
>>>> call. So a simplified example is
>>>>
>>>> new_foo <- function() {
>>>>     e <- new.env()
>>>>       reg.finalizer(e, function(e) message("Finalizer called"))
>>>>         e
>>>>         }
>>>>
>>>> bar <- function(x) return(x)
>>>>
>>>> bar(new_foo())
>>>> gc() # still in .Last.value
>>>> gc() # nothing
>>>>
>>>> UseMethod essentially does a return call so you see the effect there.
>>> Understood. Thanks for the explanation, Luke.
>>>
>>>> The R_ReturnedValue register could probably be safely cleared in more
>>>> places but it isn't clear exactly where. As things stand it will be
>>>> cleared on the next use of a non-local transfer of control, and those
>>>> happen frequently enough that I'm not convinced this is worth
>>>> addressing, at least not at this point in the release cycle.
>>> I barely know the R internals, and I'm sure there's a good reason
>>> behind this change (R 3.2.3 does not show this behaviour), but IMHO
>>> it's, at the very least, confusing. When .Last.value is cleared, that
>>> object loses the last reference, and I'd expect it to be eligible for
>>> gc.
>>>
>>> In my case, I was using an object that internally generates a bunch of
>>> data. I discovered this because I was benchmarking the execution, and
>>> I was running out of memory because the memory wasn't been freed as it
>>> was supposed to. So I spent half of the day on this because I thought
>>> I had a memory leak. :-\ (Not blaming anyone here, of course; just
>>> making a case to show that this may be worth addressing at some
>>> point). :-)
>>  From the perspective of the R user/programmer/package developer, please do
>> not make any assumptions on when finalizers will be run, only that they
>> indeed won't be run when the object is still alive. Similarly, it is not
>> good to make any assumptions that "gc()" will actually run a collection (and
>> a particular type of collection, that it will be immediately, etc). Such
>> guarantees would too much restrict the design space and potential
>> optimizations on the R internals side - and for this reason are typically
>> not given in other managed languages, either. I've seen R examples where
>> most time had been wasted tracing live objects because explicit "gc()" had
>> been run in a tight loop. Note in Java for instance, an explicit call to
>> gc() had been eventually turned into a hint only.
>>
>> Once you start debugging when objects are collected, you are debugging R
>> internals - and surprises/changes between svn versions/etc should be
>> expected as well as changes in behavior caused very indirectly by code
>> changes somewhere else. I work on R internals and spend most of my time
>> debugging - that is unfortunately normal when you work on a language
>> runtime. Indeed, the runtime should try not to keep references to objects
>> for too long, but it remains to be seen whether and for what cost this could
>> be fixed with R_ReturnedValue.
> To be precise, I was not debugging *when* objects were collected, I
> was debugging *whether* objects were collected. And for that, I
> necessarily need some hint about the *when*.
They would be collected eventually if you were running a non-trivial 
program (because there would be a jump inside).
> But I think that's another discussion. My point is that, as an R user
> and package developer, I expect consistency, and currently
>
> new_foo <- function() {
>    e <- new.env()
>    reg.finalizer(e, function(e) message("Finalizer called"))
>    e
> }
>
> bar <- function(x) return(x)
>
> bar(new_foo())
> gc() # still in .Last.value
> gc() # nothing
>
> behaves differently than
>
> new_foo <- function() {
>    e <- new.env()
>    reg.finalizer(e, function(e) message("Finalizer called"))
>    e
> }
>
> bar <- function(x) x
>
> bar(new_foo())
> gc() # still in .Last.value
> gc() # Finalizer called!
>
> And such a difference is not explained (AFAIK) in the documentation.
> At least the help page for 'return' does not make me think that I
> should not expect exactly the same behaviour if I write (or not) an
> explicit 'return'.
As R user and package developer, you should have consistency in 
_documented_ behavior. If not, it is a bug and has to be fixed either in 
the documentation, or in the code. You should never depend on 
undocumented behavior, because that can change at any time. You cannot 
expect that different versions of R would behave exactly the same, not 
even the svn versions, that is not possible and would not be possible 
even if we did not change any code in R implementation, because even the 
OS, C compiler, hardware, and third party libraries have their specified 
and unspecified behavior.

Best
Tomas
>
> Regards,
> I?aki
>
>> Best
>> Tomas
>>


From tomas.kalibera at gmail.com  Tue Mar 27 13:18:52 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Tue, 27 Mar 2018 13:18:52 +0200
Subject: [Rd] Typo in src/extra/tzone/registryTZ.c
In-Reply-To: <3fc01e1a09e04b55bfc1718064596c7d@C119S212VM016.msvyvi.vaha.local>
References: <3fc01e1a09e04b55bfc1718064596c7d@C119S212VM016.msvyvi.vaha.local>
Message-ID: <00aaafde-a0da-9a08-a98d-c7b63bc4aa7b@gmail.com>

Thanks! Fixed in R-devel,
Tomas

On 03/26/2018 03:22 PM, Korpela Mikko (MML) wrote:
> I stumbled upon a typo in a time zone name: Irtutsk should be Irkutsk.
> A patch is attached. I also checked that this is the only bug of its
> kind in this file, i.e., all the other Olson time zones occurring in
> the file can also be found in Unicode Common Locale Data Repository.
>
> - Mikko Korpela
>
> Index: src/extra/tzone/registryTZ.c
> ===================================================================
> --- src/extra/tzone/registryTZ.c        (revision 74465)
> +++ src/extra/tzone/registryTZ.c        (working copy)
> @@ -303,7 +303,7 @@
>       { L"Russia Time Zone 4", "Asia/Yekaterinburg" },
>       { L"Russia Time Zone 5", "Asia/Novosibirsk" },
>       { L"Russia Time Zone 6", "Asia/Krasnoyarsk" },
> -    { L"Russia Time Zone 7", "Asia/Irtutsk" },
> +    { L"Russia Time Zone 7", "Asia/Irkutsk" },
>       { L"Russia Time Zone 8", "Asia/Yakutsk" },
>       { L"Russia Time Zone 9", "Asia/Magadan" },
>       { L"Russia Time Zone 10", "Asia/Srednekolymsk" },
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From luke-tierney at uiowa.edu  Tue Mar 27 15:22:41 2018
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 27 Mar 2018 08:22:41 -0500 (CDT)
Subject: [Rd] Objects not gc'ed due to caching (?) in R's S3 dispatch
 mechanism
In-Reply-To: <alpine.DEB.2.20.1803262247070.4709@luke-Latitude>
References: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>
 <alpine.DEB.2.20.1803262247070.4709@luke-Latitude>
Message-ID: <alpine.DEB.2.20.1803270820520.4709@luke-Latitude>

I have committed a change to R-devel that addresses this. To be on the
safe side I need to run some more extensive tests before deciding if
this can be ported to the release branch for R 3.5.0. Should know in a
day or two.

Best,

luke

On Tue, 27 Mar 2018, luke-tierney at uiowa.edu wrote:

> This has nothing to do with printing or dispatch per se. It is the
> result of an internal register (R_ReturnedValue) being protected. It
> gets rewritten whenever there is a jump, e.g. by an explicit return
> call. So a simplified example is
>
> new_foo <- function() {
>  e <- new.env()
>    reg.finalizer(e, function(e) message("Finalizer called"))
>      e
>      }
>
> bar <- function(x) return(x)
>
> bar(new_foo())
> gc() # still in .Last.value
> gc() # nothing
>
> UseMethod essentially does a return call so you see the effect there.
>
> The R_ReturnedValue register could probably be safely cleared in more
> places but it isn't clear exactly where. As things stand it will be
> cleared on the next use of a non-local transfer of control, and those
> happen frequently enough that I'm not convinced this is worth
> addressing, at least not at this point in the release cycle.
>
> Best,
>
> luke
>
> On Mon, 26 Mar 2018, I?aki ?car wrote:
>
>> Hi,
>> 
>> I initially opened an issue in the R6 repo because my issue was with
>> an R6 object. But Winston (thanks!) further simplified my example, and
>> it turns out that the issue (whether a feature or a bug is yet to be
>> seen) had to do with S3 dispatching.
>> 
>> The following example, by Winston, depicts the issue:
>> 
>> print.foo <- function(x, ...) {
>>  cat("print.foo called\n")
>>  invisible(x)
>> }
>> 
>> new_foo <- function() {
>>  e <- new.env()
>>  reg.finalizer(e, function(e) message("Finalizer called"))
>>  class(e) <- "foo"
>>  e
>> }
>> 
>> new_foo()
>> gc() # still in .Last.value
>> gc() # nothing
>> 
>> I would expect that the second call to gc() should free 'e', but it's
>> not. However, if we call now *any* S3 method, then the object can be
>> finally gc'ed:
>> 
>> print(1)
>> gc() # Finalizer called
>> 
>> So the hypothesis is that there is some kind of caching (?) mechanism
>> going on. Intended behaviour or not, this is something that was
>> introduced between R 3.2.3 and 3.3.2 (the first succeeds; from the
>> second on, the example fails as described above).
>> 
>> Regards,
>> I?aki
>> 
>> PS: Further discussion and examples in 
>> https://github.com/r-lib/R6/issues/140
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From marlin- at gmx.cn  Wed Mar 28 08:31:06 2018
From: marlin- at gmx.cn (Jialin Ma)
Date: Wed, 28 Mar 2018 14:31:06 +0800
Subject: [Rd] as.pairlist does not convert call objects
Message-ID: <1522218666.10648.5.camel@gmx.cn>

Dear all,

It seems that as.pairlist does not convert call objects, producing
results like the following:

> is.pairlist(as.pairlist(quote(x + y)))
[1] FALSE

Should this behavior be expected?

Thanks,
Jialin


> sessionInfo()
R version 3.4.1 (2017-06-30)
Platform: x86_64-suse-linux-gnu (64-bit)
Running under: openSUSE Tumbleweed

Matrix products: default
BLAS: /usr/lib64/R/lib/libRblas.so
LAPACK: /usr/lib64/R/lib/libRlapack.so

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C              
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8    
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8   
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C                 
 [9] LC_ADDRESS=C               LC_TELEPHONE=C            
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C       

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods  
[7] base     

other attached packages:
[1] magrittr_1.5


From brodie.gaslam at yahoo.com  Thu Mar 29 03:53:03 2018
From: brodie.gaslam at yahoo.com (brodie gaslam)
Date: Thu, 29 Mar 2018 01:53:03 +0000 (UTC)
Subject: [Rd] Possible `substr` bug in UTF-8 Corner Case
References: <1238769437.616826.1522288383079.ref@mail.yahoo.com>
Message-ID: <1238769437.616826.1522288383079@mail.yahoo.com>

I think there is a memory bug in `substr` that is triggered by a UTF-8 corner case: an incomplete UTF-8 byte sequence at the end of a string.? With a valgrind level 2 instrumented build of R-devel I get:

> string <- "abc\xEE"??? # \xEE indicates the start of a 3 byte UTF-8 sequence
> Encoding(string) <- "UTF-8"
> substr(string, 1, 10)
==15375== Invalid read of size 1
==15375==??? at 0x45B3F0: substr (character.c:286)
==15375==??? by 0x45B3F0: do_substr (character.c:342)
==15375==??? by 0x4CFCB9: bcEval (eval.c:6775)
==15375==??? by 0x4D95AF: Rf_eval (eval.c:624)
==15375==??? by 0x4DAD12: R_execClosure (eval.c:1764)
==15375==??? by 0x4D9561: Rf_eval (eval.c:747)
==15375==??? by 0x507008: Rf_ReplIteration (main.c:258)
==15375==??? by 0x5073E7: R_ReplConsole (main.c:308)
==15375==??? by 0x507494: run_Rmainloop (main.c:1082)
==15375==??? by 0x41A8E6: main (Rmain.c:29)
==15375==? Address 0xb9e518d is 3,869 bytes inside a block of size 7,960 alloc'd
==15375==??? at 0x4C2DB8F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
==15375==??? by 0x51033E: GetNewPage (memory.c:888)
==15375==??? by 0x511FC0: Rf_allocVector3 (memory.c:2691)
==15375==??? by 0x4657AC: Rf_allocVector (Rinlinedfuns.h:577)
==15375==??? by 0x4657AC: Rf_ScalarString (Rinlinedfuns.h:1007)
==15375==??? by 0x4657AC: coerceToVectorList (coerce.c:892)
==15375==??? by 0x4657AC: Rf_coerceVector (coerce.c:1293)
==15375==??? by 0x4660EB: ascommon (coerce.c:1369)
==15375==??? by 0x4667C0: do_asvector (coerce.c:1544)
==15375==??? by 0x4CFCB9: bcEval (eval.c:6775)
==15375==??? by 0x4D95AF: Rf_eval (eval.c:624)
==15375==??? by 0x4DAD12: R_execClosure (eval.c:1764)
==15375==??? by 0x515EF7: dispatchMethod (objects.c:408)
==15375==??? by 0x516379: Rf_usemethod (objects.c:458)
==15375==??? by 0x516694: do_usemethod (objects.c:543)
==15375== 
[1] "abc<ee>"

Here is a patch for the native version of `substr` that highlights the problem and a possible fix.? Basically `substr` computes the byte width of a UTF-8 character based on the leading byte ("\xEE" here, which implies 3 bytes) and reads/writes that entire byte width irrespective of whether the string actually ends before the theoretical end of the UTF-8 "character".

Index: src/main/character.c
===================================================================
--- src/main/character.c????(revision 74482)
+++ src/main/character.c????(working copy)
@@ -283,7 +283,7 @@
????for (i = 0; i < so && str < end; i++) {
????????int used = utf8clen(*str);
????????if (i < sa - 1) { str += used; continue; }
-????????for (j = 0; j < used; j++) *buf++ = *str++;
+????????for (j = 0; j < used && str < end; j++) *buf++ = *str++;
????}
???? } else if (ienc == CE_LATIN1 || ienc == CE_BYTES) {
????for (str += (sa - 1), i = sa; i <= so; i++) *buf++ = *str++;

The change above removed the valgrind error for me.? I re-built R with the change and ran "make check" which seemed to work fine. I also ran some simple checks on UTF-8 strings and things seem to work okay.

I have very limited experience making changes to R (this is my first attempt at a patch) so please take all of the above with extreme skepticism.

Apologies in advance if this turns out to be a false alarm caused by an error on my part.

Best,

Brodie.

PS: apologies also if the formatting of this e-mail is bad.? I have not figured out how to get plaintext working properly with yahoo.


From tomas.kalibera at gmail.com  Thu Mar 29 15:11:12 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 29 Mar 2018 15:11:12 +0200
Subject: [Rd] Possible `substr` bug in UTF-8 Corner Case
In-Reply-To: <1238769437.616826.1522288383079@mail.yahoo.com>
References: <1238769437.616826.1522288383079.ref@mail.yahoo.com>
 <1238769437.616826.1522288383079@mail.yahoo.com>
Message-ID: <29cfdb5e-eda0-8524-6937-fa1ba350e0e8@gmail.com>

Thanks, fixed in R-devel (by checking validity of UTF-8 strings for 
substr/substring).
Tomas

On 03/29/2018 03:53 AM, brodie gaslam via R-devel wrote:
> I think there is a memory bug in `substr` that is triggered by a UTF-8 corner case: an incomplete UTF-8 byte sequence at the end of a string.? With a valgrind level 2 instrumented build of R-devel I get:
>
>> string <- "abc\xEE"??? # \xEE indicates the start of a 3 byte UTF-8 sequence
>> Encoding(string) <- "UTF-8"
>> substr(string, 1, 10)
> ==15375== Invalid read of size 1
> ==15375==??? at 0x45B3F0: substr (character.c:286)
> ==15375==??? by 0x45B3F0: do_substr (character.c:342)
> ==15375==??? by 0x4CFCB9: bcEval (eval.c:6775)
> ==15375==??? by 0x4D95AF: Rf_eval (eval.c:624)
> ==15375==??? by 0x4DAD12: R_execClosure (eval.c:1764)
> ==15375==??? by 0x4D9561: Rf_eval (eval.c:747)
> ==15375==??? by 0x507008: Rf_ReplIteration (main.c:258)
> ==15375==??? by 0x5073E7: R_ReplConsole (main.c:308)
> ==15375==??? by 0x507494: run_Rmainloop (main.c:1082)
> ==15375==??? by 0x41A8E6: main (Rmain.c:29)
> ==15375==? Address 0xb9e518d is 3,869 bytes inside a block of size 7,960 alloc'd
> ==15375==??? at 0x4C2DB8F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
> ==15375==??? by 0x51033E: GetNewPage (memory.c:888)
> ==15375==??? by 0x511FC0: Rf_allocVector3 (memory.c:2691)
> ==15375==??? by 0x4657AC: Rf_allocVector (Rinlinedfuns.h:577)
> ==15375==??? by 0x4657AC: Rf_ScalarString (Rinlinedfuns.h:1007)
> ==15375==??? by 0x4657AC: coerceToVectorList (coerce.c:892)
> ==15375==??? by 0x4657AC: Rf_coerceVector (coerce.c:1293)
> ==15375==??? by 0x4660EB: ascommon (coerce.c:1369)
> ==15375==??? by 0x4667C0: do_asvector (coerce.c:1544)
> ==15375==??? by 0x4CFCB9: bcEval (eval.c:6775)
> ==15375==??? by 0x4D95AF: Rf_eval (eval.c:624)
> ==15375==??? by 0x4DAD12: R_execClosure (eval.c:1764)
> ==15375==??? by 0x515EF7: dispatchMethod (objects.c:408)
> ==15375==??? by 0x516379: Rf_usemethod (objects.c:458)
> ==15375==??? by 0x516694: do_usemethod (objects.c:543)
> ==15375==
> [1] "abc<ee>"
>
> Here is a patch for the native version of `substr` that highlights the problem and a possible fix.? Basically `substr` computes the byte width of a UTF-8 character based on the leading byte ("\xEE" here, which implies 3 bytes) and reads/writes that entire byte width irrespective of whether the string actually ends before the theoretical end of the UTF-8 "character".
>
> Index: src/main/character.c
> ===================================================================
> --- src/main/character.c????(revision 74482)
> +++ src/main/character.c????(working copy)
> @@ -283,7 +283,7 @@
>  ????for (i = 0; i < so && str < end; i++) {
>  ????????int used = utf8clen(*str);
>  ????????if (i < sa - 1) { str += used; continue; }
> -????????for (j = 0; j < used; j++) *buf++ = *str++;
> +????????for (j = 0; j < used && str < end; j++) *buf++ = *str++;
>  ????}
>  ???? } else if (ienc == CE_LATIN1 || ienc == CE_BYTES) {
>  ????for (str += (sa - 1), i = sa; i <= so; i++) *buf++ = *str++;
>
> The change above removed the valgrind error for me.? I re-built R with the change and ran "make check" which seemed to work fine. I also ran some simple checks on UTF-8 strings and things seem to work okay.
>
> I have very limited experience making changes to R (this is my first attempt at a patch) so please take all of the above with extreme skepticism.
>
> Apologies in advance if this turns out to be a false alarm caused by an error on my part.
>
> Best,
>
> Brodie.
>
> PS: apologies also if the formatting of this e-mail is bad.? I have not figured out how to get plaintext working properly with yahoo.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tomas.kalibera at gmail.com  Thu Mar 29 15:38:01 2018
From: tomas.kalibera at gmail.com (Tomas Kalibera)
Date: Thu, 29 Mar 2018 15:38:01 +0200
Subject: [Rd] as.pairlist does not convert call objects
In-Reply-To: <1522218666.10648.5.camel@gmx.cn>
References: <1522218666.10648.5.camel@gmx.cn>
Message-ID: <c9e1a104-263c-a36e-2756-cdb335169da3@gmail.com>


On 03/28/2018 08:31 AM, Jialin Ma wrote:
> Dear all,
>
> It seems that as.pairlist does not convert call objects, producing
> results like the following:
>
>> is.pairlist(as.pairlist(quote(x + y)))
> [1] FALSE
>
> Should this behavior be expected?
The documentation says that the behavior of as.pairlist is undocumented 
in this case:

"
 ???? ?as.pairlist? is implemented as ?as.vector(x, "pairlist")?, and
 ???? hence will dispatch methods for the generic function ?as.vector?.
 ???? Lists are copied element-by-element into a pairlist and the names
 ???? of the list used as tags for the pairlist: the return value for
 ???? other types of argument is undocumented.
"

as.pairlist implementation does currently nothing for a language object 
(because it is internally represented using a linked list). is.pairlist 
implementation is checking whether it's argument is a user-level 
pairlist, which language object is not, so it returns FALSE in the example.

These functions are rather low-level and should not be needed in user 
programs. Certainly programs should not depend on undocumented behavior.

Tomas
> Thanks,
> Jialin
>
>
>> sessionInfo()
> R version 3.4.1 (2017-06-30)
> Platform: x86_64-suse-linux-gnu (64-bit)
> Running under: openSUSE Tumbleweed
>
> Matrix products: default
> BLAS: /usr/lib64/R/lib/libRblas.so
> LAPACK: /usr/lib64/R/lib/libRlapack.so
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods
> [7] base
>
> other attached packages:
> [1] magrittr_1.5
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From brodie.gaslam at yahoo.com  Thu Mar 29 15:56:02 2018
From: brodie.gaslam at yahoo.com (brodie gaslam)
Date: Thu, 29 Mar 2018 13:56:02 +0000 (UTC)
Subject: [Rd] Possible `substr` bug in UTF-8 Corner Case
In-Reply-To: <29cfdb5e-eda0-8524-6937-fa1ba350e0e8@gmail.com>
References: <1238769437.616826.1522288383079.ref@mail.yahoo.com>
 <1238769437.616826.1522288383079@mail.yahoo.com>
 <29cfdb5e-eda0-8524-6937-fa1ba350e0e8@gmail.com>
Message-ID: <1405627382.825169.1522331762890@mail.yahoo.com>

Thank you for the quick response and for the quick fix (and for the rchk vagrant image I used to build and test the below!).
One thing I'll note about the fix is that it may start breaking things that used to "work".? I think it is fair to say that character count is not well defined with illegal UTF-8 sequences (and noteworthy that `nchar` does actually stop when it encounters them), but there may be a bit of code out there that relied on being able to successfully complete (albeit while potentially corrupting memory) that will now produce errors.? It may be worth highlighting this in the release notes.

Best,
Brodie.


    On Thursday, March 29, 2018, 9:11:15 AM EDT, Tomas Kalibera <tomas.kalibera at gmail.com> wrote:  
 
 Thanks, fixed in R-devel (by checking validity of UTF-8 strings for 
substr/substring).
Tomas

On 03/29/2018 03:53 AM, brodie gaslam via R-devel wrote:
> I think there is a memory bug in `substr` that is triggered by a UTF-8 corner case: an incomplete UTF-8 byte sequence at the end of a string.? With a valgrind level 2 instrumented build of R-devel I get:
>
>> string <- "abc\xEE"??? # \xEE indicates the start of a 3 byte UTF-8 sequence
>> Encoding(string) <- "UTF-8"
>> substr(string, 1, 10)
> ==15375== Invalid read of size 1
> ==15375==??? at 0x45B3F0: substr (character.c:286)
> ==15375==??? by 0x45B3F0: do_substr (character.c:342)
> ==15375==??? by 0x4CFCB9: bcEval (eval.c:6775)
> ==15375==??? by 0x4D95AF: Rf_eval (eval.c:624)
> ==15375==??? by 0x4DAD12: R_execClosure (eval.c:1764)
> ==15375==??? by 0x4D9561: Rf_eval (eval.c:747)
> ==15375==??? by 0x507008: Rf_ReplIteration (main.c:258)
> ==15375==??? by 0x5073E7: R_ReplConsole (main.c:308)
> ==15375==??? by 0x507494: run_Rmainloop (main.c:1082)
> ==15375==??? by 0x41A8E6: main (Rmain.c:29)
> ==15375==? Address 0xb9e518d is 3,869 bytes inside a block of size 7,960 alloc'd
> ==15375==??? at 0x4C2DB8F: malloc (in /usr/lib/valgrind/vgpreload_memcheck-amd64-linux.so)
> ==15375==??? by 0x51033E: GetNewPage (memory.c:888)
> ==15375==??? by 0x511FC0: Rf_allocVector3 (memory.c:2691)
> ==15375==??? by 0x4657AC: Rf_allocVector (Rinlinedfuns.h:577)
> ==15375==??? by 0x4657AC: Rf_ScalarString (Rinlinedfuns.h:1007)
> ==15375==??? by 0x4657AC: coerceToVectorList (coerce.c:892)
> ==15375==??? by 0x4657AC: Rf_coerceVector (coerce.c:1293)
> ==15375==??? by 0x4660EB: ascommon (coerce.c:1369)
> ==15375==??? by 0x4667C0: do_asvector (coerce.c:1544)
> ==15375==??? by 0x4CFCB9: bcEval (eval.c:6775)
> ==15375==??? by 0x4D95AF: Rf_eval (eval.c:624)
> ==15375==??? by 0x4DAD12: R_execClosure (eval.c:1764)
> ==15375==??? by 0x515EF7: dispatchMethod (objects.c:408)
> ==15375==??? by 0x516379: Rf_usemethod (objects.c:458)
> ==15375==??? by 0x516694: do_usemethod (objects.c:543)
> ==15375==
> [1] "abc<ee>"
>
> Here is a patch for the native version of `substr` that highlights the problem and a possible fix.? Basically `substr` computes the byte width of a UTF-8 character based on the leading byte ("\xEE" here, which implies 3 bytes) and reads/writes that entire byte width irrespective of whether the string actually ends before the theoretical end of the UTF-8 "character".
>
> Index: src/main/character.c
> ===================================================================
> --- src/main/character.c????(revision 74482)
> +++ src/main/character.c????(working copy)
> @@ -283,7 +283,7 @@
>? ????for (i = 0; i < so && str < end; i++) {
>? ????????int used = utf8clen(*str);
>? ????????if (i < sa - 1) { str += used; continue; }
> -????????for (j = 0; j < used; j++) *buf++ = *str++;
> +????????for (j = 0; j < used && str < end; j++) *buf++ = *str++;
>? ????}
>? ???? } else if (ienc == CE_LATIN1 || ienc == CE_BYTES) {
>? ????for (str += (sa - 1), i = sa; i <= so; i++) *buf++ = *str++;
>
> The change above removed the valgrind error for me.? I re-built R with the change and ran "make check" which seemed to work fine. I also ran some simple checks on UTF-8 strings and things seem to work okay.
>
> I have very limited experience making changes to R (this is my first attempt at a patch) so please take all of the above with extreme skepticism.
>
> Apologies in advance if this turns out to be a false alarm caused by an error on my part.
>
> Best,
>
> Brodie.
>
> PS: apologies also if the formatting of this e-mail is bad.? I have not figured out how to get plaintext working properly with yahoo.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


  
	[[alternative HTML version deleted]]


From luke-tierney at uiowa.edu  Thu Mar 29 17:37:06 2018
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 29 Mar 2018 10:37:06 -0500 (CDT)
Subject: [Rd] Objects not gc'ed due to caching (?) in R's S3 dispatch
 mechanism
In-Reply-To: <alpine.DEB.2.20.1803270820520.4709@luke-Latitude>
References: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>
 <alpine.DEB.2.20.1803262247070.4709@luke-Latitude>
 <alpine.DEB.2.20.1803270820520.4709@luke-Latitude>
Message-ID: <alpine.DEB.2.20.1803291036460.4709@luke-Latitude>

Now also committed to the release branch.

Best,

luke

On Tue, 27 Mar 2018, luke-tierney at uiowa.edu wrote:

> I have committed a change to R-devel that addresses this. To be on the
> safe side I need to run some more extensive tests before deciding if
> this can be ported to the release branch for R 3.5.0. Should know in a
> day or two.
>
> Best,
>
> luke
>
> On Tue, 27 Mar 2018, luke-tierney at uiowa.edu wrote:
>
>> This has nothing to do with printing or dispatch per se. It is the
>> result of an internal register (R_ReturnedValue) being protected. It
>> gets rewritten whenever there is a jump, e.g. by an explicit return
>> call. So a simplified example is
>> 
>> new_foo <- function() {
>>  e <- new.env()
>>    reg.finalizer(e, function(e) message("Finalizer called"))
>>      e
>>      }
>> 
>> bar <- function(x) return(x)
>> 
>> bar(new_foo())
>> gc() # still in .Last.value
>> gc() # nothing
>> 
>> UseMethod essentially does a return call so you see the effect there.
>> 
>> The R_ReturnedValue register could probably be safely cleared in more
>> places but it isn't clear exactly where. As things stand it will be
>> cleared on the next use of a non-local transfer of control, and those
>> happen frequently enough that I'm not convinced this is worth
>> addressing, at least not at this point in the release cycle.
>> 
>> Best,
>> 
>> luke
>> 
>> On Mon, 26 Mar 2018, I?aki ?car wrote:
>> 
>>> Hi,
>>> 
>>> I initially opened an issue in the R6 repo because my issue was with
>>> an R6 object. But Winston (thanks!) further simplified my example, and
>>> it turns out that the issue (whether a feature or a bug is yet to be
>>> seen) had to do with S3 dispatching.
>>> 
>>> The following example, by Winston, depicts the issue:
>>> 
>>> print.foo <- function(x, ...) {
>>>  cat("print.foo called\n")
>>>  invisible(x)
>>> }
>>> 
>>> new_foo <- function() {
>>>  e <- new.env()
>>>  reg.finalizer(e, function(e) message("Finalizer called"))
>>>  class(e) <- "foo"
>>>  e
>>> }
>>> 
>>> new_foo()
>>> gc() # still in .Last.value
>>> gc() # nothing
>>> 
>>> I would expect that the second call to gc() should free 'e', but it's
>>> not. However, if we call now *any* S3 method, then the object can be
>>> finally gc'ed:
>>> 
>>> print(1)
>>> gc() # Finalizer called
>>> 
>>> So the hypothesis is that there is some kind of caching (?) mechanism
>>> going on. Intended behaviour or not, this is something that was
>>> introduced between R 3.2.3 and 3.3.2 (the first succeeds; from the
>>> second on, the example fails as described above).
>>> 
>>> Regards,
>>> I?aki
>>> 
>>> PS: Further discussion and examples in 
>>> https://github.com/r-lib/R6/issues/140
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> 
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From luke-tierney at uiowa.edu  Thu Mar 29 17:37:26 2018
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Thu, 29 Mar 2018 10:37:26 -0500 (CDT)
Subject: [Rd] Objects not gc'ed due to caching (?) in R's S3 dispatch
 mechanism
In-Reply-To: <alpine.DEB.2.20.1803270820520.4709@luke-Latitude>
References: <CALEXWq0gGFFf-EN5tUhgJpqF_Z5=1AAV-rokCLbEUxiWg_MjqA@mail.gmail.com>
 <alpine.DEB.2.20.1803262247070.4709@luke-Latitude>
 <alpine.DEB.2.20.1803270820520.4709@luke-Latitude>
Message-ID: <alpine.DEB.2.20.1803291037170.4709@luke-Latitude>

Now also committed to the release branch.

Best,

luke

On Tue, 27 Mar 2018, luke-tierney at uiowa.edu wrote:

> I have committed a change to R-devel that addresses this. To be on the
> safe side I need to run some more extensive tests before deciding if
> this can be ported to the release branch for R 3.5.0. Should know in a
> day or two.
>
> Best,
>
> luke
>
> On Tue, 27 Mar 2018, luke-tierney at uiowa.edu wrote:
>
>> This has nothing to do with printing or dispatch per se. It is the
>> result of an internal register (R_ReturnedValue) being protected. It
>> gets rewritten whenever there is a jump, e.g. by an explicit return
>> call. So a simplified example is
>> 
>> new_foo <- function() {
>>  e <- new.env()
>>    reg.finalizer(e, function(e) message("Finalizer called"))
>>      e
>>      }
>> 
>> bar <- function(x) return(x)
>> 
>> bar(new_foo())
>> gc() # still in .Last.value
>> gc() # nothing
>> 
>> UseMethod essentially does a return call so you see the effect there.
>> 
>> The R_ReturnedValue register could probably be safely cleared in more
>> places but it isn't clear exactly where. As things stand it will be
>> cleared on the next use of a non-local transfer of control, and those
>> happen frequently enough that I'm not convinced this is worth
>> addressing, at least not at this point in the release cycle.
>> 
>> Best,
>> 
>> luke
>> 
>> On Mon, 26 Mar 2018, I?aki ?car wrote:
>> 
>>> Hi,
>>> 
>>> I initially opened an issue in the R6 repo because my issue was with
>>> an R6 object. But Winston (thanks!) further simplified my example, and
>>> it turns out that the issue (whether a feature or a bug is yet to be
>>> seen) had to do with S3 dispatching.
>>> 
>>> The following example, by Winston, depicts the issue:
>>> 
>>> print.foo <- function(x, ...) {
>>>  cat("print.foo called\n")
>>>  invisible(x)
>>> }
>>> 
>>> new_foo <- function() {
>>>  e <- new.env()
>>>  reg.finalizer(e, function(e) message("Finalizer called"))
>>>  class(e) <- "foo"
>>>  e
>>> }
>>> 
>>> new_foo()
>>> gc() # still in .Last.value
>>> gc() # nothing
>>> 
>>> I would expect that the second call to gc() should free 'e', but it's
>>> not. However, if we call now *any* S3 method, then the object can be
>>> finally gc'ed:
>>> 
>>> print(1)
>>> gc() # Finalizer called
>>> 
>>> So the hypothesis is that there is some kind of caching (?) mechanism
>>> going on. Intended behaviour or not, this is something that was
>>> introduced between R 3.2.3 and 3.3.2 (the first succeeds; from the
>>> second on, the example fails as described above).
>>> 
>>> Regards,
>>> I?aki
>>> 
>>> PS: Further discussion and examples in 
>>> https://github.com/r-lib/R6/issues/140
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> 
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu

From h.wickham at gmail.com  Thu Mar 29 23:23:51 2018
From: h.wickham at gmail.com (Hadley Wickham)
Date: Thu, 29 Mar 2018 14:23:51 -0700
Subject: [Rd] Base R examples that write to current working directory
Message-ID: <CABdHhvEDW3nCgwNAXjNcpFtJSM_d=xooX4infq6oTfmctiU3DQ@mail.gmail.com>

Hi all,

Given the recent CRAN push to prevent examples writing to the working
directory, is there any interest in fixing base R examples that write
to the working directory? A few candidates are the graphics devices,
file.create(), writeBin(), writeChar(), write(), and saveRDS(). I'm
sure there are many more.

One way to catch these naughty examples would be to search for
unlink() in examples: e.g.,
https://github.com/wch/r-source/search?utf8=?&q=unlink+extension%3ARd&type=.
Of course, simply cleaning up after yourself is not sufficient because
if those files existed before the examples were run, the examples will
destroy them.

Hadley

-- 
http://hadley.nz


From murdoch.duncan at gmail.com  Fri Mar 30 00:08:23 2018
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Thu, 29 Mar 2018 18:08:23 -0400
Subject: [Rd] Base R examples that write to current working directory
In-Reply-To: <CABdHhvEDW3nCgwNAXjNcpFtJSM_d=xooX4infq6oTfmctiU3DQ@mail.gmail.com>
References: <CABdHhvEDW3nCgwNAXjNcpFtJSM_d=xooX4infq6oTfmctiU3DQ@mail.gmail.com>
Message-ID: <697bd1b5-4c56-d9b4-55d1-bb70b12aee0c@gmail.com>

On 29/03/2018 5:23 PM, Hadley Wickham wrote:
> Hi all,
> 
> Given the recent CRAN push to prevent examples writing to the working
> directory, is there any interest in fixing base R examples that write
> to the working directory? A few candidates are the graphics devices,
> file.create(), writeBin(), writeChar(), write(), and saveRDS(). I'm
> sure there are many more.
> 
> One way to catch these naughty examples would be to search for
> unlink() in examples: e.g.,
> https://github.com/wch/r-source/search?utf8=?&q=unlink+extension%3ARd&type=.
> Of course, simply cleaning up after yourself is not sufficient because
> if those files existed before the examples were run, the examples will
> destroy them.
> 

Why not put together a patch that fixes these?  This doesn't seem to be 
something that needs discussion, fixing the bad examples would be a good 
idea.

Duncan Murdoch


From suharto_anggono at yahoo.com  Fri Mar 30 02:19:53 2018
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Fri, 30 Mar 2018 00:19:53 +0000 (UTC)
Subject: [Rd] Nice names in deparse
References: <1916981456.1251297.1522369193823.ref@mail.yahoo.com>
Message-ID: <1916981456.1251297.1522369193823@mail.yahoo.com>

I am raising this again.

As
as.character(list(c(one = "1")))
is still
"1"
in R 3.5.0 alpha, could
as.character(list(c(one = 1)))
be
"1"
, too, as before?

The case here is the list component is atomic with length 1.

--------------------------------------------
On Sat, 16/12/17, Suharto Anggono Suharto Anggono <suharto_anggono at yahoo.com> wrote:

 Subject: Nice names in deparse
 To: r-devel at r-project.org
 Date: Saturday, 16 December, 2017, 11:09 PM

Tags (argument names) in call to 'list' becomes names of the result. It is not necessarily so with call to 'c'. The default method of 'c' has 'recursive' and 'use.names' arguments.

In R devel r73778, with
x <- 0; names(x) <- "recursive"? ,
dput(x)
or even
dput(x, control = "all")
gives
c(recursive = 0)
However, actual result of c(recursive = 0) is NULL.

Also with
x <- 0; names(x) <- "recursive"? ,
dput(x, control = c("keepNA", "keepInteger", "showAttributes"))
in R devel r73778
gives
structure(c(0), .Names = "recursive")
The 'control' is suggested by an example for output as in R < 3.5.0. However, the output is slightly different from
dput(x)
in R 3.3.2:
structure(0, .Names = "recursive")


Part of NEWS item related with "niceNames" control option:
as.character(list( c (one = 1))) now includes the name, as as.character(list(list(one = 1))) has always done.

Please reconsider.
As
as.numeric(list(c(one = 1)))
gives
1 ,
I expect that
as.character(list(c(one = "1")))
gives
"1" .
It does in R devel r73778.
Why does
as.character(list(c(one = 1)))
give
"c(one = 1)" ?

as.numeric(list(c(one = "1")))
gives
1 .

list(list(one = 1))
is not quite the same.
as.numeric(list(list(one = 1)))
gives
NA .


From ligges at statistik.tu-dortmund.de  Fri Mar 30 18:25:19 2018
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Fri, 30 Mar 2018 18:25:19 +0200
Subject: [Rd] Base R examples that write to current working directory
In-Reply-To: <697bd1b5-4c56-d9b4-55d1-bb70b12aee0c@gmail.com>
References: <CABdHhvEDW3nCgwNAXjNcpFtJSM_d=xooX4infq6oTfmctiU3DQ@mail.gmail.com>
 <697bd1b5-4c56-d9b4-55d1-bb70b12aee0c@gmail.com>
Message-ID: <672879f7-c30d-59ff-fb78-2be575b49002@statistik.tu-dortmund.de>



On 30.03.2018 00:08, Duncan Murdoch wrote:
> On 29/03/2018 5:23 PM, Hadley Wickham wrote:
>> Hi all,
>>
>> Given the recent CRAN push to prevent examples writing to the working
>> directory, is there any interest in fixing base R examples that write
>> to the working directory? A few candidates are the graphics devices,
>> file.create(), writeBin(), writeChar(), write(), and saveRDS(). I'm
>> sure there are many more.
>>
>> One way to catch these naughty examples would be to search for
>> unlink() in examples: e.g.,
>> https://github.com/wch/r-source/search?utf8=?&q=unlink+extension%3ARd&type=. 
>>
>> Of course, simply cleaning up after yourself is not sufficient because
>> if those files existed before the examples were run, the examples will
>> destroy them.
>>
> 
> Why not put together a patch that fixes these?? This doesn't seem to be 
> something that needs discussion, fixing the bad examples would be a good 
> idea.

Seconded. CRAN would not accept these base packages, hence we should 
urgently give better examples.

Best,
Uwe


> Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From henrik.bengtsson at gmail.com  Fri Mar 30 19:14:04 2018
From: henrik.bengtsson at gmail.com (Henrik Bengtsson)
Date: Fri, 30 Mar 2018 10:14:04 -0700
Subject: [Rd] Base R examples that write to current working directory
In-Reply-To: <672879f7-c30d-59ff-fb78-2be575b49002@statistik.tu-dortmund.de>
References: <CABdHhvEDW3nCgwNAXjNcpFtJSM_d=xooX4infq6oTfmctiU3DQ@mail.gmail.com>
 <697bd1b5-4c56-d9b4-55d1-bb70b12aee0c@gmail.com>
 <672879f7-c30d-59ff-fb78-2be575b49002@statistik.tu-dortmund.de>
Message-ID: <CAFDcVCTu5Cz4r4LFnzBxr4pSp1rzKW8imVBH-3U2zNr2YkS3Vg@mail.gmail.com>

So, the proposal would then be to write to tempdir(), correct?  If so,
I see three alternatives:

1. explicitly use file.path(tempdir(), filename), or tempfile() everywhere.

2. wrap example code in a withTempDir({ ... }) call.

3. Add an 'eval.path' (*) argument to example() and make it default to
eval.path = tempdir(). This would probably be backward compatible and
keep the code example clean.  The downside is when a user runs an
example and can't locate produced files. (*) or 'wd', 'workdir', ...

/Henrik

On Fri, Mar 30, 2018 at 9:25 AM, Uwe Ligges
<ligges at statistik.tu-dortmund.de> wrote:
>
>
> On 30.03.2018 00:08, Duncan Murdoch wrote:
>>
>> On 29/03/2018 5:23 PM, Hadley Wickham wrote:
>>>
>>> Hi all,
>>>
>>> Given the recent CRAN push to prevent examples writing to the working
>>> directory, is there any interest in fixing base R examples that write
>>> to the working directory? A few candidates are the graphics devices,
>>> file.create(), writeBin(), writeChar(), write(), and saveRDS(). I'm
>>> sure there are many more.
>>>
>>> One way to catch these naughty examples would be to search for
>>> unlink() in examples: e.g.,
>>>
>>> https://github.com/wch/r-source/search?utf8=?&q=unlink+extension%3ARd&type=.
>>> Of course, simply cleaning up after yourself is not sufficient because
>>> if those files existed before the examples were run, the examples will
>>> destroy them.
>>>
>>
>> Why not put together a patch that fixes these?  This doesn't seem to be
>> something that needs discussion, fixing the bad examples would be a good
>> idea.
>
>
> Seconded. CRAN would not accept these base packages, hence we should
> urgently give better examples.
>
> Best,
> Uwe
>
>
>
>> Duncan Murdoch
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


