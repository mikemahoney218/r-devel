From peter.meilstrup at gmail.com  Tue Oct  1 14:50:29 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Tue, 1 Oct 2013 05:50:29 -0700
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <CAO1zAVYh3HTSYdFW4zxBbh8ZbdSLA73utxR0k3NrxKt06xf0EQ@mail.gmail.com>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<1380552319.10008.20.camel@milan>
	<CAO1zAVYh3HTSYdFW4zxBbh8ZbdSLA73utxR0k3NrxKt06xf0EQ@mail.gmail.com>
Message-ID: <CAJoaRhZcuJ-5PJr_k760NzQUkWVWVri4490H+oPb_6=Rd6Kapw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131001/4cda6a80/attachment.pl>

From peter.meilstrup at gmail.com  Tue Oct  1 15:25:57 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Tue, 1 Oct 2013 06:25:57 -0700
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <CAJoaRhZcuJ-5PJr_k760NzQUkWVWVri4490H+oPb_6=Rd6Kapw@mail.gmail.com>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<1380552319.10008.20.camel@milan>
	<CAO1zAVYh3HTSYdFW4zxBbh8ZbdSLA73utxR0k3NrxKt06xf0EQ@mail.gmail.com>
	<CAJoaRhZcuJ-5PJr_k760NzQUkWVWVri4490H+oPb_6=Rd6Kapw@mail.gmail.com>
Message-ID: <CAJoaRhb+6k-Miz69AZxq1GUvmC1TUBoDkNXOSRaaWEaJxVyMJg@mail.gmail.com>

On Tue, Oct 1, 2013 at 5:50 AM, Peter Meilstrup
<peter.meilstrup at gmail.com> wrote:
>
> On Mon, Sep 30, 2013 at 8:10 AM, Joris Meys <jorismeys at gmail.com> wrote:
>>
>> Regardless of whether "stored as character" is interpreted the R way or the
>> ASCII way, the point Joshua makes is rather valid. Mainly because
>> read.table has an argument quote with default value \"'. This means that at
>> least according to R, everything between either " or ' should be seen as of
>> type character and not integer.
>>
>> The only way these quotes can end up in a .csv file, is when in the
>> rendering program (often Excel), these integers are called "character"
>> inside the program as well. So they're not treated as integers by the
>> person that created the file, so R won't treat them
>> as integers either. Note that read.table does read the quoted integers as
>> characters, and only afterwards convert those.
>>
>> So yes, this is an issue with read.table.ffdf more than with R itself. And
>> the problem is indeed how integers are treated *the moment they are stored*.
>> This refering to the presence/absence of the quote character.
>
>
> This assumes too much about the program that creates the file.
>
> Quoted numeric values may be necessary in non-American locales which use the comma as decimal separator. (CSV files written in these locales often use something other than the comma for the field separator, but this is not required.)
>

Additionally, while CSV is a somewhat nebulous format, most attempts
at specifying it are clear that a quoted value, containing no special
characters, is to be treated _identically_ to the unquoted version.
The reason for the quote is to escape special characters which may be
present, not to impart type information. A CSV producing program may
simplify the logic of writing a file by always quoting, whether or not
the field would contain special characters when rendered.

http://www.creativyst.com/Doc/Articles/CSV/CSV01.htm -- "When
importing CSV, do not reach down a layer and try to use the quotes to
impart type information to fields."

Peter


From dwinsemius at comcast.net  Tue Oct  1 18:29:07 2013
From: dwinsemius at comcast.net (David Winsemius)
Date: Tue, 1 Oct 2013 09:29:07 -0700
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
Message-ID: <F677287B-2406-46BB-9108-34D588B330EA@comcast.net>


On Sep 30, 2013, at 6:38 AM, Joshua Ulrich wrote:

> On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
>> Hi!
>> 
>> 
>> It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
>> quoted integers as an acceptable value for columns for which
>> colClasses="integer". But when colClasses is omitted, these columns are
>> read as integer anyway.
>> 
>> For example, let's consider a file named file.dat, containing:
>> "1"
>> "2"
>> 
>>> read.table("file.dat", colClasses="integer")
>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :
>>  scan() expected 'an integer' and got '"1"'
>> 
>> But:
>>> str(read.table("file.dat"))
>> 'data.frame':   2 obs. of  1 variable:
>> $ V1: int  1 2
>> 
>> The latter result is indeed documented in ?read.table:
>>     Unless ?colClasses? is specified, all columns are read as
>>     character columns and then converted using ?type.convert? to
>>     logical, integer, numeric, complex or (depending on ?as.is?)
>>     factor as appropriate.  Quotes are (by default) interpreted in all
>>     fields, so a column of values like ?"42"? will result in an
>>     integer column.
>> 
>> 
>> Should the former behavior be considered a bug?
>> 
> No. If you tell read.table the column is integer and it's actually
> character on disk, it should be an error.

My reading of the `read.table` help page is that one should expect that when there is an 'integer'-class and an  `as.integer` function and  "integer" is the argument to colClasses, that `as.integer` will be applied to the values in the column. Should I be reading elsewhere?

-- 
David.

> 
>> This creates problems when combined with read.table.ffdf from package
>> ff, since this function tries to guess the column classes by reading the
>> first rows of the file, and then passes colClasses to read.table to read
>> the remaining rows by chunks. A column of quoted integers is correctly
>> detected as integer in the first read, but read.table() fails in
>> subsequent reads.
>> 
> This sounds like a issue with read.table.ffdf.  The column of quoted
> integers is *incorrectly* detected as integer because they're actually
> character on disk.  read.table.ffdf should rely on how the data are
> actually stored on disk (via as.is=TRUE), not how read.table might
> convert them once they're read into R.
> 
>> 
>> Regards
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

David Winsemius
Alameda, CA, USA


From suharto_anggono at yahoo.com  Wed Oct  2 09:49:24 2013
From: suharto_anggono at yahoo.com (Suharto Anggono Suharto Anggono)
Date: Wed, 2 Oct 2013 00:49:24 -0700 (PDT)
Subject: [Rd] For numeric x, as.character(x) doesn't always match signif(x,
	15)
Message-ID: <1380700164.65582.YahooMailBasic@web125106.mail.ne1.yahoo.com>

I saw something like this.

> x <- 5180000000000003
> print(x, digits=20)
[1] 5180000000000003
> as.character(x)
[1] "5.18e+15"

I thought it was because, when x is numeric, as.character(x) represents x rounded to 15 significant digits.

> print(signif(x, 15), digits=20)
[1] 5180000000000000.0000
> as.numeric(as.character(x)) == signif(x, 15)
[1] TRUE

The documentation for 'as.character' in R states this in "Details" section.

     'as.character' represents real and complex numbers to 15
     significant digits (technically the compiler's setting of the ISO
     C constant 'DBL_DIG', which will be 15 on machines supporting
     IEC60559 arithmetic according to the C99 standard).  This ensures
     that all the digits in the result will be reliable (and not the
     result of representation error), but does mean that conversion to
     character and back to numeric may change the number.  If you want
     to convert numbers to character with the maximum possible
     precision, use 'format'.

But then, I was surprised when I also saw this, where as.character(x) didn't match signif(x, 15).

> x <- 1234567890123456
> print(x, digits=20)
[1] 1234567890123456
> as.character(x)
[1] "1234567890123456"
> print(signif(x, 15), digits=20)
[1] 1234567890123460
> as.numeric(as.character(x)) == signif(x, 15)
[1] FALSE

Then, I found another example of this behavior in https://stat.ethz.ch/pipermail/r-devel/2009-May/053341.html.

It seems that, for numeric, the result of 'as.character' equals format(., digits=15) applied to each element individually. Is it always the case?

> format(5180000000000003, digits=15)
[1] "5.18e+15"
> format(1234567890123456, digits=15)
[1] "1234567890123456"

I assume that format(x, digits=15) behaves like print(x, digits=15).

> print(5180000000000003, digits=15)
[1] 5.18e+15
> print(1234567890123456, digits=15)
[1] 1234567890123456

The result of
print(1234567890123456, digits=15)
violates the part
"at least one entry will be encoded with that minimum number"
in "Details" section in the documentation for 'print.default'.

     The same number of decimal places is used throughout a vector.
     This means that 'digits' specifies the minimum number of
     significant digits to be used, and that at least one entry will be
     encoded with that minimum number.

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] tools_3.0.2


From murdoch.duncan at gmail.com  Wed Oct  2 16:50:55 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 02 Oct 2013 10:50:55 -0400
Subject: [Rd] C++ debugging help needed
Message-ID: <524C32CF.2060307@gmail.com>

I've had reports lately about segfaults in the rgl package.  I've only 
been able to reproduce these on Linux.   I am not so familiar with C++ 
details, so I have a couple of questions way down below. But first some 
background info.

  One recipe to recreate the crash works with a new version 5.0-1 of the 
mixOmics package:

 > library(mixOmics)
 > example(pca)

This crashes with messages like this:

Program received signal SIGSEGV, Segmentation fault.
0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
     __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
48        { return __atomic_fetch_add(__mem, __val, __ATOMIC_ACQ_REL); }

The call stack ends with this:

#0  0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
     __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
#1  __exchange_and_add_dispatch (__mem=0x7f7fffff7f7ffff7,
     __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:81
#2  _M_dispose (__a=..., this=0x7f7fffff7f7fffe7)
     at /usr/include/c++/4.7/bits/basic_string.h:242
#3  ~basic_string (this=0x15f8770, __in_chrg=<optimized out>)
     at /usr/include/c++/4.7/bits/basic_string.h:536
#4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at 
Shape.cpp:13
#5  0x00007ffff22df50b in ~Background (this=0x15f8760,
     __in_chrg=<optimized out>) at Background.hpp:15
#6  Background::~Background (this=0x15f8760, __in_chrg=<optimized out>)
     at Background.hpp:15

Up to entry #4 this all looks normal.  If I go into that stack frame, I 
see this:


(gdb) up
#4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at 
Shape.cpp:13
warning: Source file is more recent than executable.
13        blended(in_material.isTransparent())
(gdb) p this
$9 = (Shape * const) 0x15f8760
(gdb) p *this
$10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
     static npos = <optimized out>,
     _M_dataplus = {<std::allocator<char>> = 
{<__gnu_cxx::new_allocator<char>> =
{<No data fields>}, <No data fields>},
       _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of 
bounds>}},
   mShapeColor = {mRed = -1.4044474254567505e+306,
     mGreen = -1.4044477603031902e+306, mBlue = 4.24399170841135e-314,
     mTransparent = 0}, mSpecularReflectivity = 0.0078125,
   mSpecularSize = 1065353216, mDiffuseReflectivity = 0.007812501848093234,
   mAmbientReflectivity = 0}

The things displayed in *this are all wrong.  Those field names come 
from the Shape object in the igraph package, not the Shape object in the 
rgl package.   The mixOmics package uses both.

My questions:

- Has my code somehow got mixed up with the igraph code, so I really do 
have a call out to igraph's Shape::~Shape instead of rgl's 
Shape::~Shape, or is this just bad info being given to me by gdb?

- If I really do have calls to the wrong destructor in there, how do I 
avoid this?

Duncan Murdoch


From murdoch.duncan at gmail.com  Wed Oct  2 17:05:19 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 02 Oct 2013 11:05:19 -0400
Subject: [Rd] C++ debugging help needed
In-Reply-To: <524C32CF.2060307@gmail.com>
References: <524C32CF.2060307@gmail.com>
Message-ID: <524C362F.1040108@gmail.com>

A quick addition:

If I add

#define Shape rglShape

near the top of my Shape.hpp header file, the bug goes away.  But I 
can't believe that would be necessary.  These are in separate packages, 
don't they have separate namespaces in C++?  How can I avoid clashes 
with types declared in other packages in the future?

Duncan Murdoch

On 02/10/2013 10:50 AM, Duncan Murdoch wrote:
> I've had reports lately about segfaults in the rgl package.  I've only
> been able to reproduce these on Linux.   I am not so familiar with C++
> details, so I have a couple of questions way down below. But first some
> background info.
>
>    One recipe to recreate the crash works with a new version 5.0-1 of the
> mixOmics package:
>
>   > library(mixOmics)
>   > example(pca)
>
> This crashes with messages like this:
>
> Program received signal SIGSEGV, Segmentation fault.
> 0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
>       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
> 48        { return __atomic_fetch_add(__mem, __val, __ATOMIC_ACQ_REL); }
>
> The call stack ends with this:
>
> #0  0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
>       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
> #1  __exchange_and_add_dispatch (__mem=0x7f7fffff7f7ffff7,
>       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:81
> #2  _M_dispose (__a=..., this=0x7f7fffff7f7fffe7)
>       at /usr/include/c++/4.7/bits/basic_string.h:242
> #3  ~basic_string (this=0x15f8770, __in_chrg=<optimized out>)
>       at /usr/include/c++/4.7/bits/basic_string.h:536
> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> Shape.cpp:13
> #5  0x00007ffff22df50b in ~Background (this=0x15f8760,
>       __in_chrg=<optimized out>) at Background.hpp:15
> #6  Background::~Background (this=0x15f8760, __in_chrg=<optimized out>)
>       at Background.hpp:15
>
> Up to entry #4 this all looks normal.  If I go into that stack frame, I
> see this:
>
>
> (gdb) up
> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> Shape.cpp:13
> warning: Source file is more recent than executable.
> 13        blended(in_material.isTransparent())
> (gdb) p this
> $9 = (Shape * const) 0x15f8760
> (gdb) p *this
> $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
>       static npos = <optimized out>,
>       _M_dataplus = {<std::allocator<char>> =
> {<__gnu_cxx::new_allocator<char>> =
> {<No data fields>}, <No data fields>},
>         _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
> bounds>}},
>     mShapeColor = {mRed = -1.4044474254567505e+306,
>       mGreen = -1.4044477603031902e+306, mBlue = 4.24399170841135e-314,
>       mTransparent = 0}, mSpecularReflectivity = 0.0078125,
>     mSpecularSize = 1065353216, mDiffuseReflectivity = 0.007812501848093234,
>     mAmbientReflectivity = 0}
>
> The things displayed in *this are all wrong.  Those field names come
> from the Shape object in the igraph package, not the Shape object in the
> rgl package.   The mixOmics package uses both.
>
> My questions:
>
> - Has my code somehow got mixed up with the igraph code, so I really do
> have a call out to igraph's Shape::~Shape instead of rgl's
> Shape::~Shape, or is this just bad info being given to me by gdb?
>
> - If I really do have calls to the wrong destructor in there, how do I
> avoid this?
>
> Duncan Murdoch


From romain at r-enthusiasts.com  Wed Oct  2 17:36:50 2013
From: romain at r-enthusiasts.com (Romain Francois)
Date: Wed, 02 Oct 2013 17:36:50 +0200
Subject: [Rd] C++ debugging help needed
In-Reply-To: <524C362F.1040108@gmail.com>
References: <524C32CF.2060307@gmail.com> <524C362F.1040108@gmail.com>
Message-ID: <524C3D92.2010900@r-enthusiasts.com>

Le 02/10/13 17:05, Duncan Murdoch a ?crit :
> A quick addition:
>
> If I add
>
> #define Shape rglShape
>
> near the top of my Shape.hpp header file, the bug goes away.  But I
> can't believe that would be necessary.  These are in separate packages,
> don't they have separate namespaces in C++?  How can I avoid clashes
> with types declared in other packages in the future?
>
> Duncan Murdoch

That is weird indeed and should not happen. But I don't know much 
linkers ...

I'd advise to scope code in some rgl namespace. At the moment (reading 
the code on r-forge) it's all in the global namespace.

This might be more involved than the macro trick you used above but this 
will be safer. It would have been more problematic if other packages 
needed to compile code against rgl headers, but apparently that is not 
what happens (you don't have inst/include and I don't see 
R_RegisterCCallable either) ...

Romain

> On 02/10/2013 10:50 AM, Duncan Murdoch wrote:
>> I've had reports lately about segfaults in the rgl package.  I've only
>> been able to reproduce these on Linux.   I am not so familiar with C++
>> details, so I have a couple of questions way down below. But first some
>> background info.
>>
>>    One recipe to recreate the crash works with a new version 5.0-1 of the
>> mixOmics package:
>>
>>   > library(mixOmics)
>>   > example(pca)
>>
>> This crashes with messages like this:
>>
>> Program received signal SIGSEGV, Segmentation fault.
>> 0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
>>       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
>> 48        { return __atomic_fetch_add(__mem, __val, __ATOMIC_ACQ_REL); }
>>
>> The call stack ends with this:
>>
>> #0  0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
>>       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
>> #1  __exchange_and_add_dispatch (__mem=0x7f7fffff7f7ffff7,
>>       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:81
>> #2  _M_dispose (__a=..., this=0x7f7fffff7f7fffe7)
>>       at /usr/include/c++/4.7/bits/basic_string.h:242
>> #3  ~basic_string (this=0x15f8770, __in_chrg=<optimized out>)
>>       at /usr/include/c++/4.7/bits/basic_string.h:536
>> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
>> Shape.cpp:13
>> #5  0x00007ffff22df50b in ~Background (this=0x15f8760,
>>       __in_chrg=<optimized out>) at Background.hpp:15
>> #6  Background::~Background (this=0x15f8760, __in_chrg=<optimized out>)
>>       at Background.hpp:15
>>
>> Up to entry #4 this all looks normal.  If I go into that stack frame, I
>> see this:
>>
>>
>> (gdb) up
>> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
>> Shape.cpp:13
>> warning: Source file is more recent than executable.
>> 13        blended(in_material.isTransparent())
>> (gdb) p this
>> $9 = (Shape * const) 0x15f8760
>> (gdb) p *this
>> $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
>>       static npos = <optimized out>,
>>       _M_dataplus = {<std::allocator<char>> =
>> {<__gnu_cxx::new_allocator<char>> =
>> {<No data fields>}, <No data fields>},
>>         _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
>> bounds>}},
>>     mShapeColor = {mRed = -1.4044474254567505e+306,
>>       mGreen = -1.4044477603031902e+306, mBlue = 4.24399170841135e-314,
>>       mTransparent = 0}, mSpecularReflectivity = 0.0078125,
>>     mSpecularSize = 1065353216, mDiffuseReflectivity =
>> 0.007812501848093234,
>>     mAmbientReflectivity = 0}
>>
>> The things displayed in *this are all wrong.  Those field names come
>> from the Shape object in the igraph package, not the Shape object in the
>> rgl package.   The mixOmics package uses both.
>>
>> My questions:
>>
>> - Has my code somehow got mixed up with the igraph code, so I really do
>> have a call out to igraph's Shape::~Shape instead of rgl's
>> Shape::~Shape, or is this just bad info being given to me by gdb?
>>
>> - If I really do have calls to the wrong destructor in there, how do I
>> avoid this?
>>
>> Duncan Murdoch

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30


From plummerm at iarc.fr  Wed Oct  2 17:45:46 2013
From: plummerm at iarc.fr (Martyn Plummer)
Date: Wed, 2 Oct 2013 15:45:46 +0000
Subject: [Rd] C++ debugging help needed
In-Reply-To: <524C362F.1040108@gmail.com>
References: <524C32CF.2060307@gmail.com> <524C362F.1040108@gmail.com>
Message-ID: <1380728746.1581.6.camel@braque.iarc.fr>

In C++, everything goes in the global namespace unless the programmer
explicitly creates one. So when you dynamically load two dynamic shared
libraries with a "Shape" object they clash.

The solution here is to put 

namespace rgl {
...
}

around your class definitions in the rglm package, and 

using rgl::Shape

at the top of any source file that refers to rgl Shape. Likewise, the
igraph package should declare shape in the "igraph" namespace.

Martyn

On Wed, 2013-10-02 at 11:05 -0400, Duncan Murdoch wrote:
> A quick addition:
> 
> If I add
> 
> #define Shape rglShape
> 
> near the top of my Shape.hpp header file, the bug goes away.  But I 
> can't believe that would be necessary.  These are in separate packages, 
> don't they have separate namespaces in C++?  How can I avoid clashes 
> with types declared in other packages in the future?
> 
> Duncan Murdoch
> 
> On 02/10/2013 10:50 AM, Duncan Murdoch wrote:
> > I've had reports lately about segfaults in the rgl package.  I've only
> > been able to reproduce these on Linux.   I am not so familiar with C++
> > details, so I have a couple of questions way down below. But first some
> > background info.
> >
> >    One recipe to recreate the crash works with a new version 5.0-1 of the
> > mixOmics package:
> >
> >   > library(mixOmics)
> >   > example(pca)
> >
> > This crashes with messages like this:
> >
> > Program received signal SIGSEGV, Segmentation fault.
> > 0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
> >       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
> > 48        { return __atomic_fetch_add(__mem, __val, __ATOMIC_ACQ_REL); }
> >
> > The call stack ends with this:
> >
> > #0  0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
> >       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
> > #1  __exchange_and_add_dispatch (__mem=0x7f7fffff7f7ffff7,
> >       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:81
> > #2  _M_dispose (__a=..., this=0x7f7fffff7f7fffe7)
> >       at /usr/include/c++/4.7/bits/basic_string.h:242
> > #3  ~basic_string (this=0x15f8770, __in_chrg=<optimized out>)
> >       at /usr/include/c++/4.7/bits/basic_string.h:536
> > #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> > Shape.cpp:13
> > #5  0x00007ffff22df50b in ~Background (this=0x15f8760,
> >       __in_chrg=<optimized out>) at Background.hpp:15
> > #6  Background::~Background (this=0x15f8760, __in_chrg=<optimized out>)
> >       at Background.hpp:15
> >
> > Up to entry #4 this all looks normal.  If I go into that stack frame, I
> > see this:
> >
> >
> > (gdb) up
> > #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> > Shape.cpp:13
> > warning: Source file is more recent than executable.
> > 13        blended(in_material.isTransparent())
> > (gdb) p this
> > $9 = (Shape * const) 0x15f8760
> > (gdb) p *this
> > $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
> >       static npos = <optimized out>,
> >       _M_dataplus = {<std::allocator<char>> =
> > {<__gnu_cxx::new_allocator<char>> =
> > {<No data fields>}, <No data fields>},
> >         _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
> > bounds>}},
> >     mShapeColor = {mRed = -1.4044474254567505e+306,
> >       mGreen = -1.4044477603031902e+306, mBlue = 4.24399170841135e-314,
> >       mTransparent = 0}, mSpecularReflectivity = 0.0078125,
> >     mSpecularSize = 1065353216, mDiffuseReflectivity = 0.007812501848093234,
> >     mAmbientReflectivity = 0}
> >
> > The things displayed in *this are all wrong.  Those field names come
> > from the Shape object in the igraph package, not the Shape object in the
> > rgl package.   The mixOmics package uses both.
> >
> > My questions:
> >
> > - Has my code somehow got mixed up with the igraph code, so I really do
> > have a call out to igraph's Shape::~Shape instead of rgl's
> > Shape::~Shape, or is this just bad info being given to me by gdb?
> >
> > - If I really do have calls to the wrong destructor in there, how do I
> > avoid this?
> >
> > Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From edd at debian.org  Wed Oct  2 17:52:22 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 2 Oct 2013 10:52:22 -0500
Subject: [Rd] C++ debugging help needed
In-Reply-To: <1380728746.1581.6.camel@braque.iarc.fr>
References: <524C32CF.2060307@gmail.com> <524C362F.1040108@gmail.com>
	<1380728746.1581.6.camel@braque.iarc.fr>
Message-ID: <21068.16694.347218.948671@max.nulle.part>


On 2 October 2013 at 15:45, Martyn Plummer wrote:
| In C++, everything goes in the global namespace unless the programmer
| explicitly creates one. So when you dynamically load two dynamic shared
| libraries with a "Shape" object they clash.
| 
| The solution here is to put 
| 
| namespace rgl {
| ...
| }
| 
| around your class definitions in the rglm package, and 
| 
| using rgl::Shape

Exactly.
 
| at the top of any source file that refers to rgl Shape. Likewise, the
| igraph package should declare shape in the "igraph" namespace.

And as I wrote to Duncan off-list, igraph doesn't, even though it otherwise
uses an igraph namespace:

   /** Shape.h
    */
   
   #ifndef SHAPE_H
   #define SHAPE_H
   
   #include <string>
   #include "Color.h"
   #include "Ray.h"
   #include "Point.h"
   
   class Shape
   [....]   

So the clash is due to two packages simulatenously failing to make use of
namespaces.  

And at that point the linker appears to pick in search (link ?) order.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From murdoch.duncan at gmail.com  Wed Oct  2 19:45:39 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 02 Oct 2013 13:45:39 -0400
Subject: [Rd] C++ debugging help needed
In-Reply-To: <21068.16694.347218.948671@max.nulle.part>
References: <524C32CF.2060307@gmail.com> <524C362F.1040108@gmail.com>
	<1380728746.1581.6.camel@braque.iarc.fr>
	<21068.16694.347218.948671@max.nulle.part>
Message-ID: <524C5BC3.1060204@gmail.com>

Thanks Dirk, Martyn and Romain.  I'm planning to do a temporary 
workaround release with the Shape class renamed to rglShape, but over 
the longer term I'll put everything that's supposed to be local inside 
an rgl namespace.  First I need to learn how namespaces interact with 
extern "C" declarations; pointers to any readable tutorials would be 
appreciated.

Duncan Murdoch

On 02/10/2013 11:52 AM, Dirk Eddelbuettel wrote:
> On 2 October 2013 at 15:45, Martyn Plummer wrote:
> | In C++, everything goes in the global namespace unless the programmer
> | explicitly creates one. So when you dynamically load two dynamic shared
> | libraries with a "Shape" object they clash.
> |
> | The solution here is to put
> |
> | namespace rgl {
> | ...
> | }
> |
> | around your class definitions in the rglm package, and
> |
> | using rgl::Shape
>
> Exactly.
>   
> | at the top of any source file that refers to rgl Shape. Likewise, the
> | igraph package should declare shape in the "igraph" namespace.
>
> And as I wrote to Duncan off-list, igraph doesn't, even though it otherwise
> uses an igraph namespace:
>
>     /** Shape.h
>      */
>     
>     #ifndef SHAPE_H
>     #define SHAPE_H
>     
>     #include <string>
>     #include "Color.h"
>     #include "Ray.h"
>     #include "Point.h"
>     
>     class Shape
>     [....]
>
> So the clash is due to two packages simulatenously failing to make use of
> namespaces.
>
> And at that point the linker appears to pick in search (link ?) order.
>
> Dirk
>


From romain at r-enthusiasts.com  Wed Oct  2 20:01:24 2013
From: romain at r-enthusiasts.com (Romain Francois)
Date: Wed, 02 Oct 2013 20:01:24 +0200
Subject: [Rd] C++ debugging help needed
In-Reply-To: <524C5BC3.1060204@gmail.com>
References: <524C32CF.2060307@gmail.com> <524C362F.1040108@gmail.com>
	<1380728746.1581.6.camel@braque.iarc.fr>
	<21068.16694.347218.948671@max.nulle.part>
	<524C5BC3.1060204@gmail.com>
Message-ID: <524C5F74.6080603@r-enthusiasts.com>

Duncan,

extern "C" just means that the function(s) below it have C calling 
conventions, so that .Call, .External, ... can find them. Without this, 
your function names would be c++ mangled to disambiguate different 
overloads.

What is inside can use namespace without any issue. You'd have something 
like:

extern "C" SEXP dot_call_function(){
     rgl::Whatever object(1, 2 ) ;
     object.do_something() ;
     return R_NilValue ;
}

IIRC, if you register your functions (see WRE #5.4), you don't need 
those extern "C" because you directly give the function pointer so you 
don't have to search for it with its name.

Romain

Le 02/10/13 19:45, Duncan Murdoch a ?crit :
> Thanks Dirk, Martyn and Romain.  I'm planning to do a temporary
> workaround release with the Shape class renamed to rglShape, but over
> the longer term I'll put everything that's supposed to be local inside
> an rgl namespace.  First I need to learn how namespaces interact with
> extern "C" declarations; pointers to any readable tutorials would be
> appreciated.
>
> Duncan Murdoch
>
> On 02/10/2013 11:52 AM, Dirk Eddelbuettel wrote:
>> On 2 October 2013 at 15:45, Martyn Plummer wrote:
>> | In C++, everything goes in the global namespace unless the programmer
>> | explicitly creates one. So when you dynamically load two dynamic shared
>> | libraries with a "Shape" object they clash.
>> |
>> | The solution here is to put
>> |
>> | namespace rgl {
>> | ...
>> | }
>> |
>> | around your class definitions in the rglm package, and
>> |
>> | using rgl::Shape
>>
>> Exactly.
>> | at the top of any source file that refers to rgl Shape. Likewise, the
>> | igraph package should declare shape in the "igraph" namespace.
>>
>> And as I wrote to Duncan off-list, igraph doesn't, even though it
>> otherwise
>> uses an igraph namespace:
>>
>>     /** Shape.h
>>      */
>>     #ifndef SHAPE_H
>>     #define SHAPE_H
>>     #include <string>
>>     #include "Color.h"
>>     #include "Ray.h"
>>     #include "Point.h"
>>     class Shape
>>     [....]
>>
>> So the clash is due to two packages simulatenously failing to make use of
>> namespaces.
>>
>> And at that point the linker appears to pick in search (link ?) order.
>>
>> Dirk

-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30


From ross at biostat.ucsf.edu  Wed Oct  2 22:01:18 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 2 Oct 2013 13:01:18 -0700
Subject: [Rd] C++ debugging help needed
In-Reply-To: <524C362F.1040108@gmail.com>
References: <524C32CF.2060307@gmail.com> <524C362F.1040108@gmail.com>
Message-ID: <20131002200118.GX32066@markov.biostat.ucsf.edu>

On Wed, Oct 02, 2013 at 11:05:19AM -0400, Duncan Murdoch wrote:
....
>> Up to entry #4 this all looks normal.  If I go into that stack frame, I
>> see this:
>>
>>
>> (gdb) up
>> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
>> Shape.cpp:13
>> warning: Source file is more recent than executable.

That warning looks suspicious.  Are your sure gdb is finding the right
source files, and that the object code has been built from them?

>> 13        blended(in_material.isTransparent())
>> (gdb) p this
>> $9 = (Shape * const) 0x15f8760
>> (gdb) p *this
>> $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
>>       static npos = <optimized out>,
>>       _M_dataplus = {<std::allocator<char>> =
>> {<__gnu_cxx::new_allocator<char>> =
>> {<No data fields>}, <No data fields>},
>>         _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
>> bounds>}},
>>     mShapeColor = {mRed = -1.4044474254567505e+306,
>>       mGreen = -1.4044477603031902e+306, mBlue = 4.24399170841135e-314,
>>       mTransparent = 0}, mSpecularReflectivity = 0.0078125,
>>     mSpecularSize = 1065353216, mDiffuseReflectivity = 0.007812501848093234,
>>     mAmbientReflectivity = 0}
>>
>> The things displayed in *this are all wrong.  Those field names come
>> from the Shape object in the igraph package, not the Shape object in the
>> rgl package.   The mixOmics package uses both.
>>
>> My questions:
>>
>> - Has my code somehow got mixed up with the igraph code, so I really do
>> have a call out to igraph's Shape::~Shape instead of rgl's
>> Shape::~Shape, or is this just bad info being given to me by gdb?
>>

I don't know, but I think it's possible to give fully qualified type
names to gdb to force it to use the right definition.  That's assuming
that both Shape's are in different namespaces.  If they aren't, that's
likely the problem.

>> - If I really do have calls to the wrong destructor in there, how do I
>> avoid this?

Are you invoking the destructor explicitly?  An object should know
it's type, which should result in the right call without much effort.

>>
>> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Wed Oct  2 22:15:56 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 02 Oct 2013 16:15:56 -0400
Subject: [Rd] C++ debugging help needed
In-Reply-To: <20131002200118.GX32066@markov.biostat.ucsf.edu>
References: <524C32CF.2060307@gmail.com> <524C362F.1040108@gmail.com>
	<20131002200118.GX32066@markov.biostat.ucsf.edu>
Message-ID: <524C7EFC.5030605@gmail.com>

On 02/10/2013 4:01 PM, Ross Boylan wrote:
> On Wed, Oct 02, 2013 at 11:05:19AM -0400, Duncan Murdoch wrote:
> ....
> >> Up to entry #4 this all looks normal.  If I go into that stack frame, I
> >> see this:
> >>
> >>
> >> (gdb) up
> >> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> >> Shape.cpp:13
> >> warning: Source file is more recent than executable.
>
> That warning looks suspicious.  Are your sure gdb is finding the right
> source files, and that the object code has been built from them?

I'm pretty sure that's a warning about the fact that igraph also has a 
file called Shape.cpp, and the Shape::~Shape destructor was in that 
file, not in my Shape.cpp file.
>
> >> 13        blended(in_material.isTransparent())
> >> (gdb) p this
> >> $9 = (Shape * const) 0x15f8760
> >> (gdb) p *this
> >> $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
> >>       static npos = <optimized out>,
> >>       _M_dataplus = {<std::allocator<char>> =
> >> {<__gnu_cxx::new_allocator<char>> =
> >> {<No data fields>}, <No data fields>},
> >>         _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
> >> bounds>}},
> >>     mShapeColor = {mRed = -1.4044474254567505e+306,
> >>       mGreen = -1.4044477603031902e+306, mBlue = 4.24399170841135e-314,
> >>       mTransparent = 0}, mSpecularReflectivity = 0.0078125,
> >>     mSpecularSize = 1065353216, mDiffuseReflectivity = 0.007812501848093234,
> >>     mAmbientReflectivity = 0}
> >>
> >> The things displayed in *this are all wrong.  Those field names come
> >> from the Shape object in the igraph package, not the Shape object in the
> >> rgl package.   The mixOmics package uses both.
> >>
> >> My questions:
> >>
> >> - Has my code somehow got mixed up with the igraph code, so I really do
> >> have a call out to igraph's Shape::~Shape instead of rgl's
> >> Shape::~Shape, or is this just bad info being given to me by gdb?
> >>
>
> I don't know, but I think it's possible to give fully qualified type
> names to gdb to force it to use the right definition.  That's assuming
> that both Shape's are in different namespaces.  If they aren't, that's
> likely the problem.

Apparently they aren't, even though they are in separately compiled and 
linked packages.  I had been assuming that the fact that rgl knows 
nothing about igraph meant I didn't need to worry about it. (igraph does 
list rgl in its "Suggests" list.)  On platforms other than Linux, I 
don't appear to need to worry about it, but Linux happily loads one, 
then loads the other and links the call to the wrong .so rather than the 
local one, without a peep of warning, just an eventual crash.

Supposing I finish my editing of the 100 or so source files and put all 
of the rgl stuff in an "rgl" namespace, that still doesn't protect me 
from what some other developer might do next week, creating their own 
"rgl" namespace with a clashing name.   Why doesn't the linking step 
resolve the calls, why does it leave it until load time?


>> - If I really do have calls to the wrong destructor in there, how do I
>> avoid this?

Are you invoking the destructor explicitly?  An object should know
it's type, which should result in the right call without much effort.


No, this is an implicit destructor call.  I'm deleting an object whose 
class descends from Shape.

Duncan Murdoch


From romain at r-enthusiasts.com  Wed Oct  2 22:26:15 2013
From: romain at r-enthusiasts.com (Romain Francois)
Date: Wed, 02 Oct 2013 22:26:15 +0200
Subject: [Rd] C++ debugging help needed
In-Reply-To: <524C7EFC.5030605@gmail.com>
References: <524C32CF.2060307@gmail.com> <524C362F.1040108@gmail.com>
	<20131002200118.GX32066@markov.biostat.ucsf.edu>
	<524C7EFC.5030605@gmail.com>
Message-ID: <524C8167.7070809@r-enthusiasts.com>

Le 02/10/13 22:15, Duncan Murdoch a ?crit :
> On 02/10/2013 4:01 PM, Ross Boylan wrote:
>> On Wed, Oct 02, 2013 at 11:05:19AM -0400, Duncan Murdoch wrote:
>> ....
>> >> Up to entry #4 this all looks normal.  If I go into that stack
>> frame, I
>> >> see this:
>> >>
>> >>
>> >> (gdb) up
>> >> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
>> >> Shape.cpp:13
>> >> warning: Source file is more recent than executable.
>>
>> That warning looks suspicious.  Are your sure gdb is finding the right
>> source files, and that the object code has been built from them?
>
> I'm pretty sure that's a warning about the fact that igraph also has a
> file called Shape.cpp, and the Shape::~Shape destructor was in that
> file, not in my Shape.cpp file.
>>
>> >> 13        blended(in_material.isTransparent())
>> >> (gdb) p this
>> >> $9 = (Shape * const) 0x15f8760
>> >> (gdb) p *this
>> >> $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
>> >>       static npos = <optimized out>,
>> >>       _M_dataplus = {<std::allocator<char>> =
>> >> {<__gnu_cxx::new_allocator<char>> =
>> >> {<No data fields>}, <No data fields>},
>> >>         _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
>> >> bounds>}},
>> >>     mShapeColor = {mRed = -1.4044474254567505e+306,
>> >>       mGreen = -1.4044477603031902e+306, mBlue =
>> 4.24399170841135e-314,
>> >>       mTransparent = 0}, mSpecularReflectivity = 0.0078125,
>> >>     mSpecularSize = 1065353216, mDiffuseReflectivity =
>> 0.007812501848093234,
>> >>     mAmbientReflectivity = 0}
>> >>
>> >> The things displayed in *this are all wrong.  Those field names come
>> >> from the Shape object in the igraph package, not the Shape object
>> in the
>> >> rgl package.   The mixOmics package uses both.
>> >>
>> >> My questions:
>> >>
>> >> - Has my code somehow got mixed up with the igraph code, so I
>> really do
>> >> have a call out to igraph's Shape::~Shape instead of rgl's
>> >> Shape::~Shape, or is this just bad info being given to me by gdb?
>> >>
>>
>> I don't know, but I think it's possible to give fully qualified type
>> names to gdb to force it to use the right definition.  That's assuming
>> that both Shape's are in different namespaces.  If they aren't, that's
>> likely the problem.
>
> Apparently they aren't, even though they are in separately compiled and
> linked packages.  I had been assuming that the fact that rgl knows
> nothing about igraph meant I didn't need to worry about it. (igraph does
> list rgl in its "Suggests" list.)  On platforms other than Linux, I
> don't appear to need to worry about it, but Linux happily loads one,
> then loads the other and links the call to the wrong .so rather than the
> local one, without a peep of warning, just an eventual crash.
>
> Supposing I finish my editing of the 100 or so source files and put all
> of the rgl stuff in an "rgl" namespace, that still doesn't protect me
> from what some other developer might do next week, creating their own
> "rgl" namespace with a clashing name.   Why doesn't the linking step
> resolve the calls, why does it leave it until load time?

That makes it less likely though.

You could also use an unnamed namespace to sort of scope your code in 
your translation unit. See 
http://publib.boulder.ibm.com/infocenter/comphelp/v8v101/index.jsp?topic=/com.ibm.xlcpp8a.doc/language/ref/unnamed_namespaces.htm

>>> - If I really do have calls to the wrong destructor in there, how do I
>>> avoid this?
>
> Are you invoking the destructor explicitly?  An object should know
> it's type, which should result in the right call without much effort.
>
>
> No, this is an implicit destructor call.  I'm deleting an object whose
> class descends from Shape.
>
> Duncan Murdoch


-- 
Romain Francois
Professional R Enthusiast
+33(0) 6 28 91 30 30


From ross at biostat.ucsf.edu  Wed Oct  2 22:37:32 2013
From: ross at biostat.ucsf.edu (Ross Boylan)
Date: Wed, 02 Oct 2013 13:37:32 -0700
Subject: [Rd] C++ debugging help needed
In-Reply-To: <524C7EFC.5030605@gmail.com>
References: <524C32CF.2060307@gmail.com> <524C362F.1040108@gmail.com>
	<20131002200118.GX32066@markov.biostat.ucsf.edu>
	<524C7EFC.5030605@gmail.com>
Message-ID: <1380746252.7443.32.camel@localhost>

On Wed, 2013-10-02 at 16:15 -0400, Duncan Murdoch wrote:
> On 02/10/2013 4:01 PM, Ross Boylan wrote:
> > On Wed, Oct 02, 2013 at 11:05:19AM -0400, Duncan Murdoch wrote:
> > ....
> > >> Up to entry #4 this all looks normal.  If I go into that stack frame, I
> > >> see this:
> > >>
> > >>
> > >> (gdb) up
> > >> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> > >> Shape.cpp:13
> > >> warning: Source file is more recent than executable.
> >
> > That warning looks suspicious.  Are your sure gdb is finding the right
> > source files, and that the object code has been built from them?
> 
> I'm pretty sure that's a warning about the fact that igraph also has a 
> file called Shape.cpp, and the Shape::~Shape destructor was in that 
> file, not in my Shape.cpp file.

I guess the notion of the "right" source file is ambiguous in this
context.  Suppose you have projects A and B each defining a function f
in f.cpp.  Use A/f() to mean the binary function defined in project A,
found in source A/f.cpp.

The you have some code that means to invoke A/f() but gets B/f()
instead.  Probably gdb should associate this with B/f.cpp, but your
intent was A/f() and A/f.cpp.  If gdb happens to find A/f.cpp, and A was
build after B, that could provoke the warning shown.

> >
> > >> 13        blended(in_material.isTransparent())
> > >> (gdb) p this
> > >> $9 = (Shape * const) 0x15f8760
> > >> (gdb) p *this
> > >> $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
> > >>       static npos = <optimized out>,
> > >>       _M_dataplus = {<std::allocator<char>> =
> > >> {<__gnu_cxx::new_allocator<char>> =
> > >> {<No data fields>}, <No data fields>},
> > >>         _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
> > >> bounds>}},
> > >>     mShapeColor = {mRed = -1.4044474254567505e+306,
> > >>       mGreen = -1.4044477603031902e+306, mBlue = 4.24399170841135e-314,
> > >>       mTransparent = 0}, mSpecularReflectivity = 0.0078125,
> > >>     mSpecularSize = 1065353216, mDiffuseReflectivity = 0.007812501848093234,
> > >>     mAmbientReflectivity = 0}
> > >>
> > >> The things displayed in *this are all wrong.  Those field names come
> > >> from the Shape object in the igraph package, not the Shape object in the
> > >> rgl package.   The mixOmics package uses both.
> > >>
> > >> My questions:
> > >>
> > >> - Has my code somehow got mixed up with the igraph code, so I really do
> > >> have a call out to igraph's Shape::~Shape instead of rgl's
> > >> Shape::~Shape, or is this just bad info being given to me by gdb?
> > >>
> >
> > I don't know, but I think it's possible to give fully qualified type
> > names to gdb to force it to use the right definition.  That's assuming
> > that both Shape's are in different namespaces.  If they aren't, that's
> > likely the problem.
> 
> Apparently they aren't, even though they are in separately compiled and 
> linked packages.  I had been assuming that the fact that rgl knows 
> nothing about igraph meant I didn't need to worry about it. (igraph does 
> list rgl in its "Suggests" list.)  On platforms other than Linux, I 
> don't appear to need to worry about it, but Linux happily loads one, 
> then loads the other and links the call to the wrong .so rather than the 
> local one, without a peep of warning, just an eventual crash.

While various OS's and tricks could provide work-arounds for clashing
function definitions (I actually had the impression the R dynamic
loading machinery might) those wouldn't necessary be right.  In
principle package A might use some functions defined in package B.  In
that case the need for namespaces would have become obvious.

> 
> Supposing I finish my editing of the 100 or so source files and put all 
> of the rgl stuff in an "rgl" namespace, that still doesn't protect me 
> from what some other developer might do next week, creating their own 
> "rgl" namespace with a clashing name.   Why doesn't the linking step 
> resolve the calls, why does it leave it until load time?

I think there is a using namespace directive that might save typing,
putting everything into that namespace by default.  Maybe just the
headers need it.

With dynamic loading you don't know til load time if you've got a
problem.  As I said, the systemm can't simply wall if different
libraries, since they may want to call each other.

The usual solution for two developers picking the same name is to have
an outer level namespace associated with the developer/company/project,
with other namespaces nested inside.  This reduces the problem, though
obviously it can still exist higher up.

Ross
> 
> 
> >> - If I really do have calls to the wrong destructor in there, how do I
> >> avoid this?
> 
> Are you invoking the destructor explicitly?  An object should know
> it's type, which should result in the right call without much effort.
> 
> 
> No, this is an implicit destructor call.  I'm deleting an object whose 
> class descends from Shape.
> 
> Duncan Murdoch
> 
>


From murdoch.duncan at gmail.com  Wed Oct  2 22:46:06 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 02 Oct 2013 16:46:06 -0400
Subject: [Rd] C++ debugging help needed
In-Reply-To: <524C8167.7070809@r-enthusiasts.com>
References: <524C32CF.2060307@gmail.com> <524C362F.1040108@gmail.com>
	<20131002200118.GX32066@markov.biostat.ucsf.edu>
	<524C7EFC.5030605@gmail.com> <524C8167.7070809@r-enthusiasts.com>
Message-ID: <524C860E.2060608@gmail.com>

On 13-10-02 4:26 PM, Romain Francois wrote:
> Le 02/10/13 22:15, Duncan Murdoch a ?crit :
>> On 02/10/2013 4:01 PM, Ross Boylan wrote:
>>> On Wed, Oct 02, 2013 at 11:05:19AM -0400, Duncan Murdoch wrote:
>>> ....
>>>>> Up to entry #4 this all looks normal.  If I go into that stack
>>> frame, I
>>>>> see this:
>>>>>
>>>>>
>>>>> (gdb) up
>>>>> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
>>>>> Shape.cpp:13
>>>>> warning: Source file is more recent than executable.
>>>
>>> That warning looks suspicious.  Are your sure gdb is finding the right
>>> source files, and that the object code has been built from them?
>>
>> I'm pretty sure that's a warning about the fact that igraph also has a
>> file called Shape.cpp, and the Shape::~Shape destructor was in that
>> file, not in my Shape.cpp file.
>>>
>>>>> 13        blended(in_material.isTransparent())
>>>>> (gdb) p this
>>>>> $9 = (Shape * const) 0x15f8760
>>>>> (gdb) p *this
>>>>> $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
>>>>>        static npos = <optimized out>,
>>>>>        _M_dataplus = {<std::allocator<char>> =
>>>>> {<__gnu_cxx::new_allocator<char>> =
>>>>> {<No data fields>}, <No data fields>},
>>>>>          _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
>>>>> bounds>}},
>>>>>      mShapeColor = {mRed = -1.4044474254567505e+306,
>>>>>        mGreen = -1.4044477603031902e+306, mBlue =
>>> 4.24399170841135e-314,
>>>>>        mTransparent = 0}, mSpecularReflectivity = 0.0078125,
>>>>>      mSpecularSize = 1065353216, mDiffuseReflectivity =
>>> 0.007812501848093234,
>>>>>      mAmbientReflectivity = 0}
>>>>>
>>>>> The things displayed in *this are all wrong.  Those field names come
>>>>> from the Shape object in the igraph package, not the Shape object
>>> in the
>>>>> rgl package.   The mixOmics package uses both.
>>>>>
>>>>> My questions:
>>>>>
>>>>> - Has my code somehow got mixed up with the igraph code, so I
>>> really do
>>>>> have a call out to igraph's Shape::~Shape instead of rgl's
>>>>> Shape::~Shape, or is this just bad info being given to me by gdb?
>>>>>
>>>
>>> I don't know, but I think it's possible to give fully qualified type
>>> names to gdb to force it to use the right definition.  That's assuming
>>> that both Shape's are in different namespaces.  If they aren't, that's
>>> likely the problem.
>>
>> Apparently they aren't, even though they are in separately compiled and
>> linked packages.  I had been assuming that the fact that rgl knows
>> nothing about igraph meant I didn't need to worry about it. (igraph does
>> list rgl in its "Suggests" list.)  On platforms other than Linux, I
>> don't appear to need to worry about it, but Linux happily loads one,
>> then loads the other and links the call to the wrong .so rather than the
>> local one, without a peep of warning, just an eventual crash.
>>
>> Supposing I finish my editing of the 100 or so source files and put all
>> of the rgl stuff in an "rgl" namespace, that still doesn't protect me
>> from what some other developer might do next week, creating their own
>> "rgl" namespace with a clashing name.   Why doesn't the linking step
>> resolve the calls, why does it leave it until load time?
>
> That makes it less likely though.
>
> You could also use an unnamed namespace to sort of scope your code in
> your translation unit. See
> http://publib.boulder.ibm.com/infocenter/comphelp/v8v101/index.jsp?topic=/com.ibm.xlcpp8a.doc/language/ref/unnamed_namespaces.htm

I think those are restricted to a single .cpp file.  rgl has about 50 
.cpp files with a corresponding number of header files.  I want most of 
that to be in one namespace.

Duncan Murdoch

>
>>>> - If I really do have calls to the wrong destructor in there, how do I
>>>> avoid this?
>>
>> Are you invoking the destructor explicitly?  An object should know
>> it's type, which should result in the right call without much effort.
>>
>>
>> No, this is an implicit destructor call.  I'm deleting an object whose
>> class descends from Shape.
>>
>> Duncan Murdoch
>
>


From murdoch.duncan at gmail.com  Wed Oct  2 22:55:31 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 02 Oct 2013 16:55:31 -0400
Subject: [Rd] C++ debugging help needed
In-Reply-To: <1380746252.7443.32.camel@localhost>
References: <524C32CF.2060307@gmail.com> <524C362F.1040108@gmail.com>
	<20131002200118.GX32066@markov.biostat.ucsf.edu>
	<524C7EFC.5030605@gmail.com> <1380746252.7443.32.camel@localhost>
Message-ID: <524C8843.1030203@gmail.com>

On 13-10-02 4:37 PM, Ross Boylan wrote:
> On Wed, 2013-10-02 at 16:15 -0400, Duncan Murdoch wrote:
>> On 02/10/2013 4:01 PM, Ross Boylan wrote:
>>> On Wed, Oct 02, 2013 at 11:05:19AM -0400, Duncan Murdoch wrote:
>>> ....
>>>>> Up to entry #4 this all looks normal.  If I go into that stack frame, I
>>>>> see this:
>>>>>
>>>>>
>>>>> (gdb) up
>>>>> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
>>>>> Shape.cpp:13
>>>>> warning: Source file is more recent than executable.
>>>
>>> That warning looks suspicious.  Are your sure gdb is finding the right
>>> source files, and that the object code has been built from them?
>>
>> I'm pretty sure that's a warning about the fact that igraph also has a
>> file called Shape.cpp, and the Shape::~Shape destructor was in that
>> file, not in my Shape.cpp file.
>
> I guess the notion of the "right" source file is ambiguous in this
> context.  Suppose you have projects A and B each defining a function f
> in f.cpp.  Use A/f() to mean the binary function defined in project A,
> found in source A/f.cpp.
>
> The you have some code that means to invoke A/f() but gets B/f()
> instead.  Probably gdb should associate this with B/f.cpp, but your
> intent was A/f() and A/f.cpp.  If gdb happens to find A/f.cpp, and A was
> build after B, that could provoke the warning shown.
>
>>>
>>>>> 13        blended(in_material.isTransparent())
>>>>> (gdb) p this
>>>>> $9 = (Shape * const) 0x15f8760
>>>>> (gdb) p *this
>>>>> $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
>>>>>        static npos = <optimized out>,
>>>>>        _M_dataplus = {<std::allocator<char>> =
>>>>> {<__gnu_cxx::new_allocator<char>> =
>>>>> {<No data fields>}, <No data fields>},
>>>>>          _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
>>>>> bounds>}},
>>>>>      mShapeColor = {mRed = -1.4044474254567505e+306,
>>>>>        mGreen = -1.4044477603031902e+306, mBlue = 4.24399170841135e-314,
>>>>>        mTransparent = 0}, mSpecularReflectivity = 0.0078125,
>>>>>      mSpecularSize = 1065353216, mDiffuseReflectivity = 0.007812501848093234,
>>>>>      mAmbientReflectivity = 0}
>>>>>
>>>>> The things displayed in *this are all wrong.  Those field names come
>>>>> from the Shape object in the igraph package, not the Shape object in the
>>>>> rgl package.   The mixOmics package uses both.
>>>>>
>>>>> My questions:
>>>>>
>>>>> - Has my code somehow got mixed up with the igraph code, so I really do
>>>>> have a call out to igraph's Shape::~Shape instead of rgl's
>>>>> Shape::~Shape, or is this just bad info being given to me by gdb?
>>>>>
>>>
>>> I don't know, but I think it's possible to give fully qualified type
>>> names to gdb to force it to use the right definition.  That's assuming
>>> that both Shape's are in different namespaces.  If they aren't, that's
>>> likely the problem.
>>
>> Apparently they aren't, even though they are in separately compiled and
>> linked packages.  I had been assuming that the fact that rgl knows
>> nothing about igraph meant I didn't need to worry about it. (igraph does
>> list rgl in its "Suggests" list.)  On platforms other than Linux, I
>> don't appear to need to worry about it, but Linux happily loads one,
>> then loads the other and links the call to the wrong .so rather than the
>> local one, without a peep of warning, just an eventual crash.
>
> While various OS's and tricks could provide work-arounds for clashing
> function definitions (I actually had the impression the R dynamic
> loading machinery might) those wouldn't necessary be right.  In
> principle package A might use some functions defined in package B.  In
> that case the need for namespaces would have become obvious.

The issue is that I don't need to import the problematic function from 
another library.  It is not defined in the same .o file, but it is in 
the same .dll/.so.   I think the linker should have resolved it, not 
left it for later resolution by the loader.

I would expect to have problems if functions like Rprintf() were defined 
in multiple places, because I need to import those.  But I think it's a 
linker bug (or a bad design) in a case where the function is defined in 
another .o file being linked into a shared library.

Duncan Murdoch

>
>>
>> Supposing I finish my editing of the 100 or so source files and put all
>> of the rgl stuff in an "rgl" namespace, that still doesn't protect me
>> from what some other developer might do next week, creating their own
>> "rgl" namespace with a clashing name.   Why doesn't the linking step
>> resolve the calls, why does it leave it until load time?
>
> I think there is a using namespace directive that might save typing,
> putting everything into that namespace by default.  Maybe just the
> headers need it.
>
> With dynamic loading you don't know til load time if you've got a
> problem.  As I said, the systemm can't simply wall if different
> libraries, since they may want to call each other.
>
> The usual solution for two developers picking the same name is to have
> an outer level namespace associated with the developer/company/project,
> with other namespaces nested inside.  This reduces the problem, though
> obviously it can still exist higher up.
>
> Ross
>>
>>
>>>> - If I really do have calls to the wrong destructor in there, how do I
>>>> avoid this?
>>
>> Are you invoking the destructor explicitly?  An object should know
>> it's type, which should result in the right call without much effort.
>>
>>
>> No, this is an implicit destructor call.  I'm deleting an object whose
>> class descends from Shape.
>>
>> Duncan Murdoch
>>
>>
>
>


From john.maindonald at anu.edu.au  Thu Oct  3 04:24:36 2013
From: john.maindonald at anu.edu.au (John Maindonald)
Date: Thu, 3 Oct 2013 02:24:36 +0000
Subject: [Rd] Error in "Writing R Extensions"
Message-ID: <DC06513B-AFAB-47C9-997B-293537331425@anu.edu.au>

In Section 1.4.2 of "Writing R Extensions"
     %\VignetteEngine{knitr::knitr}
should be
     %\VignetteEngine{knitr::knit}

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-apple-darwin10.8.0 (64-bit)

Is this sort of thing best reported here, or is a huge report in order?

John Maindonald             email: john.maindonald at anu.edu.au
phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
Centre for Mathematics & Its Applications, Room 1194,
John Dedman Mathematical Sciences Building (Building 27)
Australian National University, Canberra ACT 0200.


From xie at yihui.name  Thu Oct  3 04:44:52 2013
From: xie at yihui.name (Yihui Xie)
Date: Wed, 2 Oct 2013 21:44:52 -0500
Subject: [Rd] Error in "Writing R Extensions"
In-Reply-To: <DC06513B-AFAB-47C9-997B-293537331425@anu.edu.au>
References: <DC06513B-AFAB-47C9-997B-293537331425@anu.edu.au>
Message-ID: <CANROs4fkbUQ73RA=HsGxpFiD03iGSSM=kKMvHfLHcEMtiaFwvw@mail.gmail.com>

The double colon :: can be confusing here, but the R-exts manual is
actually correct. :: does not imply anything about the package
namespace; it is merely a separator. The vignette engines are written
in the form package::engine, and the engine name _happens_ to be
"knitr" as well in this case.

> library(knitr)
> str(tools::vignetteEngine(name='knitr', package='knitr'))
List of 5
 $ name   : chr "knitr"
 $ package: chr "knitr"
 $ pattern: chr "[.]([rRsS](nw|tex)|[Rr](md|html|rst))$"
 $ weave  :function (file, driver, syntax, encoding = "", quiet = FALSE, ...)
 $ tangle :function (file, driver, syntax, encoding = "", quiet = FALSE, ...)

I admit the engine name "knitr" is also confusing. There are other
engine names in knitr, though. For example, knitr::docco_classic
http://cran.r-project.org/web/packages/knitr/vignettes/docco-classic.html

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Wed, Oct 2, 2013 at 9:24 PM, John Maindonald
<john.maindonald at anu.edu.au> wrote:
> In Section 1.4.2 of "Writing R Extensions"
>      %\VignetteEngine{knitr::knitr}
> should be
>      %\VignetteEngine{knitr::knit}
>
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-apple-darwin10.8.0 (64-bit)
>
> Is this sort of thing best reported here, or is a huge report in order?
>
> John Maindonald             email: john.maindonald at anu.edu.au
> phone : +61 2 (6125)3473    fax  : +61 2(6125)5549
> Centre for Mathematics & Its Applications, Room 1194,
> John Dedman Mathematical Sciences Building (Building 27)
> Australian National University, Canberra ACT 0200.


From bbolker at gmail.com  Thu Oct  3 05:41:02 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Wed, 2 Oct 2013 23:41:02 -0400
Subject: [Rd] version comparison puzzle
Message-ID: <524CE74E.6000208@ufl.edu>


     Can anyone explain what I'm missing here?

max(pp1 <- package_version(c("0.99999911.3","1.0.4","1.0.5")))
## [1] ?1.0.4?

max(pp2 <- package_version(c("1.0.3","1.0.4","1.0.5")))
## [1] ?1.0.5?

I've looked at ?package_version , to no avail.

Since max() goes to .Primitive("max")
I'm having trouble figuring out where it goes from there:
I **think** this is related to ?xtfrm , which goes to
.encode_numeric_version, which is doing something I really
don't understand (it's in base/R/version.R ...)

.encode_numeric_version(pp1)
## [1] 1 1 1
## attr(,"base")
## [1] 99999912
## attr(,"lens")
## [1] 3 3 3
## attr(,".classes")
## [1] "package_version" "numeric_version"

.encode_numeric_version(pp2)
## [1] 1.083333 1.111111 1.138889
## attr(,"base")
## [1] 6
## attr(,"lens")
## [1] 3 3 3
## attr(,".classes")
## [1] "package_version" "numeric_version"

sessionInfo()
R Under development (unstable) (2013-09-09 r63889)
Platform: i686-pc-linux-gnu (32-bit)

[snip]

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] compiler_3.1.0 tools_3.1.0


From ripley at stats.ox.ac.uk  Thu Oct  3 09:17:36 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 03 Oct 2013 08:17:36 +0100
Subject: [Rd] predictions in nlme without fixed covariantes
In-Reply-To: <AA818EAD2576BC488B4F623941DA7427DFAED0B1@inbomail.inbo.be>
References: <AA818EAD2576BC488B4F623941DA7427DFAED0B1@inbomail.inbo.be>
Message-ID: <524D1A10.8030505@stats.ox.ac.uk>

This should be fixed in nlme 3.1-112.

However, nlme has little support for formulae such as resp ~ 0, and does 
things like p:1 where p is the number of columns in the model matrix. 
3.1-112 does better but evidently the design did not consider this 
possibility.


On 30/09/2013 13:42, ONKELINX, Thierry wrote:
> Dear all,
>
> predict.lme() throws an error when the fixed part consists of only an intercept and using newdata. See the reproducible example below. I've tracked the error down to asOneFormula() which returns in this case NULL instead of a formula. Changing NULL instead of ~1 in that function (see below) solves the problem in the case of an intercept only model (m1). It does not solve the problem in case of a model without intercept nor covariates (m2). The package with altered asOneFormula() passes R CMD check on my machine.
>
> Best regards,
>
> Thierry Onkelinx
>
> library(nlme)
> data(Orthodont)
> m0 <- lme(distance ~ Sex, random = ~1|Subject, data = Orthodont)
> m1 <- lme(distance ~ 1, random = ~1|Subject, data = Orthodont)
> m2 <- lme(distance ~ 0, random = ~1|Subject, data = Orthodont)
>
> test.data <- Orthodont
>
> test.data$Fitted <- predict(m0, level = 0)
> test.data$Fitted.Newdata <- predict(m0, level = 0, newdata = test.data)
> sum(abs(test.data$Fitted - test.data$Fitted.Newdata))
>
> test.data$Fitted <- predict(m0, level = 1)
> test.data$Fitted.Newdata <- predict(m0, level = 1, newdata = test.data)
> sum(abs(test.data$Fitted - test.data$Fitted.Newdata))
>
> test.data$Fitted <- predict(m1, level = 0)
> test.data$Fitted.Newdata <- predict(m1, level = 0, newdata = test.data)
> sum(abs(test.data$Fitted - test.data$Fitted.Newdata))
>
> test.data$Fitted <- predict(m1, level = 1)
> test.data$Fitted.Newdata <- predict(m1, level = 1, newdata = test.data)
> sum(abs(test.data$Fitted - test.data$Fitted.Newdata))
>
> test.data$Fitted <- predict(m2, level = 0)
> test.data$Fitted.Newdata <- predict(m2, level = 0, newdata = test.data)
> sum(abs(test.data$Fitted - test.data$Fitted.Newdata))
>
> test.data$Fitted <- predict(m2, level = 1)
> test.data$Fitted.Newdata <- predict(m2, level = 1, newdata = test.data)
> sum(abs(test.data$Fitted - test.data$Fitted.Newdata))
>
>
>
> #new version
> asOneFormula <-
>    ## Constructs a linear formula with all the variables used in a
>    ## list of formulas, except for the names in omit
>    function(..., omit = c(".", "pi"))
> {
>    names <- unique(allVarsRec((list(...))))
>    names <- names[is.na(match(names, omit))]
>    if (length(names)) {
>      eval(parse(text = paste("~", paste(names, collapse = "+")))[[1]])
>    } else {
>      ~ 1 #this was NULL
>    }
> }
>
>
>
> sessionInfo()
> R Under development (unstable) (2013-08-24 r63687)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=Dutch_Belgium.1252  LC_CTYPE=Dutch_Belgium.1252
> [3] LC_MONETARY=Dutch_Belgium.1252 LC_NUMERIC=C
> [5] LC_TIME=Dutch_Belgium.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] grid_3.1.0      lattice_0.20-15 tools_3.1.0
> * * * * * * * * * * * * * D I S C L A I M E R * * * * * * * * * * * * *
> Dit bericht en eventuele bijlagen geven enkel de visie van de schrijver weer en binden het INBO onder geen enkel beding, zolang dit bericht niet bevestigd is door een geldig ondertekend document.
> The views expressed in this message and any annex are purely those of the writer and may not be regarded as stating an official position of INBO, as long as the message is not confirmed by a duly signed document.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From plummerm at iarc.fr  Thu Oct  3 10:15:28 2013
From: plummerm at iarc.fr (Martyn Plummer)
Date: Thu, 3 Oct 2013 08:15:28 +0000
Subject: [Rd] version comparison puzzle
In-Reply-To: <524CE74E.6000208@ufl.edu>
References: <524CE74E.6000208@ufl.edu>
Message-ID: <1380788123.1581.29.camel@braque.iarc.fr>

It's an underflow problem. When comparing versions, "a.b.c" is converted
first to the integer vector c(a,b,c) and then to the double precision
value 

a + b/base + c/base^2

where base is 1 greater than the largest integer component of any of the
versions: i.e 999999912 in this case.  The last term is then smaller
than the machine precision so you can't tell the difference between
1.0.4 and 1.0.5.

Martyn

On Wed, 2013-10-02 at 23:41 -0400, Ben Bolker wrote:
>      Can anyone explain what I'm missing here?
> 
> max(pp1 <- package_version(c("0.99999911.3","1.0.4","1.0.5")))
> ## [1] ?1.0.4?
> 
> max(pp2 <- package_version(c("1.0.3","1.0.4","1.0.5")))
> ## [1] ?1.0.5?
> 
> I've looked at ?package_version , to no avail.
> 
> Since max() goes to .Primitive("max")
> I'm having trouble figuring out where it goes from there:
> I **think** this is related to ?xtfrm , which goes to
> .encode_numeric_version, which is doing something I really
> don't understand (it's in base/R/version.R ...)
> 
> .encode_numeric_version(pp1)
> ## [1] 1 1 1
> ## attr(,"base")
> ## [1] 99999912
> ## attr(,"lens")
> ## [1] 3 3 3
> ## attr(,".classes")
> ## [1] "package_version" "numeric_version"
> 
> .encode_numeric_version(pp2)
> ## [1] 1.083333 1.111111 1.138889
> ## attr(,"base")
> ## [1] 6
> ## attr(,"lens")
> ## [1] 3 3 3
> ## attr(,".classes")
> ## [1] "package_version" "numeric_version"
> 
> sessionInfo()
> R Under development (unstable) (2013-09-09 r63889)
> Platform: i686-pc-linux-gnu (32-bit)
> 
> [snip]
> 
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
> 
> loaded via a namespace (and not attached):
> [1] compiler_3.1.0 tools_3.1.0
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jari.oksanen at oulu.fi  Thu Oct  3 10:27:12 2013
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Thu, 3 Oct 2013 08:27:12 +0000
Subject: [Rd] version comparison puzzle
In-Reply-To: <1380788123.1581.29.camel@braque.iarc.fr>
References: <524CE74E.6000208@ufl.edu>,
	<1380788123.1581.29.camel@braque.iarc.fr>
Message-ID: <66C03CD1145C95448A4D73676DD9C2EDF9EF66@nippu2>

Actually, Bob O'Hara had a blog post about this in August 2012:

http://occamstypewriter.org/boboh/2012/08/17/lme4_destined_to_become_stable_through_rounding/

The concluding chapter reads:

"I have been worried that lme4 will never become stable, but this latest version mollifies me with the thought that the developers can?t go on forever, so eventually lme4 will become stable when the machine precision forces it to be rounded up to 1.0"

Cheers, Jari Oksanen
________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] on behalf of Martyn Plummer [plummerm at iarc.fr]
Sent: 03 October 2013 11:15
To: Ben Bolker
Cc: R-devel at stat.math.ethz.ch
Subject: Re: [Rd] version comparison puzzle

It's an underflow problem. When comparing versions, "a.b.c" is converted
first to the integer vector c(a,b,c) and then to the double precision
value

a + b/base + c/base^2

where base is 1 greater than the largest integer component of any of the
versions: i.e 999999912 in this case.  The last term is then smaller
than the machine precision so you can't tell the difference between
1.0.4 and 1.0.5.

Martyn

On Wed, 2013-10-02 at 23:41 -0400, Ben Bolker wrote:
>      Can anyone explain what I'm missing here?
>
> max(pp1 <- package_version(c("0.99999911.3","1.0.4","1.0.5")))
> ## [1] ?1.0.4?
>
> max(pp2 <- package_version(c("1.0.3","1.0.4","1.0.5")))
> ## [1] ?1.0.5?
>
> I've looked at ?package_version , to no avail.
>
> Since max() goes to .Primitive("max")
> I'm having trouble figuring out where it goes from there:
> I **think** this is related to ?xtfrm , which goes to
> .encode_numeric_version, which is doing something I really
> don't understand (it's in base/R/version.R ...)
>
> .encode_numeric_version(pp1)
> ## [1] 1 1 1
> ## attr(,"base")
> ## [1] 99999912
> ## attr(,"lens")
> ## [1] 3 3 3
> ## attr(,".classes")
> ## [1] "package_version" "numeric_version"
>
> .encode_numeric_version(pp2)
> ## [1] 1.083333 1.111111 1.138889
> ## attr(,"base")
> ## [1] 6
> ## attr(,"lens")
> ## [1] 3 3 3
> ## attr(,".classes")
> ## [1] "package_version" "numeric_version"
>
> sessionInfo()
> R Under development (unstable) (2013-09-09 r63889)
> Platform: i686-pc-linux-gnu (32-bit)
>
> [snip]
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] compiler_3.1.0 tools_3.1.0
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel


From Rainer at krugs.de  Thu Oct  3 12:22:57 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Thu, 3 Oct 2013 12:22:57 +0200
Subject: [Rd] check warning  with .onLoad() and setClass()
Message-ID: <m2zjqqfybi.fsf@krugs.de>

Hi

I am writing a package in which I define a new class in the .onLoad()
hook:

,----
| .onLoad <- function(libname, pkgname) {
|     setClass(
|         "inDrak",
|         representation(
|             init = "SpatialGridDataFrame"
|             ),
|         contains = "simObj"
|         )
| }
`----

The class "simObj" is defined in the package, which is in the depends
section in the DESCRIPTION file:

,----
| Package: InDrak
| Type: Package
| Title: Alien spread management simulation model for the Drakensberg
| Version: 0.1-0
| Date: 2013-10-03_11-55
| Author: Rainer M. Krug
| Maintainer: Rainer M Krug <Rainer at krugs.de>
| Description: Simulate the spread of three Invasive Alien Plants under different
|     management and budget scenarios
| License: GPL-3
| LazyLoad: yes
| Depends:
|     RSQLite,
|     simecol
| Imports:
|     methods,
|     sp,
|     spgrass6,
|     DBI,
|     logger,
|     fireSim,
|     seedProd,
|     seedGerm,
|     seedDisp
| LinkingTo: Rcpp
| Collate:
|     'beginYear.R'
|     'clearAliens.R'
|     'competition.R'
|     'cumulativeDc.R'
|     'dcToIndLayer.R'
|     'dispProb2D.R'
|     'endYear.R'
|     'fireAliens.R'
|     'germEst.R'
|     'initfunc.R'
|     'layerIO.R'
|     'layerNames.R'
|     'main.R'
|     'newInDrak.R'
|     'onLoad.R'
|     'package.R'
|     'parameter.R'
|     'parmsAcacia.R'
|     'parmsBudget.R'
|     'parmsFire.R'
|     'parmsPinus.R'
|     'parmsRubus.R'
|     'resetOptions.R'
|     'seedDispersal.R'
|     'seedProduction.R'
|     'stats.R'
`----

If important, the NAMESPACE file is here:

,----
| export(depRateName)
| export(exportRaster)
| export(fireLayerName)
| export(ignitionRiskName)
| export(importAliens)
| export(importClearingHistory)
| export(importFireHistory)
| export(importIgnitionRisk)
| export(importSpecies)
| export(importVegetation)
| export(layerExists)
| export(layerName)
| export(newInDrak)
| export(parameter)
| export(parmsAcacia)
| export(parmsBudget)
| export(parmsFire)
| export(parmsPinus)
| export(parmsRubus)
| export(resetOptions)
| export(statDistName)
| export(suitName)
| import(DBI)
| import(fireSim)
| import(logger)
| import(methods)
| import(seedDisp)
| import(seedGerm)
| import(seedProd)
| import(sp)
| import(spgrass6)
`----

The package builds fine, it installs without problems and works as
expected, but when checking it, I get the following error:

,----
| $ R CMD check ./InDrak_0.1-0.tar.gz 
| * using log directory ?/Users/rainerkrug/Documents/Projects/R-Packages/inDrak/InDrak.Rcheck?
| * using R version 3.0.1 (2013-05-16)
| * using platform: x86_64-apple-darwin10.8.0 (64-bit)
| * using session charset: UTF-8
| * checking for file ?InDrak/DESCRIPTION? ... OK
| * checking extension type ... Package
| * this is package ?InDrak? version ?0.1-0?
| * checking package namespace information ... OK
| * checking package dependencies ... OK
| * checking if this is a source package ... OK
| * checking if there is a namespace ... OK
| * checking for executable files ... OK
| * checking for hidden files and directories ... OK
| * checking for portable file names ... OK
| * checking for sufficient/correct file permissions ... OK
| * checking whether package ?InDrak? can be installed ... OK
| * checking installed package size ... OK
| * checking package directory ... OK
| * checking DESCRIPTION meta-information ... OK
| * checking top-level files ... OK
| * checking for left-over files ... OK
| * checking index information ... OK
| * checking package subdirectories ... OK
| * checking R files for non-ASCII characters ... OK
| * checking R files for syntax errors ... OK
| * checking whether the package can be loaded ... OK
| * checking whether the package can be loaded with stated dependencies ... OK
| * checking whether the package can be unloaded cleanly ... OK
| * checking whether the namespace can be loaded with stated dependencies ... WARNING
| Error: .onLoad failed in loadNamespace() for ?InDrak?, details:
|   call: reconcilePropertiesAndPrototype(name, slots, prototype, superClasses, 
|   error: no definition was found for superclass ?simObj? in the specification of class ?inDrak?
| Execution halted
| 
| A namespace must be able to be loaded with just the base namespace
| loaded: otherwise if the namespace gets loaded by a saved object, the
| session will be unable to start.
| 
| Probably some imports need to be declared in the NAMESPACE file.
| * checking whether the namespace can be unloaded cleanly ... WARNING
| Error: .onLoad failed in loadNamespace() for ?InDrak?, details:
|   call: reconcilePropertiesAndPrototype(name, slots, prototype, superClasses, 
|   error: no definition was found for superclass ?simObj? in the specification of class ?inDrak?
| Execution halted
| * checking loading without being on the library search path ... OK
| * checking for unstated dependencies in R code ... OK
| * checking S3 generic/method consistency ... OK
| * checking replacement functions ... OK
| * checking foreign function calls ... OK
| * checking R code for possible problems ... NOTE
| .initfunc: no visible global function definition for
|   ?initialSeedProductionAliens?
| .initfunc: no visible global function definition for ?endYear?
| .main: no visible global function definition for ?beginYear?
| .main: no visible global function definition for ?fireAliens?
| .main: no visible global function definition for ?seedProductionAliens?
| .main: no visible global function definition for ?seedDispersalAliens?
| .main: no visible global function definition for ?germEstAliens?
| .main: no visible global function definition for ?endYear?
| * checking Rd files ... OK
| * checking Rd metadata ... OK
| * checking Rd cross-references ... OK
| * checking for missing documentation entries ... OK
| * checking for code/documentation mismatches ... OK
| * checking Rd \usage sections ... OK
| * checking Rd contents ... OK
| * checking for unstated dependencies in examples ... OK
| * checking examples ... NONE
| * checking PDF version of manual ... OK
| 
| WARNING: There were 2 warnings.
| NOTE: There was 1 note.
| See
|   ?/Users/rainerkrug/Documents/Projects/R-Packages/inDrak/InDrak.Rcheck/00check.log?
| for details.
`----

I am sure I am missing something simple here and I really think I
overlooked it in the "Writing R extensions"...

Thanks,

Rainer

-- 
Rainer M. Krug

email: RMKrug<at>gmail<dot>com
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 486 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131003/18e7ac4e/attachment.bin>

From jmc at r-project.org  Thu Oct  3 19:03:29 2013
From: jmc at r-project.org (John Chambers)
Date: Thu, 3 Oct 2013 10:03:29 -0700
Subject: [Rd] check warning  with .onLoad() and setClass()
In-Reply-To: <m2zjqqfybi.fsf@krugs.de>
References: <m2zjqqfybi.fsf@krugs.de>
Message-ID: <AD583E37-4E49-406C-B4A8-8F13C31E9B14@r-project.org>

Don't use .onLoad() to set class (or other nontrivial) information at load time.  Use setLoadActions(), which was created exactly to get around the limitations of .onLoad().

For an example, see the Rcpp package, which uses this to set up load-time C++ linkages.

John Chambers

On Oct 3, 2013, at 3:22 AM, Rainer M Krug <Rainer at krugs.de> wrote:

> Hi
> 
> I am writing a package in which I define a new class in the .onLoad()
> hook:
> 
> ,----
> | .onLoad <- function(libname, pkgname) {
> |     setClass(
> |         "inDrak",
> |         representation(
> |             init = "SpatialGridDataFrame"
> |             ),
> |         contains = "simObj"
> |         )
> | }
> `----
> 
> The class "simObj" is defined in the package, which is in the depends
> section in the DESCRIPTION file:
> 
> ,----
> | Package: InDrak
> | Type: Package
> | Title: Alien spread management simulation model for the Drakensberg
> | Version: 0.1-0
> | Date: 2013-10-03_11-55
> | Author: Rainer M. Krug
> | Maintainer: Rainer M Krug <Rainer at krugs.de>
> | Description: Simulate the spread of three Invasive Alien Plants under different
> |     management and budget scenarios
> | License: GPL-3
> | LazyLoad: yes
> | Depends:
> |     RSQLite,
> |     simecol
> | Imports:
> |     methods,
> |     sp,
> |     spgrass6,
> |     DBI,
> |     logger,
> |     fireSim,
> |     seedProd,
> |     seedGerm,
> |     seedDisp
> | LinkingTo: Rcpp
> | Collate:
> |     'beginYear.R'
> |     'clearAliens.R'
> |     'competition.R'
> |     'cumulativeDc.R'
> |     'dcToIndLayer.R'
> |     'dispProb2D.R'
> |     'endYear.R'
> |     'fireAliens.R'
> |     'germEst.R'
> |     'initfunc.R'
> |     'layerIO.R'
> |     'layerNames.R'
> |     'main.R'
> |     'newInDrak.R'
> |     'onLoad.R'
> |     'package.R'
> |     'parameter.R'
> |     'parmsAcacia.R'
> |     'parmsBudget.R'
> |     'parmsFire.R'
> |     'parmsPinus.R'
> |     'parmsRubus.R'
> |     'resetOptions.R'
> |     'seedDispersal.R'
> |     'seedProduction.R'
> |     'stats.R'
> `----
> 
> If important, the NAMESPACE file is here:
> 
> ,----
> | export(depRateName)
> | export(exportRaster)
> | export(fireLayerName)
> | export(ignitionRiskName)
> | export(importAliens)
> | export(importClearingHistory)
> | export(importFireHistory)
> | export(importIgnitionRisk)
> | export(importSpecies)
> | export(importVegetation)
> | export(layerExists)
> | export(layerName)
> | export(newInDrak)
> | export(parameter)
> | export(parmsAcacia)
> | export(parmsBudget)
> | export(parmsFire)
> | export(parmsPinus)
> | export(parmsRubus)
> | export(resetOptions)
> | export(statDistName)
> | export(suitName)
> | import(DBI)
> | import(fireSim)
> | import(logger)
> | import(methods)
> | import(seedDisp)
> | import(seedGerm)
> | import(seedProd)
> | import(sp)
> | import(spgrass6)
> `----
> 
> The package builds fine, it installs without problems and works as
> expected, but when checking it, I get the following error:
> 
> ,----
> | $ R CMD check ./InDrak_0.1-0.tar.gz 
> | * using log directory ?/Users/rainerkrug/Documents/Projects/R-Packages/inDrak/InDrak.Rcheck?
> | * using R version 3.0.1 (2013-05-16)
> | * using platform: x86_64-apple-darwin10.8.0 (64-bit)
> | * using session charset: UTF-8
> | * checking for file ?InDrak/DESCRIPTION? ... OK
> | * checking extension type ... Package
> | * this is package ?InDrak? version ?0.1-0?
> | * checking package namespace information ... OK
> | * checking package dependencies ... OK
> | * checking if this is a source package ... OK
> | * checking if there is a namespace ... OK
> | * checking for executable files ... OK
> | * checking for hidden files and directories ... OK
> | * checking for portable file names ... OK
> | * checking for sufficient/correct file permissions ... OK
> | * checking whether package ?InDrak? can be installed ... OK
> | * checking installed package size ... OK
> | * checking package directory ... OK
> | * checking DESCRIPTION meta-information ... OK
> | * checking top-level files ... OK
> | * checking for left-over files ... OK
> | * checking index information ... OK
> | * checking package subdirectories ... OK
> | * checking R files for non-ASCII characters ... OK
> | * checking R files for syntax errors ... OK
> | * checking whether the package can be loaded ... OK
> | * checking whether the package can be loaded with stated dependencies ... OK
> | * checking whether the package can be unloaded cleanly ... OK
> | * checking whether the namespace can be loaded with stated dependencies ... WARNING
> | Error: .onLoad failed in loadNamespace() for ?InDrak?, details:
> |   call: reconcilePropertiesAndPrototype(name, slots, prototype, superClasses, 
> |   error: no definition was found for superclass ?simObj? in the specification of class ?inDrak?
> | Execution halted
> | 
> | A namespace must be able to be loaded with just the base namespace
> | loaded: otherwise if the namespace gets loaded by a saved object, the
> | session will be unable to start.
> | 
> | Probably some imports need to be declared in the NAMESPACE file.
> | * checking whether the namespace can be unloaded cleanly ... WARNING
> | Error: .onLoad failed in loadNamespace() for ?InDrak?, details:
> |   call: reconcilePropertiesAndPrototype(name, slots, prototype, superClasses, 
> |   error: no definition was found for superclass ?simObj? in the specification of class ?inDrak?
> | Execution halted
> | * checking loading without being on the library search path ... OK
> | * checking for unstated dependencies in R code ... OK
> | * checking S3 generic/method consistency ... OK
> | * checking replacement functions ... OK
> | * checking foreign function calls ... OK
> | * checking R code for possible problems ... NOTE
> | .initfunc: no visible global function definition for
> |   ?initialSeedProductionAliens?
> | .initfunc: no visible global function definition for ?endYear?
> | .main: no visible global function definition for ?beginYear?
> | .main: no visible global function definition for ?fireAliens?
> | .main: no visible global function definition for ?seedProductionAliens?
> | .main: no visible global function definition for ?seedDispersalAliens?
> | .main: no visible global function definition for ?germEstAliens?
> | .main: no visible global function definition for ?endYear?
> | * checking Rd files ... OK
> | * checking Rd metadata ... OK
> | * checking Rd cross-references ... OK
> | * checking for missing documentation entries ... OK
> | * checking for code/documentation mismatches ... OK
> | * checking Rd \usage sections ... OK
> | * checking Rd contents ... OK
> | * checking for unstated dependencies in examples ... OK
> | * checking examples ... NONE
> | * checking PDF version of manual ... OK
> | 
> | WARNING: There were 2 warnings.
> | NOTE: There was 1 note.
> | See
> |   ?/Users/rainerkrug/Documents/Projects/R-Packages/inDrak/InDrak.Rcheck/00check.log?
> | for details.
> `----
> 
> I am sure I am missing something simple here and I really think I
> overlooked it in the "Writing R extensions"...
> 
> Thanks,
> 
> Rainer
> 
> -- 
> Rainer M. Krug
> 
> email: RMKrug<at>gmail<dot>com
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jgrn at illinois.edu  Thu Oct  3 21:27:47 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Thu, 3 Oct 2013 14:27:47 -0500
Subject: [Rd] Including R code from another package...
Message-ID: <CABG0rfv86fP_u2sDLknUdS1wcmVOMZAy2i7akF8i238UPOH=JA@mail.gmail.com>

R-developers:

I had a quick question for the group -- let's say a package I am
developing depends on a single, small function from a large
CRAN-listed package.  I can, of course, set a dependency within my own
package, but are there means by which I can include the R script + man
file DIRECTLY in my package (of course attributing the code to the
original programmer).  Does it require me asking the package manager
directly?  If not, what is the proper way to cite that a given script
was coded by someone else?  Cheers!

--j

-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From 538280 at gmail.com  Thu Oct  3 21:39:19 2013
From: 538280 at gmail.com (Greg Snow)
Date: Thu, 3 Oct 2013 13:39:19 -0600
Subject: [Rd] Including R code from another package...
In-Reply-To: <CABG0rfv86fP_u2sDLknUdS1wcmVOMZAy2i7akF8i238UPOH=JA@mail.gmail.com>
References: <CABG0rfv86fP_u2sDLknUdS1wcmVOMZAy2i7akF8i238UPOH=JA@mail.gmail.com>
Message-ID: <CAFEqCdzsr-ACOGOGKH0YNTE2aQh=c5HfpGjJa5nXuy-+fjMzEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131003/4aff0d5a/attachment.pl>

From ligges at statistik.tu-dortmund.de  Thu Oct  3 23:06:45 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 3 Oct 2013 23:06:45 +0200
Subject: [Rd] Including R code from another package...
In-Reply-To: <CAFEqCdzsr-ACOGOGKH0YNTE2aQh=c5HfpGjJa5nXuy-+fjMzEw@mail.gmail.com>
References: <CABG0rfv86fP_u2sDLknUdS1wcmVOMZAy2i7akF8i238UPOH=JA@mail.gmail.com>
	<CAFEqCdzsr-ACOGOGKH0YNTE2aQh=c5HfpGjJa5nXuy-+fjMzEw@mail.gmail.com>
Message-ID: <524DDC65.4060409@statistik.tu-dortmund.de>



On 03.10.2013 21:39, Greg Snow wrote:
> If the package is on CRAN then the license should be a free one that would
> let you copy whatever you want from it.

That is not true for all CRAN packages.


> However it would be most polite to
> contact the original author first.  I know that I have given permission for
> a couple of my functions to be included in other packages where it would
> clearly be overkill for the other package to depend on my package for just
> the one function.  Since the authors of those packages asked me first I
> make sure to send them any updates that I make to those functions so that
> they can keep the copy in their package current with mine if they want to.
>
> If you do not receive a reply from the author of the original function then
> check the license, you can probably still include the function and
> documentation in your package, just be sure to give proper credit and make
> sure that your license is compatible.

Indeed.

Uwe Ligges


>
> On Thu, Oct 3, 2013 at 1:27 PM, Jonathan Greenberg <jgrn at illinois.edu>wrote:
>
>> R-developers:
>>
>> I had a quick question for the group -- let's say a package I am
>> developing depends on a single, small function from a large
>> CRAN-listed package.  I can, of course, set a dependency within my own
>> package, but are there means by which I can include the R script + man
>> file DIRECTLY in my package (of course attributing the code to the
>> original programmer).  Does it require me asking the package manager
>> directly?  If not, what is the proper way to cite that a given script
>> was coded by someone else?  Cheers!
>>
>> --j
>>
>> --
>> Jonathan A. Greenberg, PhD
>> Assistant Professor
>> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
>> Department of Geography and Geographic Information Science
>> University of Illinois at Urbana-Champaign
>> 259 Computing Applications Building, MC-150
>> 605 East Springfield Avenue
>> Champaign, IL  61820-6371
>> Phone: 217-300-1924
>> http://www.geog.illinois.edu/~jgrn/
>> AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>


From ligges at statistik.tu-dortmund.de  Thu Oct  3 23:08:09 2013
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 03 Oct 2013 23:08:09 +0200
Subject: [Rd] R-3.0.2 - Win7_64 - alone_decoder.c: Permission denied
	error
In-Reply-To: <93A2161604A30C4ABE14AC35CAFC84220164320630@USDFW11XM32.mercer.com>
References: <93A2161604A30C4ABE14AC35CAFC84220164320630@USDFW11XM32.mercer.com>
Message-ID: <524DDCB9.8080101@statistik.tu-dortmund.de>



On 30.09.2013 19:47, Adler, Avraham wrote:
> Hello.
>
> When trying to compile R-3.0.2 on Windows 7 64bit, I get an error relating to "alone_decoder.c: Permission denied." The entire error code is copied below.
>
> 	gcc -std=gnu99 -m64 -shared   -o Riconv.dll Riconv.def win_iconv.o
> 	touch stamp
> 	gcc -std=gnu99 -m64 -I../../include -I. -Iapi -DLZMA_API_STATIC -DHAVE_CONFIG_H
> 	-DWIN32  -O3 -Wall -pedantic -march=core-avx-i -O3 --param l1-cache-line-size=64
> 	 --param l1-cache-size=32 --param l2-cache-size=256   -c alone_decoder.c -o alone_decoder.o
> 	cc1.exe: fatal error: alone_decoder.c: Permission denied
> 	compilation terminated.
> 	make[5]: *** [alone_decoder.o] Error 1
> 	make[4]: *** [all] Error 2
> 	make[3]: *** [rlibs] Error 1
> 	make[2]: *** [../../bin/x64/R.dll] Error 2
> 	make[1]: *** [rbuild] Error 2
> 	make: *** [all] Error 2
>
> However, I do *not* get this error when compiling R-patched as of 9/17/2013 using the exact same parameters on the same system. What does this error mean? Is it possible something changed between that version and the release which is causing this error? What may I do to correct the error?


Well, there is a Windows binary for 3.0.2 on CRAN and we had no problems 
to build it. So probably the problem is on your end.

Best,
Uwe Ligges





> Thank you very much,
>
> Avraham Adler
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From skostysh at princeton.edu  Fri Oct  4 01:56:33 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Thu, 3 Oct 2013 19:56:33 -0400
Subject: [Rd] [PATCH] file.access returns success for NA
Message-ID: <CAE3=dmcrewPVnvMrYf6f2f-JAM-gbOeA6GScFL_8=APDauAchg@mail.gmail.com>

Currently on R I get the following:

> file.access(c("doesNotExist", NA))
doesNotExist <NA>
  -1    0

where 0 means success. Is the 0 correct? I was expecting either NA or -1.

?file.access does not mention how NA values should be handled. The
subsection "3.3.4 NA handling" from the R Language Definition manual
suggest to me that file.access should return NA if given NA. I
interpret it in this way because if an element in the input vector is
NA, that means that there is a filename that exists but is not known.
Thus, I thought that file.access should return NA because it is not
known whether the file corresponding to the missing filename exists.

Perhaps file.access acts in this way to maintain compatibility with
the S-PLUS function ?access? (which I currently do not have a way of
testing to see how it handles NAs) ? If this is the case, would a
patch for ?file.access be considered?

Below is a patch that changes the return of an NA to NA.

Index: trunk/src/main/platform.c
===================================================================
--- trunk/src/main/platform.c (revision 64011)
+++ trunk/src/main/platform.c (working copy)
@@ -1299,7 +1299,7 @@
  access(R_ExpandFileName(translateChar(STRING_ELT(fn, i))),
        modemask);
 #endif
- } else INTEGER(ans)[i] = FALSE;
+ } else INTEGER(ans)[i] = NA_INTEGER;
     UNPROTECT(1);
     return ans;
 }

Comments?

Scott

> sessionInfo()
R Under development (unstable) (2013-09-27 r64011)
Platform: x86_64-unknown-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
 [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
 [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base
>


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From i.costigan at me.com  Fri Oct  4 12:11:02 2013
From: i.costigan at me.com (Imanuel Costigan)
Date: Fri, 04 Oct 2013 20:11:02 +1000
Subject: [Rd] Possible POSIXlt / wday glitch & bugs.r-project.org status
Message-ID: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>

Wanted to raise two questions:

1. Is bugs.r-project.org down? I haven't been able to reach it for two or three days:

```
ping bugs.r-project.org
PING rbugs.research.att.com (207.140.168.137): 56 data bytes
Request timeout for icmp_seq 0
Request timeout for icmp_seq 1
Request timeout for icmp_seq 2
Request timeout for icmp_seq 3
Request timeout for icmp_seq 4
Request timeout for icmp_seq 5
Request timeout for icmp_seq 6
```

2. Is wday element of POSIXlt meant to be timezone invariant? You would expect the wday element to be invariant to the timezone of a date. That is, the same date/time instant of 5th October 2013 in both Australia/Sydney and UTC should be a Saturday (i.e. wday = 6). And indeed that is the case with 1 min past midnight on 5 October 2013:

```
library(lubridate)
d_utc <- ymd_hms(20131005000001, tz='UTC')
d_local <- ymd_hms(20131005000001, tz='Australia/Sydney')
as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 6
```

But this isn't always the case. For example,

```
d_utc <- ymd_hms(20381002000001, tz='UTC')
d_local <- ymd_hms(20381002000001, tz='Australia/Sydney')
as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 5
```

Is this expected behaviour? I would have expected a properly encoded date/time of 2 Oct 2038 to be a Saturday irrespective of its time zone.

Obligatory system dump:

```
> sessionInfo()
R version 3.0.1 (2013-05-16)
Platform: x86_64-apple-darwin12.4.0 (64-bit)

locale:
[1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base     

other attached packages:
[1] lubridate_1.3.0 testthat_0.7.1  devtools_1.3   

loaded via a namespace (and not attached):
 [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.3       evaluate_0.5.1    
 [5] ggplot2_0.9.3.1    grid_3.0.1         gtable_0.1.2       httr_0.2          
 [9] labeling_0.2       MASS_7.3-29        memoise_0.1        munsell_0.4.2     
[13] parallel_3.0.1     plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
[17] RCurl_1.95-4.1     reshape2_1.2.2     scales_0.2.3       stringr_0.6.2     
[21] tools_3.0.1        whisker_0.3-2     

```

Using R compiled by homebrew [1]. But also experiencing the same bug using R installed on Windows 7 from the CRAN binaries.

For those interested, I've also noted this on the `lubridate` Github issues page [2], even though this doesn't appear to be a lubridate issue.

Thanks for any help.

[1] http://brew.sh
[2] https://github.com/hadley/lubridate/issues/209


From Jens.Oehlschlaegel at truecluster.com  Thu Oct  3 16:44:19 2013
From: Jens.Oehlschlaegel at truecluster.com (=?ISO-8859-15?Q?Jens_Oehlschl=E4gel?=)
Date: Thu, 03 Oct 2013 16:44:19 +0200
Subject: [Rd]  read.table() with quoted integers
Message-ID: <524D82C3.6030206@truecluster.com>

I agree that quoted integer columns are not the most efficient way of 
delivering csv-files. However, the sad reality is that one receives such 
formats and still needs to read the data. Therefore it is not helpful to 
state that one should 'consider "character" to be the correct colClass 
in case an integer is surrounded by quotes'.

The philosophy of read.table.ffdf is delegating the actual csv-parsing 
to a parse engine 'similarly' parametrized like 'read.table'. It is not 
'bad coding practice' - but a conscious design decision - to assume that 
the parse engine behaves consistently, which read.table does not yet: it 
automatically recognizes a quoted integer column as 'integer', but when 
asked to explicitly interpret the column as 'integer' it does refuse to 
do so. So there is nothing wrong with read.table.ffdf (but something can 
be improved about read.table). It is *not* the 'best solution [...] to 
rewrite read.table.ffdf()' given that it nicely imports such data, see 
4+1 ways to do so below.

Jens Oehlschl?gel


# --- first create a csv file for demonstration 
-------------------------------
require(ff)
file <- "test.csv"
path <- "c:/tmp"
n <- 1e2
d <- data.frame(x=1:n, y=shQuote(1:n))
write.csv(d, file=file.path(path,file), row.names=FALSE, quote=FALSE)

# --- how to do it with read.table.ffdf 
---------------------------------------

# 1 let the parse engine ignore colClasses and hope for the best
fixedengine <- function(file, ..., colClasses=NA){
	read.csv(file, ...)
}
df <- read.table.ffdf(file=file.path(path,file), first.rows = 10, 
FUN="fixedengine")
df

# 2 Suspend colClasses(=NA) for the quoted integer column only
df <- read.csv.ffdf(file=file.path(path,file), first.rows = 10, 
colClasses=c("integer", NA))
df

# 3 do your own type conversion using transFUN
#  after reading the problematic column as character
# Being able to inject regexps is quite powerful isn't it?
# Or error handlinig in case of varying column format!
custominterp <- function(d){
	d[[2]] <- as.integer(gsub('"', '', d[[2]]))
	d
}
df <- read.table.ffdf(file=file.path(path,file), first.rows = 10, 
colClasses=c("integer", "character"), FUN="read.csv", transFUN=custominterp)
df

# 4 do your own line parsing and type conversion
# Here you can even handle non-standard formats
#  such as varying number of columns
customengine <- function(file, header=TRUE, col.names, colClasses=NA, 
nrows=0, skip=0, fileEncoding="", comment.char = ""){
	l <- scan(file, what="character", nlines=nrows+header, skip=skip, 
fileEncoding=fileEncoding, comment.char = comment.char)
	s <- do.call("rbind", strsplit(l, ","))
	if (header){
		d <- data.frame(as.integer(s[-1,1]), as.integer(gsub('"','',s[-1,2])))
		names(d) <- s[1,]
	}else{
		d <- data.frame(as.integer(s[,1]), as.integer(gsub('"','',s[,2])))
	}
	if (!missing(col.names))
		names(d) <- col.names
	d
}
df <- read.table.ffdf(file=file.path(path,file), first.rows = 10, 
FUN="customengine")
df

# 5 use a parsing engine that can apply colClasses to quoted integers
# Unfortunately Henry Bengtson's readDataFrame does not work as a
#  parse engine for read.table.ffdf because read.table.ffdf expects
#  the parse engine to read successive chunks from a file connection
#  while readDataFrame only accepts a filename as input file spec.
# Yes it has 'skip', but using that would reread the file from scratch
#  for each chunk (O(N^2) costs)


From Rainer at krugs.de  Fri Oct  4 12:59:25 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 4 Oct 2013 12:59:25 +0200
Subject: [Rd] check warning  with .onLoad() and setClass()
In-Reply-To: <AD583E37-4E49-406C-B4A8-8F13C31E9B14@r-project.org> (John
	Chambers's message of "Thu, 3 Oct 2013 10:03:29 -0700")
References: <m2zjqqfybi.fsf@krugs.de>
	<AD583E37-4E49-406C-B4A8-8F13C31E9B14@r-project.org>
Message-ID: <m28uy9b8tu.fsf@krugs.de>

Thanks John

that is likely the solution to my problem, but I don't understand how I
can use it and I can't find the example in the Rcpp package (I did grep
for setLoadAtion on the whole source package of Rcpp, but nothing came up with ). Could you
please provide me a link (or the filename) where I can see how to use
this function?

Thanks,

Rainer

John Chambers <jmc at r-project.org> writes:

> Don't use .onLoad() to set class (or other nontrivial) information at
> load time.  Use setLoadActions(), which was created exactly to get
> around the limitations of .onLoad().
>
> For an example, see the Rcpp package, which uses this to set up load-time C++ linkages.
>
> John Chambers
>
> On Oct 3, 2013, at 3:22 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>
>> Hi
>> 
>> I am writing a package in which I define a new class in the .onLoad()
>> hook:
>> 
>> ,----
>> | .onLoad <- function(libname, pkgname) {
>> |     setClass(
>> |         "inDrak",
>> |         representation(
>> |             init = "SpatialGridDataFrame"
>> |             ),
>> |         contains = "simObj"
>> |         )
>> | }
>> `----
>> 
>> The class "simObj" is defined in the package, which is in the depends
>> section in the DESCRIPTION file:
>> 
>> ,----
>> | Package: InDrak
>> | Type: Package
>> | Title: Alien spread management simulation model for the Drakensberg
>> | Version: 0.1-0
>> | Date: 2013-10-03_11-55
>> | Author: Rainer M. Krug
>> | Maintainer: Rainer M Krug <Rainer at krugs.de>
>> | Description: Simulate the spread of three Invasive Alien Plants under different
>> |     management and budget scenarios
>> | License: GPL-3
>> | LazyLoad: yes
>> | Depends:
>> |     RSQLite,
>> |     simecol
>> | Imports:
>> |     methods,
>> |     sp,
>> |     spgrass6,
>> |     DBI,
>> |     logger,
>> |     fireSim,
>> |     seedProd,
>> |     seedGerm,
>> |     seedDisp
>> | LinkingTo: Rcpp
>> | Collate:
>> |     'beginYear.R'
>> |     'clearAliens.R'
>> |     'competition.R'
>> |     'cumulativeDc.R'
>> |     'dcToIndLayer.R'
>> |     'dispProb2D.R'
>> |     'endYear.R'
>> |     'fireAliens.R'
>> |     'germEst.R'
>> |     'initfunc.R'
>> |     'layerIO.R'
>> |     'layerNames.R'
>> |     'main.R'
>> |     'newInDrak.R'
>> |     'onLoad.R'
>> |     'package.R'
>> |     'parameter.R'
>> |     'parmsAcacia.R'
>> |     'parmsBudget.R'
>> |     'parmsFire.R'
>> |     'parmsPinus.R'
>> |     'parmsRubus.R'
>> |     'resetOptions.R'
>> |     'seedDispersal.R'
>> |     'seedProduction.R'
>> |     'stats.R'
>> `----
>> 
>> If important, the NAMESPACE file is here:
>> 
>> ,----
>> | export(depRateName)
>> | export(exportRaster)
>> | export(fireLayerName)
>> | export(ignitionRiskName)
>> | export(importAliens)
>> | export(importClearingHistory)
>> | export(importFireHistory)
>> | export(importIgnitionRisk)
>> | export(importSpecies)
>> | export(importVegetation)
>> | export(layerExists)
>> | export(layerName)
>> | export(newInDrak)
>> | export(parameter)
>> | export(parmsAcacia)
>> | export(parmsBudget)
>> | export(parmsFire)
>> | export(parmsPinus)
>> | export(parmsRubus)
>> | export(resetOptions)
>> | export(statDistName)
>> | export(suitName)
>> | import(DBI)
>> | import(fireSim)
>> | import(logger)
>> | import(methods)
>> | import(seedDisp)
>> | import(seedGerm)
>> | import(seedProd)
>> | import(sp)
>> | import(spgrass6)
>> `----
>> 
>> The package builds fine, it installs without problems and works as
>> expected, but when checking it, I get the following error:
>> 
>> ,----
>> | $ R CMD check ./InDrak_0.1-0.tar.gz 
>> | * using log directory ?/Users/rainerkrug/Documents/Projects/R-Packages/inDrak/InDrak.Rcheck?
>> | * using R version 3.0.1 (2013-05-16)
>> | * using platform: x86_64-apple-darwin10.8.0 (64-bit)
>> | * using session charset: UTF-8
>> | * checking for file ?InDrak/DESCRIPTION? ... OK
>> | * checking extension type ... Package
>> | * this is package ?InDrak? version ?0.1-0?
>> | * checking package namespace information ... OK
>> | * checking package dependencies ... OK
>> | * checking if this is a source package ... OK
>> | * checking if there is a namespace ... OK
>> | * checking for executable files ... OK
>> | * checking for hidden files and directories ... OK
>> | * checking for portable file names ... OK
>> | * checking for sufficient/correct file permissions ... OK
>> | * checking whether package ?InDrak? can be installed ... OK
>> | * checking installed package size ... OK
>> | * checking package directory ... OK
>> | * checking DESCRIPTION meta-information ... OK
>> | * checking top-level files ... OK
>> | * checking for left-over files ... OK
>> | * checking index information ... OK
>> | * checking package subdirectories ... OK
>> | * checking R files for non-ASCII characters ... OK
>> | * checking R files for syntax errors ... OK
>> | * checking whether the package can be loaded ... OK
>> | * checking whether the package can be loaded with stated dependencies ... OK
>> | * checking whether the package can be unloaded cleanly ... OK
>> | * checking whether the namespace can be loaded with stated dependencies ... WARNING
>> | Error: .onLoad failed in loadNamespace() for ?InDrak?, details:
>> |   call: reconcilePropertiesAndPrototype(name, slots, prototype, superClasses, 
>> |   error: no definition was found for superclass ?simObj? in the specification of class ?inDrak?
>> | Execution halted
>> | 
>> | A namespace must be able to be loaded with just the base namespace
>> | loaded: otherwise if the namespace gets loaded by a saved object, the
>> | session will be unable to start.
>> | 
>> | Probably some imports need to be declared in the NAMESPACE file.
>> | * checking whether the namespace can be unloaded cleanly ... WARNING
>> | Error: .onLoad failed in loadNamespace() for ?InDrak?, details:
>> |   call: reconcilePropertiesAndPrototype(name, slots, prototype, superClasses, 
>> |   error: no definition was found for superclass ?simObj? in the specification of class ?inDrak?
>> | Execution halted
>> | * checking loading without being on the library search path ... OK
>> | * checking for unstated dependencies in R code ... OK
>> | * checking S3 generic/method consistency ... OK
>> | * checking replacement functions ... OK
>> | * checking foreign function calls ... OK
>> | * checking R code for possible problems ... NOTE
>> | .initfunc: no visible global function definition for
>> |   ?initialSeedProductionAliens?
>> | .initfunc: no visible global function definition for ?endYear?
>> | .main: no visible global function definition for ?beginYear?
>> | .main: no visible global function definition for ?fireAliens?
>> | .main: no visible global function definition for ?seedProductionAliens?
>> | .main: no visible global function definition for ?seedDispersalAliens?
>> | .main: no visible global function definition for ?germEstAliens?
>> | .main: no visible global function definition for ?endYear?
>> | * checking Rd files ... OK
>> | * checking Rd metadata ... OK
>> | * checking Rd cross-references ... OK
>> | * checking for missing documentation entries ... OK
>> | * checking for code/documentation mismatches ... OK
>> | * checking Rd \usage sections ... OK
>> | * checking Rd contents ... OK
>> | * checking for unstated dependencies in examples ... OK
>> | * checking examples ... NONE
>> | * checking PDF version of manual ... OK
>> | 
>> | WARNING: There were 2 warnings.
>> | NOTE: There was 1 note.
>> | See
>> |   ?/Users/rainerkrug/Documents/Projects/R-Packages/inDrak/InDrak.Rcheck/00check.log?
>> | for details.
>> `----
>> 
>> I am sure I am missing something simple here and I really think I
>> overlooked it in the "Writing R extensions"...
>> 
>> Thanks,
>> 
>> Rainer
>> 
>> -- 
>> Rainer M. Krug
>> 
>> email: RMKrug<at>gmail<dot>com
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
<#secure method=pgpmime mode=sign>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug


From josh.m.ulrich at gmail.com  Fri Oct  4 13:31:49 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 4 Oct 2013 06:31:49 -0500
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <F677287B-2406-46BB-9108-34D588B330EA@comcast.net>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<F677287B-2406-46BB-9108-34D588B330EA@comcast.net>
Message-ID: <CAPPM_gS1xxSXSnCA0W-+zh3EwoJ89BcxFXyxvffXzujqV7Qi5w@mail.gmail.com>

On Tue, Oct 1, 2013 at 11:29 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>
> On Sep 30, 2013, at 6:38 AM, Joshua Ulrich wrote:
>
>> On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
>>> Hi!
>>>
>>>
>>> It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
>>> quoted integers as an acceptable value for columns for which
>>> colClasses="integer". But when colClasses is omitted, these columns are
>>> read as integer anyway.
>>>
>>> For example, let's consider a file named file.dat, containing:
>>> "1"
>>> "2"
>>>
>>>> read.table("file.dat", colClasses="integer")
>>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :
>>>  scan() expected 'an integer' and got '"1"'
>>>
>>> But:
>>>> str(read.table("file.dat"))
>>> 'data.frame':   2 obs. of  1 variable:
>>> $ V1: int  1 2
>>>
>>> The latter result is indeed documented in ?read.table:
>>>     Unless ?colClasses? is specified, all columns are read as
>>>     character columns and then converted using ?type.convert? to
>>>     logical, integer, numeric, complex or (depending on ?as.is?)
>>>     factor as appropriate.  Quotes are (by default) interpreted in all
>>>     fields, so a column of values like ?"42"? will result in an
>>>     integer column.
>>>
>>>
>>> Should the former behavior be considered a bug?
>>>
>> No. If you tell read.table the column is integer and it's actually
>> character on disk, it should be an error.
>
> My reading of the `read.table` help page is that one should expect that when
> there is an 'integer'-class and an  `as.integer` function and  "integer" is the
> argument to colClasses, that `as.integer` will be applied to the values in the
> column. Should I be reading elsewhere?
>
I assume you're referring to the paragraph below.

  Possible values are ?NA? (the default, when ?type.convert? is
  used), ?"NULL"? (when the column is skipped), one of the
  atomic vector classes (logical, integer, numeric, complex,
  character, raw), or ?"factor"?, ?"Date"? or ?"POSIXct"?.
  Otherwise there needs to be an ?as? method (from package
  ?methods?) for conversion from ?"character"? to the specified
  formal class.

I read that as meaning that an "as" method is required for classes not
already listed in the prior sentence.  It doesn't say an "as" method
will be applied if colClasses is one of the atomic, factor, Date, or
POSIXct classes; but I can see how you might assume that, since all
the atomic, factor, Date, and POSIXct classes already have "as"
methods...

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From edd at debian.org  Fri Oct  4 13:49:55 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 4 Oct 2013 06:49:55 -0500
Subject: [Rd] check warning  with .onLoad() and setClass()
In-Reply-To: <m28uy9b8tu.fsf@krugs.de>
References: <m2zjqqfybi.fsf@krugs.de>
	<AD583E37-4E49-406C-B4A8-8F13C31E9B14@r-project.org>
	<m28uy9b8tu.fsf@krugs.de>
Message-ID: <21070.43875.526391.331124@max.nulle.part>


On 4 October 2013 at 12:59, Rainer M Krug wrote:
| Thanks John
| 
| that is likely the solution to my problem, but I don't understand how I
| can use it and I can't find the example in the Rcpp package (I did grep
| for setLoadAtion on the whole source package of Rcpp, but nothing came up with ). Could you
| please provide me a link (or the filename) where I can see how to use
| this function?

Alternatively just call

   loadModules("simObj", TRUE)

in one of the R/*R files, eg in RcppCNPy I load the module from R/cnpy.R --
and it's the sole R statement in that package as everything happens in the
Modules declaration over in in the src/ directory:

   edd at max:~$ cat svn/rcpp/pkg/RcppCNPy/R/*
   
   loadModule("cnpy", TRUE)
   
   
   edd at max:~$ 

If you had several modules, you'd need to issue a loadModules(...) for each.
Oh, and rcpp-devel is still ready, willing and able for Rcpp questions. ;-)

Hth, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From murdoch.duncan at gmail.com  Fri Oct  4 13:55:43 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 04 Oct 2013 07:55:43 -0400
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <CAPPM_gS1xxSXSnCA0W-+zh3EwoJ89BcxFXyxvffXzujqV7Qi5w@mail.gmail.com>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<F677287B-2406-46BB-9108-34D588B330EA@comcast.net>
	<CAPPM_gS1xxSXSnCA0W-+zh3EwoJ89BcxFXyxvffXzujqV7Qi5w@mail.gmail.com>
Message-ID: <524EACBF.20107@gmail.com>

On 13-10-04 7:31 AM, Joshua Ulrich wrote:
> On Tue, Oct 1, 2013 at 11:29 AM, David Winsemius <dwinsemius at comcast.net> wrote:
>>
>> On Sep 30, 2013, at 6:38 AM, Joshua Ulrich wrote:
>>
>>> On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
>>>> Hi!
>>>>
>>>>
>>>> It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
>>>> quoted integers as an acceptable value for columns for which
>>>> colClasses="integer". But when colClasses is omitted, these columns are
>>>> read as integer anyway.
>>>>
>>>> For example, let's consider a file named file.dat, containing:
>>>> "1"
>>>> "2"
>>>>
>>>>> read.table("file.dat", colClasses="integer")
>>>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :
>>>>   scan() expected 'an integer' and got '"1"'
>>>>
>>>> But:
>>>>> str(read.table("file.dat"))
>>>> 'data.frame':   2 obs. of  1 variable:
>>>> $ V1: int  1 2
>>>>
>>>> The latter result is indeed documented in ?read.table:
>>>>      Unless ?colClasses? is specified, all columns are read as
>>>>      character columns and then converted using ?type.convert? to
>>>>      logical, integer, numeric, complex or (depending on ?as.is?)
>>>>      factor as appropriate.  Quotes are (by default) interpreted in all
>>>>      fields, so a column of values like ?"42"? will result in an
>>>>      integer column.
>>>>
>>>>
>>>> Should the former behavior be considered a bug?
>>>>
>>> No. If you tell read.table the column is integer and it's actually
>>> character on disk, it should be an error.
>>
>> My reading of the `read.table` help page is that one should expect that when
>> there is an 'integer'-class and an  `as.integer` function and  "integer" is the
>> argument to colClasses, that `as.integer` will be applied to the values in the
>> column. Should I be reading elsewhere?
>>
> I assume you're referring to the paragraph below.
>
>    Possible values are ?NA? (the default, when ?type.convert? is
>    used), ?"NULL"? (when the column is skipped), one of the
>    atomic vector classes (logical, integer, numeric, complex,
>    character, raw), or ?"factor"?, ?"Date"? or ?"POSIXct"?.
>    Otherwise there needs to be an ?as? method (from package
>    ?methods?) for conversion from ?"character"? to the specified
>    formal class.
>
> I read that as meaning that an "as" method is required for classes not
> already listed in the prior sentence.  It doesn't say an "as" method
> will be applied if colClasses is one of the atomic, factor, Date, or
> POSIXct classes; but I can see how you might assume that, since all
> the atomic, factor, Date, and POSIXct classes already have "as"
> methods...

And this does suggest a workaround for ffdf:  instead of declaring the 
class to be "integer", declare a class "ffdf_integer", and write a 
conversion method.  Or simply read everything as character and call 
as.integer() explicitly.

Duncan Murdoch


From Rainer at krugs.de  Fri Oct  4 14:15:34 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 4 Oct 2013 14:15:34 +0200
Subject: [Rd] check warning  with .onLoad() and setClass()
In-Reply-To: <21070.43875.526391.331124@max.nulle.part> (Dirk Eddelbuettel's
	message of "Fri, 4 Oct 2013 06:49:55 -0500")
References: <m2zjqqfybi.fsf@krugs.de>
	<AD583E37-4E49-406C-B4A8-8F13C31E9B14@r-project.org>
	<m28uy9b8tu.fsf@krugs.de> <21070.43875.526391.331124@max.nulle.part>
Message-ID: <m2fvshfd09.fsf@krugs.de>

Dirk Eddelbuettel <edd at debian.org> writes:

> On 4 October 2013 at 12:59, Rainer M Krug wrote:
> | Thanks John
> | 
> | that is likely the solution to my problem, but I don't understand
> | how I
> | can use it and I can't find the example in the Rcpp package (I did
> | grep
> | for setLoadAtion on the whole source package of Rcpp, but nothing
> | came up with ). Could you
> | please provide me a link (or the filename) where I can see how to
> | use
> | this function?
>
> Alternatively just call
>
>    loadModules("simObj", TRUE)

Hm. loadModule is Rcpp function, but I am only interested in using the
setClass() function, which has nothing to do with Rcpp. I don't even use
Rcpp in the package, only in one which is imported.

>
> in one of the R/*R files, eg in RcppCNPy I load the module from
> R/cnpy.R --
> and it's the sole R statement in that package as everything happens in
> the
> Modules declaration over in in the src/ directory:
>
>    edd at max:~$ cat svn/rcpp/pkg/RcppCNPy/R/*
>    
>    loadModule("cnpy", TRUE)
>    
>    
>    edd at max:~$ 
>
> If you had several modules, you'd need to issue a loadModules(...) for
> each.
> Oh, and rcpp-devel is still ready, willing and able for Rcpp
> questions. ;-)

Thanks - but unless I am missing something here, this has nothing to do
with Rcpp and only concerns basic package writing. John Chambers only
referred me to an example in Rcpp which I can not find.

And I am definitely going to ask Rcpp questions there.

>
> Hth, Dirk

I guess not much this time - sorry Dirk.

Rainer

<#secure method=pgpmime mode=sign>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug


From friendly at yorku.ca  Fri Oct  4 14:34:12 2013
From: friendly at yorku.ca (Michael Friendly)
Date: Fri, 04 Oct 2013 08:34:12 -0400
Subject: [Rd] bug/infelicity in citation("base")
Message-ID: <524EB5C4.5090401@yorku.ca>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131004/a278d2c9/attachment.pl>

From josh.m.ulrich at gmail.com  Fri Oct  4 14:34:20 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 4 Oct 2013 07:34:20 -0500
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <524D82C3.6030206@truecluster.com>
References: <524D82C3.6030206@truecluster.com>
Message-ID: <CAPPM_gRs_569M0CS+Wi1v3K9FA635DdqKtVD_3Ksz0-3jR56ew@mail.gmail.com>

On Thu, Oct 3, 2013 at 9:44 AM, Jens Oehlschl?gel
<Jens.Oehlschlaegel at truecluster.com> wrote:
> I agree that quoted integer columns are not the most efficient way of
> delivering csv-files. However, the sad reality is that one receives such
> formats and still needs to read the data. Therefore it is not helpful to
> state that one should 'consider "character" to be the correct colClass in
> case an integer is surrounded by quotes'.
>
> The philosophy of read.table.ffdf is delegating the actual csv-parsing to a
> parse engine 'similarly' parametrized like 'read.table'. It is not 'bad
> coding practice' - but a conscious design decision - to assume that the
> parse engine behaves consistently, which read.table does not yet: it
> automatically recognizes a quoted integer column as 'integer', but when
> asked to explicitly interpret the column as 'integer' it does refuse to do

read.table() does not "automatically recognize a quoted integer column
as 'integer'".  If colClasses is not specified, it reads the entire
column into a 'character' vector and then calls type.convert() on it.
type.convert() does all the necessary work to determine what class the
'character' vector should be converted to.  If colClasses is
specified, quotes are not interpreted in non-'character' columns.

You want scan() to allocate an 'integer' vector, and then ensure (on
each read from the column in the file) that the value read is a valid
'integer' type, while interpreting quotes (which strtol does not do,
so someone would have to write and test this new functionality).

So your complaint is more with scan() than read.table().  And more
with Strtoi() (and therefore strtol) than scan().

> so. So there is nothing wrong with read.table.ffdf (but something can be
> improved about read.table). It is *not* the 'best solution [...] to rewrite
> read.table.ffdf()' given that it nicely imports such data, see 4+1 ways to
> do so below.
>
> Jens Oehlschl?gel
>
>
> # --- first create a csv file for demonstration
> -------------------------------
> require(ff)
> file <- "test.csv"
> path <- "c:/tmp"
> n <- 1e2
> d <- data.frame(x=1:n, y=shQuote(1:n))
> write.csv(d, file=file.path(path,file), row.names=FALSE, quote=FALSE)
>
> # --- how to do it with read.table.ffdf
> ---------------------------------------
>
> # 1 let the parse engine ignore colClasses and hope for the best
> fixedengine <- function(file, ..., colClasses=NA){
>         read.csv(file, ...)
> }
> df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
> FUN="fixedengine")
> df
>
> # 2 Suspend colClasses(=NA) for the quoted integer column only
> df <- read.csv.ffdf(file=file.path(path,file), first.rows = 10,
> colClasses=c("integer", NA))
> df
>
> # 3 do your own type conversion using transFUN
> #  after reading the problematic column as character
> # Being able to inject regexps is quite powerful isn't it?
> # Or error handlinig in case of varying column format!
> custominterp <- function(d){
>         d[[2]] <- as.integer(gsub('"', '', d[[2]]))
>         d
> }
> df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
> colClasses=c("integer", "character"), FUN="read.csv", transFUN=custominterp)
> df
>
> # 4 do your own line parsing and type conversion
> # Here you can even handle non-standard formats
> #  such as varying number of columns
> customengine <- function(file, header=TRUE, col.names, colClasses=NA,
> nrows=0, skip=0, fileEncoding="", comment.char = ""){
>         l <- scan(file, what="character", nlines=nrows+header, skip=skip,
> fileEncoding=fileEncoding, comment.char = comment.char)
>         s <- do.call("rbind", strsplit(l, ","))
>         if (header){
>                 d <- data.frame(as.integer(s[-1,1]),
> as.integer(gsub('"','',s[-1,2])))
>                 names(d) <- s[1,]
>         }else{
>                 d <- data.frame(as.integer(s[,1]),
> as.integer(gsub('"','',s[,2])))
>         }
>         if (!missing(col.names))
>                 names(d) <- col.names
>         d
> }
> df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
> FUN="customengine")
> df
>
> # 5 use a parsing engine that can apply colClasses to quoted integers
> # Unfortunately Henry Bengtson's readDataFrame does not work as a
> #  parse engine for read.table.ffdf because read.table.ffdf expects
> #  the parse engine to read successive chunks from a file connection
> #  while readDataFrame only accepts a filename as input file spec.
> # Yes it has 'skip', but using that would reread the file from scratch
> #  for each chunk (O(N^2) costs)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


From josh.m.ulrich at gmail.com  Fri Oct  4 14:50:09 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 4 Oct 2013 07:50:09 -0500
Subject: [Rd] Possible POSIXlt / wday glitch & bugs.r-project.org status
In-Reply-To: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
References: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
Message-ID: <CAPPM_gST-q+VapGdufsQ9fgUOBVg0UcJhw4F1cqMrskBXE2ZTA@mail.gmail.com>

Quoting from ?timezone:

     Note that except on Windows, the operation of time zones is an OS
     service, and even on Windows a third-party database is used and
     can be updated (see the section on ?Time zone names?).  Incorrect
     results will never be an R issue, so please ensure that you have
     the courtesy not to blame R for them.

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


On Fri, Oct 4, 2013 at 5:11 AM, Imanuel Costigan <i.costigan at me.com> wrote:
> Wanted to raise two questions:
>
> 1. Is bugs.r-project.org down? I haven't been able to reach it for two or three days:
>
> ```
> ping bugs.r-project.org
> PING rbugs.research.att.com (207.140.168.137): 56 data bytes
> Request timeout for icmp_seq 0
> Request timeout for icmp_seq 1
> Request timeout for icmp_seq 2
> Request timeout for icmp_seq 3
> Request timeout for icmp_seq 4
> Request timeout for icmp_seq 5
> Request timeout for icmp_seq 6
> ```
>
> 2. Is wday element of POSIXlt meant to be timezone invariant? You would expect the wday element to be invariant to the timezone of a date. That is, the same date/time instant of 5th October 2013 in both Australia/Sydney and UTC should be a Saturday (i.e. wday = 6). And indeed that is the case with 1 min past midnight on 5 October 2013:
>
> ```
> library(lubridate)
> d_utc <- ymd_hms(20131005000001, tz='UTC')
> d_local <- ymd_hms(20131005000001, tz='Australia/Sydney')
> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 6
> ```
>
> But this isn't always the case. For example,
>
> ```
> d_utc <- ymd_hms(20381002000001, tz='UTC')
> d_local <- ymd_hms(20381002000001, tz='Australia/Sydney')
> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 5
> ```
>
> Is this expected behaviour? I would have expected a properly encoded date/time of 2 Oct 2038 to be a Saturday irrespective of its time zone.
>
> Obligatory system dump:
>
> ```
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-apple-darwin12.4.0 (64-bit)
>
> locale:
> [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lubridate_1.3.0 testthat_0.7.1  devtools_1.3
>
> loaded via a namespace (and not attached):
>  [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.3       evaluate_0.5.1
>  [5] ggplot2_0.9.3.1    grid_3.0.1         gtable_0.1.2       httr_0.2
>  [9] labeling_0.2       MASS_7.3-29        memoise_0.1        munsell_0.4.2
> [13] parallel_3.0.1     plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
> [17] RCurl_1.95-4.1     reshape2_1.2.2     scales_0.2.3       stringr_0.6.2
> [21] tools_3.0.1        whisker_0.3-2
>
> ```
>
> Using R compiled by homebrew [1]. But also experiencing the same bug using R installed on Windows 7 from the CRAN binaries.
>
> For those interested, I've also noted this on the `lubridate` Github issues page [2], even though this doesn't appear to be a lubridate issue.
>
> Thanks for any help.
>
> [1] http://brew.sh
> [2] https://github.com/hadley/lubridate/issues/209
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Fri Oct  4 14:51:19 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 4 Oct 2013 07:51:19 -0500
Subject: [Rd] check warning  with .onLoad() and setClass()
In-Reply-To: <m2fvshfd09.fsf@krugs.de>
References: <m2zjqqfybi.fsf@krugs.de>
	<AD583E37-4E49-406C-B4A8-8F13C31E9B14@r-project.org>
	<m28uy9b8tu.fsf@krugs.de>
	<21070.43875.526391.331124@max.nulle.part>
	<m2fvshfd09.fsf@krugs.de>
Message-ID: <21070.47559.867778.190980@max.nulle.part>


On 4 October 2013 at 14:15, Rainer M Krug wrote:
| Hm. loadModule is Rcpp function, but I am only interested in using the
| setClass() function, which has nothing to do with Rcpp. I don't even use
| Rcpp in the package, only in one which is imported.

Sorry, assumed Reference Class created via Modules. My bad, and never mind.

But as John said, .onLoad() can be replaces since he made those changes in R
(and also in Rcpp). See ?setLoadAction, evalOnLoad(), ...

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From nalimilan at club.fr  Fri Oct  4 15:58:25 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Fri, 04 Oct 2013 15:58:25 +0200
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <CAPPM_gRs_569M0CS+Wi1v3K9FA635DdqKtVD_3Ksz0-3jR56ew@mail.gmail.com>
References: <524D82C3.6030206@truecluster.com>
	<CAPPM_gRs_569M0CS+Wi1v3K9FA635DdqKtVD_3Ksz0-3jR56ew@mail.gmail.com>
Message-ID: <1380895105.13506.77.camel@milan>

Le vendredi 04 octobre 2013 ? 07:34 -0500, Joshua Ulrich a ?crit :
> On Thu, Oct 3, 2013 at 9:44 AM, Jens Oehlschl?gel
> <Jens.Oehlschlaegel at truecluster.com> wrote:
> > I agree that quoted integer columns are not the most efficient way of
> > delivering csv-files. However, the sad reality is that one receives such
> > formats and still needs to read the data. Therefore it is not helpful to
> > state that one should 'consider "character" to be the correct colClass in
> > case an integer is surrounded by quotes'.
> >
> > The philosophy of read.table.ffdf is delegating the actual csv-parsing to a
> > parse engine 'similarly' parametrized like 'read.table'. It is not 'bad
> > coding practice' - but a conscious design decision - to assume that the
> > parse engine behaves consistently, which read.table does not yet: it
> > automatically recognizes a quoted integer column as 'integer', but when
> > asked to explicitly interpret the column as 'integer' it does refuse to do
> 
> read.table() does not "automatically recognize a quoted integer column
> as 'integer'".  If colClasses is not specified, it reads the entire
> column into a 'character' vector and then calls type.convert() on it.
> type.convert() does all the necessary work to determine what class the
> 'character' vector should be converted to.  If colClasses is
> specified, quotes are not interpreted in non-'character' columns.
That's pretty much the definition of "automatic". The fact that this is
realized by type.convert() is really an implementation detail. But
there's little point in discussing the question of whether this is
automatic enough. Better concentrate on the actual result.

> You want scan() to allocate an 'integer' vector, and then ensure (on
> each read from the column in the file) that the value read is a valid
> 'integer' type, while interpreting quotes (which strtol does not do,
> so someone would have to write and test this new functionality).
Yes, I think that's where the change should go. From a first look at
scan.c:extractItem(), it seems that adapting scan() to skip quotes in
the string before calling Strtoi() would not be too invasive and would
not create a significant overhead. No string copy would even be involved
since the pointer to the beginning of the string would just have to be
increased to skip the quote character, and the null character be added a
little earlier in the string.

So this line:
	    INTEGER(ans)[i] = Strtoi(buffer, 10);

would just have to be changed to something like:
            char *quote;

            if(buffer[0] == '\"' && (quote = strchr(buffer += 1, '\"')) != NULL)
                *quote = '\0';

	    INTEGER(ans)[i] = Strtoi(buffer, 10);


For cleaner operation, the hardcoded '\"' could be replaced with the
contents of read.table()'s quote argument.


What do R core developers think about this small modification?


> So your complaint is more with scan() than read.table().  And more
> with Strtoi() (and therefore strtol) than scan().
The complaint is about the combination of read.table() and scan(). It
has nothing to do with strtol(), which has no reason to accept quotes as
it's not designed to read CSV files...


Regards

> > so. So there is nothing wrong with read.table.ffdf (but something can be
> > improved about read.table). It is *not* the 'best solution [...] to rewrite
> > read.table.ffdf()' given that it nicely imports such data, see 4+1 ways to
> > do so below.
> >
> > Jens Oehlschl?gel
> >
> >
> > # --- first create a csv file for demonstration
> > -------------------------------
> > require(ff)
> > file <- "test.csv"
> > path <- "c:/tmp"
> > n <- 1e2
> > d <- data.frame(x=1:n, y=shQuote(1:n))
> > write.csv(d, file=file.path(path,file), row.names=FALSE, quote=FALSE)
> >
> > # --- how to do it with read.table.ffdf
> > ---------------------------------------
> >
> > # 1 let the parse engine ignore colClasses and hope for the best
> > fixedengine <- function(file, ..., colClasses=NA){
> >         read.csv(file, ...)
> > }
> > df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
> > FUN="fixedengine")
> > df
> >
> > # 2 Suspend colClasses(=NA) for the quoted integer column only
> > df <- read.csv.ffdf(file=file.path(path,file), first.rows = 10,
> > colClasses=c("integer", NA))
> > df
> >
> > # 3 do your own type conversion using transFUN
> > #  after reading the problematic column as character
> > # Being able to inject regexps is quite powerful isn't it?
> > # Or error handlinig in case of varying column format!
> > custominterp <- function(d){
> >         d[[2]] <- as.integer(gsub('"', '', d[[2]]))
> >         d
> > }
> > df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
> > colClasses=c("integer", "character"), FUN="read.csv", transFUN=custominterp)
> > df
> >
> > # 4 do your own line parsing and type conversion
> > # Here you can even handle non-standard formats
> > #  such as varying number of columns
> > customengine <- function(file, header=TRUE, col.names, colClasses=NA,
> > nrows=0, skip=0, fileEncoding="", comment.char = ""){
> >         l <- scan(file, what="character", nlines=nrows+header, skip=skip,
> > fileEncoding=fileEncoding, comment.char = comment.char)
> >         s <- do.call("rbind", strsplit(l, ","))
> >         if (header){
> >                 d <- data.frame(as.integer(s[-1,1]),
> > as.integer(gsub('"','',s[-1,2])))
> >                 names(d) <- s[1,]
> >         }else{
> >                 d <- data.frame(as.integer(s[,1]),
> > as.integer(gsub('"','',s[,2])))
> >         }
> >         if (!missing(col.names))
> >                 names(d) <- col.names
> >         d
> > }
> > df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
> > FUN="customengine")
> > df
> >
> > # 5 use a parsing engine that can apply colClasses to quoted integers
> > # Unfortunately Henry Bengtson's readDataFrame does not work as a
> > #  parse engine for read.table.ffdf because read.table.ffdf expects
> > #  the parse engine to read successive chunks from a file connection
> > #  while readDataFrame only accepts a filename as input file spec.
> > # Yes it has 'skip', but using that would reread the file from scratch
> > #  for each chunk (O(N^2) costs)
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> --
> Joshua Ulrich  |  about.me/joshuaulrich
> FOSS Trading  |  www.fosstrading.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nalimilan at club.fr  Fri Oct  4 16:01:46 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Fri, 04 Oct 2013 16:01:46 +0200
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <524EACBF.20107@gmail.com>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<F677287B-2406-46BB-9108-34D588B330EA@comcast.net>
	<CAPPM_gS1xxSXSnCA0W-+zh3EwoJ89BcxFXyxvffXzujqV7Qi5w@mail.gmail.com>
	<524EACBF.20107@gmail.com>
Message-ID: <1380895306.13506.79.camel@milan>

Le vendredi 04 octobre 2013 ? 07:55 -0400, Duncan Murdoch a ?crit :
> On 13-10-04 7:31 AM, Joshua Ulrich wrote:
> > On Tue, Oct 1, 2013 at 11:29 AM, David Winsemius <dwinsemius at comcast.net> wrote:
> >>
> >> On Sep 30, 2013, at 6:38 AM, Joshua Ulrich wrote:
> >>
> >>> On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> >>>> Hi!
> >>>>
> >>>>
> >>>> It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
> >>>> quoted integers as an acceptable value for columns for which
> >>>> colClasses="integer". But when colClasses is omitted, these columns are
> >>>> read as integer anyway.
> >>>>
> >>>> For example, let's consider a file named file.dat, containing:
> >>>> "1"
> >>>> "2"
> >>>>
> >>>>> read.table("file.dat", colClasses="integer")
> >>>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings, :
> >>>>   scan() expected 'an integer' and got '"1"'
> >>>>
> >>>> But:
> >>>>> str(read.table("file.dat"))
> >>>> 'data.frame':   2 obs. of  1 variable:
> >>>> $ V1: int  1 2
> >>>>
> >>>> The latter result is indeed documented in ?read.table:
> >>>>      Unless ?colClasses? is specified, all columns are read as
> >>>>      character columns and then converted using ?type.convert? to
> >>>>      logical, integer, numeric, complex or (depending on ?as.is?)
> >>>>      factor as appropriate.  Quotes are (by default) interpreted in all
> >>>>      fields, so a column of values like ?"42"? will result in an
> >>>>      integer column.
> >>>>
> >>>>
> >>>> Should the former behavior be considered a bug?
> >>>>
> >>> No. If you tell read.table the column is integer and it's actually
> >>> character on disk, it should be an error.
> >>
> >> My reading of the `read.table` help page is that one should expect that when
> >> there is an 'integer'-class and an  `as.integer` function and  "integer" is the
> >> argument to colClasses, that `as.integer` will be applied to the values in the
> >> column. Should I be reading elsewhere?
> >>
> > I assume you're referring to the paragraph below.
> >
> >    Possible values are ?NA? (the default, when ?type.convert? is
> >    used), ?"NULL"? (when the column is skipped), one of the
> >    atomic vector classes (logical, integer, numeric, complex,
> >    character, raw), or ?"factor"?, ?"Date"? or ?"POSIXct"?.
> >    Otherwise there needs to be an ?as? method (from package
> >    ?methods?) for conversion from ?"character"? to the specified
> >    formal class.
> >
> > I read that as meaning that an "as" method is required for classes not
> > already listed in the prior sentence.  It doesn't say an "as" method
> > will be applied if colClasses is one of the atomic, factor, Date, or
> > POSIXct classes; but I can see how you might assume that, since all
> > the atomic, factor, Date, and POSIXct classes already have "as"
> > methods...
> 
> And this does suggest a workaround for ffdf:  instead of declaring the 
> class to be "integer", declare a class "ffdf_integer", and write a 
> conversion method.  Or simply read everything as character and call 
> as.integer() explicitly.
This is indeed an interesting workaround for read.table.ffdf(), thanks!

I still think adapting the behavior of scan() would be an interesting
improvement for R users, though.


Regards


From Rainer at krugs.de  Fri Oct  4 16:07:59 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Fri, 4 Oct 2013 16:07:59 +0200
Subject: [Rd] check warning  with .onLoad() and setClass()
In-Reply-To: <21070.47559.867778.190980@max.nulle.part> (Dirk Eddelbuettel's
	message of "Fri, 4 Oct 2013 07:51:19 -0500")
References: <m2zjqqfybi.fsf@krugs.de>
	<AD583E37-4E49-406C-B4A8-8F13C31E9B14@r-project.org>
	<m28uy9b8tu.fsf@krugs.de> <21070.43875.526391.331124@max.nulle.part>
	<m2fvshfd09.fsf@krugs.de> <21070.47559.867778.190980@max.nulle.part>
Message-ID: <m238ohuo1s.fsf@krugs.de>

Dirk Eddelbuettel <edd at debian.org> writes:

> On 4 October 2013 at 14:15, Rainer M Krug wrote:
> | Hm. loadModule is Rcpp function, but I am only interested in using the
> | setClass() function, which has nothing to do with Rcpp. I don't even use
> | Rcpp in the package, only in one which is imported.
>
> Sorry, assumed Reference Class created via Modules. My bad, and never mind.
>
> But as John said, .onLoad() can be replaces since he made those changes in R
> (and also in Rcpp). See ?setLoadAction, evalOnLoad(), ...

Ok - theat far I folow you. But how do I implement this?

I have now the following .onLoad() function:

,----
| .onLoad <- function(libname, pkgname) {
|     setClass(
|         "inDrak",
|         representation(
|             init = "SpatialGridDataFrame"
|             ),
|         contains = "simObj"
|         )
| }
`----

in the file ./R/onLoad.R in my package.

Now how can I now use the setLoadFunction()? I tried to simply put the
setClass in the setLoadFunction() as follow into the ./R/onLoad.R file:

,----
| setLoadFunction( function(libname, pkgname) {
|     setClass(
|         "inDrak",
|         representation(
|             init = "SpatialGridDataFrame"
|             ),
|         contains = "simObj"
|         )
| }
`----

but this did not work. 

So what do I have to do with it? I only find very few examples using
setLoadFunction().

Rainer


>
> Dirk


-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug


From skostysh at princeton.edu  Fri Oct  4 16:59:08 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Fri, 4 Oct 2013 10:59:08 -0400
Subject: [Rd] Possible POSIXlt / wday glitch & bugs.r-project.org status
In-Reply-To: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
References: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
Message-ID: <CAE3=dmeXTKV=dmFD5PO30dK0spHzrb1k-F4ndiURp8_zEBxRng@mail.gmail.com>

On Fri, Oct 4, 2013 at 6:11 AM, Imanuel Costigan <i.costigan at me.com> wrote:
> Wanted to raise two questions:
>
> 1. Is bugs.r-project.org down? I haven't been able to reach it for two or three days:

Yes. Quote from Duncan:

    ... the server is currently down. The volunteer who runs the server is
    currently away from his office, so I expect it won't get fixed until he
    gets back in a few days.

https://stat.ethz.ch/pipermail/r-help/2013-October/360958.html

Scott

>
> ```
> ping bugs.r-project.org
> PING rbugs.research.att.com (207.140.168.137): 56 data bytes
> Request timeout for icmp_seq 0
> Request timeout for icmp_seq 1
> Request timeout for icmp_seq 2
> Request timeout for icmp_seq 3
> Request timeout for icmp_seq 4
> Request timeout for icmp_seq 5
> Request timeout for icmp_seq 6
> ```
>
> 2. Is wday element of POSIXlt meant to be timezone invariant? You would expect the wday element to be invariant to the timezone of a date. That is, the same date/time instant of 5th October 2013 in both Australia/Sydney and UTC should be a Saturday (i.e. wday = 6). And indeed that is the case with 1 min past midnight on 5 October 2013:
>
> ```
> library(lubridate)
> d_utc <- ymd_hms(20131005000001, tz='UTC')
> d_local <- ymd_hms(20131005000001, tz='Australia/Sydney')
> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 6
> ```
>
> But this isn't always the case. For example,
>
> ```
> d_utc <- ymd_hms(20381002000001, tz='UTC')
> d_local <- ymd_hms(20381002000001, tz='Australia/Sydney')
> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 5
> ```
>
> Is this expected behaviour? I would have expected a properly encoded date/time of 2 Oct 2038 to be a Saturday irrespective of its time zone.
>
> Obligatory system dump:
>
> ```
>> sessionInfo()
> R version 3.0.1 (2013-05-16)
> Platform: x86_64-apple-darwin12.4.0 (64-bit)
>
> locale:
> [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> other attached packages:
> [1] lubridate_1.3.0 testthat_0.7.1  devtools_1.3
>
> loaded via a namespace (and not attached):
>  [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.3       evaluate_0.5.1
>  [5] ggplot2_0.9.3.1    grid_3.0.1         gtable_0.1.2       httr_0.2
>  [9] labeling_0.2       MASS_7.3-29        memoise_0.1        munsell_0.4.2
> [13] parallel_3.0.1     plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
> [17] RCurl_1.95-4.1     reshape2_1.2.2     scales_0.2.3       stringr_0.6.2
> [21] tools_3.0.1        whisker_0.3-2
>
> ```
>
> Using R compiled by homebrew [1]. But also experiencing the same bug using R installed on Windows 7 from the CRAN binaries.
>
> For those interested, I've also noted this on the `lubridate` Github issues page [2], even though this doesn't appear to be a lubridate issue.
>
> Thanks for any help.
>
> [1] http://brew.sh
> [2] https://github.com/hadley/lubridate/issues/209
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


--
Scott Kostyshak
Economics PhD Candidate
Princeton University


From hb at biostat.ucsf.edu  Fri Oct  4 17:10:52 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 4 Oct 2013 08:10:52 -0700
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <524EACBF.20107@gmail.com>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<F677287B-2406-46BB-9108-34D588B330EA@comcast.net>
	<CAPPM_gS1xxSXSnCA0W-+zh3EwoJ89BcxFXyxvffXzujqV7Qi5w@mail.gmail.com>
	<524EACBF.20107@gmail.com>
Message-ID: <CAFDcVCQmXSM9cXVrJfZCAt8yFBcebVK=w1RgpoEsjBshEB=tsg@mail.gmail.com>

On Fri, Oct 4, 2013 at 4:55 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 13-10-04 7:31 AM, Joshua Ulrich wrote:
>>
>> On Tue, Oct 1, 2013 at 11:29 AM, David Winsemius <dwinsemius at comcast.net>
>> wrote:
>>>
>>>
>>> On Sep 30, 2013, at 6:38 AM, Joshua Ulrich wrote:
>>>
>>>> On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat <nalimilan at club.fr>
>>>> wrote:
>>>>>
>>>>> Hi!
>>>>>
>>>>>
>>>>> It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
>>>>> quoted integers as an acceptable value for columns for which
>>>>> colClasses="integer". But when colClasses is omitted, these columns are
>>>>> read as integer anyway.
>>>>>
>>>>> For example, let's consider a file named file.dat, containing:
>>>>> "1"
>>>>> "2"
>>>>>
>>>>>> read.table("file.dat", colClasses="integer")
>>>>>
>>>>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines,
>>>>> na.strings, :
>>>>>   scan() expected 'an integer' and got '"1"'
>>>>>
>>>>> But:
>>>>>>
>>>>>> str(read.table("file.dat"))
>>>>>
>>>>> 'data.frame':   2 obs. of  1 variable:
>>>>> $ V1: int  1 2
>>>>>
>>>>> The latter result is indeed documented in ?read.table:
>>>>>      Unless ?colClasses? is specified, all columns are read as
>>>>>      character columns and then converted using ?type.convert? to
>>>>>      logical, integer, numeric, complex or (depending on ?as.is?)
>>>>>      factor as appropriate.  Quotes are (by default) interpreted in all
>>>>>      fields, so a column of values like ?"42"? will result in an
>>>>>      integer column.
>>>>>
>>>>>
>>>>> Should the former behavior be considered a bug?
>>>>>
>>>> No. If you tell read.table the column is integer and it's actually
>>>> character on disk, it should be an error.
>>>
>>>
>>> My reading of the `read.table` help page is that one should expect that
>>> when
>>> there is an 'integer'-class and an  `as.integer` function and  "integer"
>>> is the
>>> argument to colClasses, that `as.integer` will be applied to the values
>>> in the
>>> column. Should I be reading elsewhere?
>>>
>> I assume you're referring to the paragraph below.
>>
>>    Possible values are ?NA? (the default, when ?type.convert? is
>>    used), ?"NULL"? (when the column is skipped), one of the
>>    atomic vector classes (logical, integer, numeric, complex,
>>    character, raw), or ?"factor"?, ?"Date"? or ?"POSIXct"?.
>>    Otherwise there needs to be an ?as? method (from package
>>    ?methods?) for conversion from ?"character"? to the specified
>>    formal class.
>>
>> I read that as meaning that an "as" method is required for classes not
>> already listed in the prior sentence.  It doesn't say an "as" method
>> will be applied if colClasses is one of the atomic, factor, Date, or
>> POSIXct classes; but I can see how you might assume that, since all
>> the atomic, factor, Date, and POSIXct classes already have "as"
>> methods...
>
>
> And this does suggest a workaround for ffdf:  instead of declaring the class
> to be "integer", declare a class "ffdf_integer", and write a conversion
> method.  Or simply read everything as character and call as.integer()
> explicitly.

Just a note of concert since several proposed it:
colClasses="character") followed by as.integer() or strtoi() misses
the validation, e.g. "foo" will be turned into NA_integer_.  Using
read.table() or scan() gives an error.

/Henrik

>
> Duncan Murdoch
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pdalgd at gmail.com  Fri Oct  4 18:15:14 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Fri, 4 Oct 2013 18:15:14 +0200
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <CAFDcVCQmXSM9cXVrJfZCAt8yFBcebVK=w1RgpoEsjBshEB=tsg@mail.gmail.com>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<F677287B-2406-46BB-9108-34D588B330EA@comcast.net>
	<CAPPM_gS1xxSXSnCA0W-+zh3EwoJ89BcxFXyxvffXzujqV7Qi5w@mail.gmail.com>
	<524EACBF.20107@gmail.com>
	<CAFDcVCQmXSM9cXVrJfZCAt8yFBcebVK=w1RgpoEsjBshEB=tsg@mail.gmail.com>
Message-ID: <7FF4D249-1124-4C77-A638-ACB2E7B3D958@gmail.com>


On Oct 4, 2013, at 17:10 , Henrik Bengtsson wrote:

> On Fri, Oct 4, 2013 at 4:55 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 13-10-04 7:31 AM, Joshua Ulrich wrote:
>>> 
>>> On Tue, Oct 1, 2013 at 11:29 AM, David Winsemius <dwinsemius at comcast.net>
>>> wrote:
>>>> 
>>>> 
>>>> On Sep 30, 2013, at 6:38 AM, Joshua Ulrich wrote:
>>>> 
>>>>> On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat <nalimilan at club.fr>
>>>>> wrote:
>>>>>> 
>>>>>> Hi!
>>>>>> 
>>>>>> 
>>>>>> It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
>>>>>> quoted integers as an acceptable value for columns for which
>>>>>> colClasses="integer". But when colClasses is omitted, these columns are
>>>>>> read as integer anyway.
>>>>>> 
>>>>>> For example, let's consider a file named file.dat, containing:
>>>>>> "1"
>>>>>> "2"
>>>>>> 
>>>>>>> read.table("file.dat", colClasses="integer")
>>>>>> 
>>>>>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines,
>>>>>> na.strings, :
>>>>>>  scan() expected 'an integer' and got '"1"'
>>>>>> 
>>>>>> But:
>>>>>>> 
>>>>>>> str(read.table("file.dat"))
>>>>>> 
>>>>>> 'data.frame':   2 obs. of  1 variable:
>>>>>> $ V1: int  1 2
>>>>>> 
>>>>>> The latter result is indeed documented in ?read.table:
>>>>>>     Unless ?colClasses? is specified, all columns are read as
>>>>>>     character columns and then converted using ?type.convert? to
>>>>>>     logical, integer, numeric, complex or (depending on ?as.is?)
>>>>>>     factor as appropriate.  Quotes are (by default) interpreted in all
>>>>>>     fields, so a column of values like ?"42"? will result in an
>>>>>>     integer column.
>>>>>> 
>>>>>> 
>>>>>> Should the former behavior be considered a bug?
>>>>>> 
>>>>> No. If you tell read.table the column is integer and it's actually
>>>>> character on disk, it should be an error.
>>>> 
>>>> 
>>>> My reading of the `read.table` help page is that one should expect that
>>>> when
>>>> there is an 'integer'-class and an  `as.integer` function and  "integer"
>>>> is the
>>>> argument to colClasses, that `as.integer` will be applied to the values
>>>> in the
>>>> column. Should I be reading elsewhere?
>>>> 
>>> I assume you're referring to the paragraph below.
>>> 
>>>   Possible values are ?NA? (the default, when ?type.convert? is
>>>   used), ?"NULL"? (when the column is skipped), one of the
>>>   atomic vector classes (logical, integer, numeric, complex,
>>>   character, raw), or ?"factor"?, ?"Date"? or ?"POSIXct"?.
>>>   Otherwise there needs to be an ?as? method (from package
>>>   ?methods?) for conversion from ?"character"? to the specified
>>>   formal class.
>>> 
>>> I read that as meaning that an "as" method is required for classes not
>>> already listed in the prior sentence.  It doesn't say an "as" method
>>> will be applied if colClasses is one of the atomic, factor, Date, or
>>> POSIXct classes; but I can see how you might assume that, since all
>>> the atomic, factor, Date, and POSIXct classes already have "as"
>>> methods...
>> 
>> 
>> And this does suggest a workaround for ffdf:  instead of declaring the class
>> to be "integer", declare a class "ffdf_integer", and write a conversion
>> method.  Or simply read everything as character and call as.integer()
>> explicitly.
> 
> Just a note of concert since several proposed it:

concerN?

> colClasses="character") followed by as.integer() or strtoi() misses
> the validation, e.g. "foo" will be turned into NA_integer_.  Using
> read.table() or scan() gives an error.

The obvious fix for that would seem to be to use scan() on the character vector:

> y <- c("1","2",3,4,5)
> y
[1] "1" "2" "3" "4" "5"
> scan(text=y)
Read 5 items
[1] 1 2 3 4 5
> y <- c("1","2",3,4,"NA")
> scan(text=y)
Read 5 items
[1]  1  2  3  4 NA
> y <- c("1","2",3,4,"foo")
> scan(text=y)
Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  : 
  scan() expected 'a real', got 'foo'


> 
> /Henrik
> 
>> 
>> Duncan Murdoch
>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From peter.meilstrup at gmail.com  Fri Oct  4 18:20:29 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Fri, 4 Oct 2013 09:20:29 -0700
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <1380895105.13506.77.camel@milan>
References: <524D82C3.6030206@truecluster.com>
	<CAPPM_gRs_569M0CS+Wi1v3K9FA635DdqKtVD_3Ksz0-3jR56ew@mail.gmail.com>
	<1380895105.13506.77.camel@milan>
Message-ID: <CAJoaRhZPsM7J-EXfXJmxv-8N6NWPodcDw_iudnE4QQM6zMqr2A@mail.gmail.com>

I think this is not the right approach -- quoting is a transport-layer
feature of the CSV format, not part of the application layer. Quotes
should always be interpreted away from column data before any data is
handed to the application layer. (CSV does not _have_ any application
layer; type information is conspicuously absent.)

If quoting is incorrectly treated as a feature of the values rather
than the encoding of the values, there's just going to be the same
problem with datetime columns, and any other column types.

So I disagree -- parsing quotes is never the column data-converter's
job, it's read.table's job.

Please refer to this specification of CSV:
http://kanspra.org/memberdirectory.csv

particularly this part:
"Fields may always be delimited with double quotes. The delimiters
will always be discarded."

and the implementation note which follows. Other CSV specs, like RFC
4180, contain similar statements. I think the only way to comply with
"always" discarding delimiters is to do it in read.table.

Peter


On Fri, Oct 4, 2013 at 6:58 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
> Le vendredi 04 octobre 2013 ? 07:34 -0500, Joshua Ulrich a ?crit :
>> On Thu, Oct 3, 2013 at 9:44 AM, Jens Oehlschl?gel
>> <Jens.Oehlschlaegel at truecluster.com> wrote:
>> > I agree that quoted integer columns are not the most efficient way of
>> > delivering csv-files. However, the sad reality is that one receives such
>> > formats and still needs to read the data. Therefore it is not helpful to
>> > state that one should 'consider "character" to be the correct colClass in
>> > case an integer is surrounded by quotes'.
>> >
>> > The philosophy of read.table.ffdf is delegating the actual csv-parsing to a
>> > parse engine 'similarly' parametrized like 'read.table'. It is not 'bad
>> > coding practice' - but a conscious design decision - to assume that the
>> > parse engine behaves consistently, which read.table does not yet: it
>> > automatically recognizes a quoted integer column as 'integer', but when
>> > asked to explicitly interpret the column as 'integer' it does refuse to do
>>
>> read.table() does not "automatically recognize a quoted integer column
>> as 'integer'".  If colClasses is not specified, it reads the entire
>> column into a 'character' vector and then calls type.convert() on it.
>> type.convert() does all the necessary work to determine what class the
>> 'character' vector should be converted to.  If colClasses is
>> specified, quotes are not interpreted in non-'character' columns.
> That's pretty much the definition of "automatic". The fact that this is
> realized by type.convert() is really an implementation detail. But
> there's little point in discussing the question of whether this is
> automatic enough. Better concentrate on the actual result.
>
>> You want scan() to allocate an 'integer' vector, and then ensure (on
>> each read from the column in the file) that the value read is a valid
>> 'integer' type, while interpreting quotes (which strtol does not do,
>> so someone would have to write and test this new functionality).
> Yes, I think that's where the change should go. From a first look at
> scan.c:extractItem(), it seems that adapting scan() to skip quotes in
> the string before calling Strtoi() would not be too invasive and would
> not create a significant overhead. No string copy would even be involved
> since the pointer to the beginning of the string would just have to be
> increased to skip the quote character, and the null character be added a
> little earlier in the string.
>
> So this line:
>             INTEGER(ans)[i] = Strtoi(buffer, 10);
>
> would just have to be changed to something like:
>             char *quote;
>
>             if(buffer[0] == '\"' && (quote = strchr(buffer += 1, '\"')) != NULL)
>                 *quote = '\0';
>
>             INTEGER(ans)[i] = Strtoi(buffer, 10);
>
>
> For cleaner operation, the hardcoded '\"' could be replaced with the
> contents of read.table()'s quote argument.
>
>
> What do R core developers think about this small modification?
>
>
>> So your complaint is more with scan() than read.table().  And more
>> with Strtoi() (and therefore strtol) than scan().
> The complaint is about the combination of read.table() and scan(). It
> has nothing to do with strtol(), which has no reason to accept quotes as
> it's not designed to read CSV files...
>
>
> Regards
>
>> > so. So there is nothing wrong with read.table.ffdf (but something can be
>> > improved about read.table). It is *not* the 'best solution [...] to rewrite
>> > read.table.ffdf()' given that it nicely imports such data, see 4+1 ways to
>> > do so below.
>> >
>> > Jens Oehlschl?gel
>> >
>> >
>> > # --- first create a csv file for demonstration
>> > -------------------------------
>> > require(ff)
>> > file <- "test.csv"
>> > path <- "c:/tmp"
>> > n <- 1e2
>> > d <- data.frame(x=1:n, y=shQuote(1:n))
>> > write.csv(d, file=file.path(path,file), row.names=FALSE, quote=FALSE)
>> >
>> > # --- how to do it with read.table.ffdf
>> > ---------------------------------------
>> >
>> > # 1 let the parse engine ignore colClasses and hope for the best
>> > fixedengine <- function(file, ..., colClasses=NA){
>> >         read.csv(file, ...)
>> > }
>> > df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
>> > FUN="fixedengine")
>> > df
>> >
>> > # 2 Suspend colClasses(=NA) for the quoted integer column only
>> > df <- read.csv.ffdf(file=file.path(path,file), first.rows = 10,
>> > colClasses=c("integer", NA))
>> > df
>> >
>> > # 3 do your own type conversion using transFUN
>> > #  after reading the problematic column as character
>> > # Being able to inject regexps is quite powerful isn't it?
>> > # Or error handlinig in case of varying column format!
>> > custominterp <- function(d){
>> >         d[[2]] <- as.integer(gsub('"', '', d[[2]]))
>> >         d
>> > }
>> > df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
>> > colClasses=c("integer", "character"), FUN="read.csv", transFUN=custominterp)
>> > df
>> >
>> > # 4 do your own line parsing and type conversion
>> > # Here you can even handle non-standard formats
>> > #  such as varying number of columns
>> > customengine <- function(file, header=TRUE, col.names, colClasses=NA,
>> > nrows=0, skip=0, fileEncoding="", comment.char = ""){
>> >         l <- scan(file, what="character", nlines=nrows+header, skip=skip,
>> > fileEncoding=fileEncoding, comment.char = comment.char)
>> >         s <- do.call("rbind", strsplit(l, ","))
>> >         if (header){
>> >                 d <- data.frame(as.integer(s[-1,1]),
>> > as.integer(gsub('"','',s[-1,2])))
>> >                 names(d) <- s[1,]
>> >         }else{
>> >                 d <- data.frame(as.integer(s[,1]),
>> > as.integer(gsub('"','',s[,2])))
>> >         }
>> >         if (!missing(col.names))
>> >                 names(d) <- col.names
>> >         d
>> > }
>> > df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
>> > FUN="customengine")
>> > df
>> >
>> > # 5 use a parsing engine that can apply colClasses to quoted integers
>> > # Unfortunately Henry Bengtson's readDataFrame does not work as a
>> > #  parse engine for read.table.ffdf because read.table.ffdf expects
>> > #  the parse engine to read successive chunks from a file connection
>> > #  while readDataFrame only accepts a filename as input file spec.
>> > # Yes it has 'skip', but using that would reread the file from scratch
>> > #  for each chunk (O(N^2) costs)
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Joshua Ulrich  |  about.me/joshuaulrich
>> FOSS Trading  |  www.fosstrading.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From hb at biostat.ucsf.edu  Fri Oct  4 18:28:57 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 4 Oct 2013 09:28:57 -0700
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <7FF4D249-1124-4C77-A638-ACB2E7B3D958@gmail.com>
References: <1380544403.10008.15.camel@milan>
	<CAPPM_gQBkwtbTR4Wv2gLp4_qHQpzqSHM=pZD8tRPYAD=uewgKg@mail.gmail.com>
	<F677287B-2406-46BB-9108-34D588B330EA@comcast.net>
	<CAPPM_gS1xxSXSnCA0W-+zh3EwoJ89BcxFXyxvffXzujqV7Qi5w@mail.gmail.com>
	<524EACBF.20107@gmail.com>
	<CAFDcVCQmXSM9cXVrJfZCAt8yFBcebVK=w1RgpoEsjBshEB=tsg@mail.gmail.com>
	<7FF4D249-1124-4C77-A638-ACB2E7B3D958@gmail.com>
Message-ID: <CAFDcVCS_f2cT4LLYmRjSL=yUDUVeF=W=KTaJSTtoXVKhisUO+A@mail.gmail.com>

On Fri, Oct 4, 2013 at 9:15 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
> On Oct 4, 2013, at 17:10 , Henrik Bengtsson wrote:
>
>> On Fri, Oct 4, 2013 at 4:55 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> On 13-10-04 7:31 AM, Joshua Ulrich wrote:
>>>>
>>>> On Tue, Oct 1, 2013 at 11:29 AM, David Winsemius <dwinsemius at comcast.net>
>>>> wrote:
>>>>>
>>>>>
>>>>> On Sep 30, 2013, at 6:38 AM, Joshua Ulrich wrote:
>>>>>
>>>>>> On Mon, Sep 30, 2013 at 7:33 AM, Milan Bouchet-Valat <nalimilan at club.fr>
>>>>>> wrote:
>>>>>>>
>>>>>>> Hi!
>>>>>>>
>>>>>>>
>>>>>>> It seems that read.table() in R 3.0.1 (Linux 64-bit) does not consider
>>>>>>> quoted integers as an acceptable value for columns for which
>>>>>>> colClasses="integer". But when colClasses is omitted, these columns are
>>>>>>> read as integer anyway.
>>>>>>>
>>>>>>> For example, let's consider a file named file.dat, containing:
>>>>>>> "1"
>>>>>>> "2"
>>>>>>>
>>>>>>>> read.table("file.dat", colClasses="integer")
>>>>>>>
>>>>>>> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines,
>>>>>>> na.strings, :
>>>>>>>  scan() expected 'an integer' and got '"1"'
>>>>>>>
>>>>>>> But:
>>>>>>>>
>>>>>>>> str(read.table("file.dat"))
>>>>>>>
>>>>>>> 'data.frame':   2 obs. of  1 variable:
>>>>>>> $ V1: int  1 2
>>>>>>>
>>>>>>> The latter result is indeed documented in ?read.table:
>>>>>>>     Unless ?colClasses? is specified, all columns are read as
>>>>>>>     character columns and then converted using ?type.convert? to
>>>>>>>     logical, integer, numeric, complex or (depending on ?as.is?)
>>>>>>>     factor as appropriate.  Quotes are (by default) interpreted in all
>>>>>>>     fields, so a column of values like ?"42"? will result in an
>>>>>>>     integer column.
>>>>>>>
>>>>>>>
>>>>>>> Should the former behavior be considered a bug?
>>>>>>>
>>>>>> No. If you tell read.table the column is integer and it's actually
>>>>>> character on disk, it should be an error.
>>>>>
>>>>>
>>>>> My reading of the `read.table` help page is that one should expect that
>>>>> when
>>>>> there is an 'integer'-class and an  `as.integer` function and  "integer"
>>>>> is the
>>>>> argument to colClasses, that `as.integer` will be applied to the values
>>>>> in the
>>>>> column. Should I be reading elsewhere?
>>>>>
>>>> I assume you're referring to the paragraph below.
>>>>
>>>>   Possible values are ?NA? (the default, when ?type.convert? is
>>>>   used), ?"NULL"? (when the column is skipped), one of the
>>>>   atomic vector classes (logical, integer, numeric, complex,
>>>>   character, raw), or ?"factor"?, ?"Date"? or ?"POSIXct"?.
>>>>   Otherwise there needs to be an ?as? method (from package
>>>>   ?methods?) for conversion from ?"character"? to the specified
>>>>   formal class.
>>>>
>>>> I read that as meaning that an "as" method is required for classes not
>>>> already listed in the prior sentence.  It doesn't say an "as" method
>>>> will be applied if colClasses is one of the atomic, factor, Date, or
>>>> POSIXct classes; but I can see how you might assume that, since all
>>>> the atomic, factor, Date, and POSIXct classes already have "as"
>>>> methods...
>>>
>>>
>>> And this does suggest a workaround for ffdf:  instead of declaring the class
>>> to be "integer", declare a class "ffdf_integer", and write a conversion
>>> method.  Or simply read everything as character and call as.integer()
>>> explicitly.
>>
>> Just a note of concert since several proposed it:
>
> concerN?

Ah, yet again, that beautiful music I always hear in my head when I
read R-devel.

>
>> colClasses="character") followed by as.integer() or strtoi() misses
>> the validation, e.g. "foo" will be turned into NA_integer_.  Using
>> read.table() or scan() gives an error.
>
> The obvious fix for that would seem to be to use scan() on the character vector:
>
>> y <- c("1","2",3,4,5)
>> y
> [1] "1" "2" "3" "4" "5"
>> scan(text=y)
> Read 5 items
> [1] 1 2 3 4 5
>> y <- c("1","2",3,4,"NA")
>> scan(text=y)
> Read 5 items
> [1]  1  2  3  4 NA
>> y <- c("1","2",3,4,"foo")
>> scan(text=y)
> Error in scan(file, what, nmax, sep, dec, quote, skip, nlines, na.strings,  :
>   scan() expected 'a real', got 'foo'

Yep, that's also what I proposed above, though it could have been more
explicit.  See also an earlier reply of mine where I refer to code of
readDataFrame for TabularTextFile
[[https://r-forge.r-project.org/scm/viewvc.php/pkg/R.filesets/R/TabularTextFile.R?view=markup&root=r-dots]
doing this (as an illustration for OP).

/H

>
>
>>
>> /Henrik
>>
>>>
>>> Duncan Murdoch
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>


From peter.meilstrup at gmail.com  Fri Oct  4 18:40:01 2013
From: peter.meilstrup at gmail.com (Peter Meilstrup)
Date: Fri, 4 Oct 2013 09:40:01 -0700
Subject: [Rd] read.table() with quoted integers
In-Reply-To: <CAJoaRhZPsM7J-EXfXJmxv-8N6NWPodcDw_iudnE4QQM6zMqr2A@mail.gmail.com>
References: <524D82C3.6030206@truecluster.com>
	<CAPPM_gRs_569M0CS+Wi1v3K9FA635DdqKtVD_3Ksz0-3jR56ew@mail.gmail.com>
	<1380895105.13506.77.camel@milan>
	<CAJoaRhZPsM7J-EXfXJmxv-8N6NWPodcDw_iudnE4QQM6zMqr2A@mail.gmail.com>
Message-ID: <CAJoaRhZVmys=vAddveQtDcqVGTS8VfjccN9cMVhQ8y18Oj6EhQ@mail.gmail.com>

On Fri, Oct 4, 2013 at 9:20 AM, Peter Meilstrup
<peter.meilstrup at gmail.com> wrote:
> I think this is not the right approach -- quoting is a transport-layer
> feature of the CSV format, not part of the application layer. Quotes
> should always be interpreted away from column data before any data is
> handed to the application layer. (CSV does not _have_ any application
> layer; type information is conspicuously absent.)
>
> If quoting is incorrectly treated as a feature of the values rather
> than the encoding of the values, there's just going to be the same
> problem with datetime columns, and any other column types.
>
> So I disagree -- parsing quotes is never the column data-converter's
> job, it's read.table's job.
>
> Please refer to this specification of CSV:

Wrong URL -- I was checking my assumptions by googling examples of CSV
files in the wild and seeing what my spreadsheet programs did with
them (which practice would settle several errant beliefs in this
thread.)

The CSV specs I was referring to are:
http://www.creativyst.com/Doc/Articles/CSV/CSV01.htm
http://tools.ietf.org/html/rfc4180

> particularly this part:
> "Fields may always be delimited with double quotes. The delimiters
> will always be discarded."
>
> and the implementation note which follows. Other CSV specs, like RFC
> 4180, contain similar statements. I think the only way to comply with
> "always" discarding delimiters is to do it in read.table.
>
> Peter
>
>
> On Fri, Oct 4, 2013 at 6:58 AM, Milan Bouchet-Valat <nalimilan at club.fr> wrote:
>> Le vendredi 04 octobre 2013 ? 07:34 -0500, Joshua Ulrich a ?crit :
>>> On Thu, Oct 3, 2013 at 9:44 AM, Jens Oehlschl?gel
>>> <Jens.Oehlschlaegel at truecluster.com> wrote:
>>> > I agree that quoted integer columns are not the most efficient way of
>>> > delivering csv-files. However, the sad reality is that one receives such
>>> > formats and still needs to read the data. Therefore it is not helpful to
>>> > state that one should 'consider "character" to be the correct colClass in
>>> > case an integer is surrounded by quotes'.
>>> >
>>> > The philosophy of read.table.ffdf is delegating the actual csv-parsing to a
>>> > parse engine 'similarly' parametrized like 'read.table'. It is not 'bad
>>> > coding practice' - but a conscious design decision - to assume that the
>>> > parse engine behaves consistently, which read.table does not yet: it
>>> > automatically recognizes a quoted integer column as 'integer', but when
>>> > asked to explicitly interpret the column as 'integer' it does refuse to do
>>>
>>> read.table() does not "automatically recognize a quoted integer column
>>> as 'integer'".  If colClasses is not specified, it reads the entire
>>> column into a 'character' vector and then calls type.convert() on it.
>>> type.convert() does all the necessary work to determine what class the
>>> 'character' vector should be converted to.  If colClasses is
>>> specified, quotes are not interpreted in non-'character' columns.
>> That's pretty much the definition of "automatic". The fact that this is
>> realized by type.convert() is really an implementation detail. But
>> there's little point in discussing the question of whether this is
>> automatic enough. Better concentrate on the actual result.
>>
>>> You want scan() to allocate an 'integer' vector, and then ensure (on
>>> each read from the column in the file) that the value read is a valid
>>> 'integer' type, while interpreting quotes (which strtol does not do,
>>> so someone would have to write and test this new functionality).
>> Yes, I think that's where the change should go. From a first look at
>> scan.c:extractItem(), it seems that adapting scan() to skip quotes in
>> the string before calling Strtoi() would not be too invasive and would
>> not create a significant overhead. No string copy would even be involved
>> since the pointer to the beginning of the string would just have to be
>> increased to skip the quote character, and the null character be added a
>> little earlier in the string.
>>
>> So this line:
>>             INTEGER(ans)[i] = Strtoi(buffer, 10);
>>
>> would just have to be changed to something like:
>>             char *quote;
>>
>>             if(buffer[0] == '\"' && (quote = strchr(buffer += 1, '\"')) != NULL)
>>                 *quote = '\0';
>>
>>             INTEGER(ans)[i] = Strtoi(buffer, 10);
>>
>>
>> For cleaner operation, the hardcoded '\"' could be replaced with the
>> contents of read.table()'s quote argument.
>>
>>
>> What do R core developers think about this small modification?
>>
>>
>>> So your complaint is more with scan() than read.table().  And more
>>> with Strtoi() (and therefore strtol) than scan().
>> The complaint is about the combination of read.table() and scan(). It
>> has nothing to do with strtol(), which has no reason to accept quotes as
>> it's not designed to read CSV files...
>>
>>
>> Regards
>>
>>> > so. So there is nothing wrong with read.table.ffdf (but something can be
>>> > improved about read.table). It is *not* the 'best solution [...] to rewrite
>>> > read.table.ffdf()' given that it nicely imports such data, see 4+1 ways to
>>> > do so below.
>>> >
>>> > Jens Oehlschl?gel
>>> >
>>> >
>>> > # --- first create a csv file for demonstration
>>> > -------------------------------
>>> > require(ff)
>>> > file <- "test.csv"
>>> > path <- "c:/tmp"
>>> > n <- 1e2
>>> > d <- data.frame(x=1:n, y=shQuote(1:n))
>>> > write.csv(d, file=file.path(path,file), row.names=FALSE, quote=FALSE)
>>> >
>>> > # --- how to do it with read.table.ffdf
>>> > ---------------------------------------
>>> >
>>> > # 1 let the parse engine ignore colClasses and hope for the best
>>> > fixedengine <- function(file, ..., colClasses=NA){
>>> >         read.csv(file, ...)
>>> > }
>>> > df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
>>> > FUN="fixedengine")
>>> > df
>>> >
>>> > # 2 Suspend colClasses(=NA) for the quoted integer column only
>>> > df <- read.csv.ffdf(file=file.path(path,file), first.rows = 10,
>>> > colClasses=c("integer", NA))
>>> > df
>>> >
>>> > # 3 do your own type conversion using transFUN
>>> > #  after reading the problematic column as character
>>> > # Being able to inject regexps is quite powerful isn't it?
>>> > # Or error handlinig in case of varying column format!
>>> > custominterp <- function(d){
>>> >         d[[2]] <- as.integer(gsub('"', '', d[[2]]))
>>> >         d
>>> > }
>>> > df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
>>> > colClasses=c("integer", "character"), FUN="read.csv", transFUN=custominterp)
>>> > df
>>> >
>>> > # 4 do your own line parsing and type conversion
>>> > # Here you can even handle non-standard formats
>>> > #  such as varying number of columns
>>> > customengine <- function(file, header=TRUE, col.names, colClasses=NA,
>>> > nrows=0, skip=0, fileEncoding="", comment.char = ""){
>>> >         l <- scan(file, what="character", nlines=nrows+header, skip=skip,
>>> > fileEncoding=fileEncoding, comment.char = comment.char)
>>> >         s <- do.call("rbind", strsplit(l, ","))
>>> >         if (header){
>>> >                 d <- data.frame(as.integer(s[-1,1]),
>>> > as.integer(gsub('"','',s[-1,2])))
>>> >                 names(d) <- s[1,]
>>> >         }else{
>>> >                 d <- data.frame(as.integer(s[,1]),
>>> > as.integer(gsub('"','',s[,2])))
>>> >         }
>>> >         if (!missing(col.names))
>>> >                 names(d) <- col.names
>>> >         d
>>> > }
>>> > df <- read.table.ffdf(file=file.path(path,file), first.rows = 10,
>>> > FUN="customengine")
>>> > df
>>> >
>>> > # 5 use a parsing engine that can apply colClasses to quoted integers
>>> > # Unfortunately Henry Bengtson's readDataFrame does not work as a
>>> > #  parse engine for read.table.ffdf because read.table.ffdf expects
>>> > #  the parse engine to read successive chunks from a file connection
>>> > #  while readDataFrame only accepts a filename as input file spec.
>>> > # Yes it has 'skip', but using that would reread the file from scratch
>>> > #  for each chunk (O(N^2) costs)
>>> >
>>> > ______________________________________________
>>> > R-devel at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> --
>>> Joshua Ulrich  |  about.me/joshuaulrich
>>> FOSS Trading  |  www.fosstrading.com
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From jmc at r-project.org  Fri Oct  4 18:56:44 2013
From: jmc at r-project.org (John Chambers)
Date: Fri, 4 Oct 2013 09:56:44 -0700
Subject: [Rd] check warning  with .onLoad() and setClass()
In-Reply-To: <m238ohuo1s.fsf@krugs.de>
References: <m2zjqqfybi.fsf@krugs.de>
	<AD583E37-4E49-406C-B4A8-8F13C31E9B14@r-project.org>
	<m28uy9b8tu.fsf@krugs.de>
	<21070.43875.526391.331124@max.nulle.part>
	<m2fvshfd09.fsf@krugs.de>
	<21070.47559.867778.190980@max.nulle.part>
	<m238ohuo1s.fsf@krugs.de>
Message-ID: <706F64ED-1815-4E92-AF2A-F054580B27D4@r-project.org>

The basic tool is setLoadActions(), which takes a function definition, with the package's namespace as its argument.  Read ?setLoadActions

There is no such thing as setLoadFunction, as far as the standard code in R.

While you haven't defined "didn't work", an off-the-top-of-the-head idea would be something like:

   setLoadActions(function(ns) {setClass(....., where = ns)})


On Oct 4, 2013, at 7:07 AM, Rainer M Krug <Rainer at krugs.de> wrote:

> Dirk Eddelbuettel <edd at debian.org> writes:
> 
>> On 4 October 2013 at 14:15, Rainer M Krug wrote:
>> | Hm. loadModule is Rcpp function, but I am only interested in using the
>> | setClass() function, which has nothing to do with Rcpp. I don't even use
>> | Rcpp in the package, only in one which is imported.
>> 
>> Sorry, assumed Reference Class created via Modules. My bad, and never mind.
>> 
>> But as John said, .onLoad() can be replaces since he made those changes in R
>> (and also in Rcpp). See ?setLoadAction, evalOnLoad(), ...
> 
> Ok - theat far I folow you. But how do I implement this?
> 
> I have now the following .onLoad() function:
> 
> ,----
> | .onLoad <- function(libname, pkgname) {
> |     setClass(
> |         "inDrak",
> |         representation(
> |             init = "SpatialGridDataFrame"
> |             ),
> |         contains = "simObj"
> |         )
> | }
> `----
> 
> in the file ./R/onLoad.R in my package.
> 
> Now how can I now use the setLoadFunction()? I tried to simply put the
> setClass in the setLoadFunction() as follow into the ./R/onLoad.R file:
> 
> ,----
> | setLoadFunction( function(libname, pkgname) {
> |     setClass(
> |         "inDrak",
> |         representation(
> |             init = "SpatialGridDataFrame"
> |             ),
> |         contains = "simObj"
> |         )
> | }
> `----
> 
> but this did not work. 
> 
> So what do I have to do with it? I only find very few examples using
> setLoadFunction().
> 
> Rainer
> 
> 
>> 
>> Dirk
> 
> 
> -- 
> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
> 
> Centre of Excellence for Invasion Biology
> Stellenbosch University
> South Africa
> 
> Tel :       +33 - (0)9 53 10 27 44
> Cell:       +33 - (0)6 85 62 59 98
> Fax :       +33 - (0)9 58 10 27 44
> 
> Fax (D):    +49 - (0)3 21 21 25 22 44
> 
> email:      Rainer at krugs.de
> 
> Skype:      RMkrug
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi.gabor at gmail.com  Fri Oct  4 20:53:50 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Fri, 4 Oct 2013 14:53:50 -0400
Subject: [Rd] Allow semantic versioning for packages
Message-ID: <CABtg=K=AB=eJu3dtEvqOtA0o_R37OdwNAZw=X-TDePJwLKnQDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131004/648fe2bb/attachment.pl>

From murdoch.duncan at gmail.com  Fri Oct  4 21:05:13 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 04 Oct 2013 15:05:13 -0400
Subject: [Rd] C++ debugging help needed
In-Reply-To: <524C32CF.2060307@gmail.com>
References: <524C32CF.2060307@gmail.com>
Message-ID: <524F1169.4020308@gmail.com>

I have now got two "solutions" to this.  The rgl version currently on 
CRAN does a simple rename to avoid the name clash. A later version, 
still only on R-forge, puts most objects into a namespace called "rgl".  
(The old code had two small namespaces "gui" and "lib"; they are gone now.)

I am not yet confident that the current version with namespaces will 
compile on all platforms; it seems much more fragile this way, with 
errors showing up on Linux that were not errors on Windows.  (E.g. 
sometimes I included a header with declarations in the rgl namespace 
followed by system header files, and the latter acted differently than 
they did when placed before the rgl header file, apparently declaring 
the system functions to be in a new anonymous namespace.)

rgl also includes some C code from the gl2ps project and some C++ code 
from FTGL; I didn't put those into the rgl namespace.  So there are 
still possibilities for clashes if anyone else uses those.

I'm still surprised that anything with plugins works on Unix-alike 
systems with such bizarre linking rules.  This is one of those few cases 
where the Windows design seems clearly superior.

Duncan Murdoch


On 02/10/2013 10:50 AM, Duncan Murdoch wrote:
> I've had reports lately about segfaults in the rgl package.  I've only
> been able to reproduce these on Linux.   I am not so familiar with C++
> details, so I have a couple of questions way down below. But first some
> background info.
>
>    One recipe to recreate the crash works with a new version 5.0-1 of the
> mixOmics package:
>
>   > library(mixOmics)
>   > example(pca)
>
> This crashes with messages like this:
>
> Program received signal SIGSEGV, Segmentation fault.
> 0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
>       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
> 48        { return __atomic_fetch_add(__mem, __val, __ATOMIC_ACQ_REL); }
>
> The call stack ends with this:
>
> #0  0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
>       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
> #1  __exchange_and_add_dispatch (__mem=0x7f7fffff7f7ffff7,
>       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:81
> #2  _M_dispose (__a=..., this=0x7f7fffff7f7fffe7)
>       at /usr/include/c++/4.7/bits/basic_string.h:242
> #3  ~basic_string (this=0x15f8770, __in_chrg=<optimized out>)
>       at /usr/include/c++/4.7/bits/basic_string.h:536
> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> Shape.cpp:13
> #5  0x00007ffff22df50b in ~Background (this=0x15f8760,
>       __in_chrg=<optimized out>) at Background.hpp:15
> #6  Background::~Background (this=0x15f8760, __in_chrg=<optimized out>)
>       at Background.hpp:15
>
> Up to entry #4 this all looks normal.  If I go into that stack frame, I
> see this:
>
>
> (gdb) up
> #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> Shape.cpp:13
> warning: Source file is more recent than executable.
> 13        blended(in_material.isTransparent())
> (gdb) p this
> $9 = (Shape * const) 0x15f8760
> (gdb) p *this
> $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
>       static npos = <optimized out>,
>       _M_dataplus = {<std::allocator<char>> =
> {<__gnu_cxx::new_allocator<char>> =
> {<No data fields>}, <No data fields>},
>         _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
> bounds>}},
>     mShapeColor = {mRed = -1.4044474254567505e+306,
>       mGreen = -1.4044477603031902e+306, mBlue = 4.24399170841135e-314,
>       mTransparent = 0}, mSpecularReflectivity = 0.0078125,
>     mSpecularSize = 1065353216, mDiffuseReflectivity = 0.007812501848093234,
>     mAmbientReflectivity = 0}
>
> The things displayed in *this are all wrong.  Those field names come
> from the Shape object in the igraph package, not the Shape object in the
> rgl package.   The mixOmics package uses both.
>
> My questions:
>
> - Has my code somehow got mixed up with the igraph code, so I really do
> have a call out to igraph's Shape::~Shape instead of rgl's
> Shape::~Shape, or is this just bad info being given to me by gdb?
>
> - If I really do have calls to the wrong destructor in there, how do I
> avoid this?
>
> Duncan Murdoch


From i.costigan at me.com  Sat Oct  5 03:02:15 2013
From: i.costigan at me.com (Imanuel Costigan)
Date: Sat, 05 Oct 2013 11:02:15 +1000
Subject: [Rd] Possible POSIXlt / wday glitch & bugs.r-project.org status
In-Reply-To: <CAE3=dmeXTKV=dmFD5PO30dK0spHzrb1k-F4ndiURp8_zEBxRng@mail.gmail.com>
References: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
	<CAE3=dmeXTKV=dmFD5PO30dK0spHzrb1k-F4ndiURp8_zEBxRng@mail.gmail.com>
Message-ID: <3CF8C970-05CC-45C4-8CE0-E078C84121AF@me.com>

Thanks for the responses and quoting the timezone help file. 

I am assuming that in order to determine the wday element of POSIXlt, R does the necessary calculations in Julian time (via POSIXct). Based on this excerpt from ?DateTimeClasses, it looks like R is responsible for determining time zones post 2037 (the example I gave was in 2038). So it could be an R issue. 

>      ?"POSIXct"? objects may also have an attribute ?"tzone"?, a
>      character vector of length one.  If set to a non-empty value, it
>      will determine how the object is converted to class ?"POSIXlt"?
>      and in particular how it is printed.  This is usually desirable,
>      but if you want to specify an object in a particular timezone but
>      to be printed in the current timezone you may want to remove the
>      ?"tzone"? attribute (e.g. by ?c(x)?).
> 
>      Unfortunately, the conversion is complicated by the operation of
>      time zones and leap seconds (24 days have been 86401 seconds long
>      so far: the times of the extra seconds are in the object
>      ?.leap.seconds?).  **The details of this are entrusted to the OS
>      services where possible.  This always covers the period 1970-2037,
>      and on most machines back to 1902 (when time zones were in their
>      infancy).  Outside the platform limits we use our own C code.


On 05/10/2013, at 12:59 AM, Scott Kostyshak <skostysh at princeton.edu> wrote:

> On Fri, Oct 4, 2013 at 6:11 AM, Imanuel Costigan <i.costigan at me.com> wrote:
>> Wanted to raise two questions:
>> 
>> 1. Is bugs.r-project.org down? I haven't been able to reach it for two or three days:
> 
> Yes. Quote from Duncan:
> 
>    ... the server is currently down. The volunteer who runs the server is
>    currently away from his office, so I expect it won't get fixed until he
>    gets back in a few days.
> 
> https://stat.ethz.ch/pipermail/r-help/2013-October/360958.html
> 
> Scott
> 
>> 
>> ```
>> ping bugs.r-project.org
>> PING rbugs.research.att.com (207.140.168.137): 56 data bytes
>> Request timeout for icmp_seq 0
>> Request timeout for icmp_seq 1
>> Request timeout for icmp_seq 2
>> Request timeout for icmp_seq 3
>> Request timeout for icmp_seq 4
>> Request timeout for icmp_seq 5
>> Request timeout for icmp_seq 6
>> ```
>> 
>> 2. Is wday element of POSIXlt meant to be timezone invariant? You would expect the wday element to be invariant to the timezone of a date. That is, the same date/time instant of 5th October 2013 in both Australia/Sydney and UTC should be a Saturday (i.e. wday = 6). And indeed that is the case with 1 min past midnight on 5 October 2013:
>> 
>> ```
>> library(lubridate)
>> d_utc <- ymd_hms(20131005000001, tz='UTC')
>> d_local <- ymd_hms(20131005000001, tz='Australia/Sydney')
>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 6
>> ```
>> 
>> But this isn't always the case. For example,
>> 
>> ```
>> d_utc <- ymd_hms(20381002000001, tz='UTC')
>> d_local <- ymd_hms(20381002000001, tz='Australia/Sydney')
>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 5
>> ```
>> 
>> Is this expected behaviour? I would have expected a properly encoded date/time of 2 Oct 2038 to be a Saturday irrespective of its time zone.
>> 
>> Obligatory system dump:
>> 
>> ```
>>> sessionInfo()
>> R version 3.0.1 (2013-05-16)
>> Platform: x86_64-apple-darwin12.4.0 (64-bit)
>> 
>> locale:
>> [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] lubridate_1.3.0 testthat_0.7.1  devtools_1.3
>> 
>> loaded via a namespace (and not attached):
>> [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.3       evaluate_0.5.1
>> [5] ggplot2_0.9.3.1    grid_3.0.1         gtable_0.1.2       httr_0.2
>> [9] labeling_0.2       MASS_7.3-29        memoise_0.1        munsell_0.4.2
>> [13] parallel_3.0.1     plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
>> [17] RCurl_1.95-4.1     reshape2_1.2.2     scales_0.2.3       stringr_0.6.2
>> [21] tools_3.0.1        whisker_0.3-2
>> 
>> ```
>> 
>> Using R compiled by homebrew [1]. But also experiencing the same bug using R installed on Windows 7 from the CRAN binaries.
>> 
>> For those interested, I've also noted this on the `lubridate` Github issues page [2], even though this doesn't appear to be a lubridate issue.
>> 
>> Thanks for any help.
>> 
>> [1] http://brew.sh
>> [2] https://github.com/hadley/lubridate/issues/209
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University


From josh.m.ulrich at gmail.com  Sat Oct  5 03:37:24 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Fri, 4 Oct 2013 20:37:24 -0500
Subject: [Rd] Possible POSIXlt / wday glitch & bugs.r-project.org status
In-Reply-To: <3CF8C970-05CC-45C4-8CE0-E078C84121AF@me.com>
References: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
	<CAE3=dmeXTKV=dmFD5PO30dK0spHzrb1k-F4ndiURp8_zEBxRng@mail.gmail.com>
	<3CF8C970-05CC-45C4-8CE0-E078C84121AF@me.com>
Message-ID: <CAPPM_gQBb_B5ukeBoCkd8rqwya-LdvUS0LGd7eRDzR=Scz8ZpA@mail.gmail.com>

On Fri, Oct 4, 2013 at 8:02 PM, Imanuel Costigan <i.costigan at me.com> wrote:
> Thanks for the responses and quoting the timezone help file.
>
> I am assuming that in order to determine the wday element of POSIXlt, R does the necessary calculations in Julian time (via POSIXct). Based on this excerpt from ?DateTimeClasses, it looks like R is responsible for determining time zones post 2037 (the example I gave was in 2038). So it could be an R issue.
>
It's an issue with size of the largest number you can store in a
signed integer, which is not specific to R.

> .POSIXct(.Machine$integer.max, tz="UTC")
[1] "2038-01-19 03:14:07 UTC"

Dates larger than that cannot be represented by a signed integer.  It
could be worked around, but it's not trivial because R would have to
use something other than the tm C struct.  Luckily, there's a decade
or two before it starts to become a pressing issue. :)

>>      ?"POSIXct"? objects may also have an attribute ?"tzone"?, a
>>      character vector of length one.  If set to a non-empty value, it
>>      will determine how the object is converted to class ?"POSIXlt"?
>>      and in particular how it is printed.  This is usually desirable,
>>      but if you want to specify an object in a particular timezone but
>>      to be printed in the current timezone you may want to remove the
>>      ?"tzone"? attribute (e.g. by ?c(x)?).
>>
>>      Unfortunately, the conversion is complicated by the operation of
>>      time zones and leap seconds (24 days have been 86401 seconds long
>>      so far: the times of the extra seconds are in the object
>>      ?.leap.seconds?).  **The details of this are entrusted to the OS
>>      services where possible.  This always covers the period 1970-2037,
>>      and on most machines back to 1902 (when time zones were in their
>>      infancy).  Outside the platform limits we use our own C code.
>
>
> On 05/10/2013, at 12:59 AM, Scott Kostyshak <skostysh at princeton.edu> wrote:
>
>> On Fri, Oct 4, 2013 at 6:11 AM, Imanuel Costigan <i.costigan at me.com> wrote:
>>> Wanted to raise two questions:
>>>
>>> 1. Is bugs.r-project.org down? I haven't been able to reach it for two or three days:
>>
>> Yes. Quote from Duncan:
>>
>>    ... the server is currently down. The volunteer who runs the server is
>>    currently away from his office, so I expect it won't get fixed until he
>>    gets back in a few days.
>>
>> https://stat.ethz.ch/pipermail/r-help/2013-October/360958.html
>>
>> Scott
>>
>>>
>>> ```
>>> ping bugs.r-project.org
>>> PING rbugs.research.att.com (207.140.168.137): 56 data bytes
>>> Request timeout for icmp_seq 0
>>> Request timeout for icmp_seq 1
>>> Request timeout for icmp_seq 2
>>> Request timeout for icmp_seq 3
>>> Request timeout for icmp_seq 4
>>> Request timeout for icmp_seq 5
>>> Request timeout for icmp_seq 6
>>> ```
>>>
>>> 2. Is wday element of POSIXlt meant to be timezone invariant? You would expect the wday element to be invariant to the timezone of a date. That is, the same date/time instant of 5th October 2013 in both Australia/Sydney and UTC should be a Saturday (i.e. wday = 6). And indeed that is the case with 1 min past midnight on 5 October 2013:
>>>
>>> ```
>>> library(lubridate)
>>> d_utc <- ymd_hms(20131005000001, tz='UTC')
>>> d_local <- ymd_hms(20131005000001, tz='Australia/Sydney')
>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 6
>>> ```
>>>
>>> But this isn't always the case. For example,
>>>
>>> ```
>>> d_utc <- ymd_hms(20381002000001, tz='UTC')
>>> d_local <- ymd_hms(20381002000001, tz='Australia/Sydney')
>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 5
>>> ```
>>>
>>> Is this expected behaviour? I would have expected a properly encoded date/time of 2 Oct 2038 to be a Saturday irrespective of its time zone.
>>>
>>> Obligatory system dump:
>>>
>>> ```
>>>> sessionInfo()
>>> R version 3.0.1 (2013-05-16)
>>> Platform: x86_64-apple-darwin12.4.0 (64-bit)
>>>
>>> locale:
>>> [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> other attached packages:
>>> [1] lubridate_1.3.0 testthat_0.7.1  devtools_1.3
>>>
>>> loaded via a namespace (and not attached):
>>> [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.3       evaluate_0.5.1
>>> [5] ggplot2_0.9.3.1    grid_3.0.1         gtable_0.1.2       httr_0.2
>>> [9] labeling_0.2       MASS_7.3-29        memoise_0.1        munsell_0.4.2
>>> [13] parallel_3.0.1     plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
>>> [17] RCurl_1.95-4.1     reshape2_1.2.2     scales_0.2.3       stringr_0.6.2
>>> [21] tools_3.0.1        whisker_0.3-2
>>>
>>> ```
>>>
>>> Using R compiled by homebrew [1]. But also experiencing the same bug using R installed on Windows 7 from the CRAN binaries.
>>>
>>> For those interested, I've also noted this on the `lubridate` Github issues page [2], even though this doesn't appear to be a lubridate issue.
>>>
>>> Thanks for any help.
>>>
>>> [1] http://brew.sh
>>> [2] https://github.com/hadley/lubridate/issues/209
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> --
>> Scott Kostyshak
>> Economics PhD Candidate
>> Princeton University
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From i.costigan at me.com  Sat Oct  5 05:18:22 2013
From: i.costigan at me.com (Imanuel Costigan)
Date: Sat, 05 Oct 2013 13:18:22 +1000
Subject: [Rd] Possible POSIXlt / wday glitch & bugs.r-project.org status
In-Reply-To: <CAPPM_gQBb_B5ukeBoCkd8rqwya-LdvUS0LGd7eRDzR=Scz8ZpA@mail.gmail.com>
References: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
	<CAE3=dmeXTKV=dmFD5PO30dK0spHzrb1k-F4ndiURp8_zEBxRng@mail.gmail.com>
	<3CF8C970-05CC-45C4-8CE0-E078C84121AF@me.com>
	<CAPPM_gQBb_B5ukeBoCkd8rqwya-LdvUS0LGd7eRDzR=Scz8ZpA@mail.gmail.com>
Message-ID: <0B52BD0D-F03D-4245-9B15-89E99027B91A@me.com>

Ok thanks for that explanation. That's bad news for me. I need to generate dates out past that limit regularly. It means that many operations past that limit are unreliable. Any suggested work arounds / alternatives?

On 05/10/2013, at 11:37 AM, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:

> On Fri, Oct 4, 2013 at 8:02 PM, Imanuel Costigan <i.costigan at me.com> wrote:
>> Thanks for the responses and quoting the timezone help file.
>> 
>> I am assuming that in order to determine the wday element of POSIXlt, R does the necessary calculations in Julian time (via POSIXct). Based on this excerpt from ?DateTimeClasses, it looks like R is responsible for determining time zones post 2037 (the example I gave was in 2038). So it could be an R issue.
>> 
> It's an issue with size of the largest number you can store in a
> signed integer, which is not specific to R.
> 
>> .POSIXct(.Machine$integer.max, tz="UTC")
> [1] "2038-01-19 03:14:07 UTC"
> 
> Dates larger than that cannot be represented by a signed integer.  It
> could be worked around, but it's not trivial because R would have to
> use something other than the tm C struct.  Luckily, there's a decade
> or two before it starts to become a pressing issue. :)
> 
>>>     ?"POSIXct"? objects may also have an attribute ?"tzone"?, a
>>>     character vector of length one.  If set to a non-empty value, it
>>>     will determine how the object is converted to class ?"POSIXlt"?
>>>     and in particular how it is printed.  This is usually desirable,
>>>     but if you want to specify an object in a particular timezone but
>>>     to be printed in the current timezone you may want to remove the
>>>     ?"tzone"? attribute (e.g. by ?c(x)?).
>>> 
>>>     Unfortunately, the conversion is complicated by the operation of
>>>     time zones and leap seconds (24 days have been 86401 seconds long
>>>     so far: the times of the extra seconds are in the object
>>>     ?.leap.seconds?).  **The details of this are entrusted to the OS
>>>     services where possible.  This always covers the period 1970-2037,
>>>     and on most machines back to 1902 (when time zones were in their
>>>     infancy).  Outside the platform limits we use our own C code.
>> 
>> 
>> On 05/10/2013, at 12:59 AM, Scott Kostyshak <skostysh at princeton.edu> wrote:
>> 
>>> On Fri, Oct 4, 2013 at 6:11 AM, Imanuel Costigan <i.costigan at me.com> wrote:
>>>> Wanted to raise two questions:
>>>> 
>>>> 1. Is bugs.r-project.org down? I haven't been able to reach it for two or three days:
>>> 
>>> Yes. Quote from Duncan:
>>> 
>>>   ... the server is currently down. The volunteer who runs the server is
>>>   currently away from his office, so I expect it won't get fixed until he
>>>   gets back in a few days.
>>> 
>>> https://stat.ethz.ch/pipermail/r-help/2013-October/360958.html
>>> 
>>> Scott
>>> 
>>>> 
>>>> ```
>>>> ping bugs.r-project.org
>>>> PING rbugs.research.att.com (207.140.168.137): 56 data bytes
>>>> Request timeout for icmp_seq 0
>>>> Request timeout for icmp_seq 1
>>>> Request timeout for icmp_seq 2
>>>> Request timeout for icmp_seq 3
>>>> Request timeout for icmp_seq 4
>>>> Request timeout for icmp_seq 5
>>>> Request timeout for icmp_seq 6
>>>> ```
>>>> 
>>>> 2. Is wday element of POSIXlt meant to be timezone invariant? You would expect the wday element to be invariant to the timezone of a date. That is, the same date/time instant of 5th October 2013 in both Australia/Sydney and UTC should be a Saturday (i.e. wday = 6). And indeed that is the case with 1 min past midnight on 5 October 2013:
>>>> 
>>>> ```
>>>> library(lubridate)
>>>> d_utc <- ymd_hms(20131005000001, tz='UTC')
>>>> d_local <- ymd_hms(20131005000001, tz='Australia/Sydney')
>>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 6
>>>> ```
>>>> 
>>>> But this isn't always the case. For example,
>>>> 
>>>> ```
>>>> d_utc <- ymd_hms(20381002000001, tz='UTC')
>>>> d_local <- ymd_hms(20381002000001, tz='Australia/Sydney')
>>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 5
>>>> ```
>>>> 
>>>> Is this expected behaviour? I would have expected a properly encoded date/time of 2 Oct 2038 to be a Saturday irrespective of its time zone.
>>>> 
>>>> Obligatory system dump:
>>>> 
>>>> ```
>>>>> sessionInfo()
>>>> R version 3.0.1 (2013-05-16)
>>>> Platform: x86_64-apple-darwin12.4.0 (64-bit)
>>>> 
>>>> locale:
>>>> [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8
>>>> 
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>> 
>>>> other attached packages:
>>>> [1] lubridate_1.3.0 testthat_0.7.1  devtools_1.3
>>>> 
>>>> loaded via a namespace (and not attached):
>>>> [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.3       evaluate_0.5.1
>>>> [5] ggplot2_0.9.3.1    grid_3.0.1         gtable_0.1.2       httr_0.2
>>>> [9] labeling_0.2       MASS_7.3-29        memoise_0.1        munsell_0.4.2
>>>> [13] parallel_3.0.1     plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
>>>> [17] RCurl_1.95-4.1     reshape2_1.2.2     scales_0.2.3       stringr_0.6.2
>>>> [21] tools_3.0.1        whisker_0.3-2
>>>> 
>>>> ```
>>>> 
>>>> Using R compiled by homebrew [1]. But also experiencing the same bug using R installed on Windows 7 from the CRAN binaries.
>>>> 
>>>> For those interested, I've also noted this on the `lubridate` Github issues page [2], even though this doesn't appear to be a lubridate issue.
>>>> 
>>>> Thanks for any help.
>>>> 
>>>> [1] http://brew.sh
>>>> [2] https://github.com/hadley/lubridate/issues/209
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> 
>>> --
>>> Scott Kostyshak
>>> Economics PhD Candidate
>>> Princeton University
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From simon.urbanek at r-project.org  Sat Oct  5 13:33:55 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 5 Oct 2013 13:33:55 +0200
Subject: [Rd] Possible POSIXlt / wday glitch & bugs.r-project.org status
In-Reply-To: <CAE3=dmeXTKV=dmFD5PO30dK0spHzrb1k-F4ndiURp8_zEBxRng@mail.gmail.com>
References: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
	<CAE3=dmeXTKV=dmFD5PO30dK0spHzrb1k-F4ndiURp8_zEBxRng@mail.gmail.com>
Message-ID: <05DD0D1F-8766-4140-B32E-FCDAF56E033F@r-project.org>


On Oct 4, 2013, at 4:59 PM, Scott Kostyshak <skostysh at princeton.edu> wrote:

> On Fri, Oct 4, 2013 at 6:11 AM, Imanuel Costigan <i.costigan at me.com> wrote:
>> Wanted to raise two questions:
>> 
>> 1. Is bugs.r-project.org down? I haven't been able to reach it for two or three days:
> 
> Yes. Quote from Duncan:
> 
>    ... the server is currently down. The volunteer who runs the server is
>    currently away from his office, so I expect it won't get fixed until he
>    gets back in a few days.
> 

FWIW it's available at

https://rbugs.urbanek.info/bugzilla3/

until the official R-project.org DNS is updated (but I have no idea how long that may take).

Cheers,
Simon


> https://stat.ethz.ch/pipermail/r-help/2013-October/360958.html
> 
> Scott
> 
>> 
>> ```
>> ping bugs.r-project.org
>> PING rbugs.research.att.com (207.140.168.137): 56 data bytes
>> Request timeout for icmp_seq 0
>> Request timeout for icmp_seq 1
>> Request timeout for icmp_seq 2
>> Request timeout for icmp_seq 3
>> Request timeout for icmp_seq 4
>> Request timeout for icmp_seq 5
>> Request timeout for icmp_seq 6
>> ```
>> 
>> 2. Is wday element of POSIXlt meant to be timezone invariant? You would expect the wday element to be invariant to the timezone of a date. That is, the same date/time instant of 5th October 2013 in both Australia/Sydney and UTC should be a Saturday (i.e. wday = 6). And indeed that is the case with 1 min past midnight on 5 October 2013:
>> 
>> ```
>> library(lubridate)
>> d_utc <- ymd_hms(20131005000001, tz='UTC')
>> d_local <- ymd_hms(20131005000001, tz='Australia/Sydney')
>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 6
>> ```
>> 
>> But this isn't always the case. For example,
>> 
>> ```
>> d_utc <- ymd_hms(20381002000001, tz='UTC')
>> d_local <- ymd_hms(20381002000001, tz='Australia/Sydney')
>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 5
>> ```
>> 
>> Is this expected behaviour? I would have expected a properly encoded date/time of 2 Oct 2038 to be a Saturday irrespective of its time zone.
>> 
>> Obligatory system dump:
>> 
>> ```
>>> sessionInfo()
>> R version 3.0.1 (2013-05-16)
>> Platform: x86_64-apple-darwin12.4.0 (64-bit)
>> 
>> locale:
>> [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8
>> 
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>> 
>> other attached packages:
>> [1] lubridate_1.3.0 testthat_0.7.1  devtools_1.3
>> 
>> loaded via a namespace (and not attached):
>> [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.3       evaluate_0.5.1
>> [5] ggplot2_0.9.3.1    grid_3.0.1         gtable_0.1.2       httr_0.2
>> [9] labeling_0.2       MASS_7.3-29        memoise_0.1        munsell_0.4.2
>> [13] parallel_3.0.1     plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
>> [17] RCurl_1.95-4.1     reshape2_1.2.2     scales_0.2.3       stringr_0.6.2
>> [21] tools_3.0.1        whisker_0.3-2
>> 
>> ```
>> 
>> Using R compiled by homebrew [1]. But also experiencing the same bug using R installed on Windows 7 from the CRAN binaries.
>> 
>> For those interested, I've also noted this on the `lubridate` Github issues page [2], even though this doesn't appear to be a lubridate issue.
>> 
>> Thanks for any help.
>> 
>> [1] http://brew.sh
>> [2] https://github.com/hadley/lubridate/issues/209
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> --
> Scott Kostyshak
> Economics PhD Candidate
> Princeton University
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From simon.urbanek at r-project.org  Sat Oct  5 13:42:49 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 5 Oct 2013 13:42:49 +0200
Subject: [Rd] Allow semantic versioning for packages
In-Reply-To: <CABtg=K=AB=eJu3dtEvqOtA0o_R37OdwNAZw=X-TDePJwLKnQDg@mail.gmail.com>
References: <CABtg=K=AB=eJu3dtEvqOtA0o_R37OdwNAZw=X-TDePJwLKnQDg@mail.gmail.com>
Message-ID: <7779BA7B-8282-44BA-9EB9-C16B33D88840@r-project.org>

Gabor,

what you propose is not really feasible, because R relies on the fact that it can meaningfully order the the versions as to determine the update order. If you use arbitrary strings then ordering becomes random - that's why git commit hashes are so useless for this purpose. The fact that you are forced to use something meaningful is for a good reason here.

Cheers,
Simon


On Oct 4, 2013, at 8:53 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> Dear R developers,
> 
> (http://bugs.r-project.org/ seems to be down, so I am writing a feature
> request here.)
> 
> It would be great to allow semantic version numbers for packages. See
> http://semver.org/ for details.
> 
> The problem I am having is that I am setting up a nightly build server, and
> there is no easy way to create a version number for builds that are in
> between releases.
> 
> Ideally I would use something like
> 
> TAG+DIST.HASH
> 
> TAG is the last tag of the git branch, usually something like
> MAJOR.MINOR.PATCH, DIST is the number of commits since the last release and
> HASH is the first seven letters of the git hash for the commit. E.g.
> 
> 0.7.0-pre+518.badcafe
> 
> Right now instead of this I am forced to use something like
> 
> 0.6.999.518
> 
> which is a lot less expressive and there is no (easy) way to include the
> branch information.
> 
> Thanks, Best Regards,
> Gabor
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From seanpor at acm.org  Sat Oct  5 16:51:05 2013
From: seanpor at acm.org (Sean O'Riordain)
Date: Sat, 5 Oct 2013 15:51:05 +0100
Subject: [Rd] Possible POSIXlt / wday glitch & bugs.r-project.org status
In-Reply-To: <CAPPM_gQBb_B5ukeBoCkd8rqwya-LdvUS0LGd7eRDzR=Scz8ZpA@mail.gmail.com>
References: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
	<CAE3=dmeXTKV=dmFD5PO30dK0spHzrb1k-F4ndiURp8_zEBxRng@mail.gmail.com>
	<3CF8C970-05CC-45C4-8CE0-E078C84121AF@me.com>
	<CAPPM_gQBb_B5ukeBoCkd8rqwya-LdvUS0LGd7eRDzR=Scz8ZpA@mail.gmail.com>
Message-ID: <CA+MmmTKJRwWegc=yPHo0mZ-=arhkMpw3PvyEspYS7jeH86gFOQ@mail.gmail.com>

Some people (luckily not me anymore!) working with mortgages and
pensions need to calculate up to 40 years into the future for the
payment schedule.

On 5 October 2013 02:37, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
> On Fri, Oct 4, 2013 at 8:02 PM, Imanuel Costigan <i.costigan at me.com> wrote:
>> Thanks for the responses and quoting the timezone help file.
>>
>> I am assuming that in order to determine the wday element of POSIXlt, R does the necessary calculations in Julian time (via POSIXct). Based on this excerpt from ?DateTimeClasses, it looks like R is responsible for determining time zones post 2037 (the example I gave was in 2038). So it could be an R issue.
>>
> It's an issue with size of the largest number you can store in a
> signed integer, which is not specific to R.
>
>> .POSIXct(.Machine$integer.max, tz="UTC")
> [1] "2038-01-19 03:14:07 UTC"
>
> Dates larger than that cannot be represented by a signed integer.  It
> could be worked around, but it's not trivial because R would have to
> use something other than the tm C struct.  Luckily, there's a decade
> or two before it starts to become a pressing issue. :)
>
>>>      ?"POSIXct"? objects may also have an attribute ?"tzone"?, a
>>>      character vector of length one.  If set to a non-empty value, it
>>>      will determine how the object is converted to class ?"POSIXlt"?
>>>      and in particular how it is printed.  This is usually desirable,
>>>      but if you want to specify an object in a particular timezone but
>>>      to be printed in the current timezone you may want to remove the
>>>      ?"tzone"? attribute (e.g. by ?c(x)?).
>>>
>>>      Unfortunately, the conversion is complicated by the operation of
>>>      time zones and leap seconds (24 days have been 86401 seconds long
>>>      so far: the times of the extra seconds are in the object
>>>      ?.leap.seconds?).  **The details of this are entrusted to the OS
>>>      services where possible.  This always covers the period 1970-2037,
>>>      and on most machines back to 1902 (when time zones were in their
>>>      infancy).  Outside the platform limits we use our own C code.
>>
>>
>> On 05/10/2013, at 12:59 AM, Scott Kostyshak <skostysh at princeton.edu> wrote:
>>
>>> On Fri, Oct 4, 2013 at 6:11 AM, Imanuel Costigan <i.costigan at me.com> wrote:
>>>> Wanted to raise two questions:
>>>>
>>>> 1. Is bugs.r-project.org down? I haven't been able to reach it for two or three days:
>>>
>>> Yes. Quote from Duncan:
>>>
>>>    ... the server is currently down. The volunteer who runs the server is
>>>    currently away from his office, so I expect it won't get fixed until he
>>>    gets back in a few days.
>>>
>>> https://stat.ethz.ch/pipermail/r-help/2013-October/360958.html
>>>
>>> Scott
>>>
>>>>
>>>> ```
>>>> ping bugs.r-project.org
>>>> PING rbugs.research.att.com (207.140.168.137): 56 data bytes
>>>> Request timeout for icmp_seq 0
>>>> Request timeout for icmp_seq 1
>>>> Request timeout for icmp_seq 2
>>>> Request timeout for icmp_seq 3
>>>> Request timeout for icmp_seq 4
>>>> Request timeout for icmp_seq 5
>>>> Request timeout for icmp_seq 6
>>>> ```
>>>>
>>>> 2. Is wday element of POSIXlt meant to be timezone invariant? You would expect the wday element to be invariant to the timezone of a date. That is, the same date/time instant of 5th October 2013 in both Australia/Sydney and UTC should be a Saturday (i.e. wday = 6). And indeed that is the case with 1 min past midnight on 5 October 2013:
>>>>
>>>> ```
>>>> library(lubridate)
>>>> d_utc <- ymd_hms(20131005000001, tz='UTC')
>>>> d_local <- ymd_hms(20131005000001, tz='Australia/Sydney')
>>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 6
>>>> ```
>>>>
>>>> But this isn't always the case. For example,
>>>>
>>>> ```
>>>> d_utc <- ymd_hms(20381002000001, tz='UTC')
>>>> d_local <- ymd_hms(20381002000001, tz='Australia/Sydney')
>>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 5
>>>> ```
>>>>
>>>> Is this expected behaviour? I would have expected a properly encoded date/time of 2 Oct 2038 to be a Saturday irrespective of its time zone.
>>>>
>>>> Obligatory system dump:
>>>>
>>>> ```
>>>>> sessionInfo()
>>>> R version 3.0.1 (2013-05-16)
>>>> Platform: x86_64-apple-darwin12.4.0 (64-bit)
>>>>
>>>> locale:
>>>> [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8
>>>>
>>>> attached base packages:
>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>
>>>> other attached packages:
>>>> [1] lubridate_1.3.0 testthat_0.7.1  devtools_1.3
>>>>
>>>> loaded via a namespace (and not attached):
>>>> [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.3       evaluate_0.5.1
>>>> [5] ggplot2_0.9.3.1    grid_3.0.1         gtable_0.1.2       httr_0.2
>>>> [9] labeling_0.2       MASS_7.3-29        memoise_0.1        munsell_0.4.2
>>>> [13] parallel_3.0.1     plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
>>>> [17] RCurl_1.95-4.1     reshape2_1.2.2     scales_0.2.3       stringr_0.6.2
>>>> [21] tools_3.0.1        whisker_0.3-2
>>>>
>>>> ```
>>>>
>>>> Using R compiled by homebrew [1]. But also experiencing the same bug using R installed on Windows 7 from the CRAN binaries.
>>>>
>>>> For those interested, I've also noted this on the `lubridate` Github issues page [2], even though this doesn't appear to be a lubridate issue.
>>>>
>>>> Thanks for any help.
>>>>
>>>> [1] http://brew.sh
>>>> [2] https://github.com/hadley/lubridate/issues/209
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>> --
>>> Scott Kostyshak
>>> Economics PhD Candidate
>>> Princeton University
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi.gabor at gmail.com  Sat Oct  5 16:58:16 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Sat, 5 Oct 2013 10:58:16 -0400
Subject: [Rd] Allow semantic versioning for packages
In-Reply-To: <7779BA7B-8282-44BA-9EB9-C16B33D88840@r-project.org>
References: <CABtg=K=AB=eJu3dtEvqOtA0o_R37OdwNAZw=X-TDePJwLKnQDg@mail.gmail.com>
	<7779BA7B-8282-44BA-9EB9-C16B33D88840@r-project.org>
Message-ID: <CABtg=K=rXyCtGmfhBa5EesSAATJiSUezm7JgTJYGCHXCx3ZZOQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131005/07d43034/attachment.pl>

From simon.urbanek at r-project.org  Sat Oct  5 20:18:27 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 5 Oct 2013 20:18:27 +0200
Subject: [Rd] Possible POSIXlt / wday glitch & bugs.r-project.org status
In-Reply-To: <CA+MmmTKJRwWegc=yPHo0mZ-=arhkMpw3PvyEspYS7jeH86gFOQ@mail.gmail.com>
References: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
	<CAE3=dmeXTKV=dmFD5PO30dK0spHzrb1k-F4ndiURp8_zEBxRng@mail.gmail.com>
	<3CF8C970-05CC-45C4-8CE0-E078C84121AF@me.com>
	<CAPPM_gQBb_B5ukeBoCkd8rqwya-LdvUS0LGd7eRDzR=Scz8ZpA@mail.gmail.com>
	<CA+MmmTKJRwWegc=yPHo0mZ-=arhkMpw3PvyEspYS7jeH86gFOQ@mail.gmail.com>
Message-ID: <C1A6679C-91B6-4EAB-A630-EFD2ABA641CB@r-project.org>

On Oct 5, 2013, at 4:51 PM, Sean O'Riordain <seanpor at acm.org> wrote:

> Some people (luckily not me anymore!) working with mortgages and
> pensions need to calculate up to 40 years into the future for the
> payment schedule.
> 

Just to clarify since the Joshua's comment was ambiguous (and in part plain wrong) - R's POSIXct has no such limit since it doesn't use integers, so that is not really the issue here. As the original post suggested there may be a bug in handing some cases where conversions hit the system libraries (that may truncate to integers) and some cases may be worked around - and that remains to be investigated.

Cheers,
Simon



> On 5 October 2013 02:37, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>> On Fri, Oct 4, 2013 at 8:02 PM, Imanuel Costigan <i.costigan at me.com> wrote:
>>> Thanks for the responses and quoting the timezone help file.
>>> 
>>> I am assuming that in order to determine the wday element of POSIXlt, R does the necessary calculations in Julian time (via POSIXct). Based on this excerpt from ?DateTimeClasses, it looks like R is responsible for determining time zones post 2037 (the example I gave was in 2038). So it could be an R issue.
>>> 
>> It's an issue with size of the largest number you can store in a
>> signed integer, which is not specific to R.
>> 
>>> .POSIXct(.Machine$integer.max, tz="UTC")
>> [1] "2038-01-19 03:14:07 UTC"
>> 
>> Dates larger than that cannot be represented by a signed integer.  It
>> could be worked around, but it's not trivial because R would have to
>> use something other than the tm C struct.  Luckily, there's a decade
>> or two before it starts to become a pressing issue. :)
>> 
>>>>     ?"POSIXct"? objects may also have an attribute ?"tzone"?, a
>>>>     character vector of length one.  If set to a non-empty value, it
>>>>     will determine how the object is converted to class ?"POSIXlt"?
>>>>     and in particular how it is printed.  This is usually desirable,
>>>>     but if you want to specify an object in a particular timezone but
>>>>     to be printed in the current timezone you may want to remove the
>>>>     ?"tzone"? attribute (e.g. by ?c(x)?).
>>>> 
>>>>     Unfortunately, the conversion is complicated by the operation of
>>>>     time zones and leap seconds (24 days have been 86401 seconds long
>>>>     so far: the times of the extra seconds are in the object
>>>>     ?.leap.seconds?).  **The details of this are entrusted to the OS
>>>>     services where possible.  This always covers the period 1970-2037,
>>>>     and on most machines back to 1902 (when time zones were in their
>>>>     infancy).  Outside the platform limits we use our own C code.
>>> 
>>> 
>>> On 05/10/2013, at 12:59 AM, Scott Kostyshak <skostysh at princeton.edu> wrote:
>>> 
>>>> On Fri, Oct 4, 2013 at 6:11 AM, Imanuel Costigan <i.costigan at me.com> wrote:
>>>>> Wanted to raise two questions:
>>>>> 
>>>>> 1. Is bugs.r-project.org down? I haven't been able to reach it for two or three days:
>>>> 
>>>> Yes. Quote from Duncan:
>>>> 
>>>>   ... the server is currently down. The volunteer who runs the server is
>>>>   currently away from his office, so I expect it won't get fixed until he
>>>>   gets back in a few days.
>>>> 
>>>> https://stat.ethz.ch/pipermail/r-help/2013-October/360958.html
>>>> 
>>>> Scott
>>>> 
>>>>> 
>>>>> ```
>>>>> ping bugs.r-project.org
>>>>> PING rbugs.research.att.com (207.140.168.137): 56 data bytes
>>>>> Request timeout for icmp_seq 0
>>>>> Request timeout for icmp_seq 1
>>>>> Request timeout for icmp_seq 2
>>>>> Request timeout for icmp_seq 3
>>>>> Request timeout for icmp_seq 4
>>>>> Request timeout for icmp_seq 5
>>>>> Request timeout for icmp_seq 6
>>>>> ```
>>>>> 
>>>>> 2. Is wday element of POSIXlt meant to be timezone invariant? You would expect the wday element to be invariant to the timezone of a date. That is, the same date/time instant of 5th October 2013 in both Australia/Sydney and UTC should be a Saturday (i.e. wday = 6). And indeed that is the case with 1 min past midnight on 5 October 2013:
>>>>> 
>>>>> ```
>>>>> library(lubridate)
>>>>> d_utc <- ymd_hms(20131005000001, tz='UTC')
>>>>> d_local <- ymd_hms(20131005000001, tz='Australia/Sydney')
>>>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 6
>>>>> ```
>>>>> 
>>>>> But this isn't always the case. For example,
>>>>> 
>>>>> ```
>>>>> d_utc <- ymd_hms(20381002000001, tz='UTC')
>>>>> d_local <- ymd_hms(20381002000001, tz='Australia/Sydney')
>>>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 5
>>>>> ```
>>>>> 
>>>>> Is this expected behaviour? I would have expected a properly encoded date/time of 2 Oct 2038 to be a Saturday irrespective of its time zone.
>>>>> 
>>>>> Obligatory system dump:
>>>>> 
>>>>> ```
>>>>>> sessionInfo()
>>>>> R version 3.0.1 (2013-05-16)
>>>>> Platform: x86_64-apple-darwin12.4.0 (64-bit)
>>>>> 
>>>>> locale:
>>>>> [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8
>>>>> 
>>>>> attached base packages:
>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>> 
>>>>> other attached packages:
>>>>> [1] lubridate_1.3.0 testthat_0.7.1  devtools_1.3
>>>>> 
>>>>> loaded via a namespace (and not attached):
>>>>> [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.3       evaluate_0.5.1
>>>>> [5] ggplot2_0.9.3.1    grid_3.0.1         gtable_0.1.2       httr_0.2
>>>>> [9] labeling_0.2       MASS_7.3-29        memoise_0.1        munsell_0.4.2
>>>>> [13] parallel_3.0.1     plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
>>>>> [17] RCurl_1.95-4.1     reshape2_1.2.2     scales_0.2.3       stringr_0.6.2
>>>>> [21] tools_3.0.1        whisker_0.3-2
>>>>> 
>>>>> ```
>>>>> 
>>>>> Using R compiled by homebrew [1]. But also experiencing the same bug using R installed on Windows 7 from the CRAN binaries.
>>>>> 
>>>>> For those interested, I've also noted this on the `lubridate` Github issues page [2], even though this doesn't appear to be a lubridate issue.
>>>>> 
>>>>> Thanks for any help.
>>>>> 
>>>>> [1] http://brew.sh
>>>>> [2] https://github.com/hadley/lubridate/issues/209
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>>> 
>>>> --
>>>> Scott Kostyshak
>>>> Economics PhD Candidate
>>>> Princeton University
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From simon.urbanek at r-project.org  Sat Oct  5 20:23:25 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 5 Oct 2013 20:23:25 +0200
Subject: [Rd] Allow semantic versioning for packages
In-Reply-To: <CABtg=K=rXyCtGmfhBa5EesSAATJiSUezm7JgTJYGCHXCx3ZZOQ@mail.gmail.com>
References: <CABtg=K=AB=eJu3dtEvqOtA0o_R37OdwNAZw=X-TDePJwLKnQDg@mail.gmail.com>
	<7779BA7B-8282-44BA-9EB9-C16B33D88840@r-project.org>
	<CABtg=K=rXyCtGmfhBa5EesSAATJiSUezm7JgTJYGCHXCx3ZZOQ@mail.gmail.com>
Message-ID: <3015BC91-3B84-4AAF-9490-9C6FE4A4EEF1@r-project.org>

Gabor,

On Oct 5, 2013, at 4:58 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> Simon,
> 
> I think there is a misunderstanding here. I am not suggesting anarchy, completely the opposite.
> 
> Semantic versioning as defined on http://semver.org was designed exactly for being able to order the versions, and being able to express release candidates, alpha and beta builds, etc. An example ordering from the homepage:
> 
> 1.0.0-alpha < 1.0.0-alpha.1 < 1.0.0-alpha.beta < 1.0.0-beta < 1.0.0-beta.2 < 1.0.0-beta.11 < 1.0.0-rc.1 < 1.0.0.
> 
> Currently there is no way to give a version number to my builds that are in between releases. Having multiple branches of development is even more problematic. 
> 
> My problem is not that I am forced to use something meaningful. My problem is that the system I am forced to use is not expressive enough.
> 
> Hope it is clearer now.

Yes, thanks. The way I understand it, you are proposing extensions to the existing scheme that allow arbitrary additional content in the version numbers that is to be ignored. I fear that the scheme as described in semver.org is incompatible with the scheme used by R, so I don't think it can be adapted as-is, but one could cook up something similar with slightly different rules which define which part is ignored. It may break existing tools, so it would have to be considered carefully.

Cheers,
Simon


> Gabor
> 
> On Sat, Oct 5, 2013 at 7:42 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> Gabor,
> 
> what you propose is not really feasible, because R relies on the fact that it can meaningfully order the the versions as to determine the update order. If you use arbitrary strings then ordering becomes random - that's why git commit hashes are so useless for this purpose. The fact that you are forced to use something meaningful is for a good reason here.
> 
> Cheers,
> Simon
> 
> 
> On Oct 4, 2013, at 8:53 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> 
> > Dear R developers,
> >
> > (http://bugs.r-project.org/ seems to be down, so I am writing a feature
> > request here.)
> >
> > It would be great to allow semantic version numbers for packages. See
> > http://semver.org/ for details.
> >
> > The problem I am having is that I am setting up a nightly build server, and
> > there is no easy way to create a version number for builds that are in
> > between releases.
> >
> > Ideally I would use something like
> >
> > TAG+DIST.HASH
> >
> > TAG is the last tag of the git branch, usually something like
> > MAJOR.MINOR.PATCH, DIST is the number of commits since the last release and
> > HASH is the first seven letters of the git hash for the commit. E.g.
> >
> > 0.7.0-pre+518.badcafe
> >
> > Right now instead of this I am forced to use something like
> >
> > 0.6.999.518
> >
> > which is a lot less expressive and there is no (easy) way to include the
> > branch information.
> >
> > Thanks, Best Regards,
> > Gabor
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 


From csardi.gabor at gmail.com  Sat Oct  5 21:19:19 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Sat, 5 Oct 2013 15:19:19 -0400
Subject: [Rd] Allow semantic versioning for packages
In-Reply-To: <3015BC91-3B84-4AAF-9490-9C6FE4A4EEF1@r-project.org>
References: <CABtg=K=AB=eJu3dtEvqOtA0o_R37OdwNAZw=X-TDePJwLKnQDg@mail.gmail.com>
	<7779BA7B-8282-44BA-9EB9-C16B33D88840@r-project.org>
	<CABtg=K=rXyCtGmfhBa5EesSAATJiSUezm7JgTJYGCHXCx3ZZOQ@mail.gmail.com>
	<3015BC91-3B84-4AAF-9490-9C6FE4A4EEF1@r-project.org>
Message-ID: <CABtg=Kknq3SW-E=LPNBiSrat9NERTATrtedXe46qcCw5tOKRQg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131005/a4aeb577/attachment.pl>

From i.costigan at me.com  Sun Oct  6 00:47:56 2013
From: i.costigan at me.com (Imanuel Costigan)
Date: Sun, 06 Oct 2013 09:47:56 +1100
Subject: [Rd] Possible POSIXlt / wday glitch & bugs.r-project.org status
In-Reply-To: <C1A6679C-91B6-4EAB-A630-EFD2ABA641CB@r-project.org>
References: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
	<CAE3=dmeXTKV=dmFD5PO30dK0spHzrb1k-F4ndiURp8_zEBxRng@mail.gmail.com>
	<3CF8C970-05CC-45C4-8CE0-E078C84121AF@me.com>
	<CAPPM_gQBb_B5ukeBoCkd8rqwya-LdvUS0LGd7eRDzR=Scz8ZpA@mail.gmail.com>
	<CA+MmmTKJRwWegc=yPHo0mZ-=arhkMpw3PvyEspYS7jeH86gFOQ@mail.gmail.com>
	<C1A6679C-91B6-4EAB-A630-EFD2ABA641CB@r-project.org>
Message-ID: <E29B6F11-2628-46E3-8A6D-0F450F021F21@me.com>

Thanks for the clarification Simon. Having a look at the code in datetime.c, I can't say that I envy its maintainer. Looks like there are a lot of "hacks" to get things working. 

For the time being, I am going to override the TZ environment variable to be UTC as at this time I don't need to worry about converting between time zones - although I will in the future.

Also - I can't submit a new bug to your website's hosting of R bugs. The "submit new bug" page doesn't load. I also get a certificate error when visiting your site's mirror.

Thanks!


On 06/10/2013, at 5:18 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> On Oct 5, 2013, at 4:51 PM, Sean O'Riordain <seanpor at acm.org> wrote:
> 
>> Some people (luckily not me anymore!) working with mortgages and
>> pensions need to calculate up to 40 years into the future for the
>> payment schedule.
>> 
> 
> Just to clarify since the Joshua's comment was ambiguous (and in part plain wrong) - R's POSIXct has no such limit since it doesn't use integers, so that is not really the issue here. As the original post suggested there may be a bug in handing some cases where conversions hit the system libraries (that may truncate to integers) and some cases may be worked around - and that remains to be investigated.
> 
> Cheers,
> Simon
> 
> 
> 
>> On 5 October 2013 02:37, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>>> On Fri, Oct 4, 2013 at 8:02 PM, Imanuel Costigan <i.costigan at me.com> wrote:
>>>> Thanks for the responses and quoting the timezone help file.
>>>> 
>>>> I am assuming that in order to determine the wday element of POSIXlt, R does the necessary calculations in Julian time (via POSIXct). Based on this excerpt from ?DateTimeClasses, it looks like R is responsible for determining time zones post 2037 (the example I gave was in 2038). So it could be an R issue.
>>>> 
>>> It's an issue with size of the largest number you can store in a
>>> signed integer, which is not specific to R.
>>> 
>>>> .POSIXct(.Machine$integer.max, tz="UTC")
>>> [1] "2038-01-19 03:14:07 UTC"
>>> 
>>> Dates larger than that cannot be represented by a signed integer.  It
>>> could be worked around, but it's not trivial because R would have to
>>> use something other than the tm C struct.  Luckily, there's a decade
>>> or two before it starts to become a pressing issue. :)
>>> 
>>>>>    ?"POSIXct"? objects may also have an attribute ?"tzone"?, a
>>>>>    character vector of length one.  If set to a non-empty value, it
>>>>>    will determine how the object is converted to class ?"POSIXlt"?
>>>>>    and in particular how it is printed.  This is usually desirable,
>>>>>    but if you want to specify an object in a particular timezone but
>>>>>    to be printed in the current timezone you may want to remove the
>>>>>    ?"tzone"? attribute (e.g. by ?c(x)?).
>>>>> 
>>>>>    Unfortunately, the conversion is complicated by the operation of
>>>>>    time zones and leap seconds (24 days have been 86401 seconds long
>>>>>    so far: the times of the extra seconds are in the object
>>>>>    ?.leap.seconds?).  **The details of this are entrusted to the OS
>>>>>    services where possible.  This always covers the period 1970-2037,
>>>>>    and on most machines back to 1902 (when time zones were in their
>>>>>    infancy).  Outside the platform limits we use our own C code.
>>>> 
>>>> 
>>>> On 05/10/2013, at 12:59 AM, Scott Kostyshak <skostysh at princeton.edu> wrote:
>>>> 
>>>>> On Fri, Oct 4, 2013 at 6:11 AM, Imanuel Costigan <i.costigan at me.com> wrote:
>>>>>> Wanted to raise two questions:
>>>>>> 
>>>>>> 1. Is bugs.r-project.org down? I haven't been able to reach it for two or three days:
>>>>> 
>>>>> Yes. Quote from Duncan:
>>>>> 
>>>>>  ... the server is currently down. The volunteer who runs the server is
>>>>>  currently away from his office, so I expect it won't get fixed until he
>>>>>  gets back in a few days.
>>>>> 
>>>>> https://stat.ethz.ch/pipermail/r-help/2013-October/360958.html
>>>>> 
>>>>> Scott
>>>>> 
>>>>>> 
>>>>>> ```
>>>>>> ping bugs.r-project.org
>>>>>> PING rbugs.research.att.com (207.140.168.137): 56 data bytes
>>>>>> Request timeout for icmp_seq 0
>>>>>> Request timeout for icmp_seq 1
>>>>>> Request timeout for icmp_seq 2
>>>>>> Request timeout for icmp_seq 3
>>>>>> Request timeout for icmp_seq 4
>>>>>> Request timeout for icmp_seq 5
>>>>>> Request timeout for icmp_seq 6
>>>>>> ```
>>>>>> 
>>>>>> 2. Is wday element of POSIXlt meant to be timezone invariant? You would expect the wday element to be invariant to the timezone of a date. That is, the same date/time instant of 5th October 2013 in both Australia/Sydney and UTC should be a Saturday (i.e. wday = 6). And indeed that is the case with 1 min past midnight on 5 October 2013:
>>>>>> 
>>>>>> ```
>>>>>> library(lubridate)
>>>>>> d_utc <- ymd_hms(20131005000001, tz='UTC')
>>>>>> d_local <- ymd_hms(20131005000001, tz='Australia/Sydney')
>>>>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>>>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 6
>>>>>> ```
>>>>>> 
>>>>>> But this isn't always the case. For example,
>>>>>> 
>>>>>> ```
>>>>>> d_utc <- ymd_hms(20381002000001, tz='UTC')
>>>>>> d_local <- ymd_hms(20381002000001, tz='Australia/Sydney')
>>>>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>>>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 5
>>>>>> ```
>>>>>> 
>>>>>> Is this expected behaviour? I would have expected a properly encoded date/time of 2 Oct 2038 to be a Saturday irrespective of its time zone.
>>>>>> 
>>>>>> Obligatory system dump:
>>>>>> 
>>>>>> ```
>>>>>>> sessionInfo()
>>>>>> R version 3.0.1 (2013-05-16)
>>>>>> Platform: x86_64-apple-darwin12.4.0 (64-bit)
>>>>>> 
>>>>>> locale:
>>>>>> [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8
>>>>>> 
>>>>>> attached base packages:
>>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>> 
>>>>>> other attached packages:
>>>>>> [1] lubridate_1.3.0 testthat_0.7.1  devtools_1.3
>>>>>> 
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.3       evaluate_0.5.1
>>>>>> [5] ggplot2_0.9.3.1    grid_3.0.1         gtable_0.1.2       httr_0.2
>>>>>> [9] labeling_0.2       MASS_7.3-29        memoise_0.1        munsell_0.4.2
>>>>>> [13] parallel_3.0.1     plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
>>>>>> [17] RCurl_1.95-4.1     reshape2_1.2.2     scales_0.2.3       stringr_0.6.2
>>>>>> [21] tools_3.0.1        whisker_0.3-2
>>>>>> 
>>>>>> ```
>>>>>> 
>>>>>> Using R compiled by homebrew [1]. But also experiencing the same bug using R installed on Windows 7 from the CRAN binaries.
>>>>>> 
>>>>>> For those interested, I've also noted this on the `lubridate` Github issues page [2], even though this doesn't appear to be a lubridate issue.
>>>>>> 
>>>>>> Thanks for any help.
>>>>>> 
>>>>>> [1] http://brew.sh
>>>>>> [2] https://github.com/hadley/lubridate/issues/209
>>>>>> 
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>>> 
>>>>> --
>>>>> Scott Kostyshak
>>>>> Economics PhD Candidate
>>>>> Princeton University
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 


From gevis.inko at gmail.com  Sat Oct  5 21:48:46 2013
From: gevis.inko at gmail.com (Gevis Inko)
Date: Sat, 5 Oct 2013 22:48:46 +0300
Subject: [Rd] Compiler warning: function returns address of local variable
Message-ID: <CAO1+OHn7tF9PZP4N9Dxfm6ScK_6=HEWFZVbrrFMrsyxVDrjb6A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131005/e6988c13/attachment.pl>

From edd at debian.org  Mon Oct  7 01:54:41 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 6 Oct 2013 18:54:41 -0500
Subject: [Rd] R 3.1.0 and C++11
Message-ID: <21073.63553.888272.510490@max.nulle.part>


I would like to bring up two issues concerning C++11.


First, the R-devel manuals contain incorrect statements regarding C++11:

  i)   R-exts.texi:

       Although there is a 2011 version of the C++ standard, it is not yet
       fully implemented (nor is it likely to be widely available for some
       years) and portable C++ code needs to follow the 1998 standard
       (and not use features from C99).

  ii)  R-ints.texi:

       The type `R_xlen_t' is made available to packages in C header
       `Rinternals.h': this should be fine in C code since C99 is
       required.  People do try to use R internals in C++, but C++98
       compilers are not required to support these types (and there are
       currently no C++11 compilers).

But since the summer we have g++ and clang with working C++11 implementations:

  iii) g++ implements C++11: 
       http://isocpp.org/blog/2013/05/gcc-4.8.1-released-c11-feature-complete
 
  iv)  llvm/clang++ implements C++11:
       http://isocpp.org/blog/2013/06/llvm-3.3-is-released

I would suggest to change the wording prior to the release of R 3.1.0 next
year as it is likely that even Microsoft will by then have a fully-conformant
compiler (per Herb Sutter at a recent talk in Chicago). If it helped, I would
be glad to provide minimal patches to the two .texi files.

Moreover, the C++ Standards Group is working towards closing the delta
between standards being adopted, and compilers being released. They expect
corresponding compilers for C++14 (a "patch" release for C++11 expected to be
ready next spring) to be available within a year---possibly during 2014.


Second, the current R Policy regarding C++11 is unnecessarily strict. I would
propose to treat the availability of C++11 extensions more like the
availability of OpenMP: something which configure can probe at build time,
and which can be deployed later via suitable #ifdef tests.

As a proof of concept, I added this macro from the autoconf archive to the
m4/ directory of R-devel:

  http://www.gnu.org/software/autoconf-archive/ax_cxx_compile_stdcxx_11.html

and made a one-line change to configure.ac (indented two spaces just for email)

  edd at max:~/svn/r-devel$ svn di configure.ac
  Index: configure.ac
  ===================================================================
  --- configure.ac	(revision 64031)
  +++ configure.ac	(working copy)
  @@ -906,6 +906,7 @@
 
   AC_LANG_PUSH(C++)
   AC_OPENMP
  +AX_CXX_COMPILE_STDCXX_11(noext)
   AC_LANG_POP(C++)
 
   ### *** ObjC compiler
  edd at max:~/svn/r-devel$ 

After running 'aclocal -Im4; autoheader; autoconf', the configure test then
properly detected C++11 (or, in one case, C++0x) on four different compilers:

  [ g++-4.7 case, Ubuntu 13.04 ]
  checking whether g++ supports C++11 features by default... no
  checking whether g++ supports C++11 features with -std=c++11... no
  checking whether g++ supports C++11 features with -std=c++0x... yes

  [ CC=clang CXX=clang++ (3.1), Ubuntu 13.04 ]
  checking whether clang++ accepts -M for generating dependencies... yes
  checking for clang++ option to support OpenMP... unsupported
  checking whether clang++ supports C++11 features by default... no
  checking whether clang++ supports C++11 features with -std=c++11... yes

  [ g++-4.8 case, Debian testing ]
  checking whether g++ supports C++11 features by default... no
  checking whether g++ supports C++11 features with -std=c++11... yes

  [ CC=clang CXX=clang++ (3.2), Debian testing ]
  checking whether clang++ supports C++11 features by default... no
  checking whether clang++ supports C++11 features with -std=c++11... yes

It would be easy to another #define to config.h.in. 


And of course, I understand that R Core is comprised primarily of C
programmers.  But to those of us who lean more towards C++ than C, the step
towards C++11 is a big one, and a very exciting one.  More and more upstream
authors are considering right now whether to switch to C++11-only.  I expect
such switches to become more common as time pass. C++11 provides a lot -- and
preventing programmers from using these tools cannot be in our interest.

I think that the timing of the next R release will be a good opportunity to
permit use of C++11 where compilers support it -- as a wide range of sites
will already be capable of deploying it.

Thanks, Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From ripley at stats.ox.ac.uk  Mon Oct  7 09:05:29 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 07 Oct 2013 08:05:29 +0100
Subject: [Rd] Compiler warning: function returns address of local
	variable
In-Reply-To: <CAO1+OHn7tF9PZP4N9Dxfm6ScK_6=HEWFZVbrrFMrsyxVDrjb6A@mail.gmail.com>
References: <CAO1+OHn7tF9PZP4N9Dxfm6ScK_6=HEWFZVbrrFMrsyxVDrjb6A@mail.gmail.com>
Message-ID: <52525D39.5070304@stats.ox.ac.uk>

On 05/10/2013 20:48, Gevis Inko wrote:
> I am a Gentoo user. I have just upgraded my Gentoo system,
> as I usually do every Saturday. During this process, my previous
> dev-lang/R-2.10.1 ebuild package has been upgraded to R-3.0.1.
> While compiling it, I have got the following compiler warning:
>
>   * QA Notice: Package triggers severe warnings which indicate that it
>   *            may exhibit random runtime failures.
>   * main.c:1548:5: warning: function returns address of local variable
> [enabled by default]
>
>   * Please do not file a Gentoo bug and instead report the above QA
>   * issues directly to the upstream developers of this software.
>   * Homepage: http://www.r-project.org/
>
> The Bug Tracking page of www.r-project.org simply do not open.

It was down for a few days whilst the hardware was moved to another 
site.  It is up now at https://rbugs.urbanek.info/bugzilla3/, and 
hopefully will be available again as bugs.r-project.org today.

> So, I've just subscribed to this mailing list to post this compiler
> warning here.
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

That is the whole point of that piece of C code, so please do report the 
Gentoo bug (their message is simply bogus) to them.

And also read posting guide before posting: HTML mail is not allowed here.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From radford at cs.toronto.edu  Mon Oct  7 13:06:28 2013
From: radford at cs.toronto.edu (Radford Neal)
Date: Mon, 7 Oct 2013 07:06:28 -0400
Subject: [Rd] Compiler warning: function returns address of local
	variable
In-Reply-To: <mailman.19.1381140007.24261.r-devel@r-project.org>
References: <mailman.19.1381140007.24261.r-devel@r-project.org>
Message-ID: <20131007110628.GA10478@cs.toronto.edu>

> > ..., my previous
> > dev-lang/R-2.10.1 ebuild package has been upgraded to R-3.0.1.
> > While compiling it, I have got the following compiler warning:
> >
> >   * QA Notice: Package triggers severe warnings which indicate that it
> >   *            may exhibit random runtime failures.
> >   * main.c:1548:5: warning: function returns address of local variable
> > [enabled by default]
> >
> >   * Please do not file a Gentoo bug and instead report the above QA
> >   * issues directly to the upstream developers of this software.
> >   * Homepage: http://www.r-project.org/

> That is the whole point of that piece of C code, so please do report the 
> Gentoo bug (their message is simply bogus) to them.
> 
> And also read posting guide before posting: HTML mail is not allowed here.
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk


The message is certainly not "simply bogus".  Returning the address of
a local variable is almost always a bug.

In this case, there is no real bug in R-3.0.1, since the result is
used for the low-level, system-dependent operation of determining the
direction of stack growth, but this is a very rare use.  For the
compiler to issue such a warning is fully justified.

The warning could be avoided by using the approach taken in pqR, which
has the following routine in main.c:

  /* Detemine whether the stack grows down (+1) or up (-1).  Passed the
     address of a local variable in the caller's stack frame.
  
     This is put here, though called only from system.c, so that the compiler
     will not be able to inline it. */
  
  int R_stack_growth_direction (uintptr_t cvaraddr)
  {
      int dummy;
      return (uintptr_t) &dummy < cvaraddr ? 1 : -1;
  }


From Rainer at krugs.de  Mon Oct  7 14:15:33 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Mon, 7 Oct 2013 14:15:33 +0200
Subject: [Rd] SOLVED:  check warning  with .onLoad() and setClass()
In-Reply-To: <706F64ED-1815-4E92-AF2A-F054580B27D4@r-project.org> (John
	Chambers's message of "Fri, 4 Oct 2013 09:56:44 -0700")
References: <m2zjqqfybi.fsf@krugs.de>
	<AD583E37-4E49-406C-B4A8-8F13C31E9B14@r-project.org>
	<m28uy9b8tu.fsf@krugs.de> <21070.43875.526391.331124@max.nulle.part>
	<m2fvshfd09.fsf@krugs.de> <21070.47559.867778.190980@max.nulle.part>
	<m238ohuo1s.fsf@krugs.de>
	<706F64ED-1815-4E92-AF2A-F054580B27D4@r-project.org>
Message-ID: <m2a9ili8ey.fsf_-_@krugs.de>

Thanks John and Dirk for your input.

I solved the problem by importing the package "simecol" which defines
the superclass simEcol in the NAMESPACE file with import(simEcol) and to
leave it in the DESCRIPTION file in the Depends section (as the
functions have to be available for the end user).

I reverted back to the .onLoad() function:

,----
| .onLoad <- function(libname, pkgname) {
|     setClass(
|         "inDrak",
|         representation(
|             init = "SpatialGridDataFrame"
|             ),
|         contains = "simObj"
|         )
| }
`----

and it works and does not give an error on R CMD check.

Thanks a lot,

Rainer



John Chambers <jmc at r-project.org> writes:

> The basic tool is setLoadActions(), which takes a function definition,
> with the package's namespace as its argument.  Read ?setLoadActions
>
> There is no such thing as setLoadFunction, as far as the standard code in R.
>
> While you haven't defined "didn't work", an off-the-top-of-the-head
> idea would be something like:
>
>    setLoadActions(function(ns) {setClass(....., where = ns)})
>
>
> On Oct 4, 2013, at 7:07 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>
>> Dirk Eddelbuettel <edd at debian.org> writes:
>> 
>>> On 4 October 2013 at 14:15, Rainer M Krug wrote:
>>> | Hm. loadModule is Rcpp function, but I am only interested in using the
>>> | setClass() function, which has nothing to do with Rcpp. I don't even use
>>> | Rcpp in the package, only in one which is imported.
>>> 
>>> Sorry, assumed Reference Class created via Modules. My bad, and never mind.
>>> 
>>> But as John said, .onLoad() can be replaces since he made those changes in R
>>> (and also in Rcpp). See ?setLoadAction, evalOnLoad(), ...
>> 
>> Ok - theat far I folow you. But how do I implement this?
>> 
>> I have now the following .onLoad() function:
>> 
>> ,----
>> | .onLoad <- function(libname, pkgname) {
>> |     setClass(
>> |         "inDrak",
>> |         representation(
>> |             init = "SpatialGridDataFrame"
>> |             ),
>> |         contains = "simObj"
>> |         )
>> | }
>> `----
>> 
>> in the file ./R/onLoad.R in my package.
>> 
>> Now how can I now use the setLoadFunction()? I tried to simply put the
>> setClass in the setLoadFunction() as follow into the ./R/onLoad.R file:
>> 
>> ,----
>> | setLoadFunction( function(libname, pkgname) {
>> |     setClass(
>> |         "inDrak",
>> |         representation(
>> |             init = "SpatialGridDataFrame"
>> |             ),
>> |         contains = "simObj"
>> |         )
>> | }
>> `----
>> 
>> but this did not work. 
>> 
>> So what do I have to do with it? I only find very few examples using
>> setLoadFunction().
>> 
>> Rainer
>> 
>> 
>>> 
>>> Dirk
>> 
>> 
>> -- 
>> Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)
>> 
>> Centre of Excellence for Invasion Biology
>> Stellenbosch University
>> South Africa
>> 
>> Tel :       +33 - (0)9 53 10 27 44
>> Cell:       +33 - (0)6 85 62 59 98
>> Fax :       +33 - (0)9 58 10 27 44
>> 
>> Fax (D):    +49 - (0)3 21 21 25 22 44
>> 
>> email:      Rainer at krugs.de
>> 
>> Skype:      RMkrug
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
<#secure method=pgpmime mode=sign>

-- 
Rainer M. Krug, PhD (Conservation Ecology, SUN), MSc (Conservation Biology, UCT), Dipl. Phys. (Germany)

Centre of Excellence for Invasion Biology
Stellenbosch University
South Africa

Tel :       +33 - (0)9 53 10 27 44
Cell:       +33 - (0)6 85 62 59 98
Fax :       +33 - (0)9 58 10 27 44

Fax (D):    +49 - (0)3 21 21 25 22 44

email:      Rainer at krugs.de

Skype:      RMkrug


From renaud at mancala.cbio.uct.ac.za  Mon Oct  7 14:27:10 2013
From: renaud at mancala.cbio.uct.ac.za (Renaud Gaujoux)
Date: Mon, 7 Oct 2013 14:27:10 +0200
Subject: [Rd] [Windows] Behaviour of shell on error
Message-ID: <CAHavPHH-y85tNHni+TS1edWNjuuzYtQSPrfbdhCSMTQu2PTHAA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131007/2712230e/attachment.pl>

From Rainer at krugs.de  Mon Oct  7 16:29:49 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Mon, 7 Oct 2013 16:29:49 +0200
Subject: [Rd] search for variable in package in .GlobalEnv first
Message-ID: <m2d2nhgnmq.fsf@krugs.de>

Hi

First, sorry if I get the terminology wrong, I am still quite new to the
concept of using environments and workspaces.

Say I have a statement in a package SIM like

sim <- TYPE

where the variable TYPE is initialized in the package to
e.g. "exponential" (SIM::TYPE == "exponential").

Now, I want to give the user the option of specifying the variable TYPE,
but to the effect, that if the user does not define a variable TYPE in
the user workspace (.GobalEnv), the one in the namespace from the
package is used.

In other words, I want to look first in the workspace, and then in SIM::
for the variable TYPE. How can do this?

Thanks,

Rainer

-- 
Rainer M. Krug

email: RMKrug<at>gmail<dot>com
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 486 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131007/97e26fd7/attachment.bin>

From murdoch.duncan at gmail.com  Mon Oct  7 17:06:11 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 7 Oct 2013 11:06:11 -0400
Subject: [Rd] search for variable in package in .GlobalEnv first
In-Reply-To: <m2d2nhgnmq.fsf@krugs.de>
References: <m2d2nhgnmq.fsf@krugs.de>
Message-ID: <5252CDE3.7070008@gmail.com>

On 07/10/2013 10:29 AM, Rainer M Krug wrote:
> Hi
>
> First, sorry if I get the terminology wrong, I am still quite new to the
> concept of using environments and workspaces.
>
> Say I have a statement in a package SIM like
>
> sim <- TYPE
>
> where the variable TYPE is initialized in the package to
> e.g. "exponential" (SIM::TYPE == "exponential").
>
> Now, I want to give the user the option of specifying the variable TYPE,
> but to the effect, that if the user does not define a variable TYPE in
> the user workspace (.GobalEnv), the one in the namespace from the
> package is used.
>
> In other words, I want to look first in the workspace, and then in SIM::
> for the variable TYPE. How can do this?

The rgl package does this when looking for defaults for graphics. Here's 
the code:


getr3dDefaults <- function()
     tryCatch(get("r3dDefaults", envir=.GlobalEnv),
          error = function(e) r3dDefaults)

This will find the variable r3dDefaults if it is in the global 
environment or in a package on the search path; if that fails, it 
returns the local one.  Since that function is defined in the package, 
it can see the local r3dDefaults variable.  You might not want to accept 
anything except what is in .GlobalEnv; in that case, use inherits = 
FALSE in the call to get().

Duncan Murdoch


From Rainer at krugs.de  Mon Oct  7 17:22:12 2013
From: Rainer at krugs.de (Rainer M Krug)
Date: Mon, 7 Oct 2013 17:22:12 +0200
Subject: [Rd] SOLVED: search for variable in package in .GlobalEnv first
In-Reply-To: <5252CDE3.7070008@gmail.com> (Duncan Murdoch's message of "Mon, 7
	Oct 2013 11:06:11 -0400")
References: <m2d2nhgnmq.fsf@krugs.de> <5252CDE3.7070008@gmail.com>
Message-ID: <m261t9gl7f.fsf_-_@krugs.de>

Duncan Murdoch <murdoch.duncan at gmail.com> writes:

> On 07/10/2013 10:29 AM, Rainer M Krug wrote:
>> Hi
>>
>> First, sorry if I get the terminology wrong, I am still quite new to the
>> concept of using environments and workspaces.
>>
>> Say I have a statement in a package SIM like
>>
>> sim <- TYPE
>>
>> where the variable TYPE is initialized in the package to
>> e.g. "exponential" (SIM::TYPE == "exponential").
>>
>> Now, I want to give the user the option of specifying the variable TYPE,
>> but to the effect, that if the user does not define a variable TYPE in
>> the user workspace (.GobalEnv), the one in the namespace from the
>> package is used.
>>
>> In other words, I want to look first in the workspace, and then in SIM::
>> for the variable TYPE. How can do this?
>
> The rgl package does this when looking for defaults for
> graphics. Here's the code:
>
>
> getr3dDefaults <- function()
>     tryCatch(get("r3dDefaults", envir=.GlobalEnv),
>          error = function(e) r3dDefaults)
>
> This will find the variable r3dDefaults if it is in the global
> environment or in a package on the search path; if that fails, it
> returns the local one.  Since that function is defined in the package,
> it can see the local r3dDefaults variable.  You might not want to
> accept anything except what is in .GlobalEnv; in that case, use
> inherits = FALSE in the call to get().

Thanks a lot - works like a charm.

I actually like the ide of searching the searchpath down.

Thanks,

Rainer

>
> Duncan Murdoch
>
<#secure method=pgpmime mode=sign>

-- 
Rainer M. Krug

email: RMKrug<at>gmail<dot>com


From plummerm at iarc.fr  Mon Oct  7 18:18:39 2013
From: plummerm at iarc.fr (Martyn Plummer)
Date: Mon, 7 Oct 2013 16:18:39 +0000
Subject: [Rd] C++ debugging help needed
In-Reply-To: <524F1169.4020308@gmail.com>
References: <524C32CF.2060307@gmail.com> <524F1169.4020308@gmail.com>
Message-ID: <1381162714.1811.27.camel@braque.iarc.fr>

Yes, on reflection it's an ABI problem on Linux (use of PIC code in
shared libraries means that any symbol can be interposed).  Using
namespaces isn't really the answer because that's an API issue.  I think
what you really need to do is control the visibility of your classes and
functions so that everything is hidden except for the entry points you
call from R (Writing R Extensions section 6.15).  This should stop the
symbol collision because hidden functions are resolved inside the shared
object instead of going through a lookup table that can be overwritten
by someone else's package.

Martyn



On Fri, 2013-10-04 at 15:05 -0400, Duncan Murdoch wrote:
> I have now got two "solutions" to this.  The rgl version currently on 
> CRAN does a simple rename to avoid the name clash. A later version, 
> still only on R-forge, puts most objects into a namespace called "rgl".  
> (The old code had two small namespaces "gui" and "lib"; they are gone now.)
> 
> I am not yet confident that the current version with namespaces will 
> compile on all platforms; it seems much more fragile this way, with 
> errors showing up on Linux that were not errors on Windows.  (E.g. 
> sometimes I included a header with declarations in the rgl namespace 
> followed by system header files, and the latter acted differently than 
> they did when placed before the rgl header file, apparently declaring 
> the system functions to be in a new anonymous namespace.)
> 
> rgl also includes some C code from the gl2ps project and some C++ code 
> from FTGL; I didn't put those into the rgl namespace.  So there are 
> still possibilities for clashes if anyone else uses those.
> 
> I'm still surprised that anything with plugins works on Unix-alike 
> systems with such bizarre linking rules.  This is one of those few cases 
> where the Windows design seems clearly superior.
> 
> Duncan Murdoch
> 
> 
> On 02/10/2013 10:50 AM, Duncan Murdoch wrote:
> > I've had reports lately about segfaults in the rgl package.  I've only
> > been able to reproduce these on Linux.   I am not so familiar with C++
> > details, so I have a couple of questions way down below. But first some
> > background info.
> >
> >    One recipe to recreate the crash works with a new version 5.0-1 of the
> > mixOmics package:
> >
> >   > library(mixOmics)
> >   > example(pca)
> >
> > This crashes with messages like this:
> >
> > Program received signal SIGSEGV, Segmentation fault.
> > 0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
> >       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
> > 48        { return __atomic_fetch_add(__mem, __val, __ATOMIC_ACQ_REL); }
> >
> > The call stack ends with this:
> >
> > #0  0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
> >       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
> > #1  __exchange_and_add_dispatch (__mem=0x7f7fffff7f7ffff7,
> >       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:81
> > #2  _M_dispose (__a=..., this=0x7f7fffff7f7fffe7)
> >       at /usr/include/c++/4.7/bits/basic_string.h:242
> > #3  ~basic_string (this=0x15f8770, __in_chrg=<optimized out>)
> >       at /usr/include/c++/4.7/bits/basic_string.h:536
> > #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> > Shape.cpp:13
> > #5  0x00007ffff22df50b in ~Background (this=0x15f8760,
> >       __in_chrg=<optimized out>) at Background.hpp:15
> > #6  Background::~Background (this=0x15f8760, __in_chrg=<optimized out>)
> >       at Background.hpp:15
> >
> > Up to entry #4 this all looks normal.  If I go into that stack frame, I
> > see this:
> >
> >
> > (gdb) up
> > #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> > Shape.cpp:13
> > warning: Source file is more recent than executable.
> > 13        blended(in_material.isTransparent())
> > (gdb) p this
> > $9 = (Shape * const) 0x15f8760
> > (gdb) p *this
> > $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
> >       static npos = <optimized out>,
> >       _M_dataplus = {<std::allocator<char>> =
> > {<__gnu_cxx::new_allocator<char>> =
> > {<No data fields>}, <No data fields>},
> >         _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
> > bounds>}},
> >     mShapeColor = {mRed = -1.4044474254567505e+306,
> >       mGreen = -1.4044477603031902e+306, mBlue = 4.24399170841135e-314,
> >       mTransparent = 0}, mSpecularReflectivity = 0.0078125,
> >     mSpecularSize = 1065353216, mDiffuseReflectivity = 0.007812501848093234,
> >     mAmbientReflectivity = 0}
> >
> > The things displayed in *this are all wrong.  Those field names come
> > from the Shape object in the igraph package, not the Shape object in the
> > rgl package.   The mixOmics package uses both.
> >
> > My questions:
> >
> > - Has my code somehow got mixed up with the igraph code, so I really do
> > have a call out to igraph's Shape::~Shape instead of rgl's
> > Shape::~Shape, or is this just bad info being given to me by gdb?
> >
> > - If I really do have calls to the wrong destructor in there, how do I
> > avoid this?
> >
> > Duncan Murdoch
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From murdoch.duncan at gmail.com  Mon Oct  7 18:48:38 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 07 Oct 2013 12:48:38 -0400
Subject: [Rd] C++ debugging help needed
In-Reply-To: <1381162714.1811.27.camel@braque.iarc.fr>
References: <524C32CF.2060307@gmail.com> <524F1169.4020308@gmail.com>
	<1381162714.1811.27.camel@braque.iarc.fr>
Message-ID: <5252E5E6.7040306@gmail.com>

On 07/10/2013 12:18 PM, Martyn Plummer wrote:
> Yes, on reflection it's an ABI problem on Linux (use of PIC code in
> shared libraries means that any symbol can be interposed).  Using
> namespaces isn't really the answer because that's an API issue.  I think
> what you really need to do is control the visibility of your classes and
> functions so that everything is hidden except for the entry points you
> call from R (Writing R Extensions section 6.15).  This should stop the
> symbol collision because hidden functions are resolved inside the shared
> object instead of going through a lookup table that can be overwritten
> by someone else's package.

That's not possible on all platforms, but on platforms that allow it, 
rgl (on R-forge) is now doing it.  It only exposes R_init_rgl(), which 
registers all the other entry points.

I think the work that I did to add the namespace was also worthwhile for 
those platforms that don't allow you to hide things; it makes collisions 
less likely, though not impossible.

For those unfamiliar with this:  it is a little tedious to add external 
registration, but you do gain extra checks on your calls. Once you have 
that it is usually very easy to hide everything except the registration 
function.  (One exception:  if your package has its own configuration 
script, it's a bit more work.)

Duncan Murdoch
>
> Martyn
>
>
>
> On Fri, 2013-10-04 at 15:05 -0400, Duncan Murdoch wrote:
> > I have now got two "solutions" to this.  The rgl version currently on
> > CRAN does a simple rename to avoid the name clash. A later version,
> > still only on R-forge, puts most objects into a namespace called "rgl".
> > (The old code had two small namespaces "gui" and "lib"; they are gone now.)
> >
> > I am not yet confident that the current version with namespaces will
> > compile on all platforms; it seems much more fragile this way, with
> > errors showing up on Linux that were not errors on Windows.  (E.g.
> > sometimes I included a header with declarations in the rgl namespace
> > followed by system header files, and the latter acted differently than
> > they did when placed before the rgl header file, apparently declaring
> > the system functions to be in a new anonymous namespace.)
> >
> > rgl also includes some C code from the gl2ps project and some C++ code
> > from FTGL; I didn't put those into the rgl namespace.  So there are
> > still possibilities for clashes if anyone else uses those.
> >
> > I'm still surprised that anything with plugins works on Unix-alike
> > systems with such bizarre linking rules.  This is one of those few cases
> > where the Windows design seems clearly superior.
> >
> > Duncan Murdoch
> >
> >
> > On 02/10/2013 10:50 AM, Duncan Murdoch wrote:
> > > I've had reports lately about segfaults in the rgl package.  I've only
> > > been able to reproduce these on Linux.   I am not so familiar with C++
> > > details, so I have a couple of questions way down below. But first some
> > > background info.
> > >
> > >    One recipe to recreate the crash works with a new version 5.0-1 of the
> > > mixOmics package:
> > >
> > >   > library(mixOmics)
> > >   > example(pca)
> > >
> > > This crashes with messages like this:
> > >
> > > Program received signal SIGSEGV, Segmentation fault.
> > > 0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
> > >       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
> > > 48        { return __atomic_fetch_add(__mem, __val, __ATOMIC_ACQ_REL); }
> > >
> > > The call stack ends with this:
> > >
> > > #0  0x00007ffff28aafd9 in __exchange_and_add (__mem=0x7f7fffff7f7ffff7,
> > >       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:48
> > > #1  __exchange_and_add_dispatch (__mem=0x7f7fffff7f7ffff7,
> > >       __val=<optimized out>) at /usr/include/c++/4.7/ext/atomicity.h:81
> > > #2  _M_dispose (__a=..., this=0x7f7fffff7f7fffe7)
> > >       at /usr/include/c++/4.7/bits/basic_string.h:242
> > > #3  ~basic_string (this=0x15f8770, __in_chrg=<optimized out>)
> > >       at /usr/include/c++/4.7/bits/basic_string.h:536
> > > #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> > > Shape.cpp:13
> > > #5  0x00007ffff22df50b in ~Background (this=0x15f8760,
> > >       __in_chrg=<optimized out>) at Background.hpp:15
> > > #6  Background::~Background (this=0x15f8760, __in_chrg=<optimized out>)
> > >       at Background.hpp:15
> > >
> > > Up to entry #4 this all looks normal.  If I go into that stack frame, I
> > > see this:
> > >
> > >
> > > (gdb) up
> > > #4  Shape::~Shape (this=0x15f8760, __in_chrg=<optimized out>) at
> > > Shape.cpp:13
> > > warning: Source file is more recent than executable.
> > > 13        blended(in_material.isTransparent())
> > > (gdb) p this
> > > $9 = (Shape * const) 0x15f8760
> > > (gdb) p *this
> > > $10 = {_vptr.Shape = 0x7ffff2d8e290, mName = 6, mType = {
> > >       static npos = <optimized out>,
> > >       _M_dataplus = {<std::allocator<char>> =
> > > {<__gnu_cxx::new_allocator<char>> =
> > > {<No data fields>}, <No data fields>},
> > >         _M_p = 0x7f7fffff7f7fffff <Address 0x7f7fffff7f7fffff out of
> > > bounds>}},
> > >     mShapeColor = {mRed = -1.4044474254567505e+306,
> > >       mGreen = -1.4044477603031902e+306, mBlue = 4.24399170841135e-314,
> > >       mTransparent = 0}, mSpecularReflectivity = 0.0078125,
> > >     mSpecularSize = 1065353216, mDiffuseReflectivity = 0.007812501848093234,
> > >     mAmbientReflectivity = 0}
> > >
> > > The things displayed in *this are all wrong.  Those field names come
> > > from the Shape object in the igraph package, not the Shape object in the
> > > rgl package.   The mixOmics package uses both.
> > >
> > > My questions:
> > >
> > > - Has my code somehow got mixed up with the igraph code, so I really do
> > > have a call out to igraph's Shape::~Shape instead of rgl's
> > > Shape::~Shape, or is this just bad info being given to me by gdb?
> > >
> > > - If I really do have calls to the wrong destructor in there, how do I
> > > avoid this?
> > >
> > > Duncan Murdoch
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> -----------------------------------------------------------------------
> This message and its attachments are strictly confiden...{{dropped:8}}


From plummerm at iarc.fr  Mon Oct  7 23:18:02 2013
From: plummerm at iarc.fr (Martyn Plummer)
Date: Mon, 7 Oct 2013 21:18:02 +0000
Subject: [Rd] R 3.1.0 and C++11
In-Reply-To: <21073.63553.888272.510490@max.nulle.part>
References: <21073.63553.888272.510490@max.nulle.part>
Message-ID: <31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>

I don't see any harm in allowing optional C++11 support, and it is no trouble to update the documentation to acknowledge the existence of C++11 conforming compilers. However, the questions of what is possible, what is recommended, and what is required for CRAN submissions are distinct.

I have a couple of comments on the macro:
a) Your version implies mandatory C++11 support. One needs AX_CXX_COMPILE_STDCXX_11(noext,optional) for optional support.
b) I find it unhelpful that the macro picks up the partial C++11 support in gcc 4.7 via the -std=c++0x flag, so I would edit (and rename) the macro to remove this.

Martyn
________________________________________
From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] on behalf of Dirk Eddelbuettel [edd at debian.org]
Sent: 07 October 2013 01:54
To: R-devel org
Subject: [Rd] R 3.1.0 and C++11

I would like to bring up two issues concerning C++11.


First, the R-devel manuals contain incorrect statements regarding C++11:

  i)   R-exts.texi:

       Although there is a 2011 version of the C++ standard, it is not yet
       fully implemented (nor is it likely to be widely available for some
       years) and portable C++ code needs to follow the 1998 standard
       (and not use features from C99).

  ii)  R-ints.texi:

       The type `R_xlen_t' is made available to packages in C header
       `Rinternals.h': this should be fine in C code since C99 is
       required.  People do try to use R internals in C++, but C++98
       compilers are not required to support these types (and there are
       currently no C++11 compilers).

But since the summer we have g++ and clang with working C++11 implementations:

  iii) g++ implements C++11:
       http://isocpp.org/blog/2013/05/gcc-4.8.1-released-c11-feature-complete

  iv)  llvm/clang++ implements C++11:
       http://isocpp.org/blog/2013/06/llvm-3.3-is-released

I would suggest to change the wording prior to the release of R 3.1.0 next
year as it is likely that even Microsoft will by then have a fully-conformant
compiler (per Herb Sutter at a recent talk in Chicago). If it helped, I would
be glad to provide minimal patches to the two .texi files.

Moreover, the C++ Standards Group is working towards closing the delta
between standards being adopted, and compilers being released. They expect
corresponding compilers for C++14 (a "patch" release for C++11 expected to be
ready next spring) to be available within a year---possibly during 2014.


Second, the current R Policy regarding C++11 is unnecessarily strict. I would
propose to treat the availability of C++11 extensions more like the
availability of OpenMP: something which configure can probe at build time,
and which can be deployed later via suitable #ifdef tests.

As a proof of concept, I added this macro from the autoconf archive to the
m4/ directory of R-devel:

  http://www.gnu.org/software/autoconf-archive/ax_cxx_compile_stdcxx_11.html

and made a one-line change to configure.ac (indented two spaces just for email)

  edd at max:~/svn/r-devel$ svn di configure.ac
  Index: configure.ac
  ===================================================================
  --- configure.ac      (revision 64031)
  +++ configure.ac      (working copy)
  @@ -906,6 +906,7 @@

   AC_LANG_PUSH(C++)
   AC_OPENMP
  +AX_CXX_COMPILE_STDCXX_11(noext)
   AC_LANG_POP(C++)

   ### *** ObjC compiler
  edd at max:~/svn/r-devel$

After running 'aclocal -Im4; autoheader; autoconf', the configure test then
properly detected C++11 (or, in one case, C++0x) on four different compilers:

  [ g++-4.7 case, Ubuntu 13.04 ]
  checking whether g++ supports C++11 features by default... no
  checking whether g++ supports C++11 features with -std=c++11... no
  checking whether g++ supports C++11 features with -std=c++0x... yes

  [ CC=clang CXX=clang++ (3.1), Ubuntu 13.04 ]
  checking whether clang++ accepts -M for generating dependencies... yes
  checking for clang++ option to support OpenMP... unsupported
  checking whether clang++ supports C++11 features by default... no
  checking whether clang++ supports C++11 features with -std=c++11... yes

  [ g++-4.8 case, Debian testing ]
  checking whether g++ supports C++11 features by default... no
  checking whether g++ supports C++11 features with -std=c++11... yes

  [ CC=clang CXX=clang++ (3.2), Debian testing ]
  checking whether clang++ supports C++11 features by default... no
  checking whether clang++ supports C++11 features with -std=c++11... yes

It would be easy to another #define to config.h.in.


And of course, I understand that R Core is comprised primarily of C
programmers.  But to those of us who lean more towards C++ than C, the step
towards C++11 is a big one, and a very exciting one.  More and more upstream
authors are considering right now whether to switch to C++11-only.  I expect
such switches to become more common as time pass. C++11 provides a lot -- and
preventing programmers from using these tools cannot be in our interest.

I think that the timing of the next R release will be a good opportunity to
permit use of C++11 where compilers support it -- as a wide range of sites
will already be capable of deploying it.

Thanks, Dirk

--
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel
-----------------------------------------------------------------------
This message and its attachments are strictly confidenti...{{dropped:8}}


From edd at debian.org  Mon Oct  7 23:47:58 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 7 Oct 2013 16:47:58 -0500
Subject: [Rd] R 3.1.0 and C++11
In-Reply-To: <31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>
References: <21073.63553.888272.510490@max.nulle.part>
	<31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>
Message-ID: <21075.11278.577153.103691@max.nulle.part>


Hi Martyn,

On 7 October 2013 at 21:18, Martyn Plummer wrote:
| I don't see any harm in allowing optional C++11 support,

That would be a nice step forward.

| and it is no trouble to update the documentation to acknowledge the
| existence of C++11 conforming compilers.

Indeed.

| However, the questions of what is possible, what is recommended, and what
|  is required for CRAN submissions are distinct. 

You may be aware of the difficulties we as R package developers have with
discussions involving CRAN maintainers.  
 
| I have a couple of comments on the macro:
| a) Your version implies mandatory C++11 support. One needs
| AX_CXX_COMPILE_STDCXX_11(noext,optional) for optional support. 

I used an existing macros from the GNU autoconf archive. It can certainly be
tweaked. R's stack of configure logic is an impressive piece of work and I
wasn't expecting this to flow through. It was meant to start a discussion.

My principal points are that 

   i)  we do have compilers now that can support this, and 

   ii) we can test for their capabilities when R itself is compiled.

| b) I find it unhelpful that the macro picks up the partial C++11 support in
| gcc 4.7 via the -std=c++0x flag, so I would edit (and rename) the macro to
| remove this. 

Of course. All this can and should be discussed. I just wanted to get the
ball rolling and had a choice between just emailing Kurt (as the configure
and m4 point man) and emailing here.

To the extent that c++0x support is also widely available, I do not see why
one could not allow it either.  But that is a minor issue: I would really
like us to (eventually) move beyond what is going to become a more and more
constraining C++ standard.  

Optional support for deployments where C++11 is indeed available seems like a
step in the right direction.

Thanks for your feedback!

Dirk

| Martyn
| ________________________________________
| From: r-devel-bounces at r-project.org [r-devel-bounces at r-project.org] on behalf of Dirk Eddelbuettel [edd at debian.org]
| Sent: 07 October 2013 01:54
| To: R-devel org
| Subject: [Rd] R 3.1.0 and C++11
| 
| I would like to bring up two issues concerning C++11.
| 
| 
| First, the R-devel manuals contain incorrect statements regarding C++11:
| 
|   i)   R-exts.texi:
| 
|        Although there is a 2011 version of the C++ standard, it is not yet
|        fully implemented (nor is it likely to be widely available for some
|        years) and portable C++ code needs to follow the 1998 standard
|        (and not use features from C99).
| 
|   ii)  R-ints.texi:
| 
|        The type `R_xlen_t' is made available to packages in C header
|        `Rinternals.h': this should be fine in C code since C99 is
|        required.  People do try to use R internals in C++, but C++98
|        compilers are not required to support these types (and there are
|        currently no C++11 compilers).
| 
| But since the summer we have g++ and clang with working C++11 implementations:
| 
|   iii) g++ implements C++11:
|        http://isocpp.org/blog/2013/05/gcc-4.8.1-released-c11-feature-complete
| 
|   iv)  llvm/clang++ implements C++11:
|        http://isocpp.org/blog/2013/06/llvm-3.3-is-released
| 
| I would suggest to change the wording prior to the release of R 3.1.0 next
| year as it is likely that even Microsoft will by then have a fully-conformant
| compiler (per Herb Sutter at a recent talk in Chicago). If it helped, I would
| be glad to provide minimal patches to the two .texi files.
| 
| Moreover, the C++ Standards Group is working towards closing the delta
| between standards being adopted, and compilers being released. They expect
| corresponding compilers for C++14 (a "patch" release for C++11 expected to be
| ready next spring) to be available within a year---possibly during 2014.
| 
| 
| Second, the current R Policy regarding C++11 is unnecessarily strict. I would
| propose to treat the availability of C++11 extensions more like the
| availability of OpenMP: something which configure can probe at build time,
| and which can be deployed later via suitable #ifdef tests.
| 
| As a proof of concept, I added this macro from the autoconf archive to the
| m4/ directory of R-devel:
| 
|   http://www.gnu.org/software/autoconf-archive/ax_cxx_compile_stdcxx_11.html
| 
| and made a one-line change to configure.ac (indented two spaces just for email)
| 
|   edd at max:~/svn/r-devel$ svn di configure.ac
|   Index: configure.ac
|   ===================================================================
|   --- configure.ac      (revision 64031)
|   +++ configure.ac      (working copy)
|   @@ -906,6 +906,7 @@
| 
|    AC_LANG_PUSH(C++)
|    AC_OPENMP
|   +AX_CXX_COMPILE_STDCXX_11(noext)
|    AC_LANG_POP(C++)
| 
|    ### *** ObjC compiler
|   edd at max:~/svn/r-devel$
| 
| After running 'aclocal -Im4; autoheader; autoconf', the configure test then
| properly detected C++11 (or, in one case, C++0x) on four different compilers:
| 
|   [ g++-4.7 case, Ubuntu 13.04 ]
|   checking whether g++ supports C++11 features by default... no
|   checking whether g++ supports C++11 features with -std=c++11... no
|   checking whether g++ supports C++11 features with -std=c++0x... yes
| 
|   [ CC=clang CXX=clang++ (3.1), Ubuntu 13.04 ]
|   checking whether clang++ accepts -M for generating dependencies... yes
|   checking for clang++ option to support OpenMP... unsupported
|   checking whether clang++ supports C++11 features by default... no
|   checking whether clang++ supports C++11 features with -std=c++11... yes
| 
|   [ g++-4.8 case, Debian testing ]
|   checking whether g++ supports C++11 features by default... no
|   checking whether g++ supports C++11 features with -std=c++11... yes
| 
|   [ CC=clang CXX=clang++ (3.2), Debian testing ]
|   checking whether clang++ supports C++11 features by default... no
|   checking whether clang++ supports C++11 features with -std=c++11... yes
| 
| It would be easy to another #define to config.h.in.
| 
| 
| And of course, I understand that R Core is comprised primarily of C
| programmers.  But to those of us who lean more towards C++ than C, the step
| towards C++11 is a big one, and a very exciting one.  More and more upstream
| authors are considering right now whether to switch to C++11-only.  I expect
| such switches to become more common as time pass. C++11 provides a lot -- and
| preventing programmers from using these tools cannot be in our interest.
| 
| I think that the timing of the next R release will be a good opportunity to
| permit use of C++11 where compilers support it -- as a wide range of sites
| will already be capable of deploying it.
| 
| Thanks, Dirk
| 
| --
| Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel
| -----------------------------------------------------------------------
| This message and its attachments are strictly confidential. If you are
| not the intended recipient of this message, please immediately notify
| the sender and delete it. Since its integrity cannot be guaranteed,
| its content cannot involve the sender's responsibility. Any misuse,
| any disclosure or publication of its content, either whole or partial,
| is prohibited, exception made of formally approved use
| -----------------------------------------------------------------------

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From simon.urbanek at r-project.org  Tue Oct  8 00:32:53 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 Oct 2013 00:32:53 +0200
Subject: [Rd] Allow semantic versioning for packages
In-Reply-To: <CABtg=Kknq3SW-E=LPNBiSrat9NERTATrtedXe46qcCw5tOKRQg@mail.gmail.com>
References: <CABtg=K=AB=eJu3dtEvqOtA0o_R37OdwNAZw=X-TDePJwLKnQDg@mail.gmail.com>
	<7779BA7B-8282-44BA-9EB9-C16B33D88840@r-project.org>
	<CABtg=K=rXyCtGmfhBa5EesSAATJiSUezm7JgTJYGCHXCx3ZZOQ@mail.gmail.com>
	<3015BC91-3B84-4AAF-9490-9C6FE4A4EEF1@r-project.org>
	<CABtg=Kknq3SW-E=LPNBiSrat9NERTATrtedXe46qcCw5tOKRQg@mail.gmail.com>
Message-ID: <6B0E7890-061E-4D35-A04C-66C1C553F0FF@r-project.org>

On Oct 5, 2013, at 9:19 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:

> On Sat, Oct 5, 2013 at 2:23 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> Gabor,
> 
> On Oct 5, 2013, at 4:58 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> 
> > Simon,
> >
> > I think there is a misunderstanding here. I am not suggesting anarchy, completely the opposite.
> >
> > Semantic versioning as defined on http://semver.org was designed exactly for being able to order the versions, and being able to express release candidates, alpha and beta builds, etc. An example ordering from the homepage:
> >
> > 1.0.0-alpha < 1.0.0-alpha.1 < 1.0.0-alpha.beta < 1.0.0-beta < 1.0.0-beta.2 < 1.0.0-beta.11 < 1.0.0-rc.1 < 1.0.0.
> >
> > Currently there is no way to give a version number to my builds that are in between releases. Having multiple branches of development is even more problematic.
> >
> > My problem is not that I am forced to use something meaningful. My problem is that the system I am forced to use is not expressive enough.
> >
> > Hope it is clearer now.
> 
> Yes, thanks. The way I understand it, you are proposing extensions to the existing scheme that allow arbitrary additional content in the version numbers that is to be ignored.
> 
> Nothing is ignored in the version string IMHO.
>  

e.g. quoting the spec: "Build metadata SHOULD be ignored when determining version precedence."


> I fear that the scheme as described in semver.org is incompatible with the scheme used by R,
> 
> I believe that they are fully compatible. In the sense that the current R package versioning is a subset of the one at semver.org. In other words, the current compareVersion only gives results that are valid according to semver.org.
>  

Nope, e.g. the most commonly used format 1.0-0 is not even allowed by semver. 


> so I don't think it can be adapted as-is, but one could cook up something similar with slightly different rules which define which part is ignored. It may break existing tools, so it would have to be considered carefully.
> 
> Indeed, it may break existing tools depending on how they are programmed. The current (3.0.2) version of compareVersion() fails:
> 
> compareVersion("1.0.0", "1.0.0-alpha")
> # [1] -1
> # Warning message:
> # In compareVersion("1.0.0", "1.0.0-alpha") : NAs introduced by coercion
> 


It doesn't fail - just the order inverse to that defined by semver, because R treats all parts as integers, regardless of how many exist, and the existence of any additional components has higher precedence than the lack thereof (assuming full match on existing ones).

Cheers,
Simon



> So, yes, this is something that you don't want to introduce immediately. But maybe in a new major version it could be done. 
> 
> I understand if you say it is not worth the trouble, this is up to you to decide.
> 
> Actually I don't know how you create version strings for R itself currently, I mean, for patched versions, release candidates, devel builds, etc. I guess for R the number.number.number rule does not apply.
> 
> Best,
> Gabor
> 
> 
>  
>  
> 
> Cheers,
> Simon
> 
> 
> > Gabor
> >
> > On Sat, Oct 5, 2013 at 7:42 AM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> > Gabor,
> >
> > what you propose is not really feasible, because R relies on the fact that it can meaningfully order the the versions as to determine the update order. If you use arbitrary strings then ordering becomes random - that's why git commit hashes are so useless for this purpose. The fact that you are forced to use something meaningful is for a good reason here.
> >
> > Cheers,
> > Simon
> >
> >
> > On Oct 4, 2013, at 8:53 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> >
> > > Dear R developers,
> > >
> > > (http://bugs.r-project.org/ seems to be down, so I am writing a feature
> > > request here.)
> > >
> > > It would be great to allow semantic version numbers for packages. See
> > > http://semver.org/ for details.
> > >
> > > The problem I am having is that I am setting up a nightly build server, and
> > > there is no easy way to create a version number for builds that are in
> > > between releases.
> > >
> > > Ideally I would use something like
> > >
> > > TAG+DIST.HASH
> > >
> > > TAG is the last tag of the git branch, usually something like
> > > MAJOR.MINOR.PATCH, DIST is the number of commits since the last release and
> > > HASH is the first seven letters of the git hash for the commit. E.g.
> > >
> > > 0.7.0-pre+518.badcafe
> > >
> > > Right now instead of this I am forced to use something like
> > >
> > > 0.6.999.518
> > >
> > > which is a lot less expressive and there is no (easy) way to include the
> > > branch information.
> > >
> > > Thanks, Best Regards,
> > > Gabor
> > >
> > >       [[alternative HTML version deleted]]
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> > >
> >
> >
> 
> 


From dtenenba at fhcrc.org  Tue Oct  8 00:40:45 2013
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Mon, 7 Oct 2013 15:40:45 -0700 (PDT)
Subject: [Rd] =?utf-8?q?uninformative_error_message_when_building_package?=
 =?utf-8?q?=3A_=E2=80=98x=E2=80=99_must_be_an_atomic_vector?=
In-Reply-To: <1081449143.1222532.1381185545087.JavaMail.root@fhcrc.org>
Message-ID: <832591770.1222536.1381185645759.JavaMail.root@fhcrc.org>

Hi,

When building this Bioconductor package with R-devel:

http://www.bioconductor.org/packages/devel/bioc/src/contrib/ROntoTools_1.1.2.tar.gz

I get the following:

[...]
Error: processing vignette ?rontotools.Rnw? failed with diagnostics:
?x? must be an atomic vector
Execution halted

If I install the package, Stangle and then source the vignette, I see that the "real" error is:

[...]
> ###################################################
> ### code chunk number 14: rontotools.Rnw:177-178
> ###################################################
> peRes <- pe(x = fc, graphs = kpg, ref = ref,  nboot = 200, verbose = FALSE)
Error in La.svd(x, nu, nv) : error code 1 from Lapack routine 'dgesdd'

It would be great if R CMD build could produce this error instead of the uninformative 
?x? must be an atomic vector. 

I see this with many different packages and I always have to do the same dance in order to find out what is really going on.

BTW, I don't think it's referring to the x in the line of code right before the error, because that x is an atomic vector:

> class(fc)
[1] "numeric"
> length(fc)
[1] 2864

Thanks,
Dan


From csardi.gabor at gmail.com  Tue Oct  8 01:35:33 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Mon, 7 Oct 2013 19:35:33 -0400
Subject: [Rd] Allow semantic versioning for packages
In-Reply-To: <6B0E7890-061E-4D35-A04C-66C1C553F0FF@r-project.org>
References: <CABtg=K=AB=eJu3dtEvqOtA0o_R37OdwNAZw=X-TDePJwLKnQDg@mail.gmail.com>
	<7779BA7B-8282-44BA-9EB9-C16B33D88840@r-project.org>
	<CABtg=K=rXyCtGmfhBa5EesSAATJiSUezm7JgTJYGCHXCx3ZZOQ@mail.gmail.com>
	<3015BC91-3B84-4AAF-9490-9C6FE4A4EEF1@r-project.org>
	<CABtg=Kknq3SW-E=LPNBiSrat9NERTATrtedXe46qcCw5tOKRQg@mail.gmail.com>
	<6B0E7890-061E-4D35-A04C-66C1C553F0FF@r-project.org>
Message-ID: <CABtg=KmfujFJq+w0B0CYA5A6cFkV1XWDH+nwpM5=d5UXH6Z6OA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131007/ee7fe0e0/attachment.pl>

From ch.haeni at gmail.com  Tue Oct  8 07:48:01 2013
From: ch.haeni at gmail.com (=?ISO-8859-1?Q?Christoph_H=E4ni?=)
Date: Tue, 8 Oct 2013 07:48:01 +0200
Subject: [Rd] graphics:persp - suggestion
Message-ID: <CAOKy5g9rAWSfqSPxoa_6hNjOeccxvhp5UZCtkjfoyxxT6Hs4aw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131008/c2a6907c/attachment.pl>

From murdoch.duncan at gmail.com  Tue Oct  8 12:28:06 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 08 Oct 2013 06:28:06 -0400
Subject: [Rd] graphics:persp - suggestion
In-Reply-To: <CAOKy5g9rAWSfqSPxoa_6hNjOeccxvhp5UZCtkjfoyxxT6Hs4aw@mail.gmail.com>
References: <CAOKy5g9rAWSfqSPxoa_6hNjOeccxvhp5UZCtkjfoyxxT6Hs4aw@mail.gmail.com>
Message-ID: <5253DE36.1050801@gmail.com>

On 13-10-08 1:48 AM, Christoph H?ni wrote:
> Dear Devels,
>
> I'm not sure if I'm going the right way by mailing to this list. I have two
> suggestions regarding the persp function from the graphics package:
>
> 1. In the documentation of the persp function, it is said, that the "col"
> argument will ignore transparent colors. However, this is not true, if you
> use strings as color code - at least it works with HEX-code (eg. :
> col="#bf000022" would produce a red-colored surface with transparency = 22).

That may be an obsolete limitation.  I'll take a look...
>
> 2. It would be helpful if one could add a surface to an existing plot. I
> simply copied persp and deleted the "plot.new()" line, but I guess there
> are better ways...


That won't work in general.  persp() relies in the "painter's 
algorithm", in which objects at the back are drawn before objects in 
front of them.  If you put two surfaces into the same plot there will be 
no way to guarantee that.

If you want two surfaces in the same plot (or other things in a surface 
plot), you should probably use persp3d from the rgl package.

Duncan Murdoch


From murdoch.duncan at gmail.com  Tue Oct  8 13:38:25 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 08 Oct 2013 07:38:25 -0400
Subject: [Rd] graphics:persp - suggestion
In-Reply-To: <CAOKy5g9rAWSfqSPxoa_6hNjOeccxvhp5UZCtkjfoyxxT6Hs4aw@mail.gmail.com>
References: <CAOKy5g9rAWSfqSPxoa_6hNjOeccxvhp5UZCtkjfoyxxT6Hs4aw@mail.gmail.com>
Message-ID: <5253EEB1.7070403@gmail.com>

On 13-10-08 1:48 AM, Christoph H?ni wrote:
> Dear Devels,
>
> I'm not sure if I'm going the right way by mailing to this list. I have two
> suggestions regarding the persp function from the graphics package:
>
> 1. In the documentation of the persp function, it is said, that the "col"
> argument will ignore transparent colors. However, this is not true, if you
> use strings as color code - at least it works with HEX-code (eg. :
> col="#bf000022" would produce a red-colored surface with transparency = 22).

The actual behaviour is that if lighting (controlled by the "shade" 
argument) is active, transparency is ignored.  However, if
the first colour is transparent, lighting is turned off, so transparency 
*will* be used.  I'm not sure what the intention was behind the latter 
behaviour.

Duncan Murdoch

>
> 2. It would be helpful if one could add a surface to an existing plot. I
> simply copied persp and deleted the "plot.new()" line, but I guess there
> are better ways...
>
> Cheers,
> Christoph
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From simon.urbanek at r-project.org  Tue Oct  8 17:14:54 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 8 Oct 2013 11:14:54 -0400
Subject: [Rd] Allow semantic versioning for packages
In-Reply-To: <CABtg=KmfujFJq+w0B0CYA5A6cFkV1XWDH+nwpM5=d5UXH6Z6OA@mail.gmail.com>
References: <CABtg=K=AB=eJu3dtEvqOtA0o_R37OdwNAZw=X-TDePJwLKnQDg@mail.gmail.com>
	<7779BA7B-8282-44BA-9EB9-C16B33D88840@r-project.org>
	<CABtg=K=rXyCtGmfhBa5EesSAATJiSUezm7JgTJYGCHXCx3ZZOQ@mail.gmail.com>
	<3015BC91-3B84-4AAF-9490-9C6FE4A4EEF1@r-project.org>
	<CABtg=Kknq3SW-E=LPNBiSrat9NERTATrtedXe46qcCw5tOKRQg@mail.gmail.com>
	<6B0E7890-061E-4D35-A04C-66C1C553F0FF@r-project.org>
	<CABtg=KmfujFJq+w0B0CYA5A6cFkV1XWDH+nwpM5=d5UXH6Z6OA@mail.gmail.com>
Message-ID: <233A67CE-CE44-4506-90B2-151285B0F816@r-project.org>

On Oct 7, 2013, at 7:35 PM, G?bor Cs?rdi wrote:

> On Mon, Oct 7, 2013 at 6:32 PM, Simon Urbanek <simon.urbanek at r-project.org> wrote:
> On Oct 5, 2013, at 9:19 PM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> [...] 
> e.g. quoting the spec: "Build metadata SHOULD be ignored when determining version precedence."
> 
> Indeed, although 'SHOULD' means that it is only a recommendation. And the build metadata is the stuff after the plus sign, so the -alpha, -beta, etc. is still used to determine precedence.
> 
> > I fear that the scheme as described in semver.org is incompatible with the scheme used by R,
> >
> > I believe that they are fully compatible. In the sense that the current R package versioning is a subset of the one at semver.org. In other words, the current compareVersion only gives results that are valid according to semver.org.
> >
> 
> Nope, e.g. the most commonly used format 1.0-0 is not even allowed by semver.
> 
> Indeed again, I overlooked that the three numbers are required. This is something that should be relaxed for R packages, the patch level can be omitted.
> 

That's not what it means in R - the number after the dash *is* the patch level. The point is that the semantics of the dash are different in the two standards and so is the interpretation of the components. That's why I said earlier (in the part that you cut out) that probably the only viable option is to enhance the R handling to add some handling of non-integer components.


> You are right, maybe semver.org is something that is appropriate for R packages, as it is. But I guess, my feature request still makes sense. I just want to be able to use more flexible version strings, and I think semver.org is a good starting point, nevertheless.
> 
> Again, I understand if you say, that it would cause too much trouble for CRAN for not too much benefit. I cannot estimate the amount of extra work required. As for updating the compareVersion function, that is probably not too bad, there is an existing Python package for it called semver, so that could be the starting point.
> 

Updating compareVersion() is the least problem - tools that handle package files often use regexps which will fail once non-intergers are allowed.

Cheers,
Simon


> [...]
> > compareVersion("1.0.0", "1.0.0-alpha")
> > # [1] -1
> > # Warning message:
> > # In compareVersion("1.0.0", "1.0.0-alpha") : NAs introduced by coercion
> >
> 
> 
> It doesn't fail - just the order inverse to that defined by semver, because R treats all parts as integers, regardless of how many exist, and the existence of any additional components has higher precedence than the lack thereof (assuming full match on existing ones).
> 
> Well, there are surely some for which it fails, e.g.:
> 
> compareVersion("1.0-alpha", "1.0-beta")
> # Error in if (a[k] > b[k]) return(1) else if (a[k] < b[k]) return(-1L) : 
> #   missing value where TRUE/FALSE needed
> # In addition: Warning messages:
> # 1: In compareVersion("1.0-alpha", "1.0-beta") : NAs introduced by coercion
> # 2: In compareVersion("1.0-alpha", "1.0-beta") : NAs introduced by coercion
> 
> Thanks for taking the time to discuss this issue!
> 
> Best,
> Gabor
>  
> 
> Cheers,
> Simon
> 
> [...] 


From csardi.gabor at gmail.com  Tue Oct  8 17:30:48 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Tue, 8 Oct 2013 11:30:48 -0400
Subject: [Rd] Allow semantic versioning for packages
In-Reply-To: <233A67CE-CE44-4506-90B2-151285B0F816@r-project.org>
References: <CABtg=K=AB=eJu3dtEvqOtA0o_R37OdwNAZw=X-TDePJwLKnQDg@mail.gmail.com>
	<7779BA7B-8282-44BA-9EB9-C16B33D88840@r-project.org>
	<CABtg=K=rXyCtGmfhBa5EesSAATJiSUezm7JgTJYGCHXCx3ZZOQ@mail.gmail.com>
	<3015BC91-3B84-4AAF-9490-9C6FE4A4EEF1@r-project.org>
	<CABtg=Kknq3SW-E=LPNBiSrat9NERTATrtedXe46qcCw5tOKRQg@mail.gmail.com>
	<6B0E7890-061E-4D35-A04C-66C1C553F0FF@r-project.org>
	<CABtg=KmfujFJq+w0B0CYA5A6cFkV1XWDH+nwpM5=d5UXH6Z6OA@mail.gmail.com>
	<233A67CE-CE44-4506-90B2-151285B0F816@r-project.org>
Message-ID: <CABtg=Knj4Ftyic9M6gbpveCv9V4xwfYs0uf4iuHr2P2pSr_1GQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131008/04673a1a/attachment.pl>

From dtenenba at fhcrc.org  Tue Oct  8 20:34:30 2013
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Tue, 8 Oct 2013 11:34:30 -0700 (PDT)
Subject: [Rd] "Failed to locate the 'texi2pdf' output file"
In-Reply-To: <1471856549.1234313.1381257059533.JavaMail.root@fhcrc.org>
Message-ID: <1461841680.1235725.1381257269992.JavaMail.root@fhcrc.org>

Just thought I would mention that the issue below (and in https://stat.ethz.ch/pipermail/r-devel/2013-April/066318.html) is still not resolved.

It hasn't been a big problem, but it potentially could be, if a critical package were to have this error on release day, then all its dependencies would fail to build, which would probably require us to postpone our release.

See the complete thread (link above) for followup posts which establish that this has nothing to do with databases, sockets, or virus scanners, and occurs even in packages that have no dependencies or R code in them. The post below from Henrik points to a possible cause.

Thanks,
Dan




On Fri, Apr 12, 2013 at 4:23 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> On Fri, Apr 12, 2013 at 3:53 PM, Kasper Daniel Hansen
> <kasperdanielhansen at gmail.com> wrote:
>> Dan,
>>
>> This error looks _very_ similar to what I reported regarding the use of
>> 'foreach' inside a windows vignette, on the bioc-devel email list.  As you
>> say, it looks funny that it lists the tex file, yet fails to find it.
>
> It's not looking for the TeX file, but the PDF file - that is what the
> error message is referring to by "Failed to locate the 'texi2pdf'
> output file".  [ Note that in this error message I use the term
> "vignette" in a conceptual sense, not necessarily the vignette
> *source* file (here *.Rnw) - maybe that is what is confusing. ]
> Immediately after calling tools::texi2pdf("OrganismDbi.tex"), the code
> tries to locate the texi2pdf output file, that is, 'OrganismDbi.pdf',
> which it cannot find.  This indicates that tools::texi2pdf() gave an
> error (an error message which is currently not reported/available),
> which in turn indicates that the 'OrganismDbi.tex' file is
> corrupt/incomplete.
>
>>
>> The issue had to do with closing relevant connections (for foreach, this
>> was a Windows issue because the default foreach backend on Windows uses
>> connections).   For my particular case, solving it was a bit difficult
>> because I could not just close all connections since a vignette is being
>> run inside sink().
>>
>> The package name makes me suspect a database connection. As a starting
>> point I suggest closing all existing connections in the vignette.
>
> I think it's worth looking into what Kasper says - that's hopefully the reason.
>
> /Henrik
>
> PS. I do find it odd that these issues starting to occur now, because
> most of the vignette framework is performing the same steps as in R (<
> 3.0.0).  The main difference is see is that it now validates/asserts
> that the expected output file is there *immediately* after trying to
> generate them (using weave, tangle, and texi2pdf).  If for some reason
> texi2pdf generates the PDF in a background process which is not
> completed in full when returning the control to R, then the PDF is not
> there and you would get this error.  I don't know if this can happen.
> The reason why I came to think of this is because I recall that I've
> seen this behavior when using bitmap() and Ghostscript to create PNGs.
>  Just a shot from the hip, though.
>
>>
>> Kasper
>>
>>
>>
>> On Fri, Apr 12, 2013 at 5:34 PM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
>>
>>> Hi,
>>> Every day a few Bioconductor packages (different ones each day) fail
>>> to build, on Windows only, with an error like this:
>>>
>>> D:\biocbld\bbs-2.13-bioc\meat>D:\biocbld\bbs-2.13-bioc\R\bin\R.exe CMD
>>> build --keep-empty-dirs --no-resave-data OrganismDbi
>>> [...]
>>> Error in find_vignette_product(name, by = "texi2pdf", engine = engine) :
>>>   Failed to locate the 'texi2pdf' output file (by engine
>>> 'utils::Sweave') for vignette with name 'OrganismDbi'. The following
>>> files exists in directory '.': 'OrganismDbi.Rnw', 'OrganismDbi.tex',
>>> 'databaseTypes.pdf'
>>> Calls: <Anonymous> -> find_vignette_product
>>> Execution halted
>>>
>>> This is puzzling to me because I would have thought that
>>> 'OrganismDbi.tex' was the file it was looking for, yet it says that
>>> file exists.
>>>
>>> These build errors are transient...if I re-run the build, the error
>>> does not recur. So I was hesitant to report the problem because can't
>>> be reproduced consistently. Nevertheless it is a problem.
>>>
>>> > sessionInfo()
>>> R version 3.0.0 (2013-04-03)
>>> Platform: i386-w64-mingw32/i386 (32-bit)
>>>
>>> locale:
>>> [1] LC_COLLATE=English_United States.1252
>>> [2] LC_CTYPE=English_United States.1252
>>> [3] LC_MONETARY=English_United States.1252
>>> [4] LC_NUMERIC=C
>>> [5] LC_TIME=English_United States.1252
>>>
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>
>>> Thanks,
>>> Dan
>>>


From hb at biostat.ucsf.edu  Tue Oct  8 21:45:16 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Tue, 8 Oct 2013 12:45:16 -0700
Subject: [Rd] http://r.research.att.com/ (daily R binaries for OSX) seems to
	be down
Message-ID: <CAFDcVCS85b4LxvV4hAtv3ZK-SGCmsfmYc0RTzC71=A3BFEAnhA@mail.gmail.com>

It appears that http://r.research.att.com/, which provides "daily
builds of the R GUI, R-patched and R-devel" for OSX, is down (at least
since yesterday).  I didn't find any contact information in online web
caches, so I'm posting here in case the maintainer is listening.

/Henrik


From marc_schwartz at me.com  Tue Oct  8 21:54:30 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Tue, 08 Oct 2013 14:54:30 -0500
Subject: [Rd] http://r.research.att.com/ (daily R binaries for OSX)
 seems to	be down
In-Reply-To: <CAFDcVCS85b4LxvV4hAtv3ZK-SGCmsfmYc0RTzC71=A3BFEAnhA@mail.gmail.com>
References: <CAFDcVCS85b4LxvV4hAtv3ZK-SGCmsfmYc0RTzC71=A3BFEAnhA@mail.gmail.com>
Message-ID: <7DC4BD81-4C85-479F-90FC-9B6AA012D0EF@me.com>


On Oct 8, 2013, at 2:45 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:

> It appears that http://r.research.att.com/, which provides "daily
> builds of the R GUI, R-patched and R-devel" for OSX, is down (at least
> since yesterday).  I didn't find any contact information in online web
> caches, so I'm posting here in case the maintainer is listening.
> 
> /Henrik


There was a post on this to R-SIG-MAC earlier today, with a reply by Peter:

  https://stat.ethz.ch/pipermail/r-sig-mac/2013-October/010364.html

Regards,

Marc Schwartz


From gdsayshi at gmail.com  Wed Oct  9 11:24:03 2013
From: gdsayshi at gmail.com (Gaurav Dasgupta)
Date: Wed, 9 Oct 2013 14:54:03 +0530
Subject: [Rd] How to write R data frame to HDFS using rhdfs?
Message-ID: <CACq8Ys1kQxz-zUDJbYRdEoU64ZLGNeySiMwxsreDmfrtG3FOOA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131009/e810ec5f/attachment.pl>

From brian at braverock.com  Wed Oct  9 11:43:10 2013
From: brian at braverock.com (Brian G. Peterson)
Date: Wed, 09 Oct 2013 04:43:10 -0500
Subject: [Rd] How to write R data frame to HDFS using rhdfs?
In-Reply-To: <CACq8Ys1kQxz-zUDJbYRdEoU64ZLGNeySiMwxsreDmfrtG3FOOA@mail.gmail.com>
References: <CACq8Ys1kQxz-zUDJbYRdEoU64ZLGNeySiMwxsreDmfrtG3FOOA@mail.gmail.com>
Message-ID: <5255252E.8040606@braverock.com>

On 10/09/2013 04:24 AM, Gaurav Dasgupta wrote:
> I am trying to write the default "OrchardSprays" R data frame into HDFS
> using the "rhdfs" package. I want to write this data frame directly into
> HDFS without first storing it into any file in local file system.
>
> Which rhdfs command i should use? Can some one help me? I am very new to R
> and rhdfs.

This is a question for the rhdfs maintainer or R-help or maybe R-SIG-hpc.

It also appears that there are many RHadoop guides online that may 
answer your question...

Please see the posting guide:

http://www.r-project.org/posting-guide.html

Regards,

Brian

-- 
Brian G. Peterson
http://braverock.com/brian/
Ph: 773-459-4973
IM: bgpbraverock


From David.Duffy at qimr.edu.au  Wed Oct  9 07:46:40 2013
From: David.Duffy at qimr.edu.au (David Duffy)
Date: Wed, 9 Oct 2013 15:46:40 +1000
Subject: [Rd] Version of L-BFGS-B used in optim etc
Message-ID: <alpine.LMD.2.00.1310091458420.632@orpheus.qimr.edu.au>

Hi.

I just noticed the paper by Morales and Nocedal

Remark on "Algorithm 778: L-BFGS-B: Fortran Subroutines for Large-Scale 
Bound Constrained Optimization". TOMS 2011; 38(1): 7

http://www.ece.northwestern.edu/~morales/PSfiles/acm-remark.pdf

which describes a couple of improvements (speed and accuracy) to the 
original Netlib code which AFAICT is that still used by optim() 
via f2c.  Updated code is under

http://www.ece.northwestern.edu/~nocedal/lbfgsb.html

released under the New BSD License.  Has this already been made available 
in R, perhaps in other packages such as optimx?

Cheers, David Duffy.


| David Duffy (MBBS PhD)                                         ,-_|\
| email: davidD at qimr.edu.au  ph: INT+61+7+3362-0217 fax: -0101  /     *
| Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
| 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From murdoch.duncan at gmail.com  Wed Oct  9 18:34:49 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 09 Oct 2013 12:34:49 -0400
Subject: [Rd] "Failed to locate the 'texi2pdf' output file"
In-Reply-To: <1461841680.1235725.1381257269992.JavaMail.root@fhcrc.org>
References: <1461841680.1235725.1381257269992.JavaMail.root@fhcrc.org>
Message-ID: <525585A9.8010903@gmail.com>

On 08/10/2013 2:34 PM, Dan Tenenbaum wrote:
> Just thought I would mention that the issue below (and in https://stat.ethz.ch/pipermail/r-devel/2013-April/066318.html) is still not resolved.

The bug reporting system is back up, so if you haven't filed a bug 
report on this, please do.

If you have filed a bug report on it that doesn't include instructions 
to reproduce it, please add them.  Intermittent non-reproducible bugs 
are unlikely to be fixed.

Duncan Murdoch

>
> It hasn't been a big problem, but it potentially could be, if a critical package were to have this error on release day, then all its dependencies would fail to build, which would probably require us to postpone our release.
>
> See the complete thread (link above) for followup posts which establish that this has nothing to do with databases, sockets, or virus scanners, and occurs even in packages that have no dependencies or R code in them. The post below from Henrik points to a possible cause.
>
> Thanks,
> Dan
>
>
>
>
> On Fri, Apr 12, 2013 at 4:23 PM, Henrik Bengtsson <hb at biostat.ucsf.edu> wrote:
> > On Fri, Apr 12, 2013 at 3:53 PM, Kasper Daniel Hansen
> > <kasperdanielhansen at gmail.com> wrote:
> >> Dan,
> >>
> >> This error looks _very_ similar to what I reported regarding the use of
> >> 'foreach' inside a windows vignette, on the bioc-devel email list.  As you
> >> say, it looks funny that it lists the tex file, yet fails to find it.
> >
> > It's not looking for the TeX file, but the PDF file - that is what the
> > error message is referring to by "Failed to locate the 'texi2pdf'
> > output file".  [ Note that in this error message I use the term
> > "vignette" in a conceptual sense, not necessarily the vignette
> > *source* file (here *.Rnw) - maybe that is what is confusing. ]
> > Immediately after calling tools::texi2pdf("OrganismDbi.tex"), the code
> > tries to locate the texi2pdf output file, that is, 'OrganismDbi.pdf',
> > which it cannot find.  This indicates that tools::texi2pdf() gave an
> > error (an error message which is currently not reported/available),
> > which in turn indicates that the 'OrganismDbi.tex' file is
> > corrupt/incomplete.
> >
> >>
> >> The issue had to do with closing relevant connections (for foreach, this
> >> was a Windows issue because the default foreach backend on Windows uses
> >> connections).   For my particular case, solving it was a bit difficult
> >> because I could not just close all connections since a vignette is being
> >> run inside sink().
> >>
> >> The package name makes me suspect a database connection. As a starting
> >> point I suggest closing all existing connections in the vignette.
> >
> > I think it's worth looking into what Kasper says - that's hopefully the reason.
> >
> > /Henrik
> >
> > PS. I do find it odd that these issues starting to occur now, because
> > most of the vignette framework is performing the same steps as in R (<
> > 3.0.0).  The main difference is see is that it now validates/asserts
> > that the expected output file is there *immediately* after trying to
> > generate them (using weave, tangle, and texi2pdf).  If for some reason
> > texi2pdf generates the PDF in a background process which is not
> > completed in full when returning the control to R, then the PDF is not
> > there and you would get this error.  I don't know if this can happen.
> > The reason why I came to think of this is because I recall that I've
> > seen this behavior when using bitmap() and Ghostscript to create PNGs.
> >  Just a shot from the hip, though.
> >
> >>
> >> Kasper
> >>
> >>
> >>
> >> On Fri, Apr 12, 2013 at 5:34 PM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> >>
> >>> Hi,
> >>> Every day a few Bioconductor packages (different ones each day) fail
> >>> to build, on Windows only, with an error like this:
> >>>
> >>> D:\biocbld\bbs-2.13-bioc\meat>D:\biocbld\bbs-2.13-bioc\R\bin\R.exe CMD
> >>> build --keep-empty-dirs --no-resave-data OrganismDbi
> >>> [...]
> >>> Error in find_vignette_product(name, by = "texi2pdf", engine = engine) :
> >>>   Failed to locate the 'texi2pdf' output file (by engine
> >>> 'utils::Sweave') for vignette with name 'OrganismDbi'. The following
> >>> files exists in directory '.': 'OrganismDbi.Rnw', 'OrganismDbi.tex',
> >>> 'databaseTypes.pdf'
> >>> Calls: <Anonymous> -> find_vignette_product
> >>> Execution halted
> >>>
> >>> This is puzzling to me because I would have thought that
> >>> 'OrganismDbi.tex' was the file it was looking for, yet it says that
> >>> file exists.
> >>>
> >>> These build errors are transient...if I re-run the build, the error
> >>> does not recur. So I was hesitant to report the problem because can't
> >>> be reproduced consistently. Nevertheless it is a problem.
> >>>
> >>> > sessionInfo()
> >>> R version 3.0.0 (2013-04-03)
> >>> Platform: i386-w64-mingw32/i386 (32-bit)
> >>>
> >>> locale:
> >>> [1] LC_COLLATE=English_United States.1252
> >>> [2] LC_CTYPE=English_United States.1252
> >>> [3] LC_MONETARY=English_United States.1252
> >>> [4] LC_NUMERIC=C
> >>> [5] LC_TIME=English_United States.1252
> >>>
> >>> attached base packages:
> >>> [1] stats     graphics  grDevices utils     datasets  methods   base
> >>>
> >>> Thanks,
> >>> Dan
> >>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From kasperdanielhansen at gmail.com  Wed Oct  9 21:57:45 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 9 Oct 2013 15:57:45 -0400
Subject: [Rd] user defined macros in Rd files
Message-ID: <CAC2h7usETeFHChYavo-mCP=4rSRX+Jzxta=e=S=S2sR0_6AAUw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131009/a57ba6cc/attachment.pl>

From h.wickham at gmail.com  Wed Oct  9 22:21:40 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 9 Oct 2013 15:21:40 -0500
Subject: [Rd] No warning for conflicting methods?
Message-ID: <CABdHhvEUJoJNAxe4HaDTvaY3=HVUpsnv2DLq1Lox0rLd6mMSOQ@mail.gmail.com>

It would be really nice if R warned you when packages had conflicting
methods. For example (and this took me a couple of hours to track
down), RMySQL and RPostgreSQL both define setMethod("print",
"dbObjectId"), so that:

library(RMySQL)
getMethod("print", "dbObjectId")

library(RPostgreSQL)
getMethod("print", "dbObjectId")

Obviously it's a bad idea to associate methods with classes that you
don't own, but it would be great if R could give some warning in this
situation.

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From xie at yihui.name  Wed Oct  9 22:34:13 2013
From: xie at yihui.name (Yihui Xie)
Date: Wed, 9 Oct 2013 15:34:13 -0500
Subject: [Rd] user defined macros in Rd files
In-Reply-To: <CAC2h7usETeFHChYavo-mCP=4rSRX+Jzxta=e=S=S2sR0_6AAUw@mail.gmail.com>
References: <CAC2h7usETeFHChYavo-mCP=4rSRX+Jzxta=e=S=S2sR0_6AAUw@mail.gmail.com>
Message-ID: <CANROs4er+wdYVQ3MBS7tBn7uWTnot3VQPe3Tm-RTGhHo7AMm1A@mail.gmail.com>

+1. As an example, there are 91 instances of \newcommand{\CRANpkg} in
R source, and this number is still growing as I see:

$ grep "\\\\newcommand{\\\\CRANpkg}" -r . | wc
     91      91   10317

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Wed, Oct 9, 2013 at 2:57 PM, Kasper Daniel Hansen
<kasperdanielhansen at gmail.com> wrote:
> R-exts, in "2.13 User-defined macros", discusses user-defined macros.  Is
> it possible to have macros defined in one file, be used by another (within
> a package)?  This would increase the usefulness substantially, IMHO.
>
> Best,
> Kasper


From murdoch.duncan at gmail.com  Wed Oct  9 22:55:06 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 09 Oct 2013 16:55:06 -0400
Subject: [Rd] user defined macros in Rd files
In-Reply-To: <CANROs4er+wdYVQ3MBS7tBn7uWTnot3VQPe3Tm-RTGhHo7AMm1A@mail.gmail.com>
References: <CAC2h7usETeFHChYavo-mCP=4rSRX+Jzxta=e=S=S2sR0_6AAUw@mail.gmail.com>
	<CANROs4er+wdYVQ3MBS7tBn7uWTnot3VQPe3Tm-RTGhHo7AMm1A@mail.gmail.com>
Message-ID: <5255C2AA.6010807@gmail.com>

On 13-10-09 4:34 PM, Yihui Xie wrote:
> +1. As an example, there are 91 instances of \newcommand{\CRANpkg} in
> R source, and this number is still growing as I see:
>
> $ grep "\\\\newcommand{\\\\CRANpkg}" -r . | wc
>       91      91   10317
>

So you're saying if I ever get around to doing this, I'll have to track 
down 91+ files to make use of it?  This sounds like an argument why 
someone else should do it. ;-)

Duncan Murdoch


From xie at yihui.name  Wed Oct  9 23:04:16 2013
From: xie at yihui.name (Yihui Xie)
Date: Wed, 9 Oct 2013 16:04:16 -0500
Subject: [Rd] user defined macros in Rd files
In-Reply-To: <5255C2AA.6010807@gmail.com>
References: <CAC2h7usETeFHChYavo-mCP=4rSRX+Jzxta=e=S=S2sR0_6AAUw@mail.gmail.com>
	<CANROs4er+wdYVQ3MBS7tBn7uWTnot3VQPe3Tm-RTGhHo7AMm1A@mail.gmail.com>
	<5255C2AA.6010807@gmail.com>
Message-ID: <CANROs4d9xM5Qj7OW4T8KZe9s8y6d5h6AgMO9fnCueFW_-my38w@mail.gmail.com>

I mean, it sounds like a better idea to define \CRANpkg only once in
one central place, and use it in base R, instead of defining it in
every single Rd file, because it seems to be generally useful (is 91 a
large number? maybe).

Similarly, when it comes to an add-on package, it will be nice if the
package author can define these macros in one place, and use them in
his/her package.

When we have to copy and paste a macro 91 times, it seems to have
defeated the purpose of a macro.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Wed, Oct 9, 2013 at 3:55 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 13-10-09 4:34 PM, Yihui Xie wrote:
>>
>> +1. As an example, there are 91 instances of \newcommand{\CRANpkg} in
>> R source, and this number is still growing as I see:
>>
>> $ grep "\\\\newcommand{\\\\CRANpkg}" -r . | wc
>>       91      91   10317
>>
>
> So you're saying if I ever get around to doing this, I'll have to track down
> 91+ files to make use of it?  This sounds like an argument why someone else
> should do it. ;-)
>
> Duncan Murdoch
>


From h.wickham at gmail.com  Wed Oct  9 23:08:15 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 9 Oct 2013 16:08:15 -0500
Subject: [Rd] No warning for conflicting methods?
In-Reply-To: <CABdHhvEUJoJNAxe4HaDTvaY3=HVUpsnv2DLq1Lox0rLd6mMSOQ@mail.gmail.com>
References: <CABdHhvEUJoJNAxe4HaDTvaY3=HVUpsnv2DLq1Lox0rLd6mMSOQ@mail.gmail.com>
Message-ID: <CABdHhvGPrRHfw-+5m7HJVbswGsUkkE8OtLpxyTzoQx3wFBbKNw@mail.gmail.com>

As Duncan pointed to me off-list, I may have mis-diagnosed this
problem because both RMySQL and RPostgreSQL define their own
(identically named) dbObjectId classes.  So this may be a more subtle
S4 dispatch bug.

Hadley

On Wed, Oct 9, 2013 at 3:21 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
> It would be really nice if R warned you when packages had conflicting
> methods. For example (and this took me a couple of hours to track
> down), RMySQL and RPostgreSQL both define setMethod("print",
> "dbObjectId"), so that:
>
> library(RMySQL)
> getMethod("print", "dbObjectId")
>
> library(RPostgreSQL)
> getMethod("print", "dbObjectId")
>
> Obviously it's a bad idea to associate methods with classes that you
> don't own, but it would be great if R could give some warning in this
> situation.
>
> Hadley
>
> --
> Chief Scientist, RStudio
> http://had.co.nz/



-- 
Chief Scientist, RStudio
http://had.co.nz/


From hb at biostat.ucsf.edu  Thu Oct 10 01:54:49 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Wed, 9 Oct 2013 16:54:49 -0700
Subject: [Rd] user defined macros in Rd files
In-Reply-To: <CANROs4d9xM5Qj7OW4T8KZe9s8y6d5h6AgMO9fnCueFW_-my38w@mail.gmail.com>
References: <CAC2h7usETeFHChYavo-mCP=4rSRX+Jzxta=e=S=S2sR0_6AAUw@mail.gmail.com>
	<CANROs4er+wdYVQ3MBS7tBn7uWTnot3VQPe3Tm-RTGhHo7AMm1A@mail.gmail.com>
	<5255C2AA.6010807@gmail.com>
	<CANROs4d9xM5Qj7OW4T8KZe9s8y6d5h6AgMO9fnCueFW_-my38w@mail.gmail.com>
Message-ID: <CAFDcVCS0mfjQt6OQiot6mqij-RM6dxnMutyZUJ1mgityeEGnfQ@mail.gmail.com>

On Wed, Oct 9, 2013 at 2:04 PM, Yihui Xie <xie at yihui.name> wrote:
> I mean, it sounds like a better idea to define \CRANpkg only once in
> one central place, and use it in base R, instead of defining it in
> every single Rd file, because it seems to be generally useful (is 91 a
> large number? maybe).
>
> Similarly, when it comes to an add-on package, it will be nice if the
> package author can define these macros in one place, and use them in
> his/her package.
>
> When we have to copy and paste a macro 91 times, it seems to have
> defeated the purpose of a macro.

On my related wishlist: A standardized mechanism to 'R CMD build' for
building man/*.Rd from any input format (e.g. roxygen and so on)
analogously how we can now build vignettes of any input format.  With
that in place, it would a be piece of cake to include macros from
external files.

Just wanted to throw it out there.

/Henrik

>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
>
> On Wed, Oct 9, 2013 at 3:55 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 13-10-09 4:34 PM, Yihui Xie wrote:
>>>
>>> +1. As an example, there are 91 instances of \newcommand{\CRANpkg} in
>>> R source, and this number is still growing as I see:
>>>
>>> $ grep "\\\\newcommand{\\\\CRANpkg}" -r . | wc
>>>       91      91   10317
>>>
>>
>> So you're saying if I ever get around to doing this, I'll have to track down
>> 91+ files to make use of it?  This sounds like an argument why someone else
>> should do it. ;-)
>>
>> Duncan Murdoch
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Thu Oct 10 03:18:48 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 09 Oct 2013 21:18:48 -0400
Subject: [Rd] user defined macros in Rd files
In-Reply-To: <CAFDcVCS0mfjQt6OQiot6mqij-RM6dxnMutyZUJ1mgityeEGnfQ@mail.gmail.com>
References: <CAC2h7usETeFHChYavo-mCP=4rSRX+Jzxta=e=S=S2sR0_6AAUw@mail.gmail.com>
	<CANROs4er+wdYVQ3MBS7tBn7uWTnot3VQPe3Tm-RTGhHo7AMm1A@mail.gmail.com>
	<5255C2AA.6010807@gmail.com>
	<CANROs4d9xM5Qj7OW4T8KZe9s8y6d5h6AgMO9fnCueFW_-my38w@mail.gmail.com>
	<CAFDcVCS0mfjQt6OQiot6mqij-RM6dxnMutyZUJ1mgityeEGnfQ@mail.gmail.com>
Message-ID: <52560078.9090709@gmail.com>

On 13-10-09 7:54 PM, Henrik Bengtsson wrote:
> On Wed, Oct 9, 2013 at 2:04 PM, Yihui Xie <xie at yihui.name> wrote:
>> I mean, it sounds like a better idea to define \CRANpkg only once in
>> one central place, and use it in base R, instead of defining it in
>> every single Rd file, because it seems to be generally useful (is 91 a
>> large number? maybe).
>>
>> Similarly, when it comes to an add-on package, it will be nice if the
>> package author can define these macros in one place, and use them in
>> his/her package.
>>
>> When we have to copy and paste a macro 91 times, it seems to have
>> defeated the purpose of a macro.
>
> On my related wishlist: A standardized mechanism to 'R CMD build' for
> building man/*.Rd from any input format (e.g. roxygen and so on)
> analogously how we can now build vignettes of any input format.  With
> that in place, it would a be piece of cake to include macros from
> external files.
>
> Just wanted to throw it out there.

No, we certainly won't do that.  We rely on being able to process the Rd 
files in multiple ways.

Duncan Murdoch

>
> /Henrik
>
>>
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Web: http://yihui.name
>> Department of Statistics, Iowa State University
>> 2215 Snedecor Hall, Ames, IA
>>
>>
>> On Wed, Oct 9, 2013 at 3:55 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> On 13-10-09 4:34 PM, Yihui Xie wrote:
>>>>
>>>> +1. As an example, there are 91 instances of \newcommand{\CRANpkg} in
>>>> R source, and this number is still growing as I see:
>>>>
>>>> $ grep "\\\\newcommand{\\\\CRANpkg}" -r . | wc
>>>>        91      91   10317
>>>>
>>>
>>> So you're saying if I ever get around to doing this, I'll have to track down
>>> 91+ files to make use of it?  This sounds like an argument why someone else
>>> should do it. ;-)
>>>
>>> Duncan Murdoch
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From nashjc at uottawa.ca  Thu Oct 10 15:06:52 2013
From: nashjc at uottawa.ca (Prof J C Nash (U30A))
Date: Thu, 10 Oct 2013 09:06:52 -0400
Subject: [Rd] Version of L-BFGS-B used in optim etc
In-Reply-To: <mailman.21.1381399207.21578.r-devel@r-project.org>
References: <mailman.21.1381399207.21578.r-devel@r-project.org>
Message-ID: <5256A66C.9090600@uottawa.ca>

This issue has been known for some time and I've had "why don't you fix 
this?" queries. However, I'm not one of the R-core folk who could do so, 
and don't code in C.  Moreover, as far as I can tell, the version of 
L-BFGS-B in R is not one of the standard releases from Morales and Nocedal.

As maintainer of optimx, I can state that I won't be including L-BFGS-B 
except through optim() unless someone implements the new code as a 
package, which I would welcome. I've decided to focus only on codes 
written all in R. For bounds constrained optimization, I've put together 
Rvmmin which is the "BFGS" method of optim() (a misnomer, but I'd better 
not get started...) and Rcgmin. I've got my brother's truncated Newton 
code running unconstrained, but still trying to find time to get the 
bounds debugged. I find codes in R more flexible in allowing 
improvements, and easier to avoid those nasty mismatches in coding style 
that happen across languages.

I'd be glad to collaborate with anyone on getting latest L-BFGS-B 
packaged, or on improvements to the TNmin etc. And, of course, I welcome 
examples where things don't work smoothly in my codes.

There are upgrades to optimx on R-forge that will not likely move to 
CRAN for a few months until TN is completed and added etc.

Best, JN


On 13-10-10 06:00 AM, r-devel-request at r-project.org wrote:
> Message: 1
> Date: Wed, 9 Oct 2013 15:46:40 +1000
> From: David Duffy<David.Duffy at qimr.edu.au>
> To:<r-devel at r-project.org>
> Subject: [Rd] Version of L-BFGS-B used in optim etc
> Message-ID:<alpine.LMD.2.00.1310091458420.632 at orpheus.qimr.edu.au>
> Content-Type: text/plain; format=flowed; charset="US-ASCII"
>
> Hi.
>
> I just noticed the paper by Morales and Nocedal
>
> Remark on "Algorithm 778: L-BFGS-B: Fortran Subroutines for Large-Scale
> Bound Constrained Optimization". TOMS 2011; 38(1): 7
>
> http://www.ece.northwestern.edu/~morales/PSfiles/acm-remark.pdf
>
> which describes a couple of improvements (speed and accuracy) to the
> original Netlib code which AFAICT is that still used by optim()
> via f2c.  Updated code is under
>
> http://www.ece.northwestern.edu/~nocedal/lbfgsb.html
>
> released under the New BSD License.  Has this already been made available
> in R, perhaps in other packages such as optimx?
>
> Cheers, David Duffy.
>
>
> | David Duffy (MBBS PhD)                                         ,-_|\
> | email:davidD at qimr.edu.au   ph: INT+61+7+3362-0217 fax: -0101  /     *
> | Epidemiology Unit, Queensland Institute of Medical Research   \_,-._/
> | 300 Herston Rd, Brisbane, Queensland 4029, Australia  GPG 4D0B994A v


From nigel.delaney at outlook.com  Thu Oct 10 23:04:24 2013
From: nigel.delaney at outlook.com (Nigel Delaney)
Date: Thu, 10 Oct 2013 17:04:24 -0400
Subject: [Rd] Replacing the Random Number Generator in Stand Alone Library
In-Reply-To: <BAY406-EAS212BD9C215DD7A2A1C548F9E51E0@phx.gbl>
References: <BAY406-EAS212BD9C215DD7A2A1C548F9E51E0@phx.gbl>
Message-ID: <BAY406-EAS163E93209B12379E553BEA1E51E0@phx.gbl>

Hi R-Developers,

I had a question about the random number generator used in the R StandAlone
Math Library.  The stand-alone library depends on the unif_rand() function
for most simulated values, and this function is provided in the sunif.c file
in the relevant directory.  At present, this program implements the
"Marsaglia-Multicarry" algorithm, which is described throughout the R
documentation as:

 "A multiply-with-carry RNG is used, as recommended by George Marsaglia in
his post to the mailing list 'sci.stat.math'. It has a period of more than
2^60 and has passed all tests (according to Marsaglia). The seed is two
integers (all values allowed)."

However, I do not think this RNG actually passes all tests.   For example,
the Handbook of Computational Econometrics (illegal web copy at link below),
shows that it fails the mtuple test and gives an explicit example where it
leads to problems because it failed this test.  The mtuple test was
introduced by Marsaglia in 1985, and I gather he wrote his mailing list
comment that it "passes all tests" sometime after this, so I am not sure
what explains this distinction (though I am not sure if the mtuple test is
included in the diehard tests, which he may have been what he was referring
to).  However, there are clearly some areas where this PRNG runs in to
trouble (although the books example is better, another problem is that it
can't seem to simulate a value above (1/2)^1+(1/4)^4) after simulating a
value below 1e-6.

Given that the Mersenne Twister seems to be the standard for simulation
these days (and used as the default in R), it seems like it might be useful
to change the stand alone library so it also uses this routine.  I gather
this would be pretty easy to do by pulling this function from the RNG.c file
and moving it into the sunif.c file, and have a prototype of this.

However, I thought I would ask, is there a reason this hasn't been done?  Or
is it just a historical carry-over (pun intended I suppose).

Warm wishes,
Nigel

********************
Research Fellow
Massachusetts General Hospital / Broad Institute


Book link:
http://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/handboo
k-of-computational-econometrics-belsley.pdf


From dtenenba at fhcrc.org  Fri Oct 11 01:28:08 2013
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Thu, 10 Oct 2013 16:28:08 -0700 (PDT)
Subject: [Rd] install.packages() removes package on Windows
In-Reply-To: <433997010.1272981.1381443245564.JavaMail.root@fhcrc.org>
Message-ID: <702440245.1273820.1381447687920.JavaMail.root@fhcrc.org>

Hi,

Starting with the XML package installed:

> "XML" %in% rownames(installed.packages())
[1] TRUE
>

I ran the following script:

pkgs <- c("XML")

for (i in 1:100)
{
    install.packages(pkgs, repos="http://cran.fhcrc.org")
    if (!all(pkgs %in% rownames(installed.packages())))
    {
        print("failed to install pkgs!")
        print(paste("Iteration", i))
        break
    }
}

And it failed on the third iteration:

trying URL 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
Content type 'application/zip' length 4287270 bytes (4.1 Mb)
opened URL
downloaded 4.1 Mb

package 'XML' successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
trying URL 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
Content type 'application/zip' length 4287270 bytes (4.1 Mb)
opened URL
downloaded 4.1 Mb

package 'XML' successfully unpacked and MD5 sums checked

The downloaded binary packages are in
        C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
trying URL 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
Content type 'application/zip' length 4287270 bytes (4.1 Mb)
opened URL
downloaded 4.1 Mb

package 'XML' successfully unpacked and MD5 sums checked
Warning: cannot remove prior installation of package 'XML'

The downloaded binary packages are in
        C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
[1] "failed to install pkgs!"
[1] "Iteration 3"

At this point the XML package is not installed:

> "XML" %in% rownames(installed.packages())
[1] FALSE

Any idea what could cause this? There is no virus scanner running. 

I notice the warning about failing to remove prior installation, but it looks like it removed enough of it so that XML is no longer installed.

I realize my script is a little contrived but I'm trying to track down an elusive problem in our build system that is causing a lot of grief....this may or may not be the same problem but it's certainly a problem, so I thought I'd report it. 

Is there a workaround?

I've only ever seen this issue on Windows.

I did try running the same script on a vanilla windows machine and it did not fail. In fact, it does not always fail on the machine where it fails above. But once is enough to mess us up.


> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

Thanks,
Dan


From hb at biostat.ucsf.edu  Fri Oct 11 03:15:52 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Thu, 10 Oct 2013 18:15:52 -0700
Subject: [Rd] install.packages() removes package on Windows
In-Reply-To: <702440245.1273820.1381447687920.JavaMail.root@fhcrc.org>
References: <433997010.1272981.1381443245564.JavaMail.root@fhcrc.org>
	<702440245.1273820.1381447687920.JavaMail.root@fhcrc.org>
Message-ID: <CAFDcVCTvhokihvGs+--c0y+EYbOYyq465KOHYXEqyFJR9iOFEA@mail.gmail.com>

My guess is that the DLL of the already installed XML package is
loaded by another R session and that prevents the corresponding DLL
file:

> path <- system.file("libs", package="XML")
> list.files(path, recursive=TRUE, pattern="dll$")
[1] "i386/XML.dll" "x64/XML.dll"

from being deleted by install.packages() -> unpackPkgZip() ->

            ret <- unlink(instPath, recursive=TRUE, force=TRUE)

which gives the warnings.  You can verify this by checking that all
files but the DLLs are deleted;

> path <- system.file("libs", package="XML")
> list.files(path, recursive=TRUE)


REPRODUCIBLE EXAMPLE:

# Download package with native code (=has DLLs)
url <- "http://cran.r-project.org/bin/windows/contrib/r-release/png_0.1-6.zip"
pkgfile <- basename(url)
if (!file_test("-f", pkgfile)) download.file(url, dest=pkgfile, mode="wb")

# Setup temporary library
if (!file_test("-d", "local-libs")) dir.create("local-libs")

# Install to temporary library
install.packages(pkgfile, repos=NULL, lib="local-libs")

# Record package path
path <- system.file(package="png", lib.loc="local-libs")

# Launch *another* session that loads the package
Rscript <- file.path(R.home("bin"), "Rscript")
code <- "library('png', lib.loc='local-libs'); img <-
readPNG(system.file('img','Rlogo.png',package='png')); Sys.sleep(60)"
code <- "library('png', lib.loc='local-libs'); Sys.sleep(60)"
system2(Rscript, args=c("-e", dQuote(code)), wait=FALSE)

# Try to install; will fail
install.packages(pkgfile, repos=NULL, lib="local-libs")
## Gives:
## package 'png' successfully unpacked and MD5 sums checked
## Warning: cannot remove prior installation of package 'png'
files <- list.files(path, recursive=TRUE)
print(files)
## [1] "libs/x64/png.dll"


SUGGESTION:
The problem is that unlink(..., recursive=TRUE) is not atomic, leaving
a corrupt installation behind.  A better solution would be to use
file.rename() to move the existing installation to a temporary
directory/location, move the new installation in place, and then
remove the temporary/old one.  The last step will fail if there is a
session holding onto the DLL, but at least it does not leave a corrupt
installation behind.


/Henrik

On Thu, Oct 10, 2013 at 4:28 PM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
> Hi,
>
> Starting with the XML package installed:
>
>> "XML" %in% rownames(installed.packages())
> [1] TRUE
>>
>
> I ran the following script:
>
> pkgs <- c("XML")
>
> for (i in 1:100)
> {
>     install.packages(pkgs, repos="http://cran.fhcrc.org")
>     if (!all(pkgs %in% rownames(installed.packages())))
>     {
>         print("failed to install pkgs!")
>         print(paste("Iteration", i))
>         break
>     }
> }
>
> And it failed on the third iteration:
>
> trying URL 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> Content type 'application/zip' length 4287270 bytes (4.1 Mb)
> opened URL
> downloaded 4.1 Mb
>
> package 'XML' successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
>         C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
> trying URL 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> Content type 'application/zip' length 4287270 bytes (4.1 Mb)
> opened URL
> downloaded 4.1 Mb
>
> package 'XML' successfully unpacked and MD5 sums checked
>
> The downloaded binary packages are in
>         C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
> trying URL 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> Content type 'application/zip' length 4287270 bytes (4.1 Mb)
> opened URL
> downloaded 4.1 Mb
>
> package 'XML' successfully unpacked and MD5 sums checked
> Warning: cannot remove prior installation of package 'XML'
>
> The downloaded binary packages are in
>         C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
> [1] "failed to install pkgs!"
> [1] "Iteration 3"
>
> At this point the XML package is not installed:
>
>> "XML" %in% rownames(installed.packages())
> [1] FALSE
>
> Any idea what could cause this? There is no virus scanner running.
>
> I notice the warning about failing to remove prior installation, but it looks like it removed enough of it so that XML is no longer installed.
>
> I realize my script is a little contrived but I'm trying to track down an elusive problem in our build system that is causing a lot of grief....this may or may not be the same problem but it's certainly a problem, so I thought I'd report it.
>
> Is there a workaround?
>
> I've only ever seen this issue on Windows.
>
> I did try running the same script on a vanilla windows machine and it did not fail. In fact, it does not always fail on the machine where it fails above. But once is enough to mess us up.
>
>
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: i386-w64-mingw32/i386 (32-bit)
>
> locale:
> [1] LC_COLLATE=English_United States.1252
> [2] LC_CTYPE=English_United States.1252
> [3] LC_MONETARY=English_United States.1252
> [4] LC_NUMERIC=C
> [5] LC_TIME=English_United States.1252
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> Thanks,
> Dan
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jon.skoien at jrc.ec.europa.eu  Fri Oct 11 10:38:26 2013
From: jon.skoien at jrc.ec.europa.eu (Jon Olav Skoien)
Date: Fri, 11 Oct 2013 10:38:26 +0200
Subject: [Rd] install.packages() removes package on Windows
In-Reply-To: <CAFDcVCTvhokihvGs+--c0y+EYbOYyq465KOHYXEqyFJR9iOFEA@mail.gmail.com>
References: <433997010.1272981.1381443245564.JavaMail.root@fhcrc.org>
	<702440245.1273820.1381447687920.JavaMail.root@fhcrc.org>
	<CAFDcVCTvhokihvGs+--c0y+EYbOYyq465KOHYXEqyFJR9iOFEA@mail.gmail.com>
Message-ID: <5257B902.3020503@jrc.ec.europa.eu>



On 11-Oct-13 3:15, Henrik Bengtsson wrote:
> My guess is that the DLL of the already installed XML package is
> loaded by another R session and that prevents the corresponding DLL
> file:
>
>> path <- system.file("libs", package="XML")
>> list.files(path, recursive=TRUE, pattern="dll$")
> [1] "i386/XML.dll" "x64/XML.dll"
>
> from being deleted by install.packages() -> unpackPkgZip() ->
>
>              ret <- unlink(instPath, recursive=TRUE, force=TRUE)
>
> which gives the warnings.  You can verify this by checking that all
> files but the DLLs are deleted;
>
>> path <- system.file("libs", package="XML")
>> list.files(path, recursive=TRUE)
>
> REPRODUCIBLE EXAMPLE:
>
> # Download package with native code (=has DLLs)
> url <- "http://cran.r-project.org/bin/windows/contrib/r-release/png_0.1-6.zip"
> pkgfile <- basename(url)
> if (!file_test("-f", pkgfile)) download.file(url, dest=pkgfile, mode="wb")
>
> # Setup temporary library
> if (!file_test("-d", "local-libs")) dir.create("local-libs")
>
> # Install to temporary library
> install.packages(pkgfile, repos=NULL, lib="local-libs")
>
> # Record package path
> path <- system.file(package="png", lib.loc="local-libs")
>
> # Launch *another* session that loads the package
> Rscript <- file.path(R.home("bin"), "Rscript")
> code <- "library('png', lib.loc='local-libs'); img <-
> readPNG(system.file('img','Rlogo.png',package='png')); Sys.sleep(60)"
> code <- "library('png', lib.loc='local-libs'); Sys.sleep(60)"
> system2(Rscript, args=c("-e", dQuote(code)), wait=FALSE)
>
> # Try to install; will fail
> install.packages(pkgfile, repos=NULL, lib="local-libs")
> ## Gives:
> ## package 'png' successfully unpacked and MD5 sums checked
> ## Warning: cannot remove prior installation of package 'png'
> files <- list.files(path, recursive=TRUE)
> print(files)
> ## [1] "libs/x64/png.dll"
>
>
> SUGGESTION:
> The problem is that unlink(..., recursive=TRUE) is not atomic, leaving
> a corrupt installation behind.  A better solution would be to use
> file.rename() to move the existing installation to a temporary
> directory/location, move the new installation in place, and then
> remove the temporary/old one.  The last step will fail if there is a
> session holding onto the DLL, but at least it does not leave a corrupt
> installation behind.
There is an option to avoid the corrupted installations when running 
multiple instances of R:
options(install.lock = TRUE)
https://stat.ethz.ch/pipermail/r-help/2010-December/263722.html
Not sure if this will solve the original problem though.

Best wishes,
Jon

>
> /Henrik
>
> On Thu, Oct 10, 2013 at 4:28 PM, Dan Tenenbaum <dtenenba at fhcrc.org> wrote:
>> Hi,
>>
>> Starting with the XML package installed:
>>
>>> "XML" %in% rownames(installed.packages())
>> [1] TRUE
>> I ran the following script:
>>
>> pkgs <- c("XML")
>>
>> for (i in 1:100)
>> {
>>      install.packages(pkgs, repos="http://cran.fhcrc.org")
>>      if (!all(pkgs %in% rownames(installed.packages())))
>>      {
>>          print("failed to install pkgs!")
>>          print(paste("Iteration", i))
>>          break
>>      }
>> }
>>
>> And it failed on the third iteration:
>>
>> trying URL 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
>> Content type 'application/zip' length 4287270 bytes (4.1 Mb)
>> opened URL
>> downloaded 4.1 Mb
>>
>> package 'XML' successfully unpacked and MD5 sums checked
>>
>> The downloaded binary packages are in
>>          C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
>> trying URL 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
>> Content type 'application/zip' length 4287270 bytes (4.1 Mb)
>> opened URL
>> downloaded 4.1 Mb
>>
>> package 'XML' successfully unpacked and MD5 sums checked
>>
>> The downloaded binary packages are in
>>          C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
>> trying URL 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
>> Content type 'application/zip' length 4287270 bytes (4.1 Mb)
>> opened URL
>> downloaded 4.1 Mb
>>
>> package 'XML' successfully unpacked and MD5 sums checked
>> Warning: cannot remove prior installation of package 'XML'
>>
>> The downloaded binary packages are in
>>          C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
>> [1] "failed to install pkgs!"
>> [1] "Iteration 3"
>>
>> At this point the XML package is not installed:
>>
>>> "XML" %in% rownames(installed.packages())
>> [1] FALSE
>>
>> Any idea what could cause this? There is no virus scanner running.
>>
>> I notice the warning about failing to remove prior installation, but it looks like it removed enough of it so that XML is no longer installed.
>>
>> I realize my script is a little contrived but I'm trying to track down an elusive problem in our build system that is causing a lot of grief....this may or may not be the same problem but it's certainly a problem, so I thought I'd report it.
>>
>> Is there a workaround?
>>
>> I've only ever seen this issue on Windows.
>>
>> I did try running the same script on a vanilla windows machine and it did not fail. In fact, it does not always fail on the machine where it fails above. But once is enough to mess us up.
>>
>>
>>> sessionInfo()
>> R version 3.0.2 (2013-09-25)
>> Platform: i386-w64-mingw32/i386 (32-bit)
>>
>> locale:
>> [1] LC_COLLATE=English_United States.1252
>> [2] LC_CTYPE=English_United States.1252
>> [3] LC_MONETARY=English_United States.1252
>> [4] LC_NUMERIC=C
>> [5] LC_TIME=English_United States.1252
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> Thanks,
>> Dan
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Jon Olav Sk?ien
Joint Research Centre - European Commission
Institute for Environment and Sustainability (IES)
Land Resource Management Unit

Via Fermi 2749, TP 440,  I-21027 Ispra (VA), ITALY

jon.skoien at jrc.ec.europa.eu
Tel:  +39 0332 789205

Disclaimer: Views expressed in this email are those of the individual and do not necessarily represent official views of the European Commission.


From dtenenba at fhcrc.org  Fri Oct 11 18:33:38 2013
From: dtenenba at fhcrc.org (Dan Tenenbaum)
Date: Fri, 11 Oct 2013 09:33:38 -0700 (PDT)
Subject: [Rd] install.packages() removes package on Windows
In-Reply-To: <5257B902.3020503@jrc.ec.europa.eu>
Message-ID: <1853844370.1279627.1381509218663.JavaMail.root@fhcrc.org>

Thanks Henrik and Jon, that's very helpful.
Dan


----- Original Message -----
> From: "Jon Olav Skoien" <jon.skoien at jrc.ec.europa.eu>
> To: "Henrik Bengtsson" <hb at biostat.ucsf.edu>
> Cc: "Dan Tenenbaum" <dtenenba at fhcrc.org>, "R-devel" <r-devel at r-project.org>
> Sent: Friday, October 11, 2013 1:38:26 AM
> Subject: Re: [Rd] install.packages() removes package on Windows
> 
> 
> 
> On 11-Oct-13 3:15, Henrik Bengtsson wrote:
> > My guess is that the DLL of the already installed XML package is
> > loaded by another R session and that prevents the corresponding DLL
> > file:
> >
> >> path <- system.file("libs", package="XML")
> >> list.files(path, recursive=TRUE, pattern="dll$")
> > [1] "i386/XML.dll" "x64/XML.dll"
> >
> > from being deleted by install.packages() -> unpackPkgZip() ->
> >
> >              ret <- unlink(instPath, recursive=TRUE, force=TRUE)
> >
> > which gives the warnings.  You can verify this by checking that all
> > files but the DLLs are deleted;
> >
> >> path <- system.file("libs", package="XML")
> >> list.files(path, recursive=TRUE)
> >
> > REPRODUCIBLE EXAMPLE:
> >
> > # Download package with native code (=has DLLs)
> > url <-
> > "http://cran.r-project.org/bin/windows/contrib/r-release/png_0.1-6.zip"
> > pkgfile <- basename(url)
> > if (!file_test("-f", pkgfile)) download.file(url, dest=pkgfile,
> > mode="wb")
> >
> > # Setup temporary library
> > if (!file_test("-d", "local-libs")) dir.create("local-libs")
> >
> > # Install to temporary library
> > install.packages(pkgfile, repos=NULL, lib="local-libs")
> >
> > # Record package path
> > path <- system.file(package="png", lib.loc="local-libs")
> >
> > # Launch *another* session that loads the package
> > Rscript <- file.path(R.home("bin"), "Rscript")
> > code <- "library('png', lib.loc='local-libs'); img <-
> > readPNG(system.file('img','Rlogo.png',package='png'));
> > Sys.sleep(60)"
> > code <- "library('png', lib.loc='local-libs'); Sys.sleep(60)"
> > system2(Rscript, args=c("-e", dQuote(code)), wait=FALSE)
> >
> > # Try to install; will fail
> > install.packages(pkgfile, repos=NULL, lib="local-libs")
> > ## Gives:
> > ## package 'png' successfully unpacked and MD5 sums checked
> > ## Warning: cannot remove prior installation of package 'png'
> > files <- list.files(path, recursive=TRUE)
> > print(files)
> > ## [1] "libs/x64/png.dll"
> >
> >
> > SUGGESTION:
> > The problem is that unlink(..., recursive=TRUE) is not atomic,
> > leaving
> > a corrupt installation behind.  A better solution would be to use
> > file.rename() to move the existing installation to a temporary
> > directory/location, move the new installation in place, and then
> > remove the temporary/old one.  The last step will fail if there is
> > a
> > session holding onto the DLL, but at least it does not leave a
> > corrupt
> > installation behind.
> There is an option to avoid the corrupted installations when running
> multiple instances of R:
> options(install.lock = TRUE)
> https://stat.ethz.ch/pipermail/r-help/2010-December/263722.html
> Not sure if this will solve the original problem though.
> 
> Best wishes,
> Jon
> 
> >
> > /Henrik
> >
> > On Thu, Oct 10, 2013 at 4:28 PM, Dan Tenenbaum <dtenenba at fhcrc.org>
> > wrote:
> >> Hi,
> >>
> >> Starting with the XML package installed:
> >>
> >>> "XML" %in% rownames(installed.packages())
> >> [1] TRUE
> >> I ran the following script:
> >>
> >> pkgs <- c("XML")
> >>
> >> for (i in 1:100)
> >> {
> >>      install.packages(pkgs, repos="http://cran.fhcrc.org")
> >>      if (!all(pkgs %in% rownames(installed.packages())))
> >>      {
> >>          print("failed to install pkgs!")
> >>          print(paste("Iteration", i))
> >>          break
> >>      }
> >> }
> >>
> >> And it failed on the third iteration:
> >>
> >> trying URL
> >> 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> >> Content type 'application/zip' length 4287270 bytes (4.1 Mb)
> >> opened URL
> >> downloaded 4.1 Mb
> >>
> >> package 'XML' successfully unpacked and MD5 sums checked
> >>
> >> The downloaded binary packages are in
> >>          C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
> >> trying URL
> >> 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> >> Content type 'application/zip' length 4287270 bytes (4.1 Mb)
> >> opened URL
> >> downloaded 4.1 Mb
> >>
> >> package 'XML' successfully unpacked and MD5 sums checked
> >>
> >> The downloaded binary packages are in
> >>          C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
> >> trying URL
> >> 'http://cran.fhcrc.org/bin/windows/contrib/3.0/XML_3.98-1.1.zip'
> >> Content type 'application/zip' length 4287270 bytes (4.1 Mb)
> >> opened URL
> >> downloaded 4.1 Mb
> >>
> >> package 'XML' successfully unpacked and MD5 sums checked
> >> Warning: cannot remove prior installation of package 'XML'
> >>
> >> The downloaded binary packages are in
> >>          C:\Users\biocbuild\AppData\Local\Temp\3\Rtmps7OWh0\downloaded_packages
> >> [1] "failed to install pkgs!"
> >> [1] "Iteration 3"
> >>
> >> At this point the XML package is not installed:
> >>
> >>> "XML" %in% rownames(installed.packages())
> >> [1] FALSE
> >>
> >> Any idea what could cause this? There is no virus scanner running.
> >>
> >> I notice the warning about failing to remove prior installation,
> >> but it looks like it removed enough of it so that XML is no
> >> longer installed.
> >>
> >> I realize my script is a little contrived but I'm trying to track
> >> down an elusive problem in our build system that is causing a lot
> >> of grief....this may or may not be the same problem but it's
> >> certainly a problem, so I thought I'd report it.
> >>
> >> Is there a workaround?
> >>
> >> I've only ever seen this issue on Windows.
> >>
> >> I did try running the same script on a vanilla windows machine and
> >> it did not fail. In fact, it does not always fail on the machine
> >> where it fails above. But once is enough to mess us up.
> >>
> >>
> >>> sessionInfo()
> >> R version 3.0.2 (2013-09-25)
> >> Platform: i386-w64-mingw32/i386 (32-bit)
> >>
> >> locale:
> >> [1] LC_COLLATE=English_United States.1252
> >> [2] LC_CTYPE=English_United States.1252
> >> [3] LC_MONETARY=English_United States.1252
> >> [4] LC_NUMERIC=C
> >> [5] LC_TIME=English_United States.1252
> >>
> >> attached base packages:
> >> [1] stats     graphics  grDevices utils     datasets  methods
> >>   base
> >>
> >> Thanks,
> >> Dan
> >>
> >> ______________________________________________
> >> R-devel at r-project.org mailing list
> >> https://stat.ethz.ch/mailman/listinfo/r-devel
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> --
> Jon Olav Sk?ien
> Joint Research Centre - European Commission
> Institute for Environment and Sustainability (IES)
> Land Resource Management Unit
> 
> Via Fermi 2749, TP 440,  I-21027 Ispra (VA), ITALY
> 
> jon.skoien at jrc.ec.europa.eu
> Tel:  +39 0332 789205
> 
> Disclaimer: Views expressed in this email are those of the individual
> and do not necessarily represent official views of the European
> Commission.
> 
> 
> 


From djsamperi at gmail.com  Fri Oct 11 20:16:26 2013
From: djsamperi at gmail.com (Dominick Samperi)
Date: Fri, 11 Oct 2013 14:16:26 -0400
Subject: [Rd] C++ debugging help needed
In-Reply-To: <1381162714.1811.27.camel@braque.iarc.fr>
References: <524C32CF.2060307@gmail.com> <524F1169.4020308@gmail.com>
	<1381162714.1811.27.camel@braque.iarc.fr>
Message-ID: <CADUbQ5gNNbRymwn89t0PozUJvXz2A1zZO-AT+gkAvWjmV3rWFw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131011/59850205/attachment.pl>

From skostysh at princeton.edu  Sat Oct 12 23:50:52 2013
From: skostysh at princeton.edu (Scott Kostyshak)
Date: Sat, 12 Oct 2013 17:50:52 -0400
Subject: [Rd] [PATCH] minor suggestions for R-ints manual
Message-ID: <CAE3=dmcm031=PQ6Apr9JmpPfVzONaQFxKpjZvX5422zaM=XicA@mail.gmail.com>

Attached is a patch with minor suggestions for the R-ints manual at
r64048. The most substantial change is the following:

 The top layer comprises the graphics subsystems. Although there is
-provision for 24 subsystems, after 6 years only two exist, `base' and
+provision for 24 subsystems, since 2001 only two exist, `base' and
 `grid'.

Is the year 2001 correct? I base it on the date of the commit that
introduced the "6 years" string and on the date of grid 0.1.

Scott


--
Scott Kostyshak
Economics PhD Candidate
Princeton University
-------------- next part --------------
Index: trunk/doc/manual/R-ints.texi
===================================================================
--- trunk/doc/manual/R-ints.texi	(revision 64048)
+++ trunk/doc/manual/R-ints.texi	(working copy)
@@ -462,7 +462,7 @@
 (which are 32 bits on all @R{} platforms).
 
 @item REALSXP
- at code{length}, @code{truelength} followed by a block of C @code{double}s
+ at code{length}, @code{truelength} followed by a block of C @code{double}s.
 
 @item CPLXSXP
 @code{length}, @code{truelength} followed by a block of C99 @code{double
@@ -1330,7 +1330,7 @@
 The relationship between the pairs is similar: @code{warning} tries to
 fathom out a suitable call, and then calls @code{warningcall} with that
 call as the first argument if it succeeds, and with @code{call =
-R_NilValue} it is does not.  When @code{warningcall} is called, it
+R_NilValue} if it does not.  When @code{warningcall} is called, it
 includes the deparsed call in its printout unless @code{call =
 R_NilValue}.
 
@@ -2289,12 +2289,12 @@
 @file{src/main/names.c}: primitives have @samp{Y = 0} in the @samp{eval}
 field.
 
-There needs to an a @samp{\alias} entry in a help file in the @pkg{base}
+There needs to be a @samp{\alias} entry in a help file in the @pkg{base}
 package, and the primitive needs to be added to one of the lists at the
 start of this section.
 
 Some primitives are regarded as language elements (the current ones are
-listed above).  These need to be in added to two lists of exceptions,
+listed above).  These need to be added to two lists of exceptions,
 @code{langElts} in @code{undoc()} (in file
 @file{src/library/tools/R/QC.R}) and @code{lang_elements} in
 @file{tests/primitives.R}.
@@ -2778,7 +2778,7 @@
 
 
 The top layer comprises the graphics subsystems. Although there is
-provision for 24 subsystems, after 6 years only two exist, `base' and
+provision for 24 subsystems, since 2001 only two exist, `base' and
 `grid'.  The base subsystem is registered with the engine when @R{} is
 initialized, and unregistered (via @code{KillAllDevices}) when an @R{}
 session is shut down.  The grid subsystem is registered in its
@@ -3797,7 +3797,7 @@
 interactively.
 Default: true.
 @item _R_CHECK_VIGNETTES_NLINES_
-Maximum number of lines to show of the bottom of the output when reporting
+Maximum number of lines to show at the bottom of the output when reporting
 errors in running vignettes.
 Default: 10.
 @item _R_CHECK_CODOC_S4_METHODS_
@@ -4258,7 +4258,7 @@
 @file{Renviron} file.  This used to record @samp{false} if no command
 was found, but it nowadays records the name for looking up on the path
 at run time.  The latter can be important for binary distributions: one
-does not want to be tied to, for example, TeXLive 2007.
+does not want to be tied to, for example, TeX Live 2007.
 
 
 @node Current and future directions, Function and variable index, Use of TeX dialects, Top
@@ -4408,7 +4408,7 @@
 are supported provided that each of the dimensions is no more than
 2^31-1.  However, not all applications can be supported.
 
-The main problem is linear algebra, on done by FORTRAN code compiled
+The main problem is linear algebra done by FORTRAN code compiled
 with 32-bit @code{INTEGER}.  Although not guaranteed, it seems that all
 the compilers currently used with @R{} on a 64-bit platform allow
 matrices each of whose dimensions is less than 2^31 but with more than
@@ -4416,7 +4416,7 @@
 support software (such as @acronym{BLAS} and @acronym{LAPACK}) also
 work.
 
-There are exceptions: for example some complex @acronym{LAPACK})
+There are exceptions: for example some complex @acronym{LAPACK}
 auxiliary routines do use a single @code{INTEGER} index and hence
 overflow silently and segfault or give incorrect results.  One example
 is @code{svd()} on a complex matrix.

From michael.weylandt at gmail.com  Sun Oct 13 00:49:45 2013
From: michael.weylandt at gmail.com (R. Michael Weylandt <michael.weylandt@gmail.com>)
Date: Sat, 12 Oct 2013 18:49:45 -0400
Subject: [Rd] user defined macros in Rd files
In-Reply-To: <52560078.9090709@gmail.com>
References: <CAC2h7usETeFHChYavo-mCP=4rSRX+Jzxta=e=S=S2sR0_6AAUw@mail.gmail.com>
	<CANROs4er+wdYVQ3MBS7tBn7uWTnot3VQPe3Tm-RTGhHo7AMm1A@mail.gmail.com>
	<5255C2AA.6010807@gmail.com>
	<CANROs4d9xM5Qj7OW4T8KZe9s8y6d5h6AgMO9fnCueFW_-my38w@mail.gmail.com>
	<CAFDcVCS0mfjQt6OQiot6mqij-RM6dxnMutyZUJ1mgityeEGnfQ@mail.gmail.com>
	<52560078.9090709@gmail.com>
Message-ID: <F2A4D9C4-2DFF-4D87-8453-928101CF3C24@gmail.com>



On Oct 9, 2013, at 21:18, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 13-10-09 7:54 PM, Henrik Bengtsson wrote:
>> 
>> 
>> On my related wishlist: A standardized mechanism to 'R CMD build' for
>> building man/*.Rd from any input format (e.g. roxygen and so on)
>> analogously how we can now build vignettes of any input format.  With
>> that in place, it would a be piece of cake to include macros from
>> external files.
>> 
>> Just wanted to throw it out there.
> 
> No, we certainly won't do that.  We rely on being able to process the Rd files in multiple ways.
> 

I'm a but confused here Duncan: 

Henrik's proposal still results in the Rd files being created and then all of the cool things which get done (example checking, HTML, PDF, etc.) can carry on as usual. Since those are all done from the tarball by R CMD build, they can't know how the Rd files were created in the first place. 

Can you say a bit more about what would break? I'm afraid I'm missing something obvious. 

Michael

> Duncan Murdoch


From murdoch.duncan at gmail.com  Sun Oct 13 00:58:57 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 12 Oct 2013 18:58:57 -0400
Subject: [Rd] user defined macros in Rd files
In-Reply-To: <F2A4D9C4-2DFF-4D87-8453-928101CF3C24@gmail.com>
References: <CAC2h7usETeFHChYavo-mCP=4rSRX+Jzxta=e=S=S2sR0_6AAUw@mail.gmail.com>
	<CANROs4er+wdYVQ3MBS7tBn7uWTnot3VQPe3Tm-RTGhHo7AMm1A@mail.gmail.com>
	<5255C2AA.6010807@gmail.com>
	<CANROs4d9xM5Qj7OW4T8KZe9s8y6d5h6AgMO9fnCueFW_-my38w@mail.gmail.com>
	<CAFDcVCS0mfjQt6OQiot6mqij-RM6dxnMutyZUJ1mgityeEGnfQ@mail.gmail.com>
	<52560078.9090709@gmail.com>
	<F2A4D9C4-2DFF-4D87-8453-928101CF3C24@gmail.com>
Message-ID: <5259D431.6090403@gmail.com>

On 13-10-12 6:49 PM, R. Michael Weylandt <michael.weylandt at gmail.com> wrote:
>
>
> On Oct 9, 2013, at 21:18, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>> On 13-10-09 7:54 PM, Henrik Bengtsson wrote:
>>>
>>>
>>> On my related wishlist: A standardized mechanism to 'R CMD build' for
>>> building man/*.Rd from any input format (e.g. roxygen and so on)
>>> analogously how we can now build vignettes of any input format.  With
>>> that in place, it would a be piece of cake to include macros from
>>> external files.
>>>
>>> Just wanted to throw it out there.
>>
>> No, we certainly won't do that.  We rely on being able to process the Rd files in multiple ways.
>>
>
> I'm a but confused here Duncan:
>
> Henrik's proposal still results in the Rd files being created and then all of the cool things which get done (example checking, HTML, PDF, etc.) can carry on as usual. Since those are all done from the tarball by R CMD build, they can't know how the Rd files were created in the first place.
>
> Can you say a bit more about what would break? I'm afraid I'm missing something obvious.

I was assuming he wanted to build the help system from another format. 
If he just wants to build a standard *.Rd file from something else, then 
why get "R CMD build" involved?  Why not just do it in two steps, "make 
the help, build the tarball"?   He'll have to clarify, but the comment 
about vignettes makes me think I'm right:  you can have a vignette in 
any format, and you just need a way to convert it to HTML or PDF, it 
doesn't need to become a Sweave document first.

Duncan Murdoch


From hb at biostat.ucsf.edu  Sun Oct 13 22:03:01 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 13 Oct 2013 13:03:01 -0700
Subject: [Rd] user defined macros in Rd files
In-Reply-To: <5259D431.6090403@gmail.com>
References: <CAC2h7usETeFHChYavo-mCP=4rSRX+Jzxta=e=S=S2sR0_6AAUw@mail.gmail.com>
	<CANROs4er+wdYVQ3MBS7tBn7uWTnot3VQPe3Tm-RTGhHo7AMm1A@mail.gmail.com>
	<5255C2AA.6010807@gmail.com>
	<CANROs4d9xM5Qj7OW4T8KZe9s8y6d5h6AgMO9fnCueFW_-my38w@mail.gmail.com>
	<CAFDcVCS0mfjQt6OQiot6mqij-RM6dxnMutyZUJ1mgityeEGnfQ@mail.gmail.com>
	<52560078.9090709@gmail.com>
	<F2A4D9C4-2DFF-4D87-8453-928101CF3C24@gmail.com>
	<5259D431.6090403@gmail.com>
Message-ID: <CAFDcVCQp1uUKUD8Yq79U=HC2L00pih0kBWS_E+7NrOKfwJqLQg@mail.gmail.com>

On Sat, Oct 12, 2013 at 3:58 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-10-12 6:49 PM, R. Michael Weylandt <michael.weylandt at gmail.com> wrote:
>>
>>
>>
>> On Oct 9, 2013, at 21:18, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>>> On 13-10-09 7:54 PM, Henrik Bengtsson wrote:
>>>>
>>>>
>>>>
>>>> On my related wishlist: A standardized mechanism to 'R CMD build' for
>>>> building man/*.Rd from any input format (e.g. roxygen and so on)
>>>> analogously how we can now build vignettes of any input format.  With
>>>> that in place, it would a be piece of cake to include macros from
>>>> external files.
>>>>
>>>> Just wanted to throw it out there.
>>>
>>>
>>> No, we certainly won't do that.  We rely on being able to process the Rd
>>> files in multiple ways.
>>>
>>
>> I'm a but confused here Duncan:
>>
>> Henrik's proposal still results in the Rd files being created and then all
>> of the cool things which get done (example checking, HTML, PDF, etc.) can
>> carry on as usual. Since those are all done from the tarball by R CMD build,
>> they can't know how the Rd files were created in the first place.
>>
>> Can you say a bit more about what would break? I'm afraid I'm missing
>> something obvious.
>
>
> I was assuming he wanted to build the help system from another format. If he
> just wants to build a standard *.Rd file from something else, then why get
> "R CMD build" involved?  Why not just do it in two steps, "make the help,
> build the tarball"?   He'll have to clarify, but the comment about vignettes
> makes me think I'm right:  you can have a vignette in any format, and you
> just need a way to convert it to HTML or PDF, it doesn't need to become a
> Sweave document first.

To clarify, my suggestion/wish was not to replace the Rd format but a
*cross-platform* and *standardized* ("the one-and-only way") mechanism
for generating Rd files (which is *the* documentation/example/...
format of R).  The analogue to vignette engines that now support any
input format and outputs PDF or HTML files, "Rd engines" would take
any input format and output Rd files, and from there it's business as
usual.

Several developers already do this (e.g. roxygen2 -> Rd) before 'R CMD
build' either manually, via make or other home-brewed approaches.  It
would great if this would be standardized, and, analogously to how
vignettes are built, doing this during 'R CMD build' is a natural
candidate.

As I said, just throwing it out as a proposal to get the
discussion/thoughts going.  I'm sure others though about this too over
the years.

Cheers,

Henrik

>
> Duncan Murdoch
>
>
>
>


From hb at biostat.ucsf.edu  Sun Oct 13 23:35:42 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 13 Oct 2013 14:35:42 -0700
Subject: [Rd] Compatibility with R 2.15.x: Makefile for (non-Sweave)
	vignettes in vignettes/?
Message-ID: <CAFDcVCSGXYwiofaj1xFh4W-fPBYy5hRmFu2+1Qb_dB9pdDK3=w@mail.gmail.com>

In R 3.1.0 (~April 2014), support for vignettes in inst/doc/ will go
away (and probably much sooner for CRAN submission), e.g.

checking for old-style vignette sources ... NOTE
Vignette sources only in ?inst/doc?:
?R.devices-overview.tex.rsp?
A ?vignettes? directory is required as from R 3.1.0
and these will not be indexed nor checked

I've been sticking with inst/doc/ for backward compatible reasons so
that I can use a "fallback" inst/doc/Makefile for building
*non*-Sweave vignettes also under R 2.15.x.   AFAIK, it is not
possible to put a Makefile under vignettes/, i.e. it is not possible
to build non-Sweave vignette under vignettes/.

For backward compatible reason, I'd like to keep distributing my
packages on CRAN with non-Sweave vignettes available for R (>=
2.15.0), not just R (>= 3.0.0).  Does anyone know an alternative
approach?

/Henrik


From hb at biostat.ucsf.edu  Mon Oct 14 00:30:19 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 13 Oct 2013 15:30:19 -0700
Subject: [Rd] reg.finalizer(): Is it safe for the finalizer function to
 attach/load a package?
Message-ID: <CAFDcVCRx4GoGEm3ybGCAGhMou3VVbQqRB2Kyuu6veXGGwiFrxA@mail.gmail.com>

>From the help/docs it is pretty clear that one could/should only
assume that the 'base' namespace is available when a finalizer
function is evaluated. What is not clear to me is whether you can
safely attach/load packages in your finalizer function. For example,
are the following finalizer functions safe?

reg.finalizer(e, function(e, ...) {
  library("tcltk")
  .Tcl("close $con")
})

and

reg.finalizer(e, function(e, ...) {
  tcltk::.Tcl("close $con")
})

What about non-core packages, e.g.

reg.finalizer(e, function(e, ...) {
  library("R.oo")
  finalize(e)
})

(here finalize() is a generic function, but it's just an example)?.
I'm worried that (re-)attaching packages in a finalizer could be
competing with R's terminating sequence of detaching/unloading
packages.  The reason why I believe this, is that 'R CMD check' on
some of my packages occasionally generate:

* checking for unstated dependencies in R code ... WARNING
Error in attachNamespace(ns, pos = pos, dataPath = dataPath, deps) :
  namespace is already attached
Warning in function (env)  :
  Object may not be finalize():d properly because the R.oo package
failed to reload: Package: 0x0000000006a2f1b8
See the information on DESCRIPTION files in the chapter 'Creating R
packages' of the 'Writing R Extensions' manual.

Knowing whether it is considered safe/unsafe to (re-)attach a package
in the finalizer will help me troubleshoot the above and decide on an
alternative design for my finalizers.

Any help/feedback is appreciated.

/Henrik


From jari.oksanen at oulu.fi  Mon Oct 14 06:51:24 2013
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Mon, 14 Oct 2013 04:51:24 +0000
Subject: [Rd] Compatibility with R 2.15.x: Makefile for
	(non-Sweave)	vignettes in vignettes/?
In-Reply-To: <CAFDcVCSGXYwiofaj1xFh4W-fPBYy5hRmFu2+1Qb_dB9pdDK3=w@mail.gmail.com>
References: <CAFDcVCSGXYwiofaj1xFh4W-fPBYy5hRmFu2+1Qb_dB9pdDK3=w@mail.gmail.com>
Message-ID: <2A20B1E7-CDBE-40E6-8821-06B12458221D@oulu.fi>

Henrik,
On 14/10/2013, at 00:35 AM, Henrik Bengtsson wrote:

> In R 3.1.0 (~April 2014), support for vignettes in inst/doc/ will go
> away (and probably much sooner for CRAN submission), e.g.
> 
> I've been sticking with inst/doc/ for backward compatible reasons so
> that I can use a "fallback" inst/doc/Makefile for building
> *non*-Sweave vignettes also under R 2.15.x.   AFAIK, it is not
> possible to put a Makefile under vignettes/, i.e. it is not possible
> to build non-Sweave vignette under vignettes/.
> 

You can have Makefile in vignettes, and at the moment this even passes CRAN tests. You may also need to have a vignettes/.install_extras file to move the produced non-vignettes files to their final packaged location.

You still get warnings of unused, pointless and misleading files with R 2.15.3, because R 3.0.2 packaging process makes files that R 2.15.3 regards as pointless and misleading. The CRAN policy seems to be to ignore those warnings. R is not backward compatible with herself, and I don't see much that a package author could do to work around this (apart from forking the package).

Cheers, Jari O.


From hb at biostat.ucsf.edu  Mon Oct 14 06:56:46 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Sun, 13 Oct 2013 21:56:46 -0700
Subject: [Rd] Compatibility with R 2.15.x: Makefile for (non-Sweave)
 vignettes in vignettes/?
In-Reply-To: <2A20B1E7-CDBE-40E6-8821-06B12458221D@oulu.fi>
References: <CAFDcVCSGXYwiofaj1xFh4W-fPBYy5hRmFu2+1Qb_dB9pdDK3=w@mail.gmail.com>
	<2A20B1E7-CDBE-40E6-8821-06B12458221D@oulu.fi>
Message-ID: <CAFDcVCTShnqxnf1LUH-Zezui9LdAkgPYo1=EvjV+oR5aGdqTMQ@mail.gmail.com>

On Sun, Oct 13, 2013 at 9:51 PM, Jari Oksanen <jari.oksanen at oulu.fi> wrote:
> Henrik,
> On 14/10/2013, at 00:35 AM, Henrik Bengtsson wrote:
>
>> In R 3.1.0 (~April 2014), support for vignettes in inst/doc/ will go
>> away (and probably much sooner for CRAN submission), e.g.
>>
>> I've been sticking with inst/doc/ for backward compatible reasons so
>> that I can use a "fallback" inst/doc/Makefile for building
>> *non*-Sweave vignettes also under R 2.15.x.   AFAIK, it is not
>> possible to put a Makefile under vignettes/, i.e. it is not possible
>> to build non-Sweave vignette under vignettes/.
>>
>
> You can have Makefile in vignettes, and at the moment this even passes CRAN tests. You may also need to have a vignettes/.install_extras file to move the produced non-vignettes files to their final packaged location.
>
> You still get warnings of unused, pointless and misleading files with R 2.15.3, because R 3.0.2 packaging process makes files that R 2.15.3 regards as pointless and misleading. The CRAN policy seems to be to ignore those warnings. R is not backward compatible with herself, and I don't see much that a package author could do to work around this (apart from forking the package).

Thank you Jari,

I'll look into this.  Do you know of/have a package that does this
that I can peek into?

/Henrik

>
> Cheers, Jari O.
>
>
>


From murdoch.duncan at gmail.com  Mon Oct 14 23:21:15 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 14 Oct 2013 17:21:15 -0400
Subject: [Rd] missing documentation entries ... WARNING
In-Reply-To: <DB7A3056-2B7A-4BC6-AD67-DA6FA0B31488@yahoo.com>
References: <BAF41C96-FB1E-4AF2-A73E-878D15A5853F@yahoo.com>
	<522E2643.6010803@gmail.com>
	<DB7A3056-2B7A-4BC6-AD67-DA6FA0B31488@yahoo.com>
Message-ID: <525C604B.4040503@gmail.com>

On 13-10-14 1:54 PM, Luis Rodr?guez wrote:
> Thanks Duncan (and othersin R-devel).
>
> I clearly got away from this project, but I am still quite interested in resolving this issue and getting these codes into the CRAN.
>
> Some attempts to repair the documentation have occurred in the intervening time, so I am including slightly updated error messages and the relevant tops of the Rd files, as requested by Duncan. See below.
>
> Thanks again!
>
> ~luis
>
>
>
> <<<<my "missing documentation entries">>>>
>
> * checking for missing documentation entries ... WARNING
> Undocumented S4 classes:
>    ?commcorrelogram?
> Undocumented S4 methods:
>    generic 'mod' and siglist 'commcorrelogram'
>    generic 'plot' and siglist 'commcorrelogram,missing'
> All user-level objects in a package (including S4 classes and methods)
> should have documentation entries.
> See the chapter ?Writing R documentation files? in the ?Writing R
> Extensions? manual.
>
> <<<<my "missing documentation entries">>>>
>
> I am also getting a * checking Rd \usage sections ? WARNING, but your message makes me think this is related to the above. JIC, here is that error message:
>
> <<<<my "\usage section" Warning>>>>
>
> * checking Rd \usage sections ... WARNING
> Objects in \usage without \alias in documentation object 'commcorrelogram':
>    ?plot.commcorrelogram?
>
> Functions with \usage entries need to have the appropriate \alias
> entries, and all their arguments documented.
> The \usage entries must correspond to syntactically valid R code.
> See the chapter ?Writing R documentation files? in the ?Writing R
>
> <<<<my "\usage section" Warning>>>>
>
>
> ****comcorrelogram.Rd \alias and \usage sections****
>
> \name{commcorrelogram}
> \docType{class}
> \alias{commcorrelogram}
> \alias{mod,commcorrelogram}
> \alias{plot,commcorrelogram,missing}

Those aliases look like S4 documentation, not S3 as the comment states.
>
> \title{
>    Community Correlogram
> }
> \description{
> Function \code{commcorrelogram} computes community correlograms using either the multivariate Mantel statistic (Mantel, 1957) or the ANOSIM R metric (Clarke, 1993), and includes functionality for both directional analyses and combinations of temporal and spatial analyses.  Mantel correlogram proposed by Sokal (1986) and Oden and Sokal (1986). ANOSIM correlogram suggested here.
> }
> \usage{
> commcorrelogram(sampleData, sampleTime = NULL, sampleLocation = NULL,
>      LocationNames = NULL, option = 1, metric = "anosim", lagNumber, lagSize,
>      lagTol, numTests = 999, anisotropic = FALSE, azimuth, azimuthTol,
>      bandwidth, dipAngle, dipTol, dipBandwidth, distmeth = "bray",
>      mantmeth = "spearman", adj = "holm", prog = TRUE, alternative =
>      "one.sided")
>
> # S3 method for class 'community.correlogram'
> plot.commcorrelogram(x, y, alpha=0.05, ?)
> }

You should use \S3method{plot}{commcorrelogram}(x, y, alpha = 0.05, ...) 
(or maybe \S4method ...).


>
> ****comcorrelogram.Rd \alias and \usage sections****
>
> ****mod.comcorrelogram.Rd \alias and \usage sections****
>
> \name{mod.commcorrelogram}
> \alias{mod.commcorrelogram}
> \alias{mod}
> \title{
> Community Correlogram Model
> }
> \description{
> Function mod.commcorrelogram automatically fits a Gaussian curve to the significance plot of a commcorrelogram object and calculates the correlation range of the data.
> }
> \usage{
> mod.commcorrelogram(object,Ch=1,Cc=5,Cw=0.01,plot=T,alpha=0.05
>    ,alternative='one.tailed',pw=5,lgpos='topleft',...)
> }

Again, use \S3method.

>
> ****mod.comcorrelogram.Rd \alias and \usage sections****
>
>
> On Sep 9, 2013, at 2:49 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
>> On 09/09/2013 3:23 PM, Luis Rodr?guez wrote:
>>> Dear R-devel,
>>>
>>> I am a relative novice in R, but I am eager to post a new package my group developed in CRAN, but I am stumped by a set of documentation related warnings created by R CMD check.
>>>
>>> So, my current plan is to recreate the documentation by religiously applying and modifying the skeleton codes that can be generated by R. In the meantime, I thought I'd post to the discussion group to see if maybe someone with more experience had some useful advice. Below you'll see a snippet of the key documentation warnings that we are stumped on.
>>>
>>> lagSelect and mod are functions created by my group, as is commcorrelogram. My belief is that they are clearly documented, but I suspect that our novice source code and documentation is not quite hitting what R CMD check is looking for.
>>
>> This message usually indicates that you don't have the relevant \alias{} defined correctly. If you do, please post the top of one or two of the Rd files, and we can tell you what's missing.  (I'd like to see at least the \alias{} and \usage{} sections.)
>>
>> Duncan Murdoch
>>
>>>
>>> If anyone has advice on how to pass R CMD check, it would be greatly appreciated.
>>>
>>> ~luis
>>>
>>>
>>>
>>> ***
>>> * checking for missing documentation entries ... WARNING
>>> Undocumented code objects:
>>>    ?lagSelect? ?mod?
>>> Undocumented S4 classes:
>>>    ?commcorrelogram?
>>> Undocumented S4 methods:
>>>    generic 'mod' and siglist 'commcorrelogram'
>>>    generic 'plot' and siglist 'commcorrelogram,missing'
>>>
>>> ***
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From wdunlap at tibco.com  Tue Oct 15 01:30:30 2013
From: wdunlap at tibco.com (William Dunlap)
Date: Mon, 14 Oct 2013 23:30:30 +0000
Subject: [Rd] how to prevent default argument values from being found
Message-ID: <E66794E69CFDE04D9A70842786030B933FA0671D@PA-MBX01.na.tibco.com>

Here is a problem I ran across in RStudio, which uses masks a number of standard R functions with versions that do a bit more than the original does.  The RStudio people have figured out a way to prevent default values of arguments from being found when an argument is missing from a call!

junk1 <- function(...) {
    fun <- function(pkgs, lib = NULL)
    {
        list(missing=missing(lib),
             lib=try(lib, silent = TRUE),
             pkgs = pkgs)
    }
    hook <- function(FUN, pkgs, lib, ...)
    {
        FUN(pkgs, lib, ...)
    }
    hook(fun, ...) 
}

When we run this with one argument, it reports that fun's 'lib' argument is missing
but it dies saying there is no default value.  But there is a default value: NULL.
(If I leave out the try() I get the same problem.)

> junk1("aPackage")
$missing
[1] TRUE

$lib
[1] "Error in try(lib, silent = TRUE) : \n  argument \"lib\" is missing, with no default\n"
attr(,"class")
[1] "try-error"
attr(,"condition")
<simpleError in doTryCatch(return(expr), name, parentenv, handler): argument "lib" is missing, with no default>

$pkgs
[1] "aPackage"

If we change that hook function so it does not assume that the 'pkgs' and 'libs' arguments are
passed in then default argument evaluation works as expected.

junk2 <- function (...)
{
    fun <- function(pkgs, lib = NULL) {
        list(missing = missing(lib), lib = try(lib, silent = TRUE),
            pkgs = pkgs)
    }
    hook <- function(FUN, ...) {
        FUN(...)
    }
    hook(fun, ...)
}
> junk2("aPackage")
$missing
[1] TRUE

$lib
NULL

$pkgs
[1] "aPackage"

It is curious that one can circumvent normal R argument processing.

Bill Dunlap
Spotfire, TIBCO Software
wdunlap tibco.com


From bbolker at gmail.com  Tue Oct 15 03:54:58 2013
From: bbolker at gmail.com (Ben Bolker)
Date: Mon, 14 Oct 2013 21:54:58 -0400
Subject: [Rd] Q-Q plot scaling in plot.lm(); bug or thinko?
Message-ID: <525CA072.10908@mcmaster.ca>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


I've been looking fairly carefully at the Q-Q plots produced by
plot.lm() and am having difficulty understanding why plot.lm()
is doing what it's doing, specifically scaling the standardized
residuals by the prior weights. Can anyone explain this to me ... ?


Multiplying by the weights seems to give the wrong plot, at least for
binomial models; at the very least, it means that the $y$ (observed
quantiles) and $x$ (expected quantiles) scales are different from each
other even when the model is exactly correct ... although if the
weights are all the same, it doesn't change the linearity of the
Q-Q plot, but it does seem confusing if one is explicitly comparing
expected to observed ...

The help page says

> The ?S-L?, the Q-Q, and the Residual-Leverage plot, use 
> _standardized_ residuals which have identical variance (under the 
> hypothesis).  They are given as R[i] / (s * sqrt(1 - h.ii)) where 
> h.ii are the diagonal entries of the hat matrix

An example (in R markdown):

```{r}
set.seed(101)
n <- 1000  ## number of observations
N <- 100   ## binomial sample size
d <- data.frame(r=rbinom(n,size=N,prob=0.5),
                num=N)
## fit with proportion/weights syntax
g1 <- glm(r/N~1,family=binomial,weights=num,data=d)
```

The scale of the standardized residuals looks appropriate:
```{r}
range(rstandard(g1))
```

Showing the results of `plot.lm()`, `qqnorm()` on standardized
residuals, and th enhanced Q-Q plot from the `mgcv` package:
```{r fig.width=10,fig.height=5}
par(mfrow=c(1,3),las=1,bty="l")
plot(g1,which=2,main="plot.lm()")
qqnorm(rstandard(g1),main="qqnorm()")
mgcv::qq.gam(g1,pch=1,main="mgcv::qq.gam()")
```

`rstandard()` uses

```{r eval=FALSE}
res <- res/sqrt(summary(model)$dispersion * (1 - infl$hat))
```

`plot.lm()` uses

```{r eval=FALSE}
r <- residuals(x)
## ... some lines skipped ...
r.w <- if (is.null(w)) {
           r
       } else sqrt(w) * r
rs <- dropInf(r.w/(s * sqrt(1 - hii)), hii)
```
-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)
Comment: Using GnuPG with Thunderbird - http://www.enigmail.net/

iQEcBAEBAgAGBQJSXKByAAoJEOCV5YRblxUH7GIIANdaisPNlYAM65BRJc+U62uQ
gdNfv7xnGhReVRvngkXWCiFWT/54WdJfODPe/gk9uHOfDaQjvyCkicDdmMwq/r5H
2IKGV/1vh9biJr4c89tr3I13Y7hpLcEU5LC+uCSbbsAFBxgmiyNRbZZolA6JI9Vx
ty4QBCSOLcFROmygr1MiLZ4S9DtK7J1s4ToT+iBCHuIT6C+qxc3YrF1NusV1kbpy
IBIRvK44JZJ+1pPrNSfP5v59pZWy9fCyokhX9Rsygx6CSD75YYcQwZ+SHJD7gZ2d
Ev2XPG1qzUeAjpZId/T08Gir7VcbMdeLNIRVIiAAgxTSwmJpWkapsBEgzrE+IDM=
=XOSY
-----END PGP SIGNATURE-----


From luis.f.rodriguez1 at gmail.com  Mon Oct 14 19:54:29 2013
From: luis.f.rodriguez1 at gmail.com (=?windows-1252?Q?Luis_Rodr=EDguez?=)
Date: Mon, 14 Oct 2013 12:54:29 -0500
Subject: [Rd] missing documentation entries ... WARNING
In-Reply-To: <522E2643.6010803@gmail.com>
References: <BAF41C96-FB1E-4AF2-A73E-878D15A5853F@yahoo.com>
	<522E2643.6010803@gmail.com>
Message-ID: <DB7A3056-2B7A-4BC6-AD67-DA6FA0B31488@yahoo.com>

Thanks Duncan (and othersin R-devel).

I clearly got away from this project, but I am still quite interested in resolving this issue and getting these codes into the CRAN.

Some attempts to repair the documentation have occurred in the intervening time, so I am including slightly updated error messages and the relevant tops of the Rd files, as requested by Duncan. See below.

Thanks again!

~luis



<<<<my "missing documentation entries">>>>

* checking for missing documentation entries ... WARNING
Undocumented S4 classes:
  ?commcorrelogram?
Undocumented S4 methods:
  generic 'mod' and siglist 'commcorrelogram'
  generic 'plot' and siglist 'commcorrelogram,missing'
All user-level objects in a package (including S4 classes and methods)
should have documentation entries.
See the chapter ?Writing R documentation files? in the ?Writing R
Extensions? manual.

<<<<my "missing documentation entries">>>>

I am also getting a * checking Rd \usage sections ? WARNING, but your message makes me think this is related to the above. JIC, here is that error message:

<<<<my "\usage section" Warning>>>>

* checking Rd \usage sections ... WARNING
Objects in \usage without \alias in documentation object 'commcorrelogram':
  ?plot.commcorrelogram?

Functions with \usage entries need to have the appropriate \alias
entries, and all their arguments documented.
The \usage entries must correspond to syntactically valid R code.
See the chapter ?Writing R documentation files? in the ?Writing R

<<<<my "\usage section" Warning>>>>


****comcorrelogram.Rd \alias and \usage sections****

\name{commcorrelogram}
\docType{class}
\alias{commcorrelogram}
\alias{mod,commcorrelogram}
\alias{plot,commcorrelogram,missing}

\title{
  Community Correlogram
}
\description{
Function \code{commcorrelogram} computes community correlograms using either the multivariate Mantel statistic (Mantel, 1957) or the ANOSIM R metric (Clarke, 1993), and includes functionality for both directional analyses and combinations of temporal and spatial analyses.  Mantel correlogram proposed by Sokal (1986) and Oden and Sokal (1986). ANOSIM correlogram suggested here.
}
\usage{
commcorrelogram(sampleData, sampleTime = NULL, sampleLocation = NULL,
    LocationNames = NULL, option = 1, metric = "anosim", lagNumber, lagSize,
    lagTol, numTests = 999, anisotropic = FALSE, azimuth, azimuthTol,
    bandwidth, dipAngle, dipTol, dipBandwidth, distmeth = "bray",
    mantmeth = "spearman", adj = "holm", prog = TRUE, alternative =
    "one.sided")

# S3 method for class 'community.correlogram'
plot.commcorrelogram(x, y, alpha=0.05, ?)
}

****comcorrelogram.Rd \alias and \usage sections****

****mod.comcorrelogram.Rd \alias and \usage sections****

\name{mod.commcorrelogram}
\alias{mod.commcorrelogram}
\alias{mod}
\title{
Community Correlogram Model
}
\description{
Function mod.commcorrelogram automatically fits a Gaussian curve to the significance plot of a commcorrelogram object and calculates the correlation range of the data.
}
\usage{
mod.commcorrelogram(object,Ch=1,Cc=5,Cw=0.01,plot=T,alpha=0.05
  ,alternative='one.tailed',pw=5,lgpos='topleft',...)
}

****mod.comcorrelogram.Rd \alias and \usage sections****


On Sep 9, 2013, at 2:49 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 09/09/2013 3:23 PM, Luis Rodr?guez wrote:
>> Dear R-devel,
>> 
>> I am a relative novice in R, but I am eager to post a new package my group developed in CRAN, but I am stumped by a set of documentation related warnings created by R CMD check.
>> 
>> So, my current plan is to recreate the documentation by religiously applying and modifying the skeleton codes that can be generated by R. In the meantime, I thought I'd post to the discussion group to see if maybe someone with more experience had some useful advice. Below you'll see a snippet of the key documentation warnings that we are stumped on.
>> 
>> lagSelect and mod are functions created by my group, as is commcorrelogram. My belief is that they are clearly documented, but I suspect that our novice source code and documentation is not quite hitting what R CMD check is looking for.
> 
> This message usually indicates that you don't have the relevant \alias{} defined correctly. If you do, please post the top of one or two of the Rd files, and we can tell you what's missing.  (I'd like to see at least the \alias{} and \usage{} sections.)
> 
> Duncan Murdoch
> 
>> 
>> If anyone has advice on how to pass R CMD check, it would be greatly appreciated.
>> 
>> ~luis
>> 
>> 
>> 
>> ***
>> * checking for missing documentation entries ... WARNING
>> Undocumented code objects:
>>   ?lagSelect? ?mod?
>> Undocumented S4 classes:
>>   ?commcorrelogram?
>> Undocumented S4 methods:
>>   generic 'mod' and siglist 'commcorrelogram'
>>   generic 'plot' and siglist 'commcorrelogram,missing'
>> 
>> ***
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From corentin.barbu at gmail.com  Tue Oct 15 02:04:40 2013
From: corentin.barbu at gmail.com (corentin barbu)
Date: Mon, 14 Oct 2013 20:04:40 -0400
Subject: [Rd] discrepancy between r cmd check --as-cran and messages at
	submission
Message-ID: <CAPMyHTxTAF6CRLZr_=zQ125Bq9RiENbvcQE-5KVh0LWR5-=pEw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131014/6fd01556/attachment.pl>

From ripley at stats.ox.ac.uk  Tue Oct 15 13:30:50 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 15 Oct 2013 12:30:50 +0100
Subject: [Rd] discrepancy between r cmd check --as-cran and messages at
 submission
In-Reply-To: <CAPMyHTxTAF6CRLZr_=zQ125Bq9RiENbvcQE-5KVh0LWR5-=pEw@mail.gmail.com>
References: <CAPMyHTxTAF6CRLZr_=zQ125Bq9RiENbvcQE-5KVh0LWR5-=pEw@mail.gmail.com>
Message-ID: <525D276A.2030204@stats.ox.ac.uk>

On 15/10/2013 01:04, corentin barbu wrote:
> Dear r-devel list,
>
> I've observed at both of my submissions that issues arise at submission
> that were not pointed out by
> R cmd check --as-cran
>
> For example at my last submission:
>
> You have
> VignetteBuilder: knitr
> but there is nothing looking like a vignette in your source package....
>
> We also see:
>
> * checking DESCRIPTION meta-information ... NOTE
> Author field differs from that derived from Authors at R
>    Author:    'Corentin M Barbu <corentin.barbu at gmail.com> [aut, cre],
> Sebastian Gibb <mail at sebastiangibb.de> [ctb]'
>    Authors at R: 'Corentin M Barbu [aut, cre], Sebastian Gibb [ctb]'
>
> Maintainer field differs from that derived from Authors at R
>    Maintainer: 'Corentin M. Barbu <corentin.barbu at gmail.com>'
>    Authors at R:  'Corentin M Barbu <corentin.barbu at gmail.com>'
>
> Both were stupid mistakes, largely due to my inexperience but none was
> detected by R cmd check --as-cran or even at build by
>
> http://win-builder.r-project.org/upload.aspx
>
> Is there anything else I can use to better check my packages before
> submission?

Yes, follow the CRAN policies:

'Please ensure that R CMD check --as-cran has been run on the tarball to 
be uploaded before submission. This should be done with the current 
version of R-devel (or if that is not possible, current R-patched or the 
current release of R.)'

The check of Authors at R is in R-devel only, and requires --as-cran.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From josh.m.ulrich at gmail.com  Tue Oct 15 13:37:52 2013
From: josh.m.ulrich at gmail.com (Joshua Ulrich)
Date: Tue, 15 Oct 2013 06:37:52 -0500
Subject: [Rd] Possible POSIXlt / wday glitch & bugs.r-project.org status
In-Reply-To: <C1A6679C-91B6-4EAB-A630-EFD2ABA641CB@r-project.org>
References: <7C58F7EE-8786-45B4-B47A-7BC19A1CECCB@me.com>
	<CAE3=dmeXTKV=dmFD5PO30dK0spHzrb1k-F4ndiURp8_zEBxRng@mail.gmail.com>
	<3CF8C970-05CC-45C4-8CE0-E078C84121AF@me.com>
	<CAPPM_gQBb_B5ukeBoCkd8rqwya-LdvUS0LGd7eRDzR=Scz8ZpA@mail.gmail.com>
	<CA+MmmTKJRwWegc=yPHo0mZ-=arhkMpw3PvyEspYS7jeH86gFOQ@mail.gmail.com>
	<C1A6679C-91B6-4EAB-A630-EFD2ABA641CB@r-project.org>
Message-ID: <CAPPM_gTOmUEW0a2-84mPmbbdsr-h31gAv2We0fvi+PXM1YuhYg@mail.gmail.com>

In an effort to redeem myself, I have found and submitted a patch for
what seems to be causing this issue.

Best,
--
Joshua Ulrich  |  about.me/joshuaulrich
FOSS Trading  |  www.fosstrading.com


On Sat, Oct 5, 2013 at 1:18 PM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> On Oct 5, 2013, at 4:51 PM, Sean O'Riordain <seanpor at acm.org> wrote:
>
>> Some people (luckily not me anymore!) working with mortgages and
>> pensions need to calculate up to 40 years into the future for the
>> payment schedule.
>>
>
> Just to clarify since the Joshua's comment was ambiguous (and in part plain wrong) - R's POSIXct has no such limit since it doesn't use integers, so that is not really the issue here. As the original post suggested there may be a bug in handing some cases where conversions hit the system libraries (that may truncate to integers) and some cases may be worked around - and that remains to be investigated.
>
> Cheers,
> Simon
>
>
>
>> On 5 October 2013 02:37, Joshua Ulrich <josh.m.ulrich at gmail.com> wrote:
>>> On Fri, Oct 4, 2013 at 8:02 PM, Imanuel Costigan <i.costigan at me.com> wrote:
>>>> Thanks for the responses and quoting the timezone help file.
>>>>
>>>> I am assuming that in order to determine the wday element of POSIXlt, R does the necessary calculations in Julian time (via POSIXct). Based on this excerpt from ?DateTimeClasses, it looks like R is responsible for determining time zones post 2037 (the example I gave was in 2038). So it could be an R issue.
>>>>
>>> It's an issue with size of the largest number you can store in a
>>> signed integer, which is not specific to R.
>>>
>>>> .POSIXct(.Machine$integer.max, tz="UTC")
>>> [1] "2038-01-19 03:14:07 UTC"
>>>
>>> Dates larger than that cannot be represented by a signed integer.  It
>>> could be worked around, but it's not trivial because R would have to
>>> use something other than the tm C struct.  Luckily, there's a decade
>>> or two before it starts to become a pressing issue. :)
>>>
>>>>>     ?"POSIXct"? objects may also have an attribute ?"tzone"?, a
>>>>>     character vector of length one.  If set to a non-empty value, it
>>>>>     will determine how the object is converted to class ?"POSIXlt"?
>>>>>     and in particular how it is printed.  This is usually desirable,
>>>>>     but if you want to specify an object in a particular timezone but
>>>>>     to be printed in the current timezone you may want to remove the
>>>>>     ?"tzone"? attribute (e.g. by ?c(x)?).
>>>>>
>>>>>     Unfortunately, the conversion is complicated by the operation of
>>>>>     time zones and leap seconds (24 days have been 86401 seconds long
>>>>>     so far: the times of the extra seconds are in the object
>>>>>     ?.leap.seconds?).  **The details of this are entrusted to the OS
>>>>>     services where possible.  This always covers the period 1970-2037,
>>>>>     and on most machines back to 1902 (when time zones were in their
>>>>>     infancy).  Outside the platform limits we use our own C code.
>>>>
>>>>
>>>> On 05/10/2013, at 12:59 AM, Scott Kostyshak <skostysh at princeton.edu> wrote:
>>>>
>>>>> On Fri, Oct 4, 2013 at 6:11 AM, Imanuel Costigan <i.costigan at me.com> wrote:
>>>>>> Wanted to raise two questions:
>>>>>>
>>>>>> 1. Is bugs.r-project.org down? I haven't been able to reach it for two or three days:
>>>>>
>>>>> Yes. Quote from Duncan:
>>>>>
>>>>>   ... the server is currently down. The volunteer who runs the server is
>>>>>   currently away from his office, so I expect it won't get fixed until he
>>>>>   gets back in a few days.
>>>>>
>>>>> https://stat.ethz.ch/pipermail/r-help/2013-October/360958.html
>>>>>
>>>>> Scott
>>>>>
>>>>>>
>>>>>> ```
>>>>>> ping bugs.r-project.org
>>>>>> PING rbugs.research.att.com (207.140.168.137): 56 data bytes
>>>>>> Request timeout for icmp_seq 0
>>>>>> Request timeout for icmp_seq 1
>>>>>> Request timeout for icmp_seq 2
>>>>>> Request timeout for icmp_seq 3
>>>>>> Request timeout for icmp_seq 4
>>>>>> Request timeout for icmp_seq 5
>>>>>> Request timeout for icmp_seq 6
>>>>>> ```
>>>>>>
>>>>>> 2. Is wday element of POSIXlt meant to be timezone invariant? You would expect the wday element to be invariant to the timezone of a date. That is, the same date/time instant of 5th October 2013 in both Australia/Sydney and UTC should be a Saturday (i.e. wday = 6). And indeed that is the case with 1 min past midnight on 5 October 2013:
>>>>>>
>>>>>> ```
>>>>>> library(lubridate)
>>>>>> d_utc <- ymd_hms(20131005000001, tz='UTC')
>>>>>> d_local <- ymd_hms(20131005000001, tz='Australia/Sydney')
>>>>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>>>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 6
>>>>>> ```
>>>>>>
>>>>>> But this isn't always the case. For example,
>>>>>>
>>>>>> ```
>>>>>> d_utc <- ymd_hms(20381002000001, tz='UTC')
>>>>>> d_local <- ymd_hms(20381002000001, tz='Australia/Sydney')
>>>>>> as.POSIXlt(x=d_utc, tz=tz(d_utc))$wday # 6
>>>>>> as.POSIXlt(x=d_local, tz=tz(d_local))$wday # 5
>>>>>> ```
>>>>>>
>>>>>> Is this expected behaviour? I would have expected a properly encoded date/time of 2 Oct 2038 to be a Saturday irrespective of its time zone.
>>>>>>
>>>>>> Obligatory system dump:
>>>>>>
>>>>>> ```
>>>>>>> sessionInfo()
>>>>>> R version 3.0.1 (2013-05-16)
>>>>>> Platform: x86_64-apple-darwin12.4.0 (64-bit)
>>>>>>
>>>>>> locale:
>>>>>> [1] en_AU.UTF-8/en_AU.UTF-8/en_AU.UTF-8/C/en_AU.UTF-8/en_AU.UTF-8
>>>>>>
>>>>>> attached base packages:
>>>>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>>>>>
>>>>>> other attached packages:
>>>>>> [1] lubridate_1.3.0 testthat_0.7.1  devtools_1.3
>>>>>>
>>>>>> loaded via a namespace (and not attached):
>>>>>> [1] colorspace_1.2-4   dichromat_2.0-0    digest_0.6.3       evaluate_0.5.1
>>>>>> [5] ggplot2_0.9.3.1    grid_3.0.1         gtable_0.1.2       httr_0.2
>>>>>> [9] labeling_0.2       MASS_7.3-29        memoise_0.1        munsell_0.4.2
>>>>>> [13] parallel_3.0.1     plyr_1.8           proto_0.3-10       RColorBrewer_1.0-5
>>>>>> [17] RCurl_1.95-4.1     reshape2_1.2.2     scales_0.2.3       stringr_0.6.2
>>>>>> [21] tools_3.0.1        whisker_0.3-2
>>>>>>
>>>>>> ```
>>>>>>
>>>>>> Using R compiled by homebrew [1]. But also experiencing the same bug using R installed on Windows 7 from the CRAN binaries.
>>>>>>
>>>>>> For those interested, I've also noted this on the `lubridate` Github issues page [2], even though this doesn't appear to be a lubridate issue.
>>>>>>
>>>>>> Thanks for any help.
>>>>>>
>>>>>> [1] http://brew.sh
>>>>>> [2] https://github.com/hadley/lubridate/issues/209
>>>>>>
>>>>>> ______________________________________________
>>>>>> R-devel at r-project.org mailing list
>>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>>
>>>>> --
>>>>> Scott Kostyshak
>>>>> Economics PhD Candidate
>>>>> Princeton University
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From pauljohn32 at gmail.com  Tue Oct 15 22:15:28 2013
From: pauljohn32 at gmail.com (Paul Johnson)
Date: Tue, 15 Oct 2013 15:15:28 -0500
Subject: [Rd] Two R editiosn in Unix cluster systems
Message-ID: <CAErODj9ZdMPxqjH0JYW6O-k4QqgMDT3mG=5pJsQ2oJtw77UeKA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131015/a7f0e1e9/attachment.pl>

From corentin.barbu at gmail.com  Tue Oct 15 23:47:28 2013
From: corentin.barbu at gmail.com (corentin barbu)
Date: Tue, 15 Oct 2013 17:47:28 -0400
Subject: [Rd] discrepancy between r cmd check --as-cran and messages at
	submission
In-Reply-To: <525D276A.2030204@stats.ox.ac.uk>
References: <CAPMyHTxTAF6CRLZr_=zQ125Bq9RiENbvcQE-5KVh0LWR5-=pEw@mail.gmail.com>
	<525D276A.2030204@stats.ox.ac.uk>
Message-ID: <CAPMyHTwHk=_Uq3ym5s4+D327PKUf_G8MtZ5OHW_CHdpYwCFhZg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131015/285e6fad/attachment.pl>

From peter.langfelder at gmail.com  Wed Oct 16 01:35:38 2013
From: peter.langfelder at gmail.com (Peter Langfelder)
Date: Tue, 15 Oct 2013 16:35:38 -0700
Subject: [Rd] Two R editiosn in Unix cluster systems
In-Reply-To: <CAErODj9ZdMPxqjH0JYW6O-k4QqgMDT3mG=5pJsQ2oJtw77UeKA@mail.gmail.com>
References: <CAErODj9ZdMPxqjH0JYW6O-k4QqgMDT3mG=5pJsQ2oJtw77UeKA@mail.gmail.com>
Message-ID: <CA+hbrhWD2J8_X16Pf6ZULwxmNfmg=qsnh5AvQznjsU==GjhM0w@mail.gmail.com>

On Tue, Oct 15, 2013 at 1:15 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Dear R Devel
>
> Some of our R users are still insisting we run R-2.15.3 because of
> difficulties with a package called OpenMX.  It can't cooperate with new R,
> oh well.
>
> Other users need to run R-3.0.1. I'm looking for the most direct route to
> install both, and allow users to choose at runtime.
[...]

Since no experts have replied, here's my non-expert opinion (take it
as a disclaimer). R is happy to be installed in multiple versions. I
have always had several versions of R installed (under Linux). I
always compile from source and simply set the appropriate destination
directories appropriately, then symlink the R and Rscript executables.
In my case I put each version into a separate directory under
/usr/local/lib64, for example /usr/local/lib64/R-3.0.2-patched . I put
all executables into /usr/local/bin but change their names, e.g. R is
called R-3.0.2-patched etc; then symlink the executable that I want to
be my "default" version to /usr/local/bin/R and
/usr/local/bin/Rscript.

If I want to call another version of R, I invoke it explicitly as say
R-2.15.3 (assuming such version exists).

You could also create a separate directory for the executables for
each version and symlink them under different names to /usr/bin or
/usr/local/bin.

I never had problems with versions of R clashing. The executable R
that a user executes is a shell wrapper that sets up all necessary
environment variables and then calls the actual executable (which sits
in /usr/local/lib64/<R-directory>/bin/exec). Thus, other versions on
$PATH do not cause any trouble.

HTH,

Peter


From istazahn at gmail.com  Wed Oct 16 02:09:48 2013
From: istazahn at gmail.com (Ista Zahn)
Date: Tue, 15 Oct 2013 20:09:48 -0400
Subject: [Rd] Two R editiosn in Unix cluster systems
In-Reply-To: <CAErODj9ZdMPxqjH0JYW6O-k4QqgMDT3mG=5pJsQ2oJtw77UeKA@mail.gmail.com>
References: <CAErODj9ZdMPxqjH0JYW6O-k4QqgMDT3mG=5pJsQ2oJtw77UeKA@mail.gmail.com>
Message-ID: <CA+vqiLEG-8K-=ufLuaA_yEHYmLeVA6rZOD1ipX1BQygfr+xvug@mail.gmail.com>

OpenMx does install on R 3.01. I haven't tested extensively, but after
installing with

install.packages('OpenMx',
                 dependencies = TRUE,
                 repos = c(getOption("repos"),
'http://openmx.psyc.virginia.edu/sequential/'))

the demos appear to run correctly.

Best,
Ista

On Tue, Oct 15, 2013 at 4:15 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Dear R Devel
>
> Some of our R users are still insisting we run R-2.15.3 because of
> difficulties with a package called OpenMX.  It can't cooperate with new R,
> oh well.
>
> Other users need to run R-3.0.1. I'm looking for the most direct route to
> install both, and allow users to choose at runtime.
>
> In the cluster, things run faster if I install RPMs to each node, rather
> than putting R itself on the NFS share (but I could do that if you think
> it's really better....)
>
> In the past, I've used the SRPM packaging from EPEL repository to make a
> few little path changes and build R RPM for our cluster nodes. Now I face
> the problem of building 2 RPMS, one for R-2.15.3 and one for R-newest, and
> somehow keeping them separate.
>
> If you were me, how would you approach this?
>
> Here's my guess
>
> First, The RPM packages need unique names, of course.
>
> Second, leave the RPM packaging for R-newest exactly the same as it always
> was.  R is in the path, the R script and references among all the bits will
> be fine, no need to fight. It will find what it needs in /usr/lib64/R or
> whatnot.
>
> For the legacy R, I'm considering 2 ideas.  I could install R with the same
> prefix, /usr, but very careful so the R bits are installed into separate
> places. I just made a fresh build of R and on RedHat 6, it appears to me R
> installs these directories:
> bin
> libdir
> share.
>
> So what if the configure line has the magic bindir=/usr/bin-R-2.15.3
> libdir = /usr/lib64/R-2.15.3, and whatnot. If I were doing Debian
> packaging, I suppose I'd be obligated (by the file system standard) to do
> that kind of thing. But it looks like a headache.
>
> The easy road is to set the prefix at some out of the way place, like
> /opt/R-2.15.3, and then use a post-install script to link
> /opt/R-2/15.3/bin/R to /usr/bin/R-2.15.3.  When I tried that, it surprised
> me because R did not complain about lack access to devel headers. It
> configures and builds fine.
>
> R is now configured for x86_64-unknown-linux-gnu
>
>   Source directory:          .
>   Installation directory:    /tmp/R
>
>   C compiler:                gcc -std=gnu99  -g -O2
>   Fortran 77 compiler:       gfortran  -g -O2
>
>   C++ compiler:              g++  -g -O2
>   Fortran 90/95 compiler:    gfortran -g -O2
>   Obj-C compiler:            gcc -g -O2 -fobjc-exceptions
>
>   Interfaces supported:      X11, tcltk
>   External libraries:        readline, ICU, lzma
>   Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo
>   Options enabled:           shared BLAS, R profiling, Java
>
>   Recommended packages:      yes
>
> Should I worry about any runtime complications of this older R finding its
> of the newer R in the PATH ahead of it? I worry I'm making lazy
> assumptions?
>
> After that, I need to do some dancing with the RPM packaging.
>
> I suppose there'd be some comfort if I could get the users to define R_HOME
> in their user environment before launching jobs, I think that would
> eliminate the danger of confusion between versions, wouldn't it?
>
> pj
> --
> Paul E. Johnson
> Professor, Political Science      Assoc. Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org               http://quant.ku.edu
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From smckinney at bccrc.ca  Wed Oct 16 02:33:52 2013
From: smckinney at bccrc.ca (Steven McKinney)
Date: Tue, 15 Oct 2013 17:33:52 -0700
Subject: [Rd] Two R editiosn in Unix cluster systems
In-Reply-To: <CAErODj9ZdMPxqjH0JYW6O-k4QqgMDT3mG=5pJsQ2oJtw77UeKA@mail.gmail.com>
References: <CAErODj9ZdMPxqjH0JYW6O-k4QqgMDT3mG=5pJsQ2oJtw77UeKA@mail.gmail.com>
Message-ID: <DCE81E14EB74504B971DAD4D2DB0356B0CB926B0A3@crcmail4.BCCRC.CA>


> -----Original Message-----
> From: r-devel-bounces at r-project.org [mailto:r-devel-bounces at r-project.org]
> On Behalf Of Paul Johnson
> Sent: October-15-13 1:15 PM
> To: R Devel List
> Cc: Discussion of Rocks Clusters
> Subject: [Rd] Two R editiosn in Unix cluster systems
> 
> Dear R Devel
> 
> Some of our R users are still insisting we run R-2.15.3 because of
> difficulties with a package called OpenMX.  It can't cooperate with new R,
> oh well.
> 
> Other users need to run R-3.0.1. I'm looking for the most direct route to
> install both, and allow users to choose at runtime.
> 
> In the cluster, things run faster if I install RPMs to each node, rather
> than putting R itself on the NFS share (but I could do that if you think
> it's really better....)
> 
> In the past, I've used the SRPM packaging from EPEL repository to make a
> few little path changes and build R RPM for our cluster nodes. Now I face
> the problem of building 2 RPMS, one for R-2.15.3 and one for R-newest, and
> somehow keeping them separate.
> 
> If you were me, how would you approach this?

Our bioinformatics group needs multiple versions of R
and other software for a variety of compatibility issues.

We thus gave up on trying to keep multiple versions of
R and related pipeline software on all nodes of our
cluster.

We set up a mount point on each cluster node pointing to
a directory structure on the head node (/share/apps).  

We compile and link all necessary materials in that directory 
structure, so that no executables or shared objects from 
/usr or other local drive locations need be accessed.  
All code is in e.g. /share/apps/R/R-x.yy.z  so all the 
nodes can see all the versions.  We have shared
libraries in e.g. /share/apps/usr/lib

All pipeline scripts use full paths to R and other
executables, and since R is self-contained when 
appropriately  compiled as you note below, there's 
no path clashing.

(We also abandoned NFS for lustre so we don't have the
speed issue you might face with such an arrangement.
But generally code just needs to be read once and
is then kept in memory by current OSs, so you might
not notice much of a speed hit as far as getting the
executable into memory.)

Maintaining one set of code accessible to all nodes has
made things much simpler than trying to set up all the
rpms on the head node so that all compute nodes get
it all installed locally.  

Some attention to detail is important at compile time, 
to ensure that all bits that go into the compilation 
really do come from /share/apps  but that's about it.  
This has been easier to accomplish than maintaining 
a library of rpms on the head node and managing the 
distribution scripts to push out to the compute nodes.




Steven McKinney

Statistician
Molecular Oncology and Breast Cancer Program
British Columbia Cancer Research Centre

> Here's my guess
> 
> First, The RPM packages need unique names, of course.
> 
> Second, leave the RPM packaging for R-newest exactly the same as it always
> was.  R is in the path, the R script and references among all the bits will
> be fine, no need to fight. It will find what it needs in /usr/lib64/R or
> whatnot.
> 
> For the legacy R, I'm considering 2 ideas.  I could install R with the same
> prefix, /usr, but very careful so the R bits are installed into separate
> places. I just made a fresh build of R and on RedHat 6, it appears to me R
> installs these directories:
> bin
> libdir
> share.
> 
> So what if the configure line has the magic bindir=/usr/bin-R-2.15.3
> libdir = /usr/lib64/R-2.15.3, and whatnot. If I were doing Debian
> packaging, I suppose I'd be obligated (by the file system standard) to do
> that kind of thing. But it looks like a headache.
> 
> The easy road is to set the prefix at some out of the way place, like
> /opt/R-2.15.3, and then use a post-install script to link
> /opt/R-2/15.3/bin/R to /usr/bin/R-2.15.3.  When I tried that, it surprised
> me because R did not complain about lack access to devel headers. It
> configures and builds fine.
> 
> R is now configured for x86_64-unknown-linux-gnu
> 
>   Source directory:          .
>   Installation directory:    /tmp/R
> 
>   C compiler:                gcc -std=gnu99  -g -O2
>   Fortran 77 compiler:       gfortran  -g -O2
> 
>   C++ compiler:              g++  -g -O2
>   Fortran 90/95 compiler:    gfortran -g -O2
>   Obj-C compiler:            gcc -g -O2 -fobjc-exceptions
> 
>   Interfaces supported:      X11, tcltk
>   External libraries:        readline, ICU, lzma
>   Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo
>   Options enabled:           shared BLAS, R profiling, Java
> 
>   Recommended packages:      yes
> 
> Should I worry about any runtime complications of this older R finding its
> of the newer R in the PATH ahead of it? I worry I'm making lazy
> assumptions?
> 
> After that, I need to do some dancing with the RPM packaging.
> 
> I suppose there'd be some comfort if I could get the users to define R_HOME
> in their user environment before launching jobs, I think that would
> eliminate the danger of confusion between versions, wouldn't it?
> 
> pj
> --
> Paul E. Johnson
> Professor, Political Science      Assoc. Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org               http://quant.ku.edu
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From nigel.delaney at outlook.com  Wed Oct 16 02:41:11 2013
From: nigel.delaney at outlook.com (Nigel Delaney)
Date: Tue, 15 Oct 2013 20:41:11 -0400
Subject: [Rd] FW: Replacing the Random Number Generator in Stand Alone
	Library
In-Reply-To: <BAY406-EAS163E93209B12379E553BEA1E51E0@phx.gbl>
References: <BAY406-EAS212BD9C215DD7A2A1C548F9E51E0@phx.gbl>
	<BAY406-EAS163E93209B12379E553BEA1E51E0@phx.gbl>
Message-ID: <BAY403-EAS2567CE44A38161E0900B5FEE5040@phx.gbl>

Okay, so I am guessing everyone had the same response I initially did when
hearing that this RNG might not be so hot*...  as an alternate question, if
I submitted a patch to replace the current RNG with the twister, would it be
accepted?

-N

-----Original Message-----
From: Nigel Delaney [mailto:nigel.delaney at outlook.com] 
Sent: Thursday, October 10, 2013 5:04 PM
To: r-devel at r-project.org
Subject: Replacing the Random Number Generator in Stand Alone Library

Hi R-Developers,

I had a question about the random number generator used in the R StandAlone
Math Library.  The stand-alone library depends on the unif_rand() function
for most simulated values, and this function is provided in the sunif.c file
in the relevant directory.  At present, this program implements the
"Marsaglia-Multicarry" algorithm, which is described throughout the R
documentation as:

 "A multiply-with-carry RNG is used, as recommended by George Marsaglia in
his post to the mailing list 'sci.stat.math'. It has a period of more than
2^60 and has passed all tests (according to Marsaglia). The seed is two
integers (all values allowed)."

However, I do not think this RNG actually passes all tests.   For example,
the Handbook of Computational Econometrics (illegal web copy at link below),
shows that it fails the mtuple test and gives an explicit example where it
leads to problems because it failed this test.  The mtuple test was
introduced by Marsaglia in 1985, and I gather he wrote his mailing list
comment that it "passes all tests" sometime after this, so I am not sure
what explains this distinction (though I am not sure if the mtuple test is
included in the diehard tests, which he may have been what he was referring
to).  However, there are clearly some areas where this PRNG runs in to
trouble (although the books example is better, another problem is that it
can't seem to simulate a value above (1/2)^1+(1/4)^4) after simulating a
value below 1e-6.

Given that the Mersenne Twister seems to be the standard for simulation
these days (and used as the default in R), it seems like it might be useful
to change the stand alone library so it also uses this routine.  I gather
this would be pretty easy to do by pulling this function from the RNG.c file
and moving it into the sunif.c file, and have a prototype of this.

However, I thought I would ask, is there a reason this hasn't been done?  Or
is it just a historical carry-over (pun intended I suppose).

Warm wishes,
Nigel

********************
Research Fellow
Massachusetts General Hospital / Broad Institute


Book link:
http://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/handboo
k-of-computational-econometrics-belsley.pdf


From aebrenne at uci.edu  Wed Oct 16 03:24:50 2013
From: aebrenne at uci.edu (Adam Brenner)
Date: Tue, 15 Oct 2013 18:24:50 -0700
Subject: [Rd] [Rocks-Discuss] Two R editiosn in Unix cluster systems
In-Reply-To: <CAErODj9ZdMPxqjH0JYW6O-k4QqgMDT3mG=5pJsQ2oJtw77UeKA@mail.gmail.com>
References: <CAErODj9ZdMPxqjH0JYW6O-k4QqgMDT3mG=5pJsQ2oJtw77UeKA@mail.gmail.com>
Message-ID: <CAO9TOLeY_jUEP0XqyMbmD-Yba75ZM9HZanioxyEDfmyuZoXagQ@mail.gmail.com>

Paul,

For our HPC cluster we have ran into this issue in the past. What we use is
modules[1]. We instructor our users to run a command, like

   modules load R/2.15.2

This will load up the environment path in which R/2.15.2 lives. If they want
to switch or use R/3.0.1 they simply run

   module unload R/2.15.2
   module load R/3.0.1

For all our software install, we do *not* install software on each node. The
overhead for us to create a compilation script and fork that out to each node
within our cluster (100+) is not worth it. Instead we use modules, as I have
described above. We use a standard NFS server with lots of NFS processes that
gets mounted on each compute node. This has worked extremely well for us.

The primary reason, is due to the fact the linux kernel does a fairly good job
when caching libraries. In our setup, we have experienced most, if not all,
the R libraries stay in memory once loaded from our NFS server. The data/input
files R uses is on our Gluster or FraunhoferFS parallel file system. Of
course, keeping the data local to the compute node would be the fastest.


If you still want to install software locally on each compute node, you can
still take advantage of modules. I do suggest you install R (from source or
RPM, etc) in a non-standard location like /opt/ or make your own /apps, /data
and so on. Then create a module file similar to the following:

        #%Module1.0
        module load gcc/4.8.1
        set  ROOT  /data/apps/R/3.0.1

        prepend-path PATH            $ROOT/bin
        prepend-path MANPATH         $ROOT/share
        prepend-path R_LIBS          $ROOT/lib64/R/library
        prepend-path LD_LIBRARY_PATH $ROOT/lib64/R/lib


Replace the TCL variable ROOT with the path of where R lives and you are good
to go. This method of works with other software besides R :-)

[1]: http://modules.sourceforge.net

-Adam


--
Adam Brenner
Computer Science, Undergraduate Student
Donald Bren School of Information and Computer Sciences

Research Computing Support
Office of Information Technology
http://www.oit.uci.edu/rcs/

University of California, Irvine
www.ics.uci.edu/~aebrenne/
aebrenne at uci.edu


On Tue, Oct 15, 2013 at 1:15 PM, Paul Johnson <pauljohn32 at gmail.com> wrote:
> Dear R Devel
>
> Some of our R users are still insisting we run R-2.15.3 because of
> difficulties with a package called OpenMX.  It can't cooperate with new R,
> oh well.
>
> Other users need to run R-3.0.1. I'm looking for the most direct route to
> install both, and allow users to choose at runtime.
>
> In the cluster, things run faster if I install RPMs to each node, rather
> than putting R itself on the NFS share (but I could do that if you think
> it's really better....)
>
> In the past, I've used the SRPM packaging from EPEL repository to make a
> few little path changes and build R RPM for our cluster nodes. Now I face
> the problem of building 2 RPMS, one for R-2.15.3 and one for R-newest, and
> somehow keeping them separate.
>
> If you were me, how would you approach this?
>
> Here's my guess
>
> First, The RPM packages need unique names, of course.
>
> Second, leave the RPM packaging for R-newest exactly the same as it always
> was.  R is in the path, the R script and references among all the bits will
> be fine, no need to fight. It will find what it needs in /usr/lib64/R or
> whatnot.
>
> For the legacy R, I'm considering 2 ideas.  I could install R with the same
> prefix, /usr, but very careful so the R bits are installed into separate
> places. I just made a fresh build of R and on RedHat 6, it appears to me R
> installs these directories:
> bin
> libdir
> share.
>
> So what if the configure line has the magic bindir=/usr/bin-R-2.15.3
> libdir = /usr/lib64/R-2.15.3, and whatnot. If I were doing Debian
> packaging, I suppose I'd be obligated (by the file system standard) to do
> that kind of thing. But it looks like a headache.
>
> The easy road is to set the prefix at some out of the way place, like
> /opt/R-2.15.3, and then use a post-install script to link
> /opt/R-2/15.3/bin/R to /usr/bin/R-2.15.3.  When I tried that, it surprised
> me because R did not complain about lack access to devel headers. It
> configures and builds fine.
>
> R is now configured for x86_64-unknown-linux-gnu
>
>   Source directory:          .
>   Installation directory:    /tmp/R
>
>   C compiler:                gcc -std=gnu99  -g -O2
>   Fortran 77 compiler:       gfortran  -g -O2
>
>   C++ compiler:              g++  -g -O2
>   Fortran 90/95 compiler:    gfortran -g -O2
>   Obj-C compiler:            gcc -g -O2 -fobjc-exceptions
>
>   Interfaces supported:      X11, tcltk
>   External libraries:        readline, ICU, lzma
>   Additional capabilities:   PNG, JPEG, TIFF, NLS, cairo
>   Options enabled:           shared BLAS, R profiling, Java
>
>   Recommended packages:      yes
>
> Should I worry about any runtime complications of this older R finding its
> of the newer R in the PATH ahead of it? I worry I'm making lazy
> assumptions?
>
> After that, I need to do some dancing with the RPM packaging.
>
> I suppose there'd be some comfort if I could get the users to define R_HOME
> in their user environment before launching jobs, I think that would
> eliminate the danger of confusion between versions, wouldn't it?
>
> pj
> --
> Paul E. Johnson
> Professor, Political Science      Assoc. Director
> 1541 Lilac Lane, Room 504      Center for Research Methods
> University of Kansas                 University of Kansas
> http://pj.freefaculty.org               http://quant.ku.edu
> -------------- next part --------------
> An HTML attachment was scrubbed...
> URL: https://lists.sdsc.edu/pipermail/npaci-rocks-discussion/attachments/20131015/a7f0e1e9/attachment.html


From rosenberger at imsb.biol.ethz.ch  Tue Oct 15 15:00:55 2013
From: rosenberger at imsb.biol.ethz.ch (Rosenberger  George)
Date: Tue, 15 Oct 2013 13:00:55 +0000
Subject: [Rd] randomForest: Numeric deviation between 32/64 Windows builds
Message-ID: <DEBDABC7-17EC-4041-BBEC-55101D3D2453@imsb.biol.ethz.ch>

Dear R Developers

I'm using the great randomForest package (4.6-7) for many projects and recently stumbled upon a problem when I wrote unit tests for one of my projects:

On Windows, there are small numeric deviations when using the 32- / 64-bit version of R, which doesn't seem to be a problem on Linux or Mac.

R64 on Windows produces the same results as R64/R32 on Linux or Mac:

> set.seed(131)
> importance(randomForest(Species ~ ., data=iris))
             MeanDecreaseGini
Sepal.Length         9.452470
Sepal.Width          2.037092
Petal.Length        43.603071
Petal.Width         44.116904

R32 on Windows produces the following:

> set.seed(131)
> importance(randomForest(Species ~ ., data=iris))
             MeanDecreaseGini
Sepal.Length         9.433986
Sepal.Width          2.249871
Petal.Length        43.594159
Petal.Width         43.941870

Is there a reason why this is different for the Windows builds? Are the compilers on Windows doing different things for 32- / 64-bit builds than the ones on Linux or Mac?

Thank you very much for your help.

Best regards,
George


From ripley at stats.ox.ac.uk  Wed Oct 16 12:58:56 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 16 Oct 2013 11:58:56 +0100
Subject: [Rd] randomForest: Numeric deviation between 32/64 Windows
	builds
In-Reply-To: <DEBDABC7-17EC-4041-BBEC-55101D3D2453@imsb.biol.ethz.ch>
References: <DEBDABC7-17EC-4041-BBEC-55101D3D2453@imsb.biol.ethz.ch>
Message-ID: <525E7170.3000304@stats.ox.ac.uk>

On 15/10/2013 14:00, Rosenberger George wrote:
> Dear R Developers
>
> I'm using the great randomForest package (4.6-7) for many projects and recently stumbled upon a problem when I wrote unit tests for one of my projects:
>
> On Windows, there are small numeric deviations when using the 32- / 64-bit version of R, which doesn't seem to be a problem on Linux or Mac.
>
> R64 on Windows produces the same results as R64/R32 on Linux or Mac:
>
>> set.seed(131)
>> importance(randomForest(Species ~ ., data=iris))
>               MeanDecreaseGini
> Sepal.Length         9.452470
> Sepal.Width          2.037092
> Petal.Length        43.603071
> Petal.Width         44.116904
>
> R32 on Windows produces the following:
>
>> set.seed(131)
>> importance(randomForest(Species ~ ., data=iris))
>               MeanDecreaseGini
> Sepal.Length         9.433986
> Sepal.Width          2.249871
> Petal.Length        43.594159
> Petal.Width         43.941870
>
> Is there a reason why this is different for the Windows builds? Are the compilers on Windows doing different things for 32- / 64-bit builds than the ones on Linux or Mac?

Yes, no (but these are not R issues).

There are bigger differences in the OS's equivalent of libm on Windows. 
  You did not tell us what CPUs your compilers targeted on Linux and OS 
X (sic), but generally they assume more than the i386 assumed on 32-bit 
Windows by Microsoft.  OTOH, all x86_64 OSes, including Windows, can 
assume more as all such CPUs have post-i686 features.  Remember Windows 
XP is still supported, and that was released in 2001.

Based on much wider experience than you give (e.g. reference results 
from R itself and recommended packages), deviations from x86_64 results 
are increasingly likely on OS X, i686 Linux and then i386 Windows.


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Wed Oct 16 13:31:36 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 16 Oct 2013 13:31:36 +0200
Subject: [Rd] Replacing the Random Number Generator in Stand Alone
	Library
In-Reply-To: <BAY403-EAS2567CE44A38161E0900B5FEE5040@phx.gbl>
References: <BAY406-EAS212BD9C215DD7A2A1C548F9E51E0@phx.gbl>
	<BAY406-EAS163E93209B12379E553BEA1E51E0@phx.gbl>
	<BAY403-EAS2567CE44A38161E0900B5FEE5040@phx.gbl>
Message-ID: <0D0E371B-EEF1-476B-8EED-1A108FF61A88@gmail.com>


On Oct 16, 2013, at 02:41 , Nigel Delaney wrote:

> Okay, so I am guessing everyone had the same response I initially did when
> hearing that this RNG might not be so hot*...  as an alternate question, if
> I submitted a patch to replace the current RNG with the twister, would it be
> accepted?


Quite possibly. 

I think the reason you get no reply could be that nobody really knows to what extent the standalone library is being used, and what repercussions an internal change might have. (E.g., if a change in the seed format causes applications to crash and burn, users might not appreciate the improved RNG...)

The RNG issues really are serious, and affect actual applications. This was hashed out about 10 years ago and eventually fixed somewhere around R 1.6--1.7. 

> RNGversion("1.6.0")
Warning message:
In RNGkind("Marsaglia-Multicarry", "Buggy Kinderman-Ramage") :
  buggy version of Kinderman-Ramage generator used
> s <- replicate(1e6, max(rnorm(100)))
> plot(density(s))
> m <- matrix(runif(8e7),2)
> plot(m[1,],m[2,], xlim=c(0,1e-3), pch=".")

(The bug in the K-R generator isn't relevant here, but the pattern of RNG usage in K-R is what creates the ripple effect in the first plot. Changing _either_ of the two generators removes the effect.)

-pd


> 
> -N
> 
> -----Original Message-----
> From: Nigel Delaney [mailto:nigel.delaney at outlook.com] 
> Sent: Thursday, October 10, 2013 5:04 PM
> To: r-devel at r-project.org
> Subject: Replacing the Random Number Generator in Stand Alone Library
> 
> Hi R-Developers,
> 
> I had a question about the random number generator used in the R StandAlone
> Math Library.  The stand-alone library depends on the unif_rand() function
> for most simulated values, and this function is provided in the sunif.c file
> in the relevant directory.  At present, this program implements the
> "Marsaglia-Multicarry" algorithm, which is described throughout the R
> documentation as:
> 
> "A multiply-with-carry RNG is used, as recommended by George Marsaglia in
> his post to the mailing list 'sci.stat.math'. It has a period of more than
> 2^60 and has passed all tests (according to Marsaglia). The seed is two
> integers (all values allowed)."
> 
> However, I do not think this RNG actually passes all tests.   For example,
> the Handbook of Computational Econometrics (illegal web copy at link below),
> shows that it fails the mtuple test and gives an explicit example where it
> leads to problems because it failed this test.  The mtuple test was
> introduced by Marsaglia in 1985, and I gather he wrote his mailing list
> comment that it "passes all tests" sometime after this, so I am not sure
> what explains this distinction (though I am not sure if the mtuple test is
> included in the diehard tests, which he may have been what he was referring
> to).  However, there are clearly some areas where this PRNG runs in to
> trouble (although the books example is better, another problem is that it
> can't seem to simulate a value above (1/2)^1+(1/4)^4) after simulating a
> value below 1e-6.
> 
> Given that the Mersenne Twister seems to be the standard for simulation
> these days (and used as the default in R), it seems like it might be useful
> to change the stand alone library so it also uses this routine.  I gather
> this would be pretty easy to do by pulling this function from the RNG.c file
> and moving it into the sunif.c file, and have a prototype of this.
> 
> However, I thought I would ask, is there a reason this hasn't been done?  Or
> is it just a historical carry-over (pun intended I suppose).
> 
> Warm wishes,
> Nigel
> 
> ********************
> Research Fellow
> Massachusetts General Hospital / Broad Institute
> 
> 
> Book link:
> http://thenigerianprofessionalaccountant.files.wordpress.com/2013/04/handboo
> k-of-computational-econometrics-belsley.pdf
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From winstonchang1 at gmail.com  Wed Oct 16 21:47:30 2013
From: winstonchang1 at gmail.com (Winston Chang)
Date: Wed, 16 Oct 2013 14:47:30 -0500
Subject: [Rd] Internally accessing ref class methods with .self$x is
	different from .self[['x']]
Message-ID: <CAFOpNVHwYJRXtwk0Y3v9RvFY9=B+na81MnCBHzMc2Y7SKBPekg@mail.gmail.com>

When a reference class method is accessed with .self$x, it has
different behavior from .self[['x']]. The former copies the function
to the object's environment (with some attributes attached), and the
latter just return NULL (unless it has already been accessed once with
.self$x). Is this how it's supposed to work?

Here's an example that illustrates: https://gist.github.com/wch/7013262

TestClass <- setRefClass(
  'TestClass',
  fields = list(a = 'ANY'),
  methods = list(
    initialize = function() {
      e <- environment()
      pe <- parent.env(e)
      ppe <- parent.env(pe)

      # The environment of this object
      print(ls(pe))
      # The environment of the class
      print(ls(ppe))

      # No surprises with fields
      cat("==================== .self[['a']] ====================\n")
      print(.self[['a']])


      # Getting b these ways isn't quite what we want
      cat("==================== .self[['b']] ====================\n")
      print(.self[['b']])
      cat("==================== b ====================\n")
      print(b)


      # Accessing b with $ works, and it changes things from here on in
      cat("==================== .self$b ====================\n")
      print(.self$b)


      # Now these return the b method with some attributes attached
      cat("==================== .self[['b']] ====================\n")
      print(.self[['b']])
      cat("==================== b ====================\n")
      print(b)


      cat("===============================================\n")
      print(ls(parent.env(e)))
      print(ls(parent.env(parent.env(e))))

    },

    b = function() {
      "Yes, this is b."
    }
  )
)

tc <- TestClass$new()


Output:
============================================================

[1] "a"          "initialize"
[1] "b"         "e"         "tc"        "TestClass"
==================== .self[['a']] ====================
An object of class "uninitializedField"
Slot "field":
[1] "a"

Slot "className":
[1] "ANY"

==================== .self[['b']] ====================
NULL
==================== b ====================
function() {
      "Yes, this is b."
    }
==================== .self$b ====================
function() {
      "Yes, this is b."
    }
<environment: 0x5a65418>
attr(,"mayCall")
character(0)
attr(,"name")
[1] "b"
attr(,"refClassName")
[1] "TestClass"
attr(,"superClassMethod")
[1] ""
attr(,"class")
[1] "refMethodDef"
attr(,"class")attr(,"package")
[1] "methods"
==================== .self[['b']] ====================
function() {
      "Yes, this is b."
    }
<environment: 0x5a65418>
attr(,"mayCall")
character(0)
attr(,"name")
[1] "b"
attr(,"refClassName")
[1] "TestClass"
attr(,"superClassMethod")
[1] ""
attr(,"class")
[1] "refMethodDef"
attr(,"class")attr(,"package")
[1] "methods"
==================== b ====================
function() {
      "Yes, this is b."
    }
<environment: 0x5a65418>
attr(,"mayCall")
character(0)
attr(,"name")
[1] "b"
attr(,"refClassName")
[1] "TestClass"
attr(,"superClassMethod")
[1] ""
attr(,"class")
[1] "refMethodDef"
attr(,"class")attr(,"package")
[1] "methods"
===============================================
[1] "a"          "b"          "initialize"
[1] "b"         "e"         "tc"        "TestClass"



-Winston


From gmbecker at ucdavis.edu  Wed Oct 16 22:41:02 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 16 Oct 2013 13:41:02 -0700
Subject: [Rd] Internally accessing ref class methods with .self$x is
 different from .self[['x']]
In-Reply-To: <CAFOpNVEv+1kQnS5g_zK0m--9v6K_M+CpAmq1RyPm3S967eFeRA@mail.gmail.com>
References: <CAFOpNVHwYJRXtwk0Y3v9RvFY9=B+na81MnCBHzMc2Y7SKBPekg@mail.gmail.com>
	<CADwqtCN1kEWcwZ_3ZUXvwPvjryWWkHgct9JjFuK3tjPJ0wKPkQ@mail.gmail.com>
	<CAFOpNVEv+1kQnS5g_zK0m--9v6K_M+CpAmq1RyPm3S967eFeRA@mail.gmail.com>
Message-ID: <CADwqtCOcyt5ePHH0fSdypPCqq34ndSMiiXNdeaDWw1WgWs=xDg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131016/c2457e17/attachment.pl>

From winstonchang1 at gmail.com  Wed Oct 16 23:12:18 2013
From: winstonchang1 at gmail.com (Winston Chang)
Date: Wed, 16 Oct 2013 16:12:18 -0500
Subject: [Rd] Internally accessing ref class methods with .self$x is
 different from .self[['x']]
In-Reply-To: <CADwqtCOcyt5ePHH0fSdypPCqq34ndSMiiXNdeaDWw1WgWs=xDg@mail.gmail.com>
References: <CAFOpNVHwYJRXtwk0Y3v9RvFY9=B+na81MnCBHzMc2Y7SKBPekg@mail.gmail.com>
	<CADwqtCN1kEWcwZ_3ZUXvwPvjryWWkHgct9JjFuK3tjPJ0wKPkQ@mail.gmail.com>
	<CAFOpNVEv+1kQnS5g_zK0m--9v6K_M+CpAmq1RyPm3S967eFeRA@mail.gmail.com>
	<CADwqtCOcyt5ePHH0fSdypPCqq34ndSMiiXNdeaDWw1WgWs=xDg@mail.gmail.com>
Message-ID: <CAFOpNVG4e0L_eubbk+cZsaZcHgwqcmqZoeQ+Q=qkLCY1fLZUcQ@mail.gmail.com>

On Wed, Oct 16, 2013 at 3:41 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> Winston,
>
>  (back on list since I found some official info)
>
> Looks like the behavior you are seeing is "documented-ish"
>
> Only methods actually used will be included in the environment corresponding
> to an individual object. To declare that a method requires a particular
> other method, the first method should include a call to $usingMethods() with
> the name of the other method as an argument. Declaring the methods this way
> is essential if the other method is used indirectly (e.g., via sapply() or
> do.call()). If it is called directly, code analysis will find it. Declaring
> the method is harmless in any case, however, and may aid readability of the
> source code.
>
> Seems like .self$usingMethods() is supposed to allow you to do what you
> want, but I wasn't able to get it to work after a few minutes of fiddling
> and the actual usingMethods method doesn't seem to do anything on cursory
> inspection in a toy example but I don't pretend to know the arcane depths of
> the refclass machinery.
>

I wasn't able to get .self$usingMethods() to work either. I think that
for my case, it still won't do the job - the issue is that I'm calling
a method and passing the name of another method, which is accessed via
[[. Since .self$usingMethods() supposedly analyzes code when the class
is installed (and not at runtime), that wouldn't help in this case.

Previously I said that code like this would work, but I was wrong:
  var <- "someMethod"
  `$`(.self, var)
It doesn't work because $ doesn't evaluate var; it thinks you're
trying to get .self$var, not .self$someMethod.

The workaround we're using for now is:
  do.call(`$`, list(.self, var))

-Winston


From gmbecker at ucdavis.edu  Wed Oct 16 23:27:13 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 16 Oct 2013 14:27:13 -0700
Subject: [Rd] Internally accessing ref class methods with .self$x is
 different from .self[['x']]
In-Reply-To: <CAFOpNVG4e0L_eubbk+cZsaZcHgwqcmqZoeQ+Q=qkLCY1fLZUcQ@mail.gmail.com>
References: <CAFOpNVHwYJRXtwk0Y3v9RvFY9=B+na81MnCBHzMc2Y7SKBPekg@mail.gmail.com>
	<CADwqtCN1kEWcwZ_3ZUXvwPvjryWWkHgct9JjFuK3tjPJ0wKPkQ@mail.gmail.com>
	<CAFOpNVEv+1kQnS5g_zK0m--9v6K_M+CpAmq1RyPm3S967eFeRA@mail.gmail.com>
	<CADwqtCOcyt5ePHH0fSdypPCqq34ndSMiiXNdeaDWw1WgWs=xDg@mail.gmail.com>
	<CAFOpNVG4e0L_eubbk+cZsaZcHgwqcmqZoeQ+Q=qkLCY1fLZUcQ@mail.gmail.com>
Message-ID: <CADwqtCMDih1gQ51H+cvEYuVnPf5dqd_TfrQBYYT3bW+LrB0vEg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131016/34e21733/attachment.pl>

From avula.jayakrishna at gmail.com  Wed Oct 16 15:57:27 2013
From: avula.jayakrishna at gmail.com (JaiReddy)
Date: Wed, 16 Oct 2013 06:57:27 -0700 (PDT)
Subject: [Rd] Parallel R expression evaluations
Message-ID: <1381931846577-4678352.post@n4.nabble.com>

Hi all,

I am using R-3.0.1 under Linux platform to embed R into my C++ code.

I am facing an error while executing more than 1 R-expressions parallelly.

I am executing round(X) and abs(X) parallelly on a set of 50 input rows 
which resulted in segmentation fault after getting the following errors.

Error: unprotect_ptr: pointer not found
Error: argument to 'findVar' is not an environment

I am using the following code snippet for initializing R, parsing and
evaluation of R expression

// For initialization

        int res= Rf_initEmbeddedR(R_argc, (char**)R_argv);

// For parsing and evaluation

        SEXP cmd1= Rf_mkChar(rscript);
	SEXP cmdSexp, cmdexpr, sresult = R_NilValue;
	ParseStatus status;
	R_len_t i=0;

	PROTECT(cmdSexp = Rf_allocVector(STRSXP, 1));
	SET_STRING_ELT(cmdSexp, 0, cmd1);
	// parsing vector for R expressions
	cmdexpr = PROTECT(R_ParseVector(cmdSexp, -1, &status, R_NilValue));
	if (status != PARSE_OK) {
		UNPROTECT(2);
		// error handling
		return;
	}
	
	for(i = 0; i < Rf_length(cmdexpr); i++)
	{
		int error;
		sresult = R_tryEval(VECTOR_ELT(cmdexpr, i), R_GlobalEnv, &error);	// R
expression evaluation 
		if(error)		// checking for error
		{
			// error handling
			return;
		}
	}
	UNPROTECT(2);


I wonder if R supports parallel evaluations within a single session. I have
seen parallel evaluations of R using Rserve package. As I am trying to
overcome the overhead (using Rserve) in creating new connection for each
evaluation, here I am trying using embeded R.

I tried Rf_endEmbeddedR each time after one evaluation and initializing R
for the next set of evaluation. Even that did't work.

Please suggest me possible solution if any.

Thanks in advance.

Jai
 




--
View this message in context: http://r.789695.n4.nabble.com/Parallel-R-expression-evaluations-tp4678352.html
Sent from the R devel mailing list archive at Nabble.com.


From S.Ellison at LGCGroup.com  Thu Oct 17 17:16:48 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Thu, 17 Oct 2013 16:16:48 +0100
Subject: [Rd] Q-Q plot scaling in plot.lm(); bug or thinko?
In-Reply-To: <525CA072.10908@mcmaster.ca>
References: <525CA072.10908@mcmaster.ca>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487F20FE4@GOLD.corp.lgc-group.com>

 
> I've been looking fairly carefully at the Q-Q plots produced by
> plot.lm() and am having difficulty understanding why plot.lm()
> is doing what it's doing, specifically scaling the standardized
> residuals by the prior weights. Can anyone explain this to me ... ?
Because with ideal choice of prior weights the scaled residuals are expected to be IID Normal (under the normality assumption for a linear model) and without scaling they aren't IID, so a Q-Q plot would be meaningless without scaling.

S Ellison



*******************************************************************
This email and any attachments are confidential. Any use...{{dropped:8}}


From S.Ellison at LGCGroup.com  Fri Oct 18 16:12:41 2013
From: S.Ellison at LGCGroup.com (S Ellison)
Date: Fri, 18 Oct 2013 15:12:41 +0100
Subject: [Rd] Possible tweak to R intro - was RE: [R] Subseting a data.frame
	-
In-Reply-To: <CACk-te1Y2jifecRE3fam8SMUgDZNcjTKAsHDprQoCrnq+tarhQ@mail.gmail.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5487F213BA@GOLD.corp.lgc-group.com>
	<CACk-te1Y2jifecRE3fam8SMUgDZNcjTKAsHDprQoCrnq+tarhQ@mail.gmail.com>
Message-ID: <A4E5A0B016B8CB41A485FC629B633CED5487F2148A@GOLD.corp.lgc-group.com>

Transferred from R-help:
>> From: S Ellison
>> Subsetting using subset() is perhaps the most natural way of
>> subsetting data frames; perhaps a line or two and an example could
>> usefully be included in the 'Working with data frames' section of the R
>> Intro?
>
> From: Bert Gunter [mailto:gunter.berton at gene.com]
> The R Intro Manual was largely or entirely the work of Bill Venables
> some years ago. So it is not really a part of R's maintained document
> system and has thus not been kept up to date with changes like the
> convenience function, subset(), which is basically a wrapper for "[]"
> .
> 
> This is not to say that your suggestion is not worthwhile, only to
> explain why it probably won't be acted upon.
> 

It's trivial enough that I could offer a 3-line patch if someone has time and inclination to add it...

S Ellison




*******************************************************************
This email and any attachments are confidential. Any use, copying or
disclosure other than by the intended recipient is unauthorised. If 
you have received this message in error, please notify the sender 
immediately via +44(0)20 8943 7000 or notify postmaster at lgcgroup.com 
and delete this message and any copies from your computer and network. 
LGC Limited. Registered in England 2991879. 
Registered office: Queens Road, Teddington, Middlesex, TW11 0LY, UK

From simon.urbanek at r-project.org  Fri Oct 18 16:43:00 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 18 Oct 2013 10:43:00 -0400
Subject: [Rd] Parallel R expression evaluations
In-Reply-To: <1381931846577-4678352.post@n4.nabble.com>
References: <1381931846577-4678352.post@n4.nabble.com>
Message-ID: <77E2443B-BF01-42F8-B3AE-6AAF5CA9B391@r-project.org>

On Oct 16, 2013, at 9:57 AM, JaiReddy wrote:

> Hi all,
> 
> I am using R-3.0.1 under Linux platform to embed R into my C++ code.
> 
> I am facing an error while executing more than 1 R-expressions parallelly.
> 

R is not thread-safe so you cannot execute any API calls in parallel. Also you can use the embedded init only once. If you break any of these rules, the behavior is undefined (and everything comes down crashing).

Cheers,
Simon



> I am executing round(X) and abs(X) parallelly on a set of 50 input rows 
> which resulted in segmentation fault after getting the following errors.
> 
> Error: unprotect_ptr: pointer not found
> Error: argument to 'findVar' is not an environment
> 
> I am using the following code snippet for initializing R, parsing and
> evaluation of R expression
> 
> // For initialization
> 
>        int res= Rf_initEmbeddedR(R_argc, (char**)R_argv);
> 
> // For parsing and evaluation
> 
>        SEXP cmd1= Rf_mkChar(rscript);
> 	SEXP cmdSexp, cmdexpr, sresult = R_NilValue;
> 	ParseStatus status;
> 	R_len_t i=0;
> 
> 	PROTECT(cmdSexp = Rf_allocVector(STRSXP, 1));
> 	SET_STRING_ELT(cmdSexp, 0, cmd1);
> 	// parsing vector for R expressions
> 	cmdexpr = PROTECT(R_ParseVector(cmdSexp, -1, &status, R_NilValue));
> 	if (status != PARSE_OK) {
> 		UNPROTECT(2);
> 		// error handling
> 		return;
> 	}
> 	
> 	for(i = 0; i < Rf_length(cmdexpr); i++)
> 	{
> 		int error;
> 		sresult = R_tryEval(VECTOR_ELT(cmdexpr, i), R_GlobalEnv, &error);	// R
> expression evaluation 
> 		if(error)		// checking for error
> 		{
> 			// error handling
> 			return;
> 		}
> 	}
> 	UNPROTECT(2);
> 
> 
> I wonder if R supports parallel evaluations within a single session. I have
> seen parallel evaluations of R using Rserve package. As I am trying to
> overcome the overhead (using Rserve) in creating new connection for each
> evaluation, here I am trying using embeded R.
> 
> I tried Rf_endEmbeddedR each time after one evaluation and initializing R
> for the next set of evaluation. Even that did't work.
> 
> Please suggest me possible solution if any.
> 
> Thanks in advance.
> 
> Jai
> 
> 
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Parallel-R-expression-evaluations-tp4678352.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From karl.forner at gmail.com  Fri Oct 18 17:51:06 2013
From: karl.forner at gmail.com (Karl Forner)
Date: Fri, 18 Oct 2013 17:51:06 +0200
Subject: [Rd] Possible problem with namespaceImportFrom() and methods for
 generic primitive functions
Message-ID: <CAMd4_AdXCZX3QnAfO5DiPi_6jOaEEkOy55OGpgrnWGC7UkL6pg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131018/b643565a/attachment.pl>

From jmc at r-project.org  Fri Oct 18 23:20:25 2013
From: jmc at r-project.org (John Chambers)
Date: Fri, 18 Oct 2013 14:20:25 -0700
Subject: [Rd] Possible problem with namespaceImportFrom() and methods
	for generic primitive functions
In-Reply-To: <CAMd4_AdXCZX3QnAfO5DiPi_6jOaEEkOy55OGpgrnWGC7UkL6pg@mail.gmail.com>
References: <CAMd4_AdXCZX3QnAfO5DiPi_6jOaEEkOy55OGpgrnWGC7UkL6pg@mail.gmail.com>
Message-ID: <2786183D-20A2-4096-A1AD-6874AAFDAD88@r-project.org>

Very good report.

Should be fixed in the development version for 3.1.0 and in 3.0.2 patched. (svn revision 64076).

John


On Oct 18, 2013, at 8:51 AM, Karl Forner <karl.forner at gmail.com> wrote:

> Hi all,
> 
> I have a problem with a package that imports two other packages which both
> export a method for the `[` primitive function.
> 
> I set up a reproducible example here:
> https://github.com/kforner/namespaceImportFrom_problem.git
> 
> Basically, the testPrimitiveImport package imports testPrimitiveExport1 and
> testPrimitiveExport2, which both export a S4 class and a `[` method for the
> class.
> Then:
> R CMD INSTALL -l lib testPrimitiveExport1
> R CMD INSTALL -l lib testPrimitiveExport2
> 
> The command:
> R CMD INSTALL -l lib testPrimitiveImport
> 
> gives me:
> Error in namespaceImportFrom(self, asNamespace(ns)) :
>  trying to get slot "package" from an object of a basic class ("function")
> with no slots
> 
> I get the same message if I check the package (with R CMD check), or even
> if I try to load it using devtools::load_all()
> 
> 
> I tried to investigate the problem, and I found that the error arises in
> the base::namespaceImportFrom() function, and more precisely in
> this block:
>    for (n in impnames) if (exists(n, envir = impenv, inherits = FALSE)) {
>        if (.isMethodsDispatchOn() && methods:::isGeneric(n,  ns)) {
>            genNs <- get(n, envir = ns)@package
> 
> Here n is '[', and the get(n, envir = ns) expression returns
> .Primitive("["), which is a function and has no @package slot.
> 
> This will only occur if exists(n, envir = impenv, inherits = FALSE) returns
> TRUE, i.e. if the '[' symbol is already in the imports env of the package.
> In my case, the first call to namespaceImportFrom() is for the first import
> of testPrimitiveExport1, which runs fine and populate the imports env with
> '['.
> But for the second call, exists(n, envir = impenv, inherits = FALSE) will
> be TRUE, so that the offending line will be called.
> 
> 
> I do not know if the problem is on my side, e.g. from a misconfiguration of
> the NAMESPACE file, or if it is a bug and in which case what should be done.
> 
> Any feedback appreciated.
> 
> Karl Forner
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jgrn at illinois.edu  Sat Oct 19 02:32:49 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Fri, 18 Oct 2013 19:32:49 -0500
Subject: [Rd] Suggestions for an "official" place to store
 permissions/options for a package?
Message-ID: <CABG0rfty=WteccOEFLG5D5fPq9=he8A3t4_a1WZd1E_2H3J0mw@mail.gmail.com>

R-developers:

Duncan Murdoch suggested I move a post I started on r-help over here,
since it is more at the developer level.  Here is my
question/challenge -- to my knowledge, there is not currently an
official way to store a *package*'s options to a standardized location
on a user's computer.  Given that OS-level programs have standard
preference locations, I was hoping to first assess:

- Does R, in fact, have a place for a *package* to store preferences
(a file-based "setOptions") that would be persistent across sessions.

One suggestion that was given was to perhaps write these options to
the .RProfile, but this strikes me as potentially dangerous -- a
poorly written function to write to a user's .RProfile could corrupt
it.

If the answer to the initial question is "no" (there is not an
official location/approach for a package to store its own files), I'd
like to suggest we open this for a wider discussion amongst the
developers, to perhaps come up with a general (not package-by-package)
solution for a package to store options (and perhaps other files) in a
standard location.

The particular application that has brought me to asking about this is
that I'm writing a package that has external calls to command-line
programs that may not be properly registered with a user's environment
(think: Windows, in particular, although I've found issues with a Mac
as well), so the first step of these R - wrapper functions is to
search a user's local machine for the binaries.  If it finds it, it
stores the path to this binary as an option.  Since this is a
brute-force search, this can take some time and, ideally, this
information would be preserved across sessions, without the function
having to re-search their drive every time they start R fresh.

--j


-- 
Jonathan A. Greenberg, PhD
Assistant Professor
Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
Department of Geography and Geographic Information Science
University of Illinois at Urbana-Champaign
259 Computing Applications Building, MC-150
605 East Springfield Avenue
Champaign, IL  61820-6371
Phone: 217-300-1924
http://www.geog.illinois.edu/~jgrn/
AIM: jgrn307, MSN: jgrn307 at hotmail.com, Gchat: jgrn307, Skype: jgrn3007


From reijo.sund at helsinki.fi  Sat Oct 19 07:57:48 2013
From: reijo.sund at helsinki.fi (Reijo Sund)
Date: Sat, 19 Oct 2013 01:57:48 -0400
Subject: [Rd] Suggestions for an "official" place to store
	permissions/options for a package?
In-Reply-To: <CABG0rfty=WteccOEFLG5D5fPq9=he8A3t4_a1WZd1E_2H3J0mw@mail.gmail.com>
References: <CABG0rfty=WteccOEFLG5D5fPq9=he8A3t4_a1WZd1E_2H3J0mw@mail.gmail.com>
Message-ID: <668BD9CF-3768-41F1-A273-6074D439FB9B@helsinki.fi>

> to my knowledge, there is not currently an official way to store a
> *package*'s options to a standardized location on a user's computer.

CRAN Repository policy gives some guidance:
"Packages should not write in the users? home filespace, nor anywhere else on the file system apart from the R session?s temporary directory (or during installation in the location pointed to by TMPDIR: and such usage should be cleaned up). Installing into the system?s R installation (e.g., scripts to its bin directory) is not allowed. Limited exceptions may be allowed in interactive sessions if the package obtains confirmation from the user."

Of the existing packages in CRAN, at least Rcmdr allows to use config files.

If there is a need for storing package's options for longer time, it may not be a good idea to write package's directories (or to system's R installation) as updates of the package (or R) would then erase the config file. It is also obvious that storing of options is sensible only for directories for which the user has write access. In this sense, a (subdirectory in) user's home directory is probably the best place to store package's config files unless the user has provided other information in function call or using environmental variables.

Below is an extract of code from my package muste that also uses config files. I'm not claiming that it would provide any general or even good solution, but at least it gives a concrete example that hopefully stimulates discussion on this topic..

Best wishes,
Reijo Sund


- - -


# Create environment for package's global variables 
.muste <- new.env(hash=TRUE, parent=emptyenv())

muste <- function(config="<empty>") 
    {

# Package directory
    .muste$mustepath <- system.file(package="muste")

# Check write access to package directory
    if(file.access(.muste$mustepath,mode=2)==-1) .muste$writeaccess <-FALSE
    else .muste$writeaccess <- TRUE
  
# Start path  
    .muste$startdir <- getwd()
  
# Path to actual R directory 
    .muste$Rhome <- normalizePath(R.home())
  
# Path to home directory (see R documentation for more information)
    .muste$homedir <- normalizePath("~/")

# Path to temp directory with guaranteed write access
    .muste$Rtempdir <- tempdir()
  
# System, OS and R info  
    .muste$sysname<-unlist(Sys.info()["sysname"])[[1]]
    .muste$OS.type <- .Platform$OS.type
    .muste$r_arch <- .Platform$r_arch
  
# Path to R binary  
    if (.muste$sysname=="Windows")
      {
      .muste$Rbin <-  paste(file.path(R.home("bin"),"Rgui --sdi"))  
      }
    else .muste$Rbin <- paste(file.path(R.home("bin"),"R"))  
  
# Location of config file
    if (config=="<empty>") 
        {
        .muste$apufile <- Sys.getenv("MUSTEAPU") # Read path from environmental variable
        if (nchar(.muste$apufile)==0) # If file is not given, use defaults
            {
            if (.muste$sysname=="Windows") .muste$apufile <- paste(.muste$homedir,'\\.muste\\muste.apu',sep="")
            else .muste$apufile <- paste(.muste$homedir,'/.muste/muste.apu',sep="")
            }
        }
    else .muste$apufile <- config  # Path to file given as a parameter

# Check if given setup file exists
    if(!file.exists(.muste$apufile)) .muste.setup()

}

.muste.setup <- function()
    {
# Ask about creation of dir(s)/file(s)    
    viesti <- paste("Configuration file was not found!\nIs it OK to create\n",.muste$apufile,"?",sep=" ")
    response <- "no"
    if (interactive())
        {
        require(tcltk)
        response <- tclvalue(tkmessageBox(message=viesti, icon="question", type="yesno", default="no", title=""))
        }
    if (response == "no") return()

# Directory part of the path to config file	
    .muste$apufiledir <- dirname(.muste$apufile) 
    
# Create directory for config file
    dir.create(.muste$apufiledir,showWarnings=FALSE)
	
# Check write access to given config file directory		
    if(file.access(.muste$apufiledir,mode=2)==-1) stop("No write access!")     
    
# Create and initialize config file
    file.create(.muste$apufile)
    cat("/ Configuration file",file=.muste$apufile,sep="\n",append=TRUE)
    }


From nalimilan at club.fr  Sat Oct 19 13:47:03 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Sat, 19 Oct 2013 13:47:03 +0200
Subject: [Rd] Suggestions for an "official" place to store
 permissions/options for a package?
In-Reply-To: <CABG0rfty=WteccOEFLG5D5fPq9=he8A3t4_a1WZd1E_2H3J0mw@mail.gmail.com>
References: <CABG0rfty=WteccOEFLG5D5fPq9=he8A3t4_a1WZd1E_2H3J0mw@mail.gmail.com>
Message-ID: <1382183223.13698.49.camel@milan>

Le vendredi 18 octobre 2013 ? 19:32 -0500, Jonathan Greenberg a ?crit :
> R-developers:
> 
> Duncan Murdoch suggested I move a post I started on r-help over here,
> since it is more at the developer level.  Here is my
> question/challenge -- to my knowledge, there is not currently an
> official way to store a *package*'s options to a standardized location
> on a user's computer.  Given that OS-level programs have standard
> preference locations, I was hoping to first assess:
> 
> - Does R, in fact, have a place for a *package* to store preferences
> (a file-based "setOptions") that would be persistent across sessions.
> 
> One suggestion that was given was to perhaps write these options to
> the .RProfile, but this strikes me as potentially dangerous -- a
> poorly written function to write to a user's .RProfile could corrupt
> it.
> 
> If the answer to the initial question is "no" (there is not an
> official location/approach for a package to store its own files), I'd
> like to suggest we open this for a wider discussion amongst the
> developers, to perhaps come up with a general (not package-by-package)
> solution for a package to store options (and perhaps other files) in a
> standard location.
> 
> The particular application that has brought me to asking about this is
> that I'm writing a package that has external calls to command-line
> programs that may not be properly registered with a user's environment
> (think: Windows, in particular, although I've found issues with a Mac
> as well), so the first step of these R - wrapper functions is to
> search a user's local machine for the binaries.  If it finds it, it
> stores the path to this binary as an option.  Since this is a
> brute-force search, this can take some time and, ideally, this
> information would be preserved across sessions, without the function
> having to re-search their drive every time they start R fresh.
I support this request. This would be useful for Rcmdr and Rcmdr
plug-ins to save GUI preferences in a cleaner fashion than writing
to .Rprofile. A major use case for R base itself would be to store the
default CRAN mirror once for all instead of asking the user every time
(s)he installs a package.

Any mechanism will do, from a simple .ini style key-value file to
serializing and restoring an arbitrary (but usually very simple) R
object. .Rprofile is really not designed to store preferences. A
per-package way of saving settings would mean that a package has no
chance of messing with the user's global settings when it is not loaded,
reducing the risk of breakage.


Regards


From murdoch.duncan at gmail.com  Sat Oct 19 14:06:51 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 19 Oct 2013 08:06:51 -0400
Subject: [Rd] Suggestions for an "official" place to store
 permissions/options for a package?
In-Reply-To: <CABG0rfty=WteccOEFLG5D5fPq9=he8A3t4_a1WZd1E_2H3J0mw@mail.gmail.com>
References: <CABG0rfty=WteccOEFLG5D5fPq9=he8A3t4_a1WZd1E_2H3J0mw@mail.gmail.com>
Message-ID: <526275DB.1030304@gmail.com>

On 13-10-18 8:32 PM, Jonathan Greenberg wrote:
> R-developers:
>
> Duncan Murdoch suggested I move a post I started on r-help over here,
> since it is more at the developer level.  Here is my
> question/challenge -- to my knowledge, there is not currently an
> official way to store a *package*'s options to a standardized location
> on a user's computer.  Given that OS-level programs have standard
> preference locations, I was hoping to first assess:
>
> - Does R, in fact, have a place for a *package* to store preferences
> (a file-based "setOptions") that would be persistent across sessions.
>
> One suggestion that was given was to perhaps write these options to
> the .RProfile, but this strikes me as potentially dangerous -- a
> poorly written function to write to a user's .RProfile could corrupt
> it.

I think you misread that suggestion.  I think it was a suggestion that 
the user should write that information into their own .RProfile.

What I'd suggest you do is have two functions, saveFooOptions and 
loadFooOptions in your package Foo. (The exact names aren't important, 
but don't use generic names like saveOptions and loadOptions; other 
packages may want to follow your model.)  Instruct the user to set the 
options in a session, then call saveFooOptions to save them.  Tell them 
how to put loadFooOptions into their .RProfile file if they want them 
loaded automatically at startup.

Currently the only files that R writes automatically are .RData and 
.RHistory. It only writes those after confirmation from the user, and 
they are not written to a standard location, so users can maintain 
multiple copies of them.  Packages should be no more intrusive.

On Windows, the R GUI maintains a collection of preferences, but they 
are never written automatically.  The loadRconsole() function can load 
them from an arbitrary file; they are saved from a dialog in the GUI. 
There's a default set in the R install directory, but often users don't 
have write permission there.  You could do the same, having a default 
set of options in your package installation, but you shouldn't assume 
the user has rights to change it.


> If the answer to the initial question is "no" (there is not an
> official location/approach for a package to store its own files), I'd
> like to suggest we open this for a wider discussion amongst the
> developers, to perhaps come up with a general (not package-by-package)
> solution for a package to store options (and perhaps other files) in a
> standard location.
>
> The particular application that has brought me to asking about this is
> that I'm writing a package that has external calls to command-line
> programs that may not be properly registered with a user's environment
> (think: Windows, in particular, although I've found issues with a Mac
> as well), so the first step of these R - wrapper functions is to
> search a user's local machine for the binaries.  If it finds it, it
> stores the path to this binary as an option.  Since this is a
> brute-force search, this can take some time and, ideally, this
> information would be preserved across sessions, without the function
> having to re-search their drive every time they start R fresh.

That sounds like a case where a user might choose to save the locations. 
  But you shouldn't do it without asking, and you should allow the user 
to decide where the file goes.

Duncan Murdoch


From avula.jayakrishna at gmail.com  Sat Oct 19 07:37:29 2013
From: avula.jayakrishna at gmail.com (JaiReddy)
Date: Fri, 18 Oct 2013 22:37:29 -0700 (PDT)
Subject: [Rd] Parallel R expression evaluations
In-Reply-To: <77E2443B-BF01-42F8-B3AE-6AAF5CA9B391@r-project.org>
References: <1381931846577-4678352.post@n4.nabble.com>
	<77E2443B-BF01-42F8-B3AE-6AAF5CA9B391@r-project.org>
Message-ID: <1382161049530-4678587.post@n4.nabble.com>

Thanks Simon.

May I know how R works if two expressions come at the same time for
evaluation. When I debug my case I found that issue was found with indexed
values of protected items. 

As R is single threaded engine, I just want to know how does R behave when
2nd expression comes for parsing and evaluation even before 1st expression
evaluation does complete?


Thanks
Jai



--
View this message in context: http://r.789695.n4.nabble.com/Parallel-R-expression-evaluations-tp4678352p4678587.html
Sent from the R devel mailing list archive at Nabble.com.


From bhh at xs4all.nl  Sun Oct 20 08:00:08 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Sun, 20 Oct 2013 08:00:08 +0200
Subject: [Rd] Subversion log no longer being updated daily
Message-ID: <BA44C7DC-8A15-49B5-A318-A858C4E97979@xs4all.nl>


The subversion log for 2013 (http://developer.r-project.org/R_svnlog_2013) on the R developer page hasn't been updated since September  29. I would appreciate the daily updates returning.

Berend Hasselman


From jgrn at illinois.edu  Sun Oct 20 22:43:16 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Sun, 20 Oct 2013 15:43:16 -0500
Subject: [Rd] Question about selective importing of package functions...
Message-ID: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131020/658ff717/attachment.pl>

From murdoch.duncan at gmail.com  Sun Oct 20 22:49:44 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 20 Oct 2013 16:49:44 -0400
Subject: [Rd] Question about selective importing of package functions...
In-Reply-To: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>
References: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>
Message-ID: <526441E8.4000408@gmail.com>

On 13-10-20 4:43 PM, Jonathan Greenberg wrote:
> I'm working on an update for my CRAN package "spatial.tools" and I noticed
> a new warning when running R CMD CHECK --as-cran:
>
> * checking CRAN incoming feasibility ... NOTE
> Maintainer: 'Jonathan Asher Greenberg <spatial-tools at estarcion.net>'
> Depends: includes the non-default packages:
>    'sp' 'raster' 'rgdal' 'mmap' 'abind' 'parallel' 'foreach'
>    'doParallel' 'rgeos'
> Adding so many packages to the search path is excessive
> and importing selectively is preferable.
>
> Is this a warning that would need to be fixed pre-CRAN (not really sure
> how, since I need functions from all of those packages)?  Is there a way to
> import only a single function from a package, if that function is a
> dependency?

You really want to use imports.  Those are defined in the NAMESPACE 
file; you can import everything from a package if you want, but the best 
style is in fact to just import exactly what you need.  This is more 
robust than using Depends, and it doesn't add so much to the user's 
search path, so it's less likely to break something else (e.g. by 
putting a package on the path that masks some function the user already 
had there.)

Duncan Murdoch


From jgrn at illinois.edu  Sun Oct 20 22:54:13 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Sun, 20 Oct 2013 15:54:13 -0500
Subject: [Rd] Question about selective importing of package functions...
In-Reply-To: <526441E8.4000408@gmail.com>
References: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>
	<526441E8.4000408@gmail.com>
Message-ID: <CABG0rfsL-HnzfmKWMd9uBGtXv2UaMeE3zPbohLXQyovap-kqMw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131020/143bffb3/attachment.pl>

From ggrothendieck at gmail.com  Sun Oct 20 22:58:52 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sun, 20 Oct 2013 16:58:52 -0400
Subject: [Rd] Question about selective importing of package functions...
In-Reply-To: <526441E8.4000408@gmail.com>
References: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>
	<526441E8.4000408@gmail.com>
Message-ID: <CAP01uR=J+vSrS-XAciXq_X4n985zJsysnimT+z5rJ4KvSMjViA@mail.gmail.com>

On Sun, Oct 20, 2013 at 4:49 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-10-20 4:43 PM, Jonathan Greenberg wrote:
>>
>> I'm working on an update for my CRAN package "spatial.tools" and I noticed
>> a new warning when running R CMD CHECK --as-cran:
>>
>> * checking CRAN incoming feasibility ... NOTE
>> Maintainer: 'Jonathan Asher Greenberg <spatial-tools at estarcion.net>'
>> Depends: includes the non-default packages:
>>    'sp' 'raster' 'rgdal' 'mmap' 'abind' 'parallel' 'foreach'
>>    'doParallel' 'rgeos'
>> Adding so many packages to the search path is excessive
>> and importing selectively is preferable.
>>
>> Is this a warning that would need to be fixed pre-CRAN (not really sure
>> how, since I need functions from all of those packages)?  Is there a way
>> to
>> import only a single function from a package, if that function is a
>> dependency?
>
>
> You really want to use imports.  Those are defined in the NAMESPACE file;
> you can import everything from a package if you want, but the best style is
> in fact to just import exactly what you need.  This is more robust than
> using Depends, and it doesn't add so much to the user's search path, so it's
> less likely to break something else (e.g. by putting a package on the path
> that masks some function the user already had there.)

That may answer the specific case of the poster but how does one
handle the case
where one wants the user to be able to access the functions in the
dependent package.

For example, sqldf depends on gsubfn which provides fn which is used
with sqldf to
perform substitutions in the SQL string.

library(sqldf)
tt <- 3
fn$sqldf("select * from BOD where Time > $tt")

I don't want to ask the user to tediously issue a library(gsubfn) too since
fn is frequently needed and for literally years this has not been necessary.
Also I don't want to duplicate fn's code in sqldf since that makes the whole
thing less modular -- it would imply having to change fn in two places
if anything
in fn changed.

-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From jgrn at illinois.edu  Sun Oct 20 23:20:33 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Sun, 20 Oct 2013 16:20:33 -0500
Subject: [Rd] Question about selective importing of package functions...
In-Reply-To: <CAP01uR=J+vSrS-XAciXq_X4n985zJsysnimT+z5rJ4KvSMjViA@mail.gmail.com>
References: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>
	<526441E8.4000408@gmail.com>
	<CAP01uR=J+vSrS-XAciXq_X4n985zJsysnimT+z5rJ4KvSMjViA@mail.gmail.com>
Message-ID: <CABG0rfvboosWxEVOJetx9gXtGvVdVjhGMz6g4=dGuZPVcJtwZg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131020/21484722/attachment.pl>

From edd at debian.org  Mon Oct 21 00:34:39 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 20 Oct 2013 17:34:39 -0500
Subject: [Rd] Question about selective importing of package functions...
In-Reply-To: <CABG0rfvboosWxEVOJetx9gXtGvVdVjhGMz6g4=dGuZPVcJtwZg@mail.gmail.com>
References: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>
	<526441E8.4000408@gmail.com>
	<CAP01uR=J+vSrS-XAciXq_X4n985zJsysnimT+z5rJ4KvSMjViA@mail.gmail.com>
	<CABG0rfvboosWxEVOJetx9gXtGvVdVjhGMz6g4=dGuZPVcJtwZg@mail.gmail.com>
Message-ID: <21092.23167.178513.715084@max.nulle.part>


On 20 October 2013 at 16:20, Jonathan Greenberg wrote:
| One more follow-up -- will I now need to include a library() statement in
| each function?

No.

NAMESPACE entry, coupled with Imports: in DESCRIPTION.

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From jgrn at illinois.edu  Mon Oct 21 00:41:39 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Sun, 20 Oct 2013 17:41:39 -0500
Subject: [Rd] Question about selective importing of package functions...
In-Reply-To: <21092.23167.178513.715084@max.nulle.part>
References: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>
	<526441E8.4000408@gmail.com>
	<CAP01uR=J+vSrS-XAciXq_X4n985zJsysnimT+z5rJ4KvSMjViA@mail.gmail.com>
	<CABG0rfvboosWxEVOJetx9gXtGvVdVjhGMz6g4=dGuZPVcJtwZg@mail.gmail.com>
	<21092.23167.178513.715084@max.nulle.part>
Message-ID: <CABG0rfvYDUJc_-4RyiB=JUafEJD4F1mTYHy18OoPz+5AVY=Mrg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131020/2abfbf10/attachment.pl>

From murdoch.duncan at gmail.com  Mon Oct 21 00:43:13 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 20 Oct 2013 18:43:13 -0400
Subject: [Rd] Question about selective importing of package functions...
In-Reply-To: <CABG0rfsL-HnzfmKWMd9uBGtXv2UaMeE3zPbohLXQyovap-kqMw@mail.gmail.com>
References: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>	<526441E8.4000408@gmail.com>
	<CABG0rfsL-HnzfmKWMd9uBGtXv2UaMeE3zPbohLXQyovap-kqMw@mail.gmail.com>
Message-ID: <52645C81.1020309@gmail.com>

On 13-10-20 4:54 PM, Jonathan Greenberg wrote:
> Duncan:
>
> Thanks -- learning something new today -- quick follow-up, will using
> the import statements in the NAMESPACE, when a user goes to
> install.packages(), auto-install the "dependent" packages the same way
> Depends forces?
>

You need to list the other packages in Imports instead of Depends; then 
the answer is yes.

Duncan Murdoch

> --j
>
>
> On Sun, Oct 20, 2013 at 3:49 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>
>     On 13-10-20 4:43 PM, Jonathan Greenberg wrote:
>
>         I'm working on an update for my CRAN package "spatial.tools" and
>         I noticed
>         a new warning when running R CMD CHECK --as-cran:
>
>         * checking CRAN incoming feasibility ... NOTE
>         Maintainer: 'Jonathan Asher Greenberg
>         <spatial-tools at estarcion.net <mailto:spatial-tools at estarcion.net>>'
>         Depends: includes the non-default packages:
>             'sp' 'raster' 'rgdal' 'mmap' 'abind' 'parallel' 'foreach'
>             'doParallel' 'rgeos'
>         Adding so many packages to the search path is excessive
>         and importing selectively is preferable.
>
>         Is this a warning that would need to be fixed pre-CRAN (not
>         really sure
>         how, since I need functions from all of those packages)?  Is
>         there a way to
>         import only a single function from a package, if that function is a
>         dependency?
>
>
>     You really want to use imports.  Those are defined in the NAMESPACE
>     file; you can import everything from a package if you want, but the
>     best style is in fact to just import exactly what you need.  This is
>     more robust than using Depends, and it doesn't add so much to the
>     user's search path, so it's less likely to break something else
>     (e.g. by putting a package on the path that masks some function the
>     user already had there.)
>
>     Duncan Murdoch
>
>
>
>
> --
> Jonathan A. Greenberg, PhD
> Assistant Professor
> Global Environmental Analysis and Remote Sensing (GEARS) Laboratory
> Department of Geography and Geographic Information Science
> University of Illinois at Urbana-Champaign
> 259 Computing Applications Building, MC-150
> 605 East Springfield Avenue
> Champaign, IL  61820-6371
> Phone: 217-300-1924
> http://www.geog.illinois.edu/~jgrn/ <http://www.geog.illinois.edu/%7Ejgrn/>
> AIM: jgrn307, MSN: jgrn307 at hotmail.com <mailto:jgrn307 at hotmail.com>,
> Gchat: jgrn307, Skype: jgrn3007


From gmbecker at ucdavis.edu  Mon Oct 21 00:44:16 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Sun, 20 Oct 2013 15:44:16 -0700
Subject: [Rd] Question about selective importing of package functions...
In-Reply-To: <CABG0rfvYDUJc_-4RyiB=JUafEJD4F1mTYHy18OoPz+5AVY=Mrg@mail.gmail.com>
References: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>
	<526441E8.4000408@gmail.com>
	<CAP01uR=J+vSrS-XAciXq_X4n985zJsysnimT+z5rJ4KvSMjViA@mail.gmail.com>
	<CABG0rfvboosWxEVOJetx9gXtGvVdVjhGMz6g4=dGuZPVcJtwZg@mail.gmail.com>
	<21092.23167.178513.715084@max.nulle.part>
	<CABG0rfvYDUJc_-4RyiB=JUafEJD4F1mTYHy18OoPz+5AVY=Mrg@mail.gmail.com>
Message-ID: <CADwqtCOpw7M9GcjpCOFMcVObjwmQe65PSJ3H2JNj4fAiGVhTiw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131020/deebf0fa/attachment.pl>

From murdoch.duncan at gmail.com  Mon Oct 21 00:47:44 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 20 Oct 2013 18:47:44 -0400
Subject: [Rd] Question about selective importing of package functions...
In-Reply-To: <CABG0rfvYDUJc_-4RyiB=JUafEJD4F1mTYHy18OoPz+5AVY=Mrg@mail.gmail.com>
References: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>	<526441E8.4000408@gmail.com>	<CAP01uR=J+vSrS-XAciXq_X4n985zJsysnimT+z5rJ4KvSMjViA@mail.gmail.com>	<CABG0rfvboosWxEVOJetx9gXtGvVdVjhGMz6g4=dGuZPVcJtwZg@mail.gmail.com>	<21092.23167.178513.715084@max.nulle.part>
	<CABG0rfvYDUJc_-4RyiB=JUafEJD4F1mTYHy18OoPz+5AVY=Mrg@mail.gmail.com>
Message-ID: <52645D90.7020201@gmail.com>

On 13-10-20 6:41 PM, Jonathan Greenberg wrote:
> To be clear, if I used Depends: somepackage before, and switched over to
> using Imports: somepackage, I'll need to mod my code that used to have a
> call to, say, somefunction to now have somepackage::somefunction, correct?

No.  You need to modify both the DESCRIPTION file as you say above, and 
the NAMESPACE file to say what to import.  Once you do that, those 
functions will appear to your own package functions without any prefix 
needed.

Duncan Murdoch

>
> --j
>
>
> On Sun, Oct 20, 2013 at 5:34 PM, Dirk Eddelbuettel <edd at debian.org> wrote:
>
>>
>> On 20 October 2013 at 16:20, Jonathan Greenberg wrote:
>> | One more follow-up -- will I now need to include a library() statement in
>> | each function?
>>
>> No.
>>
>> NAMESPACE entry, coupled with Imports: in DESCRIPTION.
>>
>> Dirk
>>
>> --
>> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>>
>
>
>


From pgilbert902 at gmail.com  Mon Oct 21 00:48:10 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Sun, 20 Oct 2013 18:48:10 -0400
Subject: [Rd] Question about selective importing of package functions...
In-Reply-To: <CAP01uR=J+vSrS-XAciXq_X4n985zJsysnimT+z5rJ4KvSMjViA@mail.gmail.com>
References: <CABG0rfuqopYT3mDwZ9JXsketm5bw_wcAgzHGy4MrZ1F2HmUfUA@mail.gmail.com>	<526441E8.4000408@gmail.com>
	<CAP01uR=J+vSrS-XAciXq_X4n985zJsysnimT+z5rJ4KvSMjViA@mail.gmail.com>
Message-ID: <52645DAA.8020602@gmail.com>



On 13-10-20 04:58 PM, Gabor Grothendieck wrote:
> On Sun, Oct 20, 2013 at 4:49 PM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>> On 13-10-20 4:43 PM, Jonathan Greenberg wrote:
>>>
>>> I'm working on an update for my CRAN package "spatial.tools" and I noticed
>>> a new warning when running R CMD CHECK --as-cran:
>>>
>>> * checking CRAN incoming feasibility ... NOTE
>>> Maintainer: 'Jonathan Asher Greenberg <spatial-tools at estarcion.net>'
>>> Depends: includes the non-default packages:
>>>     'sp' 'raster' 'rgdal' 'mmap' 'abind' 'parallel' 'foreach'
>>>     'doParallel' 'rgeos'
>>> Adding so many packages to the search path is excessive
>>> and importing selectively is preferable.
>>>
>>> Is this a warning that would need to be fixed pre-CRAN (not really sure
>>> how, since I need functions from all of those packages)?  Is there a way
>>> to
>>> import only a single function from a package, if that function is a
>>> dependency?
>>
>>
>> You really want to use imports.  Those are defined in the NAMESPACE file;
>> you can import everything from a package if you want, but the best style is
>> in fact to just import exactly what you need.  This is more robust than
>> using Depends, and it doesn't add so much to the user's search path, so it's
>> less likely to break something else (e.g. by putting a package on the path
>> that masks some function the user already had there.)
>
> That may answer the specific case of the poster but how does one
> handle the case
> where one wants the user to be able to access the functions in the
> dependent package.

There are two answers to this, depending on how much of the dependent 
package you want to make available to the user. If you want most of that 
package to be available then this is the (only?) exception to the rule. 
 From Writing R Extensions:

   Field ?Depends? should nowadays be used rarely, only for packages
   which are intended to be put on the search path to make their
   facilities available to the end user (and not to the package itself):
   for example it makes sense that a user of package latticeExtra would
    want the functions of package lattice made available.

If you really only want to make a couple of functions available then you 
can import and export the functions. Currently this has the unfortunate 
side effect that you need to document the functions, you cannot just 
re-direct to the documentation in the imported package, at least, I have 
not figured out how to do that.

Paul

>
> For example, sqldf depends on gsubfn which provides fn which is used
> with sqldf to
> perform substitutions in the SQL string.
>
> library(sqldf)
> tt <- 3
> fn$sqldf("select * from BOD where Time > $tt")
>
> I don't want to ask the user to tediously issue a library(gsubfn) too since
> fn is frequently needed and for literally years this has not been necessary.
> Also I don't want to duplicate fn's code in sqldf since that makes the whole
> thing less modular -- it would imply having to change fn in two places
> if anything
> in fn changed.
>


From simon.urbanek at r-project.org  Mon Oct 21 02:24:22 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 20 Oct 2013 20:24:22 -0400
Subject: [Rd] Parallel R expression evaluations
In-Reply-To: <1382161049530-4678587.post@n4.nabble.com>
References: <1381931846577-4678352.post@n4.nabble.com>
	<77E2443B-BF01-42F8-B3AE-6AAF5CA9B391@r-project.org>
	<1382161049530-4678587.post@n4.nabble.com>
Message-ID: <70F220AA-E852-43F5-B3CA-302B72AF2C89@r-project.org>

Jai,

On Oct 19, 2013, at 1:37 AM, JaiReddy wrote:

> Thanks Simon.
> 
> May I know how R works if two expressions come at the same time for
> evaluation. When I debug my case I found that issue was found with indexed
> values of protected items. 
> 
> As R is single threaded engine, I just want to know how does R behave when
> 2nd expression comes for parsing and evaluation even before 1st expression
> evaluation does complete?
> 

As I said, no API calls may be performed in parallel, that includes parsing and evaluation. Typically, R is run in a sequential loop: read, parse, eval, print so anything that is not processed is blocked until the loop is back to reading. However, given that R can be called from arbitrary front-ends, it's really up to the front-end to decide what to do - as long as it serializes the calls appropriately.

Cheers,
Simon


> 
> Thanks
> Jai
> 
> 
> 
> --
> View this message in context: http://r.789695.n4.nabble.com/Parallel-R-expression-evaluations-tp4678352p4678587.html
> Sent from the R devel mailing list archive at Nabble.com.
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From simon.urbanek at r-project.org  Mon Oct 21 03:38:23 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sun, 20 Oct 2013 21:38:23 -0400
Subject: [Rd] Subversion log no longer being updated daily
In-Reply-To: <BA44C7DC-8A15-49B5-A318-A858C4E97979@xs4all.nl>
References: <BA44C7DC-8A15-49B5-A318-A858C4E97979@xs4all.nl>
Message-ID: <ABD636A2-94CA-45E5-86A3-F9678452A606@r-project.org>

On Oct 20, 2013, at 2:00 AM, Berend Hasselman wrote:

> 
> The subversion log for 2013 (http://developer.r-project.org/R_svnlog_2013) on the R developer page hasn't been updated since September  29. I would appreciate the daily updates returning.
> 

Sorry, my bad, with all the server switching I forgot to put some pieces that Duncan was running on the new server. It should be all working now.

Thanks,
Simon


From bhh at xs4all.nl  Mon Oct 21 07:54:09 2013
From: bhh at xs4all.nl (Berend Hasselman)
Date: Mon, 21 Oct 2013 07:54:09 +0200
Subject: [Rd] Subversion log no longer being updated daily
In-Reply-To: <ABD636A2-94CA-45E5-86A3-F9678452A606@r-project.org>
References: <BA44C7DC-8A15-49B5-A318-A858C4E97979@xs4all.nl>
	<ABD636A2-94CA-45E5-86A3-F9678452A606@r-project.org>
Message-ID: <90175A77-4ABB-4D05-A5C8-7D2E5199870A@xs4all.nl>


On 21-10-2013, at 03:38, Simon Urbanek <simon.urbanek at r-project.org> wrote:

> On Oct 20, 2013, at 2:00 AM, Berend Hasselman wrote:
> 
>> 
>> The subversion log for 2013 (http://developer.r-project.org/R_svnlog_2013) on the R developer page hasn't been updated since September  29. I would appreciate the daily updates returning.
>> 
> 
> Sorry, my bad, with all the server switching I forgot to put some pieces that Duncan was running on the new server. It should be all working now.

Thanks. All working again.

Berend


From mtmorgan at fhcrc.org  Mon Oct 21 08:22:22 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Sun, 20 Oct 2013 23:22:22 -0700
Subject: [Rd] Building Windows package .zip files
Message-ID: <5264C81E.2030306@fhcrc.org>

Section 1.3.3 of Writing R Extensions says

"The recommended method of building binary packages is to use

R CMD INSTALL --build pkg where pkg is either the name of a source tarball (in 
the usual .tar.gz format) or the location of the directory of the package source 
to be built. "

(a) vignettes are not created when R CMD INSTALL --build is run on a source 
directory, so it seems that there is only one way to build full .zip files 
(running R CMD INSTALL --build on the tar.gz file created by R CMD build). (b) 
probably the intention was to have R CMD INSTALL --build pkg on a line by itself

Index: R-exts.texi
===================================================================
--- R-exts.texi	(revision 64082)
+++ R-exts.texi	(working copy)
@@ -2660,12 +2660,12 @@
  The recommended method of building binary packages is to use

  @command{R CMD INSTALL --build pkg}
+
  @noindent
-where @file{pkg} is either the name of a source tarball (in the usual
- at file{.tar.gz} format) or the location of the directory of the package
-source to be built.  This operates by first installing the package and
-then packing the installed binaries into the appropriate binary package
-file for the particular platform.
+where @file{pkg} is the name of a source tarball (in the usual
+ at file{.tar.gz} format) produced by @command{R CMD build}.  This operates
+by first installing the package and then packing the installed binaries
+into the appropriate binary package file for the particular platform.

  By default, @command{R CMD INSTALL --build} will attempt to install the package
  into the default library tree for the local installation of @R{}. This has two
-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From spencer.graves at prodsyse.com  Mon Oct 21 08:39:53 2013
From: spencer.graves at prodsyse.com (Spencer Graves)
Date: Sun, 20 Oct 2013 23:39:53 -0700
Subject: [Rd] lapply(ts(1:2), length) inconsistent answers
Message-ID: <5264CC39.6020307@prodsyse.com>

Hello, All:


       I'm getting different answers from "lapply(ts(1:2), length)", 
depending on what is attached, with nothing obviously masked.


             1.  Am I correct that the answer to "lapply(ts(1:2), 
length)" should be a list of length 2 consisting of "int 1" twice? This 
is what I get from R 3.0.2 with nothing else attached.  If I've attached 
other things including mar1s and a version of fda prior to the current 
2.4.0 on CRAN, I get a list of length 1 consisting of "int 2".  See below.


              2.  What might cause this inconsistency?  I'm guessing 
this may be due to something strange in the NAMESPACE, but I wouldn't 
now what.


       Thanks,
       Spencer Graves


# FROM R 3.0.2 ALONE:

 > sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: i386-w64-mingw32/i386 (32-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

other attached packages:
[1] sos_1.3-8  brew_1.0-6
 > lapply(ts(1:2), length)
[[1]]
[1] 1

[[2]]
[1] 1

###############################

# FROM R 3.0.2 AFTER attach(fda), with a version between 2.3.8 and 2.4.0 
but closer for this purpose to 2.3.8:

  lapply(ts(1:2), length)
[[1]]
[1] 2

Browse[2]> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-w64-mingw32/x64 (64-bit)

locale:
[1] LC_COLLATE=English_United States.1252
[2] LC_CTYPE=English_United States.1252
[3] LC_MONETARY=English_United States.1252
[4] LC_NUMERIC=C
[5] LC_TIME=English_United States.1252

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base

loaded via a namespace (and not attached):
  [1] chron_2.3-44    cmrutils_1.2-2  fda_2.4.0       grid_3.0.2
  [5] lattice_0.20-24 mar1s_2.0-1     Matrix_1.0-14   splines_3.0.2
  [9] tools_3.0.2     zoo_1.7-10


##*** NOTE:  This says fda_2.4.0.  However, I believe that's an error:  
With this session open and with fda 2.3.9 attached, I did "R CMD INSTALL 
fda_2.4.0.tar.gz".  The open session seemed to use fda 2.3.9, generating 
the inconsistent behavior documented above;  I finally simplified it to 
the form here.  I believe that sessionInfo() got the version number not 
from the version it was actually using but from the latest installed 
version, which in this case is different.


From ripley at stats.ox.ac.uk  Mon Oct 21 10:17:27 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Mon, 21 Oct 2013 09:17:27 +0100
Subject: [Rd] Possible tweak to R intro - was RE: [R] Subseting a
 data.frame -
In-Reply-To: <A4E5A0B016B8CB41A485FC629B633CED5487F2148A@GOLD.corp.lgc-group.com>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED5487F213BA@GOLD.corp.lgc-group.com>	<CACk-te1Y2jifecRE3fam8SMUgDZNcjTKAsHDprQoCrnq+tarhQ@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5487F2148A@GOLD.corp.lgc-group.com>
Message-ID: <5264E317.2000908@stats.ox.ac.uk>

On 18/10/2013 15:12, S Ellison wrote:
> Transferred from R-help:
>>> From: S Ellison
>>> Subsetting using subset() is perhaps the most natural way of
>>> subsetting data frames; perhaps a line or two and an example could
>>> usefully be included in the 'Working with data frames' section of the R
>>> Intro?
>>
>> From: Bert Gunter [mailto:gunter.berton at gene.com]
>> The R Intro Manual was largely or entirely the work of Bill Venables
>> some years ago. So it is not really a part of R's maintained document
>> system and has thus not been kept up to date with changes like the
>> convenience function, subset(), which is basically a wrapper for "[]"
>> .
>>
>> This is not to say that your suggestion is not worthwhile, only to
>> explain why it probably won't be acted upon.

No, this is deliberate and R-intro is kept up-to-date (although it 
remains an introduction, not a full manual).

Some of us think convenience functions such as subset() and transform() 
were mistakes, not least as we see the problems they cause when people 
try to use them in functions and packages.  Sooner or later you will 
need to learn to use indexing, and knowing about two systems with 
different scoping rules is too confusing for quite a few R users.

>
> It's trivial enough that I could offer a 3-line patch if someone has time and inclination to add it...
>
> S Ellison

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From murdoch.duncan at gmail.com  Mon Oct 21 11:20:05 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 21 Oct 2013 05:20:05 -0400
Subject: [Rd] Subversion log no longer being updated daily
In-Reply-To: <BA44C7DC-8A15-49B5-A318-A858C4E97979@xs4all.nl>
References: <BA44C7DC-8A15-49B5-A318-A858C4E97979@xs4all.nl>
Message-ID: <5264F1C5.4070201@gmail.com>

On 13-10-20 2:00 AM, Berend Hasselman wrote:
>
> The subversion log for 2013 (http://developer.r-project.org/R_svnlog_2013) on the R developer page hasn't been updated since September  29. I would appreciate the daily updates returning.

Thanks for pointing that out.  It's now back to being updated.  (There 
were hardware changes on developer.r-project.org, and this didn't get 
transferred until now.)

Duncan Murdoch


From pdalgd at gmail.com  Mon Oct 21 16:10:17 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 21 Oct 2013 16:10:17 +0200
Subject: [Rd] Possible tweak to R intro - was RE: [R] Subseting a
	data.frame -
In-Reply-To: <5264E317.2000908@stats.ox.ac.uk>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>	<A4E5A0B016B8CB41A485FC629B633CED5487F213BA@GOLD.corp.lgc-group.com>	<CACk-te1Y2jifecRE3fam8SMUgDZNcjTKAsHDprQoCrnq+tarhQ@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5487F2148A@GOLD.corp.lgc-group.com>
	<5264E317.2000908@stats.ox.ac.uk>
Message-ID: <C0704652-E45E-45D3-96D7-2CA7D264D65E@gmail.com>


On Oct 21, 2013, at 10:17 , Prof Brian Ripley wrote:

> Some of us think convenience functions such as subset() and transform() were mistakes, not least as we see the problems they cause when people try to use them in functions and packages. Sooner or later you will need to learn to use indexing, and knowing about two systems with different scoping rules is too confusing for quite a few R users.

The author of the two functions begs to differ, except that in hindsight he might have selected to require a formula-style ~ prefix on arguments that have nonstandard evaluation. The potential confusion is of the same sort as when lm() or anything else with a formula interface is used in a function.

I agree, however, that subset() is pretty useless for generic indexing, and that for the target audience of R-Intro, you might as well introduce proper indexing right away. And, of course, the document has named authors, who are entitled to have their opinions reflected in its contents.

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From gunter.berton at gene.com  Mon Oct 21 16:47:54 2013
From: gunter.berton at gene.com (Bert Gunter)
Date: Mon, 21 Oct 2013 07:47:54 -0700
Subject: [Rd] Possible tweak to R intro - was RE: [R] Subseting a
 data.frame -
In-Reply-To: <5264E317.2000908@stats.ox.ac.uk>
References: <1381992934.80794.YahooMailNeo@web193203.mail.sg3.yahoo.com>
	<CACk-te1_Oxvn6Zad9mV6zKvbTAWE=Ft7WXS3_F5pBPyGhdqCtg@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5487F213BA@GOLD.corp.lgc-group.com>
	<CACk-te1Y2jifecRE3fam8SMUgDZNcjTKAsHDprQoCrnq+tarhQ@mail.gmail.com>
	<A4E5A0B016B8CB41A485FC629B633CED5487F2148A@GOLD.corp.lgc-group.com>
	<5264E317.2000908@stats.ox.ac.uk>
Message-ID: <CACk-te3oo1Gwev-Pb+99Qft2tWz0XOEEnH7m2GrjxO4S_FZEAA@mail.gmail.com>

Thank you.

I stand corrected.

Cheers,
Bert

On Mon, Oct 21, 2013 at 1:17 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 18/10/2013 15:12, S Ellison wrote:
>>
>> Transferred from R-help:
>>>>
>>>> From: S Ellison
>>>> Subsetting using subset() is perhaps the most natural way of
>>>> subsetting data frames; perhaps a line or two and an example could
>>>> usefully be included in the 'Working with data frames' section of the R
>>>> Intro?
>>>
>>>
>>> From: Bert Gunter [mailto:gunter.berton at gene.com]
>>> The R Intro Manual was largely or entirely the work of Bill Venables
>>> some years ago. So it is not really a part of R's maintained document
>>> system and has thus not been kept up to date with changes like the
>>> convenience function, subset(), which is basically a wrapper for "[]"
>>> .
>>>
>>> This is not to say that your suggestion is not worthwhile, only to
>>> explain why it probably won't be acted upon.
>
>
> No, this is deliberate and R-intro is kept up-to-date (although it remains
> an introduction, not a full manual).
>
> Some of us think convenience functions such as subset() and transform() were
> mistakes, not least as we see the problems they cause when people try to use
> them in functions and packages.  Sooner or later you will need to learn to
> use indexing, and knowing about two systems with different scoping rules is
> too confusing for quite a few R users.
>
>>
>> It's trivial enough that I could offer a 3-line patch if someone has time
>> and inclination to add it...
>>
>> S Ellison
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595



-- 

Bert Gunter
Genentech Nonclinical Biostatistics

(650) 467-7374


From pdalgd at gmail.com  Mon Oct 21 18:07:34 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 21 Oct 2013 18:07:34 +0200
Subject: [Rd] Parallel R expression evaluations
In-Reply-To: <70F220AA-E852-43F5-B3CA-302B72AF2C89@r-project.org>
References: <1381931846577-4678352.post@n4.nabble.com>
	<77E2443B-BF01-42F8-B3AE-6AAF5CA9B391@r-project.org>
	<1382161049530-4678587.post@n4.nabble.com>
	<70F220AA-E852-43F5-B3CA-302B72AF2C89@r-project.org>
Message-ID: <3D598EAF-DC1F-4721-A98B-10676146AA41@gmail.com>


On Oct 21, 2013, at 02:24 , Simon Urbanek wrote:

> Jai,
> 
> On Oct 19, 2013, at 1:37 AM, JaiReddy wrote:
> 
>> Thanks Simon.
>> 
>> May I know how R works if two expressions come at the same time for
>> evaluation. When I debug my case I found that issue was found with indexed
>> values of protected items. 
>> 
>> As R is single threaded engine, I just want to know how does R behave when
>> 2nd expression comes for parsing and evaluation even before 1st expression
>> evaluation does complete?
>> 
> 
> As I said, no API calls may be performed in parallel, that includes parsing and evaluation. Typically, R is run in a sequential loop: read, parse, eval, print so anything that is not processed is blocked until the loop is back to reading. However, given that R can be called from arbitrary front-ends, it's really up to the front-end to decide what to do - as long as it serializes the calls appropriately.
> 

Things like GUI callbacks can get evaluated while other evaluation is in progress. In that case, a stack discipline is maintained, i.e. expression1 does not continue until expression2 is evaluated, but expression3 may arrive and block the other two. This isn't really much different from what happens if expression1 encounters an object that requires lazy evaluation. If the intermittent calls have no side effects, or at least keep them within a well-defined universe, the interrupted call should be unaffected.

However, this will not happen while expression1 is evaluating C code, only when the R evaluator is called. 

-pd


> Cheers,
> Simon
> 
> 
>> 
>> Thanks
>> Jai
>> 
>> 
>> 
>> --
>> View this message in context: http://r.789695.n4.nabble.com/Parallel-R-expression-evaluations-tp4678352p4678587.html
>> Sent from the R devel mailing list archive at Nabble.com.
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From william.tambellini at galaxysemi.com  Mon Oct 21 19:09:26 2013
From: william.tambellini at galaxysemi.com (Tambellini William)
Date: Mon, 21 Oct 2013 10:09:26 -0700
Subject: [Rd] About integrating R inside a C++ software
Message-ID: <52655FC6.7030700@galaxysemi.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131021/425e9bdf/attachment.pl>

From edd at debian.org  Mon Oct 21 19:31:29 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Mon, 21 Oct 2013 17:31:29 +0000
Subject: [Rd] About integrating R inside a C++ software
References: <52655FC6.7030700@galaxysemi.com>
Message-ID: <loom.20131021T192956-461@post.gmane.org>

Tambellini William <william.tambellini <at> galaxysemi.com> writes:
>   We want to integrate R inside our software in order to use mainly the 
> engine (usual stats as mean, sigma, Pearson, outlier detection, CPA, 
> multivariate, ...) and probably later the chart solution.
>   Of course we don't want to temporary write the data to some csv files 
> and then do an ugly system() call : system("RScript.exe myscript.R") for 
> many legitimate reasons.

That is *precisely* the use case for RInside which you already found.

>   We are also using Qt so a Qt to/from R wrapper could be interesting.

The RInside distribution contains *a fully working example* for a Qt-based
C++ main program with an embedded R instance:  RInside.

Hope this helps,  Dirk


From h.wickham at gmail.com  Mon Oct 21 19:51:59 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 21 Oct 2013 10:51:59 -0700
Subject: [Rd] Set operation generics
Message-ID: <CABdHhvEnx34qMWJnHoOprK0tHCmJswS3oLU0MJpBpWTyUEpL8Q@mail.gmail.com>

Hi all,

Would anyone be interested in reviewing a patch to make the set
operations (union, intersect, setdiff, setequal, is.element) generic?

Thanks,

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From jeroen.ooms at stat.ucla.edu  Mon Oct 21 21:31:50 2013
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Mon, 21 Oct 2013 15:31:50 -0400
Subject: [Rd] Assigning empty symbol to variable.
Message-ID: <CABFfbXv+jHnxcPafiHXFZmN_c-wE7H5Pu23GXwRtj2O5nXfFqA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131021/177b5f0c/attachment.pl>

From gmbecker at ucdavis.edu  Mon Oct 21 22:30:26 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 21 Oct 2013 13:30:26 -0700
Subject: [Rd] Assigning empty symbol to variable.
In-Reply-To: <CABFfbXv+jHnxcPafiHXFZmN_c-wE7H5Pu23GXwRtj2O5nXfFqA@mail.gmail.com>
References: <CABFfbXv+jHnxcPafiHXFZmN_c-wE7H5Pu23GXwRtj2O5nXfFqA@mail.gmail.com>
Message-ID: <CADwqtCMVEkevTJ2i+duOgyx18qncJyactx5+xaj8UJ=kOsyLgA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131021/62efb7e0/attachment.pl>

From gmbecker at ucdavis.edu  Mon Oct 21 22:44:25 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Mon, 21 Oct 2013 13:44:25 -0700
Subject: [Rd] Assigning empty symbol to variable.
In-Reply-To: <CADwqtCMVEkevTJ2i+duOgyx18qncJyactx5+xaj8UJ=kOsyLgA@mail.gmail.com>
References: <CABFfbXv+jHnxcPafiHXFZmN_c-wE7H5Pu23GXwRtj2O5nXfFqA@mail.gmail.com>
	<CADwqtCMVEkevTJ2i+duOgyx18qncJyactx5+xaj8UJ=kOsyLgA@mail.gmail.com>
Message-ID: <CADwqtCMY-mgerLrS1KD2XW9DLM-6HoUdycgPYAbwqz3Yrij_1A@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131021/e118579d/attachment.pl>

From luke-tierney at uiowa.edu  Mon Oct 21 22:52:03 2013
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Mon, 21 Oct 2013 15:52:03 -0500
Subject: [Rd] Assigning empty symbol to variable.
In-Reply-To: <CABFfbXv+jHnxcPafiHXFZmN_c-wE7H5Pu23GXwRtj2O5nXfFqA@mail.gmail.com>
References: <CABFfbXv+jHnxcPafiHXFZmN_c-wE7H5Pu23GXwRtj2O5nXfFqA@mail.gmail.com>
Message-ID: <alpine.LFD.2.03.1310211549520.8055@uiowa.edu>

On Mon, 21 Oct 2013, Jeroen Ooms wrote:

> When a variable is assigned the empty symbol, looking up the variable
> results in an error message that looks like a function call:
>
>> foo <- as.list(lm)$data
>> ls()
> [1] "foo"
>> foo
> Error: argument "foo" is missing, with no default
>> get("foo")
> Error in get("foo") : argument "foo" is missing, with no default
>> rm("foo")
>
> I ran into this problem when writing a function to serialize functions by
> their list representation, e.g. as.list(lm). It is quite hard to debug
> because of the confusing error message. I would have expected that:
>
>  foo == substitute()
>
> just like
>
>  as.list(lm)$data == substitute()
>
> Is this intended behaviour?
>
> 	[[alternative HTML version deleted]]

'intended' is probably too strong, but it is a consequence of long-ago
implementation decisions that are buried deeply enough to be hard to
change at this point. Any code that computes on the language and want
to be able to handle missing arguments needs to be aware of this. You
can look at the compiler sources or the woven version to see how it is
handled there.

Best,

luke

>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Chair, Statistics and Actuarial Science
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From hpages at fhcrc.org  Mon Oct 21 23:11:33 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 21 Oct 2013 14:11:33 -0700
Subject: [Rd] Set operation generics
In-Reply-To: <CABdHhvEnx34qMWJnHoOprK0tHCmJswS3oLU0MJpBpWTyUEpL8Q@mail.gmail.com>
References: <CABdHhvEnx34qMWJnHoOprK0tHCmJswS3oLU0MJpBpWTyUEpL8Q@mail.gmail.com>
Message-ID: <52659885.1040809@fhcrc.org>

Hi Hadley,

On 10/21/2013 10:51 AM, Hadley Wickham wrote:
> Hi all,
>
> Would anyone be interested in reviewing a patch to make the set
> operations (union, intersect, setdiff, setequal, is.element) generic?

S3 generics, S4 generics, or primitives?

Since they are binary operations, sounds like supporting multiple
dispatch would be a plus.

Note that all those things heavily rely on match() behind the scene.
If match() itself was an S4 generic (or a primitive like c() and [)
then union(), intersect(), setdiff(), is.element() could be defined
with something like:

   union <- function(x, y)
   {
     xy <- c(x, y)
     sm <- match(xy, xy)
     xy[sm == seq_along(sm)]
   }

   intersect <- function(x, y)
   {
     sm <- match(x, x)
     x <- x[sm == seq_along(sm)]
     m <- match(x, y)
     x[!is.na(m)]
   }

   setequal <- function(x, y)
   {
     !(anyNA(match(x, y)) || anyNA(match(x, y)))
   }

and as long as your objects support [, c(), and match(), then the set
operations will work out-of-the-box on them. Note that you would also
get %in% for free.

There might be some rare situations where it might still be useful
that the set operations are generic functions but I see a lot more
value in making match() itself a generic (which doesn't exclude also
making the set operations generic).

For the record, match(), union(), intersect(), and setdiff() are S4
generics in the BiocGenerics package. But there is no doubt it would
be a better/cleaner situation if base::match() itself was an S4 generic
or primitive.

My 2 cents,

Cheers,
H.


>
> Thanks,
>
> Hadley
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From xie at yihui.name  Mon Oct 21 23:43:08 2013
From: xie at yihui.name (Yihui Xie)
Date: Mon, 21 Oct 2013 16:43:08 -0500
Subject: [Rd] png(type='cairo'): point symbols without boarders are not
	anti-aliased?
Message-ID: <CANROs4eMXzueFLzoeAs7OyRgUMj6fv9jcLZ-GQZd=hxx4jB4nQ@mail.gmail.com>

Hi,

It seems that anti-aliasing in png(type = 'cairo') is not well
supported for the point symbols without boarders, e.g. pch = 16. The
Cairo package works well, though. You can compare png() with
CairoPNG():

png(): http://i.imgur.com/8niB3jX.png
CairoPNG(): http://i.imgur.com/FZBJOxm.png

f = function(dev, ..., main = '') {
  dev(...)
  plot(c(1, 2, 1, 2), c(1, 1, 2, 2), pch=c(16, 19), cex=c(2, 2, 15, 15),
       xlim=c(0.5, 2.5), ylim=c(0.5, 3), main = deparse(substitute(dev)))
  dev.off()
}
f(grDevices::png, 'png-base.png', type = 'cairo')
f(Cairo::CairoPNG, 'png-Cairo.png')

If I remove the border for pch=19 (i.e. lwd=0), the point shows rough
edges as well.

I'm not sure if that is expected, or it is due to my misconfiguration
somewhere. I installed R via `apt-get install r-base-dev` under Ubuntu
using the CRAN repository.

> sessionInfo()
R version 3.0.2 (2013-09-25)
Platform: x86_64-pc-linux-gnu (64-bit)

locale:
 [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
 [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
LC_PAPER=en_US.UTF-8       LC_NAME=C
 [9] LC_ADDRESS=C               LC_TELEPHONE=C
LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

loaded via a namespace (and not attached):
[1] Cairo_1.5-2 tools_3.0.2

> capabilities()
    jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets
    TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE     TRUE
  libxml     fifo   cledit    iconv      NLS  profmem    cairo
    TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE


Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


From xie at yihui.name  Mon Oct 21 23:44:31 2013
From: xie at yihui.name (Yihui Xie)
Date: Mon, 21 Oct 2013 16:44:31 -0500
Subject: [Rd] png(type='cairo'): point symbols without boarders are not
	anti-aliased?
In-Reply-To: <CANROs4eMXzueFLzoeAs7OyRgUMj6fv9jcLZ-GQZd=hxx4jB4nQ@mail.gmail.com>
References: <CANROs4eMXzueFLzoeAs7OyRgUMj6fv9jcLZ-GQZd=hxx4jB4nQ@mail.gmail.com>
Message-ID: <CANROs4d0Ev5EiCGykoTodmxEViuR88UHH5FLb6e-tpyO+aUFnw@mail.gmail.com>

Sorry, typo in the subject: I mean "borders".

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Mon, Oct 21, 2013 at 4:43 PM, Yihui Xie <xie at yihui.name> wrote:
> Hi,
>
> It seems that anti-aliasing in png(type = 'cairo') is not well
> supported for the point symbols without boarders, e.g. pch = 16. The
> Cairo package works well, though. You can compare png() with
> CairoPNG():
>
> png(): http://i.imgur.com/8niB3jX.png
> CairoPNG(): http://i.imgur.com/FZBJOxm.png
>
> f = function(dev, ..., main = '') {
>   dev(...)
>   plot(c(1, 2, 1, 2), c(1, 1, 2, 2), pch=c(16, 19), cex=c(2, 2, 15, 15),
>        xlim=c(0.5, 2.5), ylim=c(0.5, 3), main = deparse(substitute(dev)))
>   dev.off()
> }
> f(grDevices::png, 'png-base.png', type = 'cairo')
> f(Cairo::CairoPNG, 'png-Cairo.png')
>
> If I remove the border for pch=19 (i.e. lwd=0), the point shows rough
> edges as well.
>
> I'm not sure if that is expected, or it is due to my misconfiguration
> somewhere. I installed R via `apt-get install r-base-dev` under Ubuntu
> using the CRAN repository.
>
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] Cairo_1.5-2 tools_3.0.2
>
>> capabilities()
>     jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets
>     TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE     TRUE
>   libxml     fifo   cledit    iconv      NLS  profmem    cairo
>     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
>
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA


From paul at stat.auckland.ac.nz  Tue Oct 22 00:28:04 2013
From: paul at stat.auckland.ac.nz (Paul Murrell)
Date: Tue, 22 Oct 2013 11:28:04 +1300
Subject: [Rd] png(type='cairo'): point symbols without boarders are not
 anti-aliased?
In-Reply-To: <CANROs4eMXzueFLzoeAs7OyRgUMj6fv9jcLZ-GQZd=hxx4jB4nQ@mail.gmail.com>
References: <CANROs4eMXzueFLzoeAs7OyRgUMj6fv9jcLZ-GQZd=hxx4jB4nQ@mail.gmail.com>
Message-ID: <5265AA74.4080509@stat.auckland.ac.nz>

Hi

Is this the same as "Bug 15462" ?
https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15462

Paul

On 10/22/13 10:43, Yihui Xie wrote:
> Hi,
>
> It seems that anti-aliasing in png(type = 'cairo') is not well
> supported for the point symbols without boarders, e.g. pch = 16. The
> Cairo package works well, though. You can compare png() with
> CairoPNG():
>
> png(): http://i.imgur.com/8niB3jX.png
> CairoPNG(): http://i.imgur.com/FZBJOxm.png
>
> f = function(dev, ..., main = '') {
>    dev(...)
>    plot(c(1, 2, 1, 2), c(1, 1, 2, 2), pch=c(16, 19), cex=c(2, 2, 15, 15),
>         xlim=c(0.5, 2.5), ylim=c(0.5, 3), main = deparse(substitute(dev)))
>    dev.off()
> }
> f(grDevices::png, 'png-base.png', type = 'cairo')
> f(Cairo::CairoPNG, 'png-Cairo.png')
>
> If I remove the border for pch=19 (i.e. lwd=0), the point shows rough
> edges as well.
>
> I'm not sure if that is expected, or it is due to my misconfiguration
> somewhere. I installed R via `apt-get install r-base-dev` under Ubuntu
> using the CRAN repository.
>
>> sessionInfo()
> R version 3.0.2 (2013-09-25)
> Platform: x86_64-pc-linux-gnu (64-bit)
>
> locale:
>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
> LC_PAPER=en_US.UTF-8       LC_NAME=C
>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods   base
>
> loaded via a namespace (and not attached):
> [1] Cairo_1.5-2 tools_3.0.2
>
>> capabilities()
>      jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets
>      TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE     TRUE
>    libxml     fifo   cledit    iconv      NLS  profmem    cairo
>      TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
>
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Dr Paul Murrell
Department of Statistics
The University of Auckland
Private Bag 92019
Auckland
New Zealand
64 9 3737599 x85392
paul at stat.auckland.ac.nz
http://www.stat.auckland.ac.nz/~paul/


From jeroenooms at gmail.com  Tue Oct 22 00:29:50 2013
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Mon, 21 Oct 2013 15:29:50 -0700 (PDT)
Subject: [Rd] About integrating R inside a C++ software
In-Reply-To: <52655FC6.7030700@galaxysemi.com>
References: <52655FC6.7030700@galaxysemi.com>
Message-ID: <1382394590413-4678748.post@n4.nabble.com>

Rcpp is great, and I second that suggestion. But you could also explore
another route and use something like OpenCPU. 

OpenCPU is a framework for embedding R in systems and applications. It
exposes a simple HTTP(s) RPC API to call R functions and scripts, and makes
it easy to retrieve the resulting object and graphics in various formats.
Hence, you can use any c++ http client library to connect to your OpenCPU
computation server. 

This is perhaps a little more work than RInside, but the advantage is that R
will run on a separate server, decoupled from your C++ software. In my
experience this is often a good idea, because R can be a bit unpredictable
and greedy with hardware resources. Furthermore, you don't need to install a
copy of R on each of your software deployments: in a client/server design
you can maintain a single centralized computation server that all clients
connect to. Have a look at opencpu.org :-)





--
View this message in context: http://r.789695.n4.nabble.com/About-integrating-R-inside-a-C-software-tp4678712p4678748.html
Sent from the R devel mailing list archive at Nabble.com.


From xie at yihui.name  Tue Oct 22 03:07:32 2013
From: xie at yihui.name (Yihui Xie)
Date: Mon, 21 Oct 2013 20:07:32 -0500
Subject: [Rd] png(type='cairo'): point symbols without boarders are not
	anti-aliased?
In-Reply-To: <5265AA74.4080509@stat.auckland.ac.nz>
References: <CANROs4eMXzueFLzoeAs7OyRgUMj6fv9jcLZ-GQZd=hxx4jB4nQ@mail.gmail.com>
	<5265AA74.4080509@stat.auckland.ac.nz>
Message-ID: <CANROs4cOqL2H1XX5iKJKAKdv6TmCT-6S=-Csu+x+uUam6LNX-w@mail.gmail.com>

Perhaps yes. Sorry I did not check the bug reports. Can someone
elaborate on the "undesirable artefacts"? I made two heatmaps using
png() and CairoPNG(), respectively. I can see the difference, but it
is not very clear to me what the artefacts are, or what the facts
should be.

png(): http://i.imgur.com/lKrFG9i.png
CairoPNG(): http://i.imgur.com/Dv0rsKK.png

f = function(dev, ...) {
  dev(...)
  x = y <- seq(-4*pi, 4*pi, len = 27)
  r = sqrt(outer(x^2, y^2, "+"))
  z = cos(r^2)*exp(-r/6)
  image(z, main = deparse(substitute(dev)))
  dev.off()
}
f(grDevices::png, 'png-base.png', type = 'cairo')
f(Cairo::CairoPNG, 'png-Cairo.png')

Thanks!

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Mon, Oct 21, 2013 at 5:28 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
> Hi
>
> Is this the same as "Bug 15462" ?
> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15462
>
> Paul
>
>
> On 10/22/13 10:43, Yihui Xie wrote:
>>
>> Hi,
>>
>> It seems that anti-aliasing in png(type = 'cairo') is not well
>> supported for the point symbols without boarders, e.g. pch = 16. The
>> Cairo package works well, though. You can compare png() with
>> CairoPNG():
>>
>> png(): http://i.imgur.com/8niB3jX.png
>> CairoPNG(): http://i.imgur.com/FZBJOxm.png
>>
>> f = function(dev, ..., main = '') {
>>    dev(...)
>>    plot(c(1, 2, 1, 2), c(1, 1, 2, 2), pch=c(16, 19), cex=c(2, 2, 15, 15),
>>         xlim=c(0.5, 2.5), ylim=c(0.5, 3), main = deparse(substitute(dev)))
>>    dev.off()
>> }
>> f(grDevices::png, 'png-base.png', type = 'cairo')
>> f(Cairo::CairoPNG, 'png-Cairo.png')
>>
>> If I remove the border for pch=19 (i.e. lwd=0), the point shows rough
>> edges as well.
>>
>> I'm not sure if that is expected, or it is due to my misconfiguration
>> somewhere. I installed R via `apt-get install r-base-dev` under Ubuntu
>> using the CRAN repository.
>>
>>> sessionInfo()
>>
>> R version 3.0.2 (2013-09-25)
>> Platform: x86_64-pc-linux-gnu (64-bit)
>>
>> locale:
>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>> LC_PAPER=en_US.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> loaded via a namespace (and not attached):
>> [1] Cairo_1.5-2 tools_3.0.2
>>
>>> capabilities()
>>
>>      jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets
>>      TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE     TRUE
>>    libxml     fifo   cledit    iconv      NLS  profmem    cairo
>>      TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE


From simon.urbanek at r-project.org  Tue Oct 22 16:09:05 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Tue, 22 Oct 2013 10:09:05 -0400
Subject: [Rd] png(type='cairo'): point symbols without boarders are not
	anti-aliased?
In-Reply-To: <CANROs4cOqL2H1XX5iKJKAKdv6TmCT-6S=-Csu+x+uUam6LNX-w@mail.gmail.com>
References: <CANROs4eMXzueFLzoeAs7OyRgUMj6fv9jcLZ-GQZd=hxx4jB4nQ@mail.gmail.com>
	<5265AA74.4080509@stat.auckland.ac.nz>
	<CANROs4cOqL2H1XX5iKJKAKdv6TmCT-6S=-Csu+x+uUam6LNX-w@mail.gmail.com>
Message-ID: <BAEDB1D6-7221-4940-9C6D-E4D39946C1BC@r-project.org>

On Oct 21, 2013, at 9:07 PM, Yihui Xie wrote:

> Perhaps yes. Sorry I did not check the bug reports. Can someone
> elaborate on the "undesirable artefacts"? I made two heatmaps using
> png() and CairoPNG(), respectively. I can see the difference, but it
> is not very clear to me what the artefacts are, or what the facts
> should be.
> 

The Cairo package does "smart" anti-aliasing - it aligns lines that are perpendicular to the axes such that they centered at pixels. That avoids the anti-aliasing effects that Brian was talking about for the heatmap example. This enables Cairo to have full anti-aliasing support and still render heatmaps without artifacts.

However, there is no way around the anti-aliasing artifacts if you use arbitrary polygons without borders. For example:

library(deldir)
plot(c(-1,1),c(-1,1),ty='n')
for(p in tile.list(deldir(rnorm(200),rnorm(200)))) polygon(p$x,p$y,col=heat.colors(15)[runif(1,1,15)], border=NA)

That said, in our experience the Cairo approach works very well in practice.

Cheers,
Simon


> png(): http://i.imgur.com/lKrFG9i.png
> CairoPNG(): http://i.imgur.com/Dv0rsKK.png
> 
> f = function(dev, ...) {
>  dev(...)
>  x = y <- seq(-4*pi, 4*pi, len = 27)
>  r = sqrt(outer(x^2, y^2, "+"))
>  z = cos(r^2)*exp(-r/6)
>  image(z, main = deparse(substitute(dev)))
>  dev.off()
> }
> f(grDevices::png, 'png-base.png', type = 'cairo')
> f(Cairo::CairoPNG, 'png-Cairo.png')
> 
> Thanks!
> 
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
> 
> 
> On Mon, Oct 21, 2013 at 5:28 PM, Paul Murrell <paul at stat.auckland.ac.nz> wrote:
>> Hi
>> 
>> Is this the same as "Bug 15462" ?
>> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=15462
>> 
>> Paul
>> 
>> 
>> On 10/22/13 10:43, Yihui Xie wrote:
>>> 
>>> Hi,
>>> 
>>> It seems that anti-aliasing in png(type = 'cairo') is not well
>>> supported for the point symbols without boarders, e.g. pch = 16. The
>>> Cairo package works well, though. You can compare png() with
>>> CairoPNG():
>>> 
>>> png(): http://i.imgur.com/8niB3jX.png
>>> CairoPNG(): http://i.imgur.com/FZBJOxm.png
>>> 
>>> f = function(dev, ..., main = '') {
>>>   dev(...)
>>>   plot(c(1, 2, 1, 2), c(1, 1, 2, 2), pch=c(16, 19), cex=c(2, 2, 15, 15),
>>>        xlim=c(0.5, 2.5), ylim=c(0.5, 3), main = deparse(substitute(dev)))
>>>   dev.off()
>>> }
>>> f(grDevices::png, 'png-base.png', type = 'cairo')
>>> f(Cairo::CairoPNG, 'png-Cairo.png')
>>> 
>>> If I remove the border for pch=19 (i.e. lwd=0), the point shows rough
>>> edges as well.
>>> 
>>> I'm not sure if that is expected, or it is due to my misconfiguration
>>> somewhere. I installed R via `apt-get install r-base-dev` under Ubuntu
>>> using the CRAN repository.
>>> 
>>>> sessionInfo()
>>> 
>>> R version 3.0.2 (2013-09-25)
>>> Platform: x86_64-pc-linux-gnu (64-bit)
>>> 
>>> locale:
>>>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>> LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>> LC_PAPER=en_US.UTF-8       LC_NAME=C
>>>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
>>> LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>> 
>>> attached base packages:
>>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>> 
>>> loaded via a namespace (and not attached):
>>> [1] Cairo_1.5-2 tools_3.0.2
>>> 
>>>> capabilities()
>>> 
>>>     jpeg      png     tiff    tcltk      X11     aqua http/ftp  sockets
>>>     TRUE     TRUE     TRUE     TRUE     TRUE    FALSE     TRUE     TRUE
>>>   libxml     fifo   cledit    iconv      NLS  profmem    cairo
>>>     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE     TRUE
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From h.wickham at gmail.com  Tue Oct 22 16:54:57 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 22 Oct 2013 07:54:57 -0700
Subject: [Rd] Set operation generics
In-Reply-To: <52659885.1040809@fhcrc.org>
References: <CABdHhvEnx34qMWJnHoOprK0tHCmJswS3oLU0MJpBpWTyUEpL8Q@mail.gmail.com>
	<52659885.1040809@fhcrc.org>
Message-ID: <CABdHhvG_jBfhw97PuVcW3PtPMmiN7YYGsEwhWM+v57EDF=agnw@mail.gmail.com>

>> Would anyone be interested in reviewing a patch to make the set
>> operations (union, intersect, setdiff, setequal, is.element) generic?
>
> S3 generics, S4 generics, or primitives?

I would expect S3. Can you even have an S4 generic in the base
package? (i.e. before the methods package is loaded)

> Note that all those things heavily rely on match() behind the scene.
> If match() itself was an S4 generic (or a primitive like c() and [)
> then union(), intersect(), setdiff(), is.element() could be defined
> with something like:
>
>
>   union <- function(x, y)
>   {
>     xy <- c(x, y)
>     sm <- match(xy, xy)
>     xy[sm == seq_along(sm)]
>   }
>
>   intersect <- function(x, y)
>   {
>     sm <- match(x, x)
>     x <- x[sm == seq_along(sm)]
>     m <- match(x, y)
>     x[!is.na(m)]
>   }
>
>   setequal <- function(x, y)
>   {
>     !(anyNA(match(x, y)) || anyNA(match(x, y)))
>   }

Although I suspect R-core would prefer a minimal change where it's
easier to see that existing behaviour is preserved.

> For the record, match(), union(), intersect(), and setdiff() are S4
> generics in the BiocGenerics package. But there is no doubt it would
> be a better/cleaner situation if base::match() itself was an S4 generic
> or primitive.

By primitive, you mean internal generic?

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From xie at yihui.name  Tue Oct 22 17:14:48 2013
From: xie at yihui.name (Yihui Xie)
Date: Tue, 22 Oct 2013 10:14:48 -0500
Subject: [Rd] png(type='cairo'): point symbols without boarders are not
	anti-aliased?
In-Reply-To: <BAEDB1D6-7221-4940-9C6D-E4D39946C1BC@r-project.org>
References: <CANROs4eMXzueFLzoeAs7OyRgUMj6fv9jcLZ-GQZd=hxx4jB4nQ@mail.gmail.com>
	<5265AA74.4080509@stat.auckland.ac.nz>
	<CANROs4cOqL2H1XX5iKJKAKdv6TmCT-6S=-Csu+x+uUam6LNX-w@mail.gmail.com>
	<BAEDB1D6-7221-4940-9C6D-E4D39946C1BC@r-project.org>
Message-ID: <CANROs4dw1rpQY4SBEaVOf7=x7E41KZWwE4wpjdByeWsU4x+VcA@mail.gmail.com>

Thanks for the hints! I was originally wondering the difference
between grDevices::png(type='cairo') and Cairo::CairoPNG() for the
case pch=16, a solid point without border. Cairo does a nice job for
such point symbols, but png() renders them very poorly.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Tue, Oct 22, 2013 at 9:09 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> The Cairo package does "smart" anti-aliasing - it aligns lines that are perpendicular to the axes such that they centered at pixels. That avoids the anti-aliasing effects that Brian was talking about for the heatmap example. This enables Cairo to have full anti-aliasing support and still render heatmaps without artifacts.
>
> However, there is no way around the anti-aliasing artifacts if you use arbitrary polygons without borders. For example:
>
> library(deldir)
> plot(c(-1,1),c(-1,1),ty='n')
> for(p in tile.list(deldir(rnorm(200),rnorm(200)))) polygon(p$x,p$y,col=heat.colors(15)[runif(1,1,15)], border=NA)
>
> That said, in our experience the Cairo approach works very well in practice.
>
> Cheers,
> Simon


From hpages at fhcrc.org  Tue Oct 22 18:52:21 2013
From: hpages at fhcrc.org (=?ISO-8859-1?Q?Herv=E9_Pag=E8s?=)
Date: Tue, 22 Oct 2013 09:52:21 -0700
Subject: [Rd] Set operation generics
In-Reply-To: <CABdHhvG_jBfhw97PuVcW3PtPMmiN7YYGsEwhWM+v57EDF=agnw@mail.gmail.com>
References: <CABdHhvEnx34qMWJnHoOprK0tHCmJswS3oLU0MJpBpWTyUEpL8Q@mail.gmail.com>
	<52659885.1040809@fhcrc.org>
	<CABdHhvG_jBfhw97PuVcW3PtPMmiN7YYGsEwhWM+v57EDF=agnw@mail.gmail.com>
Message-ID: <5266AD45.8020500@fhcrc.org>

Hi Hadley,

On 10/22/2013 07:54 AM, Hadley Wickham wrote:
>>> Would anyone be interested in reviewing a patch to make the set
>>> operations (union, intersect, setdiff, setequal, is.element) generic?
>>
>> S3 generics, S4 generics, or primitives?
>
> I would expect S3. Can you even have an S4 generic in the base
> package? (i.e. before the methods package is loaded)

Probably not. But the patch could be trying to put them in stats4.

>
>> Note that all those things heavily rely on match() behind the scene.
>> If match() itself was an S4 generic (or a primitive like c() and [)
>> then union(), intersect(), setdiff(), is.element() could be defined
>> with something like:
>>
>>
>>    union <- function(x, y)
>>    {
>>      xy <- c(x, y)
>>      sm <- match(xy, xy)
>>      xy[sm == seq_along(sm)]
>>    }
>>
>>    intersect <- function(x, y)
>>    {
>>      sm <- match(x, x)
>>      x <- x[sm == seq_along(sm)]
>>      m <- match(x, y)
>>      x[!is.na(m)]
>>    }
>>
>>    setequal <- function(x, y)
>>    {
>>      !(anyNA(match(x, y)) || anyNA(match(x, y)))
>>    }
>
> Although I suspect R-core would prefer a minimal change where it's
> easier to see that existing behaviour is preserved.
>
>> For the record, match(), union(), intersect(), and setdiff() are S4
>> generics in the BiocGenerics package. But there is no doubt it would
>> be a better/cleaner situation if base::match() itself was an S4 generic
>> or primitive.
>
> By primitive, you mean internal generic?

Yes.

Thanks,
H.

>
> Hadley
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From mdsumner at gmail.com  Wed Oct 23 03:45:06 2013
From: mdsumner at gmail.com (Michael Sumner)
Date: Wed, 23 Oct 2013 12:45:06 +1100
Subject: [Rd] interrupting Sweave leaves open sink connection
Message-ID: <CAAcGz9_eB7nUgrDuAroEfP6bwg-mMjXgqMeokVzRXGj0y_jDQQ@mail.gmail.com>

Hello, if I interrupt Sweave while it's processing a file it seemingly
leaves an open sink connection that hides printed output.

Can this be changed to reset the sink on exit?  I've been baffled by
this for years.

This is seen in Windows (R Under development (unstable) (2013-10-20
r64082))  and an older Linux (R version 3.0.0 (2013-04-03)).

Run the code below in two parts with a manual interrupt to 1) to see it.

Cheers, MIke.

## 1)

## this code creates a temporary file to run Sweave

## interrupt this code before Sweave() finishes

txt <-  c("\\documentclass[a4paper]{article}", "\\title{Sweave bail out}",
"\\author{M. Sumner}", "\\begin{document}", "\\maketitle", "",
"Run a loop and bail out when Sweave()ing.", "", "<<>>=",
"for (i in seq_len(1e6)) {", "    if (i %% 1000 == 0)
print(sprintf(\"%i\", i))",
"    Sys.sleep(0.5)", "}", "@", "", "\\end{document}")

f <- tempfile()
writeLines(txt, f)

Sweave(f)

## 2)
## now no printed output is seen
print(1)
##

sink(NULL)

## now it's back
print(1)
## [1] 1

## tidy up
## unlink(f)





-- 
Michael Sumner
Hobart, Australia
e-mail: mdsumner at gmail.com


From murdoch.duncan at gmail.com  Wed Oct 23 04:45:04 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Tue, 22 Oct 2013 22:45:04 -0400
Subject: [Rd] interrupting Sweave leaves open sink connection
In-Reply-To: <CAAcGz9_eB7nUgrDuAroEfP6bwg-mMjXgqMeokVzRXGj0y_jDQQ@mail.gmail.com>
References: <CAAcGz9_eB7nUgrDuAroEfP6bwg-mMjXgqMeokVzRXGj0y_jDQQ@mail.gmail.com>
Message-ID: <52673830.8090405@gmail.com>

On 13-10-22 9:45 PM, Michael Sumner wrote:
> Hello, if I interrupt Sweave while it's processing a file it seemingly
> leaves an open sink connection that hides printed output.
>
> Can this be changed to reset the sink on exit?  I've been baffled by
> this for years.
>
> This is seen in Windows (R Under development (unstable) (2013-10-20
> r64082))  and an older Linux (R version 3.0.0 (2013-04-03)).
>
> Run the code below in two parts with a manual interrupt to 1) to see it.

That's a bug in the Rweave driver.  It runs the code in try() so that it 
can catch errors and undo the sink, but try() doesn't catch user 
interrupts, so it never gets undone.

Shouldn't be too hard to fix...

Duncan Murdoch

>
> Cheers, MIke.
>
> ## 1)
>
> ## this code creates a temporary file to run Sweave
>
> ## interrupt this code before Sweave() finishes
>
> txt <-  c("\\documentclass[a4paper]{article}", "\\title{Sweave bail out}",
> "\\author{M. Sumner}", "\\begin{document}", "\\maketitle", "",
> "Run a loop and bail out when Sweave()ing.", "", "<<>>=",
> "for (i in seq_len(1e6)) {", "    if (i %% 1000 == 0)
> print(sprintf(\"%i\", i))",
> "    Sys.sleep(0.5)", "}", "@", "", "\\end{document}")
>
> f <- tempfile()
> writeLines(txt, f)
>
> Sweave(f)
>
> ## 2)
> ## now no printed output is seen
> print(1)
> ##
>
> sink(NULL)
>
> ## now it's back
> print(1)
> ## [1] 1
>
> ## tidy up
> ## unlink(f)
>
>
>
>
>


From skyebend at skyeome.net  Tue Oct 22 21:12:26 2013
From: skyebend at skyeome.net (Skye Bender-deMoll)
Date: Tue, 22 Oct 2013 12:12:26 -0700
Subject: [Rd] possible Sweave problem in rdevel build on Debian 6.0.8?
Message-ID: <5266CE1A.90200@skyeome.net>

Dear R-Devel,

Note:  I posted a similar message to R-sig-debian yesterday because I 
assumed it was a Debian issue, received response that it it may be more 
appropriate for r-devel since it involves building from the svn version.

As of Oct 21, we are running into a build failure when trying to
compile the development version of R from the svn repository.  The 
problem still persists as of Revision:64096:

We are running:

./configure && make -j4 distclean && ./configure && make -j4

[lots of normal compile output not shown...]

building/updating vignettes for package 'utils' ...
processing 'Sweave.Rnw'
Error: running Sweave on vignette
'/net/home/rpackagebuilder/src/R.trunk/src/library/utils/vignettes/Sweave.Rnw' 


failed with message:
<text>:1:1: unexpected '|'
1: |
       ^
Execution halted
make[1]: *** [vignettes-lattice] Error 1
make[1]: Leaving directory
`/net/home/rpackagebuilder/src/R.trunk/src/library'
make: *** [vignettes] Error 2


The same vignette compiles without error on the same machine using the
stable release version of R (which we also build from source with same 
commands).

Dirk reported yesterday that he was unable to reproduce the problem on 
r-devel svn "..Using Ubuntu 13.04, current"

Does anyone have suggestions on how I might debug this further to 
determine if this is an issue with Sweave, or something with our system 
configuration which would impact one build and not the other?  When I 
diff the files in utils I see quite a few changes to Sweave between the 
stable and devel branches, but I'm not sure how to interpret them.

thanks for your help,
    -skye


From ripley at stats.ox.ac.uk  Wed Oct 23 10:30:15 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Wed, 23 Oct 2013 09:30:15 +0100
Subject: [Rd] possible Sweave problem in rdevel build on Debian 6.0.8?
In-Reply-To: <5266CE1A.90200@skyeome.net>
References: <5266CE1A.90200@skyeome.net>
Message-ID: <52678917.7060607@stats.ox.ac.uk>

Please try again: I could reproduce this on one system prior to r64100.

On 22/10/2013 20:12, Skye Bender-deMoll wrote:
> Dear R-Devel,
>
> Note:  I posted a similar message to R-sig-debian yesterday because I
> assumed it was a Debian issue, received response that it it may be more
> appropriate for r-devel since it involves building from the svn version.
>
> As of Oct 21, we are running into a build failure when trying to
> compile the development version of R from the svn repository.  The
> problem still persists as of Revision:64096:
>
> We are running:
>
> ./configure && make -j4 distclean && ./configure && make -j4
>
> [lots of normal compile output not shown...]
>
> building/updating vignettes for package 'utils' ...
> processing 'Sweave.Rnw'
> Error: running Sweave on vignette
> '/net/home/rpackagebuilder/src/R.trunk/src/library/utils/vignettes/Sweave.Rnw'
>
>
> failed with message:
> <text>:1:1: unexpected '|'
> 1: |
>        ^
> Execution halted
> make[1]: *** [vignettes-lattice] Error 1
> make[1]: Leaving directory
> `/net/home/rpackagebuilder/src/R.trunk/src/library'
> make: *** [vignettes] Error 2
>
>
> The same vignette compiles without error on the same machine using the
> stable release version of R (which we also build from source with same
> commands).
>
> Dirk reported yesterday that he was unable to reproduce the problem on
> r-devel svn "..Using Ubuntu 13.04, current"
>
> Does anyone have suggestions on how I might debug this further to
> determine if this is an issue with Sweave, or something with our system
> configuration which would impact one build and not the other?  When I
> diff the files in utils I see quite a few changes to Sweave between the
> stable and devel branches, but I'm not sure how to interpret them.
>
> thanks for your help,
>     -skye
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pdalgd at gmail.com  Wed Oct 23 10:37:47 2013
From: pdalgd at gmail.com (peter dalgaard)
Date: Wed, 23 Oct 2013 10:37:47 +0200
Subject: [Rd] possible Sweave problem in rdevel build on Debian 6.0.8?
In-Reply-To: <52678917.7060607@stats.ox.ac.uk>
References: <5266CE1A.90200@skyeome.net> <52678917.7060607@stats.ox.ac.uk>
Message-ID: <FAE36E98-BD3A-4ACF-B32D-AC2108017A6E@gmail.com>

Affirmative. I was seeing this in 64099, but it disappeared with 64101. (OSX Lion if it matters to anyone)

-pd

On Oct 23, 2013, at 10:30 , Prof Brian Ripley wrote:

> Please try again: I could reproduce this on one system prior to r64100.
> 
> On 22/10/2013 20:12, Skye Bender-deMoll wrote:
>> Dear R-Devel,
>> 
>> Note:  I posted a similar message to R-sig-debian yesterday because I
>> assumed it was a Debian issue, received response that it it may be more
>> appropriate for r-devel since it involves building from the svn version.
>> 
>> As of Oct 21, we are running into a build failure when trying to
>> compile the development version of R from the svn repository.  The
>> problem still persists as of Revision:64096:
>> 
>> We are running:
>> 
>> ./configure && make -j4 distclean && ./configure && make -j4
>> 
>> [lots of normal compile output not shown...]
>> 
>> building/updating vignettes for package 'utils' ...
>> processing 'Sweave.Rnw'
>> Error: running Sweave on vignette
>> '/net/home/rpackagebuilder/src/R.trunk/src/library/utils/vignettes/Sweave.Rnw'
>> 
>> 
>> failed with message:
>> <text>:1:1: unexpected '|'
>> 1: |
>>       ^
>> Execution halted
>> make[1]: *** [vignettes-lattice] Error 1
>> make[1]: Leaving directory
>> `/net/home/rpackagebuilder/src/R.trunk/src/library'
>> make: *** [vignettes] Error 2
>> 
>> 
>> The same vignette compiles without error on the same machine using the
>> stable release version of R (which we also build from source with same
>> commands).
>> 
>> Dirk reported yesterday that he was unable to reproduce the problem on
>> r-devel svn "..Using Ubuntu 13.04, current"
>> 
>> Does anyone have suggestions on how I might debug this further to
>> determine if this is an issue with Sweave, or something with our system
>> configuration which would impact one build and not the other?  When I
>> diff the files in utils I see quite a few changes to Sweave between the
>> stable and devel branches, but I'm not sure how to interpret them.
>> 
>> thanks for your help,
>>    -skye
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> -- 
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From skyebend at skyeome.net  Wed Oct 23 11:33:40 2013
From: skyebend at skyeome.net (Skye Bender-deMoll)
Date: Wed, 23 Oct 2013 02:33:40 -0700
Subject: [Rd] possible Sweave problem in rdevel build on Debian 6.0.8?
In-Reply-To: <FAE36E98-BD3A-4ACF-B32D-AC2108017A6E@gmail.com>
References: <5266CE1A.90200@skyeome.net> <52678917.7060607@stats.ox.ac.uk>
	<FAE36E98-BD3A-4ACF-B32D-AC2108017A6E@gmail.com>
Message-ID: <526797F4.3010003@skyeome.net>

That fixed it for me,  r64100 is building cleanly again.

thanks!
  -skye

On 10/23/2013 01:37 AM, peter dalgaard wrote:
> Affirmative. I was seeing this in 64099, but it disappeared with 64101. (OSX Lion if it matters to anyone)
>
> -pd
>
> On Oct 23, 2013, at 10:30 , Prof Brian Ripley wrote:
>
>> Please try again: I could reproduce this on one system prior to r64100.
>>
>> On 22/10/2013 20:12, Skye Bender-deMoll wrote:
>>> Dear R-Devel,
>>>
>>> Note:  I posted a similar message to R-sig-debian yesterday because I
>>> assumed it was a Debian issue, received response that it it may be more
>>> appropriate for r-devel since it involves building from the svn version.
>>>
>>> As of Oct 21, we are running into a build failure when trying to
>>> compile the development version of R from the svn repository.  The
>>> problem still persists as of Revision:64096:
>>>
>>> We are running:
>>>
>>> ./configure && make -j4 distclean && ./configure && make -j4
>>>
>>> [lots of normal compile output not shown...]
>>>
>>> building/updating vignettes for package 'utils' ...
>>> processing 'Sweave.Rnw'
>>> Error: running Sweave on vignette
>>> '/net/home/rpackagebuilder/src/R.trunk/src/library/utils/vignettes/Sweave.Rnw'
>>>
>>>
>>> failed with message:
>>> <text>:1:1: unexpected '|'
>>> 1: |
>>>        ^
>>> Execution halted
>>> make[1]: *** [vignettes-lattice] Error 1
>>> make[1]: Leaving directory
>>> `/net/home/rpackagebuilder/src/R.trunk/src/library'
>>> make: *** [vignettes] Error 2
>>>
>>>
>>> The same vignette compiles without error on the same machine using the
>>> stable release version of R (which we also build from source with same
>>> commands).
>>>
>>> Dirk reported yesterday that he was unable to reproduce the problem on
>>> r-devel svn "..Using Ubuntu 13.04, current"
>>>
>>> Does anyone have suggestions on how I might debug this further to
>>> determine if this is an issue with Sweave, or something with our system
>>> configuration which would impact one build and not the other?  When I
>>> diff the files in utils I see quite a few changes to Sweave between the
>>> stable and devel branches, but I'm not sure how to interpret them.
>>>
>>> thanks for your help,
>>>     -skye
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From murdoch.duncan at gmail.com  Wed Oct 23 13:48:37 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 23 Oct 2013 07:48:37 -0400
Subject: [Rd] interrupting Sweave leaves open sink connection
In-Reply-To: <52673830.8090405@gmail.com>
References: <CAAcGz9_eB7nUgrDuAroEfP6bwg-mMjXgqMeokVzRXGj0y_jDQQ@mail.gmail.com>
	<52673830.8090405@gmail.com>
Message-ID: <5267B795.5040906@gmail.com>

On 13-10-22 10:45 PM, Duncan Murdoch wrote:
> On 13-10-22 9:45 PM, Michael Sumner wrote:
>> Hello, if I interrupt Sweave while it's processing a file it seemingly
>> leaves an open sink connection that hides printed output.
>>
>> Can this be changed to reset the sink on exit?  I've been baffled by
>> this for years.
>>
>> This is seen in Windows (R Under development (unstable) (2013-10-20
>> r64082))  and an older Linux (R version 3.0.0 (2013-04-03)).
>>
>> Run the code below in two parts with a manual interrupt to 1) to see it.
>
> That's a bug in the Rweave driver.  It runs the code in try() so that it
> can catch errors and undo the sink, but try() doesn't catch user
> interrupts, so it never gets undone.
>
> Shouldn't be too hard to fix...

It should now be fixed in R-devel and R-patched.

Likely the reason this went unfixed for so long is that the more common 
way to use Sweave is in a separate R session.  If you run it in the 
current R session, the results aren't necessarily reproducible, because 
they may depend on whatever variables you have in your workspace.  It's 
better to run it on its own.  One way is to use the command line version

R CMD Sweave ...

but it can also be done by piping specific commands into an R session. 
I do it that way, because it lets me run some project management code, 
and lets me patch the Synctex information so it points to the .Rnw file.

Duncan Murdoch

>
> Duncan Murdoch
>
>>
>> Cheers, MIke.
>>
>> ## 1)
>>
>> ## this code creates a temporary file to run Sweave
>>
>> ## interrupt this code before Sweave() finishes
>>
>> txt <-  c("\\documentclass[a4paper]{article}", "\\title{Sweave bail out}",
>> "\\author{M. Sumner}", "\\begin{document}", "\\maketitle", "",
>> "Run a loop and bail out when Sweave()ing.", "", "<<>>=",
>> "for (i in seq_len(1e6)) {", "    if (i %% 1000 == 0)
>> print(sprintf(\"%i\", i))",
>> "    Sys.sleep(0.5)", "}", "@", "", "\\end{document}")
>>
>> f <- tempfile()
>> writeLines(txt, f)
>>
>> Sweave(f)
>>
>> ## 2)
>> ## now no printed output is seen
>> print(1)
>> ##
>>
>> sink(NULL)
>>
>> ## now it's back
>> print(1)
>> ## [1] 1
>>
>> ## tidy up
>> ## unlink(f)
>>
>>
>>
>>
>>
>


From kasperdanielhansen at gmail.com  Thu Oct 24 05:33:43 2013
From: kasperdanielhansen at gmail.com (Kasper Daniel Hansen)
Date: Wed, 23 Oct 2013 23:33:43 -0400
Subject: [Rd] advise on Depends
Message-ID: <CAC2h7usRKfUJpwq+hvgGmb_fQ4NhzQxhK1ynvWHQkjf8kw5Zbg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131023/c0a5c95a/attachment.pl>

From cmr.pent at gmail.com  Wed Oct 23 20:56:26 2013
From: cmr.pent at gmail.com (=?UTF-8?B?0JDQvdC00YDQtdC5INCf0LDRgNCw0LzQvtC90L7Qsg==?=)
Date: Wed, 23 Oct 2013 22:56:26 +0400
Subject: [Rd] Multivariate time series in R 3 vs R 2
Message-ID: <CAC4Co6NmORc1vHY3G2Kd40o-eiDB+pvWHXeVtfoJYivH1-+yMQ@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131023/08342ceb/attachment.pl>

From skyebend at skyeome.net  Fri Oct 25 02:13:05 2013
From: skyebend at skyeome.net (Skye Bender-deMoll)
Date: Thu, 24 Oct 2013 17:13:05 -0700
Subject: [Rd] appropriate work-around for problems with a specific plot
 device (Rstudio)?
Message-ID: <5269B791.1040808@skyeome.net>

Dear r-devel-opers,

I'm working on a package that does some plot-intensive work using the 
animation library.  It turns out that this performs very badly in the 
RStudio plot device, which is the preferred IDE for our team.  Our 
kludgy solution is to detect if the Rstudio device is running, and if 
so, open another plot device to do the rendering and close it when done:

externalDevice<-FALSE
   if (!is.function(options()$device)){
     if (names(dev.cur())=="RStudioGD"){
       message("RStudio's graphics device is not well supported by ndtv, 
attempting to open another type of plot window")
       # try to open a new platform-appropriate plot window
       if (.Platform$OS.type=='windows'){
         windows()
       } else if(length(grep(R.version$platform,pattern='apple'))>0)  # 
is it mac?
       {
         quartz()
       } else {  # must be unix
         x11()
       }
       externalDevice<-TRUE
     }
   }

[render a whole bunch of plot frames]

# turn off external device if using one
   if (externalDevice){
     dev.off()
   }

Although this works well for us in practice, when testing against R 
devel, we get the following NOTE:


* checking R code for possible problems ... NOTE
Found an obsolete/platform-specific call in the following function:
   ?render.animation?
Found the platform-specific devices:
   ?quartz? ?windows? ?x11?
dev.new() is the preferred way to open a new device, in the unlikely
event one is needed.


Is there a better way to resolve this situation?  We can't use dev.new() 
to open the plot device, because RStudio has set the value of 
getOption("device") to "RStudioGD".  Can anyone recommend an alternative 
method of generating a platform-appropriate device to open that won't 
generate R CMD check issues?

Thanks for your help,
  best,
  -skye


From nalimilan at club.fr  Fri Oct 25 11:19:44 2013
From: nalimilan at club.fr (Milan Bouchet-Valat)
Date: Fri, 25 Oct 2013 11:19:44 +0200
Subject: [Rd] appropriate work-around for problems with a specific plot
 device (Rstudio)?
In-Reply-To: <5269B791.1040808@skyeome.net>
References: <5269B791.1040808@skyeome.net>
Message-ID: <1382692784.7000.35.camel@milan>

Le jeudi 24 octobre 2013 ? 17:13 -0700, Skye Bender-deMoll a ?crit :
> Dear r-devel-opers,
> 
> I'm working on a package that does some plot-intensive work using the 
> animation library.  It turns out that this performs very badly in the 
> RStudio plot device, which is the preferred IDE for our team.  Our 
> kludgy solution is to detect if the Rstudio device is running, and if 
> so, open another plot device to do the rendering and close it when done:
> 
> externalDevice<-FALSE
>    if (!is.function(options()$device)){
>      if (names(dev.cur())=="RStudioGD"){
>        message("RStudio's graphics device is not well supported by ndtv, 
> attempting to open another type of plot window")
>        # try to open a new platform-appropriate plot window
>        if (.Platform$OS.type=='windows'){
>          windows()
>        } else if(length(grep(R.version$platform,pattern='apple'))>0)  # 
> is it mac?
>        {
>          quartz()
>        } else {  # must be unix
>          x11()
>        }
>        externalDevice<-TRUE
>      }
>    }
> 
> [render a whole bunch of plot frames]
> 
> # turn off external device if using one
>    if (externalDevice){
>      dev.off()
>    }
> 
> Although this works well for us in practice, when testing against R 
> devel, we get the following NOTE:
> 
> 
> * checking R code for possible problems ... NOTE
> Found an obsolete/platform-specific call in the following function:
>    ?render.animation?
> Found the platform-specific devices:
>    ?quartz? ?windows? ?x11?
> dev.new() is the preferred way to open a new device, in the unlikely
> event one is needed.
> 
> 
> Is there a better way to resolve this situation?  We can't use dev.new() 
> to open the plot device, because RStudio has set the value of 
> getOption("device") to "RStudioGD".  Can anyone recommend an alternative 
> method of generating a platform-appropriate device to open that won't 
> generate R CMD check issues?
How about temporarily changing the value of the "device" option to what
you need?

I think you should also get in touch with RStudio developers to see
whether something can be done about the poor performance.


My two cents


From lorenz at usgs.gov  Fri Oct 25 16:24:34 2013
From: lorenz at usgs.gov (Lorenz, David)
Date: Fri, 25 Oct 2013 09:24:34 -0500
Subject: [Rd] appropriate work-around for problems with a specific plot
 device (Rstudio)?
In-Reply-To: <1382692784.7000.35.camel@milan>
References: <5269B791.1040808@skyeome.net> <1382692784.7000.35.camel@milan>
Message-ID: <CALxY2Lf4SORY6a_t2sOmcs57cMat3qavVnGM+0coZWG2i8Nx1g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131025/c0b96a9b/attachment.pl>

From sandy at umn.edu  Fri Oct 25 17:37:15 2013
From: sandy at umn.edu (Sanford Weisberg)
Date: Fri, 25 Oct 2013 10:37:15 -0500
Subject: [Rd] R CMD check problem with R 3.0.2
Message-ID: <CADkZVY7vuQv_nS+H_Xvb25v6k4tS9steZ86RkLhteGxK_9YHug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131025/16c34bf8/attachment.pl>

From xie at yihui.name  Fri Oct 25 18:12:42 2013
From: xie at yihui.name (Yihui Xie)
Date: Fri, 25 Oct 2013 11:12:42 -0500
Subject: [Rd] R CMD check problem with R 3.0.2
In-Reply-To: <CADkZVY7vuQv_nS+H_Xvb25v6k4tS9steZ86RkLhteGxK_9YHug@mail.gmail.com>
References: <CADkZVY7vuQv_nS+H_Xvb25v6k4tS9steZ86RkLhteGxK_9YHug@mail.gmail.com>
Message-ID: <CANROs4c=0JJ0uefWezkPwYvCkZYGTLwszJ7xGJJ1REOjfGLzGA@mail.gmail.com>

This has been asked soooo many times that I think it may be a good
idea for R CMD check to just stop when the user passes a directory
instead of a tar ball to it, or automatically run R CMD build before
moving on. In my opinion, sometimes an FAQ and a bug are not entirely
different.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Fri, Oct 25, 2013 at 10:37 AM, Sanford Weisberg <sandy at umn.edu> wrote:
> Using SUSE Linux, Windows 32 bit and Windows 64 bit R 3.0.2 , I am unable
> to use R CMD check successfully.  Here is the Windows 64 bit report:
>
>
> Z:\R\source\effects>R CMD check pkg
> * using log directory 'Z:/R/source/effects/pkg.Rcheck'
> * using R version 3.0.2 (2013-09-25)
> * using platform: x86_64-w64-mingw32 (64-bit)
> * using session charset: ISO8859-1
> * checking for file 'pkg/DESCRIPTION' ... ERROR
> Required fields missing or empty:
>   'Author' 'Maintainer'
>
> The file DESCRIPTION looks like this:
>
> Package: effects
> Version: 2.3-0
> Date: 2013/10/22
> Title: Effect Displays for Linear, Generalized Linear, Multinomial-Logit,
> Proportional-Odds Logit Models and Mixed-Effects Models
> Authors at R: c(person("John", "Fox", role = c("aut", "cre"), email = "
> jfox at mcmaster.ca"),
>     person("Sanford", "Weisberg", role = "aut", email = "sandy at umn.edu"),
>     person("Michael", "Friendly", role = "aut", email = "friendly at yorku.ca
> "),
>     person("Jangman", "Hong", role = "aut"),
>     person("Robert", "Andersen", role = "ctb"),
>     person("David", "Firth", role = "ctb"),
>     person("Steve", "Taylor", role = "ctb"))
> Depends: lattice, grid, colorspace
> Suggests: nlme, lme4, MASS, nnet, poLCA, heplots
> LazyLoad: yes
> LazyData: yes
> Description:
>   Graphical and tabular effect displays, e.g., of interactions, for linear
>   generalized linear, multinomial-logit, proportional-odds logit models,
>   mixed-effect models,  polytomous latent-class models and multivariate
> linear models.
> License: GPL (>= 2)
> URL: http://www.r-project.org, http://socserv.socsci.mcmaster.ca/jfox/
>
> The 'Author' and 'Maintainer' fields should be automatically generated.
> With version 3.0.1, I had no such problem, and my coauthors who use Eciplse
> and R-studio have no problems with R 3.0.2.  John Fox suggested the
> following:
>
> When R CMD build creates a package tarball it writes the information from
> Authors at R into the
> Author and Maintainer fields. I think that Sandy's
> problem is produced by checking the package source directory rather than a
> package source tarball. I use RStudio to check packages, and it
> automatically builds the tarball first, which is the recommended procedure.
> R-Forge does that too. Michael uses Eclipse, and if I remember right, it too
> creates a tarball (but I haven't used it in quite some time).
>
> Is this a bug in R CMD check?
>
>
> --
> Sanford Weisberg, sandy at umn.edu
> <sandy at umn.edu>
> For undergraduate matters:  undergrad at stat.umn.edu
> University of Minnesota, School of Statistics
> 312 Ford Hall, 224 Church St. SE, Minneapolis, MN  55455
> 612-625-8355, FAX 612-624-8868
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From xie at yihui.name  Fri Oct 25 18:23:36 2013
From: xie at yihui.name (Yihui Xie)
Date: Fri, 25 Oct 2013 11:23:36 -0500
Subject: [Rd] appropriate work-around for problems with a specific plot
 device (Rstudio)?
In-Reply-To: <CALxY2Lf4SORY6a_t2sOmcs57cMat3qavVnGM+0coZWG2i8Nx1g@mail.gmail.com>
References: <5269B791.1040808@skyeome.net> <1382692784.7000.35.camel@milan>
	<CALxY2Lf4SORY6a_t2sOmcs57cMat3qavVnGM+0coZWG2i8Nx1g@mail.gmail.com>
Message-ID: <CANROs4dwUeDh6LMB=m0icfKTQrdj2F=77YXBpzpJEgpu61VJ7g@mail.gmail.com>

You can see how R sets up the device option in grDevices:::.onLoad,
but unfortunately the code there is not easily usable.

I think you can treat the NOTE in R CMD check as a false warning and
explain the situation to CRAN maintainers in the email. Code analysis
using codetools in R CMD check is not always reliable. I'm not sure if
grDevices::quartz, grDevices::x11, and grDevices::windows can "fix"
the NOTE.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Fri, Oct 25, 2013 at 9:24 AM, Lorenz, David <lorenz at usgs.gov> wrote:
> Skye,
>   I ran into a similar problem with RStudio. My solution was just to check
> if "windows" exists and if it does, open windows, then check "quartz" and
> so forth. You can restrict the exists function to look only in grDevices.
> Dave
>
>
> On Fri, Oct 25, 2013 at 4:19 AM, Milan Bouchet-Valat <nalimilan at club.fr>wrote:
>
>> Le jeudi 24 octobre 2013 ? 17:13 -0700, Skye Bender-deMoll a ?crit :
>> > Dear r-devel-opers,
>> >
>> > I'm working on a package that does some plot-intensive work using the
>> > animation library.  It turns out that this performs very badly in the
>> > RStudio plot device, which is the preferred IDE for our team.  Our
>> > kludgy solution is to detect if the Rstudio device is running, and if
>> > so, open another plot device to do the rendering and close it when done:
>> >
>> > externalDevice<-FALSE
>> >    if (!is.function(options()$device)){
>> >      if (names(dev.cur())=="RStudioGD"){
>> >        message("RStudio's graphics device is not well supported by ndtv,
>> > attempting to open another type of plot window")
>> >        # try to open a new platform-appropriate plot window
>> >        if (.Platform$OS.type=='windows'){
>> >          windows()
>> >        } else if(length(grep(R.version$platform,pattern='apple'))>0)  #
>> > is it mac?
>> >        {
>> >          quartz()
>> >        } else {  # must be unix
>> >          x11()
>> >        }
>> >        externalDevice<-TRUE
>> >      }
>> >    }
>> >
>> > [render a whole bunch of plot frames]
>> >
>> > # turn off external device if using one
>> >    if (externalDevice){
>> >      dev.off()
>> >    }
>> >
>> > Although this works well for us in practice, when testing against R
>> > devel, we get the following NOTE:
>> >
>> >
>> > * checking R code for possible problems ... NOTE
>> > Found an obsolete/platform-specific call in the following function:
>> >    ?render.animation?
>> > Found the platform-specific devices:
>> >    ?quartz? ?windows? ?x11?
>> > dev.new() is the preferred way to open a new device, in the unlikely
>> > event one is needed.
>> >
>> >
>> > Is there a better way to resolve this situation?  We can't use dev.new()
>> > to open the plot device, because RStudio has set the value of
>> > getOption("device") to "RStudioGD".  Can anyone recommend an alternative
>> > method of generating a platform-appropriate device to open that won't
>> > generate R CMD check issues?
>> How about temporarily changing the value of the "device" option to what
>> you need?
>>
>> I think you should also get in touch with RStudio developers to see
>> whether something can be done about the poor performance.
>>
>>
>> My two cents


From murdoch.duncan at gmail.com  Fri Oct 25 19:19:04 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 25 Oct 2013 13:19:04 -0400
Subject: [Rd] R CMD check problem with R 3.0.2
In-Reply-To: <CADkZVY7vuQv_nS+H_Xvb25v6k4tS9steZ86RkLhteGxK_9YHug@mail.gmail.com>
References: <CADkZVY7vuQv_nS+H_Xvb25v6k4tS9steZ86RkLhteGxK_9YHug@mail.gmail.com>
Message-ID: <526AA808.9080007@gmail.com>

On 25/10/2013 11:37 AM, Sanford Weisberg wrote:
> Using SUSE Linux, Windows 32 bit and Windows 64 bit R 3.0.2 , I am unable
> to use R CMD check successfully.  Here is the Windows 64 bit report:

Both checking and installing code are really designed to work on 
tarballs, as John said.  Some parts of them work on directories, because 
that can be a lot quicker (e.g. you may not need to recompile a ton of 
files), but you should expect to get some extra warnings or errors.  
Looks like you did.

Since there's an easy workaround for this (build before checking), I 
don't think it will be a high priority to fix, but feel free to submit 
it as a bug report, and someone will likely deal with it eventually.  
Please attach a tiny package that illustrates the error to your bug 
report (e.g. pkg with just about everything taken out).

Duncan Murdoch
>
>
> Z:\R\source\effects>R CMD check pkg
> * using log directory 'Z:/R/source/effects/pkg.Rcheck'
> * using R version 3.0.2 (2013-09-25)
> * using platform: x86_64-w64-mingw32 (64-bit)
> * using session charset: ISO8859-1
> * checking for file 'pkg/DESCRIPTION' ... ERROR
> Required fields missing or empty:
>    'Author' 'Maintainer'
>
> The file DESCRIPTION looks like this:
>
> Package: effects
> Version: 2.3-0
> Date: 2013/10/22
> Title: Effect Displays for Linear, Generalized Linear, Multinomial-Logit,
> Proportional-Odds Logit Models and Mixed-Effects Models
> Authors at R: c(person("John", "Fox", role = c("aut", "cre"), email = "
> jfox at mcmaster.ca"),
>      person("Sanford", "Weisberg", role = "aut", email = "sandy at umn.edu"),
>      person("Michael", "Friendly", role = "aut", email = "friendly at yorku.ca
> "),
>      person("Jangman", "Hong", role = "aut"),
>      person("Robert", "Andersen", role = "ctb"),
>      person("David", "Firth", role = "ctb"),
>      person("Steve", "Taylor", role = "ctb"))
> Depends: lattice, grid, colorspace
> Suggests: nlme, lme4, MASS, nnet, poLCA, heplots
> LazyLoad: yes
> LazyData: yes
> Description:
>    Graphical and tabular effect displays, e.g., of interactions, for linear
>    generalized linear, multinomial-logit, proportional-odds logit models,
>    mixed-effect models,  polytomous latent-class models and multivariate
> linear models.
> License: GPL (>= 2)
> URL: http://www.r-project.org, http://socserv.socsci.mcmaster.ca/jfox/
>
> The 'Author' and 'Maintainer' fields should be automatically generated.
> With version 3.0.1, I had no such problem, and my coauthors who use Eciplse
> and R-studio have no problems with R 3.0.2.  John Fox suggested the
> following:
>
> When R CMD build creates a package tarball it writes the information from
> Authors at R into the
> Author and Maintainer fields. I think that Sandy's
> problem is produced by checking the package source directory rather than a
> package source tarball. I use RStudio to check packages, and it
> automatically builds the tarball first, which is the recommended procedure.
> R-Forge does that too. Michael uses Eclipse, and if I remember right, it too
> creates a tarball (but I haven't used it in quite some time).
>
> Is this a bug in R CMD check?
>
>


From lawrence.michael at gene.com  Fri Oct 25 20:26:08 2013
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 25 Oct 2013 11:26:08 -0700
Subject: [Rd] advise on Depends
In-Reply-To: <CAC2h7usRKfUJpwq+hvgGmb_fQ4NhzQxhK1ynvWHQkjf8kw5Zbg@mail.gmail.com>
References: <CAC2h7usRKfUJpwq+hvgGmb_fQ4NhzQxhK1ynvWHQkjf8kw5Zbg@mail.gmail.com>
Message-ID: <CAOQ5Nyf=OtctzAgkTFL17w74++xzSgbBHB=p5WkAuxbsq7sO1w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131025/3455a63c/attachment.pl>

From plummerm at iarc.fr  Fri Oct 25 21:53:39 2013
From: plummerm at iarc.fr (Martyn Plummer)
Date: Fri, 25 Oct 2013 19:53:39 +0000
Subject: [Rd] Multivariate time series in R 3 vs R 2
In-Reply-To: <CAC4Co6NmORc1vHY3G2Kd40o-eiDB+pvWHXeVtfoJYivH1-+yMQ@mail.gmail.com>
References: <CAC4Co6NmORc1vHY3G2Kd40o-eiDB+pvWHXeVtfoJYivH1-+yMQ@mail.gmail.com>
Message-ID: <1382730814.12488.65.camel@braque.iarc.fr>

This has nothing to do with changes in base R. It is due to changes in
the dependent packages. These changes mean that when you call lapply it
does not dispatch the right as.list method.

The method you want (as.list.ts) is provided by the zoo package. It
splits a multivariate time series into a list of univariate time series
in the way you are expecting.  Your package mar1s used to depend on zoo
indirectly through the fda package. But now fda does not depend on zoo,
it only suggests it. So now, when you load your package, zoo is not on
the search path and you get the default as.list method, which produces
the bad results.

The solution is to add "Imports: zoo" to your DESCRIPTION file and
"import(zoo)" to your NAMESPACE file.

Martyn


On Wed, 2013-10-23 at 22:56 +0400, ?????? ????????? wrote:
> Hello!
> 
> Recently I got report that my package mar1s doesn't pass checks any more on
> R 3.0.2. I started to investigate and found the following difference in
> multivariate time series handling in R 3.0.2 compared to R 2 (I've checked
> on 2.14.0).
> 
> Suppose I wish to calculate seasonal component for time series. In case of
> multivariate time series, I wish to process each column independently. Let
> f be a simple (trivial) model of seasonal component:
> 
> f <- function(x)
>   return(ts(rep(0, length(x)), start = 0, frequency = frequency(x)))
> 
> In previous versions of R, I used the following compact and efficient
> expression to calculate seasonal component:
> 
> y <- do.call(cbind, lapply(x, f))
> 
> It worked equally good for univariate and multivariate time series:
> 
> > R.Version()$version.string
> [1] "R version 2.14.0 (2011-10-31)"
> > t <- ts(1:10, start = 100, frequency = 10)
> >
> > x <- t
> > y <- do.call(cbind, lapply(x, f))
> > y
> Time Series:
> Start = c(0, 1)
> End = c(0, 10)
> Frequency = 10
>  [1] 0 0 0 0 0 0 0 0 0 0
> >
> > x <- cbind(t, t)
> > y <- do.call(cbind, lapply(x, f))
> > y
> Time Series:
> Start = c(0, 1)
> End = c(0, 10)
> Frequency = 10
>     t t
> 0.0 0 0
> 0.1 0 0
> 0.2 0 0
> 0.3 0 0
> 0.4 0 0
> 0.5 0 0
> 0.6 0 0
> 0.7 0 0
> 0.8 0 0
> 0.9 0 0
> 
> But in version 3, I get some frustrating results:
> 
> > R.Version()$version.string
> [1] "R version 3.0.2 (2013-09-25)"
> > t <- ts(1:10, start = 100, frequency = 10)
> >
> > x <- t
> > y <- do.call(cbind, lapply(x, f))
> > y
> Time Series:
> Start = 0
> End = 0
> Frequency = 1
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
> >
> > x <- cbind(t, t)
> > y <- do.call(cbind, lapply(x, f))
> > y
> Time Series:
> Start = 0
> End = 0
> Frequency = 1
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
> 
> I didn't watch R development for quite some time now. Could anyone please
> help me to construct similar expression to what I have used in R 2, for
> multivariate case (or better, for both univariate and multivariate cases)?
> 
> Best wishes,
> Andrey Paramonov
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jmc at r-project.org  Fri Oct 25 22:39:53 2013
From: jmc at r-project.org (John Chambers)
Date: Fri, 25 Oct 2013 13:39:53 -0700
Subject: [Rd] advise on Depends
In-Reply-To: <CAOQ5Nyf=OtctzAgkTFL17w74++xzSgbBHB=p5WkAuxbsq7sO1w@mail.gmail.com>
References: <CAC2h7usRKfUJpwq+hvgGmb_fQ4NhzQxhK1ynvWHQkjf8kw5Zbg@mail.gmail.com>
	<CAOQ5Nyf=OtctzAgkTFL17w74++xzSgbBHB=p5WkAuxbsq7sO1w@mail.gmail.com>
Message-ID: <7E4EAF71-7FB8-42C6-9669-D128F3CCCC19@r-project.org>

One additional point to Michael's summary:

The "methods" package itself should stay in Depends:, to be safe.

There are a number of function calls to the methods package that may be included in generated methods for user classes.  These have not been revised to work when the methods package is not attached, so importing the package only may run into problems.  This has been an issue, for example, in using Rscript.

John

On Oct 25, 2013, at 11:26 AM, Michael Lawrence <lawrence.michael at gene.com> wrote:

> On Wed, Oct 23, 2013 at 8:33 PM, Kasper Daniel Hansen <
> kasperdanielhansen at gmail.com> wrote:
> 
>> This is about the new note
>> 
>> Depends: includes the non-default packages:
>>  ?BiocGenerics? ?Biobase? ?lattice? ?reshape? ?GenomicRanges?
>>  ?Biostrings? ?bumphunter?
>> Adding so many packages to the search path is excessive and importing
>> selectively is preferable.
>> 
>> Let us say my package A either uses a class B (by producing an object that
>> has B embedded as a slot) from another package or provides a specific
>> method for a generic defined in another package (both examples using S4).
>> In both case my impression is that best practices is I ought to Depend on
>> such a package, so it is a available at run time to the user.
>> 
>> 
> For classes, you just need to import the class with importClassesFrom().
> For generics, as long as your package exports the method with
> exportMethods(), the generic will also be exported from your package,
> regardless of whether the defining package is attached. And the methods
> from the loaded-but-not-attached packages are available for the generic. So
> neither of these two is really a problem.
> 
> The rationale for Depends is that the user might always want to use
> functions defined by another package with objects consumed/produced by your
> package, such as generics for which your package has not defined any
> methods. For example, rtracklayer Depends on GenomicRanges, because it
> imports objects from files as GenomicRanges objects.  So just consider what
> the user sees when looking at your API. What's private, what's public?
> 
> Michael
> 
> 
>> Comments?
>> 
>> Best,
>> Kasper
>> 
>>        [[alternative HTML version deleted]]
>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Fri Oct 25 22:58:00 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 25 Oct 2013 15:58:00 -0500
Subject: [Rd] advise on Depends
In-Reply-To: <7E4EAF71-7FB8-42C6-9669-D128F3CCCC19@r-project.org>
References: <CAC2h7usRKfUJpwq+hvgGmb_fQ4NhzQxhK1ynvWHQkjf8kw5Zbg@mail.gmail.com>
	<CAOQ5Nyf=OtctzAgkTFL17w74++xzSgbBHB=p5WkAuxbsq7sO1w@mail.gmail.com>
	<7E4EAF71-7FB8-42C6-9669-D128F3CCCC19@r-project.org>
Message-ID: <21098.56152.866708.506242@max.nulle.part>


On 25 October 2013 at 13:39, John Chambers wrote:
| One additional point to Michael's summary:
| 
| The "methods" package itself should stay in Depends:, to be safe.
| 
| There are a number of function calls to the methods package that may be included in generated methods for user classes.  These have not been revised to work when the methods package is not attached, so importing the package only may run into problems.  This has been an issue, for example, in using Rscript.

Right.  

Our command-line / scripting frontend r from the littler package has always
defaulted to loading "methods".  And as r is a small and fully compiled
binary, it still starts up faster than Rscript by a nice margin even though
it has to load the "methods" package.  But who cares about 200 msec.  :)

Dirk

-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From hb at biostat.ucsf.edu  Fri Oct 25 23:21:23 2013
From: hb at biostat.ucsf.edu (Henrik Bengtsson)
Date: Fri, 25 Oct 2013 14:21:23 -0700
Subject: [Rd] advise on Depends
In-Reply-To: <7E4EAF71-7FB8-42C6-9669-D128F3CCCC19@r-project.org>
References: <CAC2h7usRKfUJpwq+hvgGmb_fQ4NhzQxhK1ynvWHQkjf8kw5Zbg@mail.gmail.com>
	<CAOQ5Nyf=OtctzAgkTFL17w74++xzSgbBHB=p5WkAuxbsq7sO1w@mail.gmail.com>
	<7E4EAF71-7FB8-42C6-9669-D128F3CCCC19@r-project.org>
Message-ID: <CAFDcVCQfQtvx1CF3x7WU95Du_BDHLq5+ey4mB-OnTNC68aZsBw@mail.gmail.com>

On Fri, Oct 25, 2013 at 1:39 PM, John Chambers <jmc at r-project.org> wrote:
> One additional point to Michael's summary:
>
> The "methods" package itself should stay in Depends:, to be safe.
>
> There are a number of function calls to the methods package that may be included in generated methods for user classes.  These have not been revised to work when the methods package is not attached, so importing the package only may run into problems.  This has been an issue, for example, in using Rscript.

To clarify that last sentence for those not aware (and hopefully spare
someone having to troubleshoot this), executing R scripts/expressions
using 'Rscript' rather than 'R' differs by which packages are attached
by default.  Example:

% Rscript -e "search()"
[1] ".GlobalEnv"        "package:stats"     "package:graphics"
[4] "package:grDevices" "package:utils"     "package:datasets"
[7] "Autoloads"         "package:base"

% R --quiet -e "search()"
> search()
[1] ".GlobalEnv"        "package:stats"     "package:graphics"
[4] "package:grDevices" "package:utils"     "package:datasets"
[7] "package:methods"   "Autoloads"         "package:base"

Note how 'methods' is not attached when using Rscript.  This is
explained in help("Rscript"), help("options"), and in 'R Installation
and Administration'.

/Henrik


>
> John
>
> On Oct 25, 2013, at 11:26 AM, Michael Lawrence <lawrence.michael at gene.com> wrote:
>
>> On Wed, Oct 23, 2013 at 8:33 PM, Kasper Daniel Hansen <
>> kasperdanielhansen at gmail.com> wrote:
>>
>>> This is about the new note
>>>
>>> Depends: includes the non-default packages:
>>>  ?BiocGenerics? ?Biobase? ?lattice? ?reshape? ?GenomicRanges?
>>>  ?Biostrings? ?bumphunter?
>>> Adding so many packages to the search path is excessive and importing
>>> selectively is preferable.
>>>
>>> Let us say my package A either uses a class B (by producing an object that
>>> has B embedded as a slot) from another package or provides a specific
>>> method for a generic defined in another package (both examples using S4).
>>> In both case my impression is that best practices is I ought to Depend on
>>> such a package, so it is a available at run time to the user.
>>>
>>>
>> For classes, you just need to import the class with importClassesFrom().
>> For generics, as long as your package exports the method with
>> exportMethods(), the generic will also be exported from your package,
>> regardless of whether the defining package is attached. And the methods
>> from the loaded-but-not-attached packages are available for the generic. So
>> neither of these two is really a problem.
>>
>> The rationale for Depends is that the user might always want to use
>> functions defined by another package with objects consumed/produced by your
>> package, such as generics for which your package has not defined any
>> methods. For example, rtracklayer Depends on GenomicRanges, because it
>> imports objects from files as GenomicRanges objects.  So just consider what
>> the user sees when looking at your API. What's private, what's public?
>>
>> Michael
>>
>>
>>> Comments?
>>>
>>> Best,
>>> Kasper
>>>
>>>        [[alternative HTML version deleted]]
>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>>
>>       [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From pgilbert902 at gmail.com  Sat Oct 26 00:46:31 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Fri, 25 Oct 2013 18:46:31 -0400
Subject: [Rd] advise on Depends
In-Reply-To: <CAFDcVCQfQtvx1CF3x7WU95Du_BDHLq5+ey4mB-OnTNC68aZsBw@mail.gmail.com>
References: <CAC2h7usRKfUJpwq+hvgGmb_fQ4NhzQxhK1ynvWHQkjf8kw5Zbg@mail.gmail.com>	<CAOQ5Nyf=OtctzAgkTFL17w74++xzSgbBHB=p5WkAuxbsq7sO1w@mail.gmail.com>	<7E4EAF71-7FB8-42C6-9669-D128F3CCCC19@r-project.org>
	<CAFDcVCQfQtvx1CF3x7WU95Du_BDHLq5+ey4mB-OnTNC68aZsBw@mail.gmail.com>
Message-ID: <526AF4C7.2020808@gmail.com>



On 13-10-25 05:21 PM, Henrik Bengtsson wrote:
> On Fri, Oct 25, 2013 at 1:39 PM, John Chambers <jmc at r-project.org>
> wrote:
>> One additional point to Michael's summary:
>>
>> The "methods" package itself should stay in Depends:, to be safe.

It would be nice to have more detail about when this is necessary, 
rather than suggested as a general workaround. I thought the principle 
of putting things in Imports was that it is safer. I have methods listed 
in Imports rather than Depends in 16 of my packages, doing roughly what 
was the basis for the original question, and I am not aware of a 
problem, yet.

Paul

>>
>> There are a number of function calls to the methods package that
>> may be included in generated methods for user classes.  These have
>> not been revised to work when the methods package is not attached,
>> so importing the package only may run into problems.  This has been
>> an issue, for example, in using Rscript.
>
> To clarify that last sentence for those not aware (and hopefully
> spare someone having to troubleshoot this), executing R
> scripts/expressions using 'Rscript' rather than 'R' differs by which
> packages are attached by default.  Example:
>
> % Rscript -e "search()" [1] ".GlobalEnv"        "package:stats"
> "package:graphics" [4] "package:grDevices" "package:utils"
> "package:datasets" [7] "Autoloads"         "package:base"
>
> % R --quiet -e "search()"
>> search()
> [1] ".GlobalEnv"        "package:stats"     "package:graphics" [4]
> "package:grDevices" "package:utils"     "package:datasets" [7]
> "package:methods"   "Autoloads"         "package:base"
>
> Note how 'methods' is not attached when using Rscript.  This is
> explained in help("Rscript"), help("options"), and in 'R
> Installation and Administration'.
>
> /Henrik
>
>
>>
>> John
>>
>> On Oct 25, 2013, at 11:26 AM, Michael Lawrence
>> <lawrence.michael at gene.com> wrote:
>>
>>> On Wed, Oct 23, 2013 at 8:33 PM, Kasper Daniel Hansen <
>>> kasperdanielhansen at gmail.com> wrote:
>>>
>>>> This is about the new note
>>>>
>>>> Depends: includes the non-default packages: ?BiocGenerics?
>>>> ?Biobase? ?lattice? ?reshape? ?GenomicRanges? ?Biostrings?
>>>> ?bumphunter? Adding so many packages to the search path is
>>>> excessive and importing selectively is preferable.
>>>>
>>>> Let us say my package A either uses a class B (by producing an
>>>> object that has B embedded as a slot) from another package or
>>>> provides a specific method for a generic defined in another
>>>> package (both examples using S4). In both case my impression is
>>>> that best practices is I ought to Depend on such a package, so
>>>> it is a available at run time to the user.
>>>>
>>>>
>>> For classes, you just need to import the class with
>>> importClassesFrom(). For generics, as long as your package
>>> exports the method with exportMethods(), the generic will also be
>>> exported from your package, regardless of whether the defining
>>> package is attached. And the methods from the
>>> loaded-but-not-attached packages are available for the generic.
>>> So neither of these two is really a problem.
>>>
>>> The rationale for Depends is that the user might always want to
>>> use functions defined by another package with objects
>>> consumed/produced by your package, such as generics for which
>>> your package has not defined any methods. For example,
>>> rtracklayer Depends on GenomicRanges, because it imports objects
>>> from files as GenomicRanges objects.  So just consider what the
>>> user sees when looking at your API. What's private, what's
>>> public?
>>>
>>> Michael
>>>
>>>
>>>> Comments?
>>>>
>>>> Best, Kasper
>>>>
>>>> [[alternative HTML version deleted]]
>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>>
>>>
>>> [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________ R-devel at r-project.org
> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jmc at r-project.org  Sat Oct 26 02:15:56 2013
From: jmc at r-project.org (John Chambers)
Date: Fri, 25 Oct 2013 17:15:56 -0700
Subject: [Rd] advise on Depends
In-Reply-To: <526AF4C7.2020808@gmail.com>
References: <CAC2h7usRKfUJpwq+hvgGmb_fQ4NhzQxhK1ynvWHQkjf8kw5Zbg@mail.gmail.com>	<CAOQ5Nyf=OtctzAgkTFL17w74++xzSgbBHB=p5WkAuxbsq7sO1w@mail.gmail.com>	<7E4EAF71-7FB8-42C6-9669-D128F3CCCC19@r-project.org>
	<CAFDcVCQfQtvx1CF3x7WU95Du_BDHLq5+ey4mB-OnTNC68aZsBw@mail.gmail.com>
	<526AF4C7.2020808@gmail.com>
Message-ID: <45E32099-C8F1-4C06-868E-DFA7C33E48D9@r-project.org>

Software generated in methods for user classes calls functions in the methods package, as I said.  I don't  know the circumstances (if any) when such calls fail to find functions if  the whole package is  imported.   Perhaps someone on this list may have examples.

But for sure just importing the functions your package calls during installation (setClass(), setMethod(), etc.) won't always be enough.

When the S4 classes and methods were implemented in R in the early 2000s, it was assumed that the methods package would be considered part of the system, as the analogous code was in S.  

It would be nice to either have the package included in Rscript, CMD check, etc. or for some enterprising and very thorough person to go through and bullet-proof the generated code for the absence of the package from the search list.

Absent either of those, the defensive approach is to put methods in Depends.   Or at least, import the package rather than just the obvious functions.

John


On Oct 25, 2013, at 3:46 PM, Paul Gilbert <pgilbert902 at gmail.com> wrote:

> 
> 
> On 13-10-25 05:21 PM, Henrik Bengtsson wrote:
>> On Fri, Oct 25, 2013 at 1:39 PM, John Chambers <jmc at r-project.org>
>> wrote:
>>> One additional point to Michael's summary:
>>> 
>>> The "methods" package itself should stay in Depends:, to be safe.
> 
> It would be nice to have more detail about when this is necessary, rather than suggested as a general workaround. I thought the principle of putting things in Imports was that it is safer. I have methods listed in Imports rather than Depends in 16 of my packages, doing roughly what was the basis for the original question, and I am not aware of a problem, yet.
> 
> Paul
> 
>>> 
>>> There are a number of function calls to the methods package that
>>> may be included in generated methods for user classes.  These have
>>> not been revised to work when the methods package is not attached,
>>> so importing the package only may run into problems.  This has been
>>> an issue, for example, in using Rscript.
>> 
>> To clarify that last sentence for those not aware (and hopefully
>> spare someone having to troubleshoot this), executing R
>> scripts/expressions using 'Rscript' rather than 'R' differs by which
>> packages are attached by default.  Example:
>> 
>> % Rscript -e "search()" [1] ".GlobalEnv"        "package:stats"
>> "package:graphics" [4] "package:grDevices" "package:utils"
>> "package:datasets" [7] "Autoloads"         "package:base"
>> 
>> % R --quiet -e "search()"
>>> search()
>> [1] ".GlobalEnv"        "package:stats"     "package:graphics" [4]
>> "package:grDevices" "package:utils"     "package:datasets" [7]
>> "package:methods"   "Autoloads"         "package:base"
>> 
>> Note how 'methods' is not attached when using Rscript.  This is
>> explained in help("Rscript"), help("options"), and in 'R
>> Installation and Administration'.
>> 
>> /Henrik
>> 
>> 
>>> 
>>> John
>>> 
>>> On Oct 25, 2013, at 11:26 AM, Michael Lawrence
>>> <lawrence.michael at gene.com> wrote:
>>> 
>>>> On Wed, Oct 23, 2013 at 8:33 PM, Kasper Daniel Hansen <
>>>> kasperdanielhansen at gmail.com> wrote:
>>>> 
>>>>> This is about the new note
>>>>> 
>>>>> Depends: includes the non-default packages: ?BiocGenerics?
>>>>> ?Biobase? ?lattice? ?reshape? ?GenomicRanges? ?Biostrings?
>>>>> ?bumphunter? Adding so many packages to the search path is
>>>>> excessive and importing selectively is preferable.
>>>>> 
>>>>> Let us say my package A either uses a class B (by producing an
>>>>> object that has B embedded as a slot) from another package or
>>>>> provides a specific method for a generic defined in another
>>>>> package (both examples using S4). In both case my impression is
>>>>> that best practices is I ought to Depend on such a package, so
>>>>> it is a available at run time to the user.
>>>>> 
>>>>> 
>>>> For classes, you just need to import the class with
>>>> importClassesFrom(). For generics, as long as your package
>>>> exports the method with exportMethods(), the generic will also be
>>>> exported from your package, regardless of whether the defining
>>>> package is attached. And the methods from the
>>>> loaded-but-not-attached packages are available for the generic.
>>>> So neither of these two is really a problem.
>>>> 
>>>> The rationale for Depends is that the user might always want to
>>>> use functions defined by another package with objects
>>>> consumed/produced by your package, such as generics for which
>>>> your package has not defined any methods. For example,
>>>> rtracklayer Depends on GenomicRanges, because it imports objects
>>>> from files as GenomicRanges objects.  So just consider what the
>>>> user sees when looking at your API. What's private, what's
>>>> public?
>>>> 
>>>> Michael
>>>> 
>>>> 
>>>>> Comments?
>>>>> 
>>>>> Best, Kasper
>>>>> 
>>>>> [[alternative HTML version deleted]]
>>>>> 
>>>>> 
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>> 
>>>>> 
>>>> 
>>>> [[alternative HTML version deleted]]
>>>> 
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> ______________________________________________ R-devel at r-project.org
>> mailing list https://stat.ethz.ch/mailman/listinfo/r-devel
>> 


From hpages at fhcrc.org  Sat Oct 26 03:05:51 2013
From: hpages at fhcrc.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Fri, 25 Oct 2013 18:05:51 -0700
Subject: [Rd] advise on Depends
In-Reply-To: <CAOQ5Nyf=OtctzAgkTFL17w74++xzSgbBHB=p5WkAuxbsq7sO1w@mail.gmail.com>
References: <CAC2h7usRKfUJpwq+hvgGmb_fQ4NhzQxhK1ynvWHQkjf8kw5Zbg@mail.gmail.com>
	<CAOQ5Nyf=OtctzAgkTFL17w74++xzSgbBHB=p5WkAuxbsq7sO1w@mail.gmail.com>
Message-ID: <526B156F.7000502@fhcrc.org>

On 10/25/2013 11:26 AM, Michael Lawrence wrote:
> On Wed, Oct 23, 2013 at 8:33 PM, Kasper Daniel Hansen <
> kasperdanielhansen at gmail.com> wrote:
>
>> This is about the new note
>>
>> Depends: includes the non-default packages:
>>    ?BiocGenerics? ?Biobase? ?lattice? ?reshape? ?GenomicRanges?
>>    ?Biostrings? ?bumphunter?
>> Adding so many packages to the search path is excessive and importing
>> selectively is preferable.
>>
>> Let us say my package A either uses a class B (by producing an object that
>> has B embedded as a slot) from another package or provides a specific
>> method for a generic defined in another package (both examples using S4).
>>   In both case my impression is that best practices is I ought to Depend on
>> such a package, so it is a available at run time to the user.
>>
>>
> For classes, you just need to import the class with importClassesFrom().
> For generics, as long as your package exports the method with
> exportMethods(), the generic will also be exported from your package,
> regardless of whether the defining package is attached. And the methods
> from the loaded-but-not-attached packages are available for the generic. So
> neither of these two is really a problem.
>
> The rationale for Depends is that the user might always want to use
> functions defined by another package with objects consumed/produced by your
> package, such as generics for which your package has not defined any
> methods. For example, rtracklayer Depends on GenomicRanges, because it
> imports objects from files as GenomicRanges objects.  So just consider what
> the user sees when looking at your API. What's private, what's public?

And also the user should be able to use ? to access the full
documentation of what is public. This means that if your package
defines and exports a method for a generic defined elsewhere, it should
"Depends" on the package where the generic is defined. Same thing if
your package extends a class defined elsewhere.

Cheers,
H.

>
> Michael
>
>
>> Comments?
>>
>> Best,
>> Kasper
>>
>>          [[alternative HTML version deleted]]
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fhcrc.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From cmr.pent at gmail.com  Sat Oct 26 03:05:40 2013
From: cmr.pent at gmail.com (=?UTF-8?B?0JDQvdC00YDQtdC5INCf0LDRgNCw0LzQvtC90L7Qsg==?=)
Date: Sat, 26 Oct 2013 05:05:40 +0400
Subject: [Rd] Multivariate time series in R 3 vs R 2
In-Reply-To: <1382730814.12488.65.camel@braque.iarc.fr>
References: <CAC4Co6NmORc1vHY3G2Kd40o-eiDB+pvWHXeVtfoJYivH1-+yMQ@mail.gmail.com>
	<1382730814.12488.65.camel@braque.iarc.fr>
Message-ID: <CAC4Co6PgRGYp=P+4j2=abK6yZeWVO-VXsZb0QbfwSeeGccwP=w@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131026/2f5f9cd7/attachment.pl>

From ggrothendieck at gmail.com  Sat Oct 26 15:00:41 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Sat, 26 Oct 2013 09:00:41 -0400
Subject: [Rd] Multivariate time series in R 3 vs R 2
In-Reply-To: <CAC4Co6NmORc1vHY3G2Kd40o-eiDB+pvWHXeVtfoJYivH1-+yMQ@mail.gmail.com>
References: <CAC4Co6NmORc1vHY3G2Kd40o-eiDB+pvWHXeVtfoJYivH1-+yMQ@mail.gmail.com>
Message-ID: <CAP01uRkGRjZ6cYyK2DSddXTjXY1nZ-Mc4ZAnGGw56F74n1yBaQ@mail.gmail.com>

On Wed, Oct 23, 2013 at 2:56 PM, ?????? ????????? <cmr.pent at gmail.com> wrote:
> Hello!
>
> Recently I got report that my package mar1s doesn't pass checks any more on
> R 3.0.2. I started to investigate and found the following difference in
> multivariate time series handling in R 3.0.2 compared to R 2 (I've checked
> on 2.14.0).
>
> Suppose I wish to calculate seasonal component for time series. In case of
> multivariate time series, I wish to process each column independently. Let
> f be a simple (trivial) model of seasonal component:
>
> f <- function(x)
>   return(ts(rep(0, length(x)), start = 0, frequency = frequency(x)))
>
> In previous versions of R, I used the following compact and efficient
> expression to calculate seasonal component:
>
> y <- do.call(cbind, lapply(x, f))
>
> It worked equally good for univariate and multivariate time series:
>
>> R.Version()$version.string
> [1] "R version 2.14.0 (2011-10-31)"
>> t <- ts(1:10, start = 100, frequency = 10)
>>
>> x <- t
>> y <- do.call(cbind, lapply(x, f))
>> y
> Time Series:
> Start = c(0, 1)
> End = c(0, 10)
> Frequency = 10
>  [1] 0 0 0 0 0 0 0 0 0 0
>>
>> x <- cbind(t, t)
>> y <- do.call(cbind, lapply(x, f))
>> y
> Time Series:
> Start = c(0, 1)
> End = c(0, 10)
> Frequency = 10
>     t t
> 0.0 0 0
> 0.1 0 0
> 0.2 0 0
> 0.3 0 0
> 0.4 0 0
> 0.5 0 0
> 0.6 0 0
> 0.7 0 0
> 0.8 0 0
> 0.9 0 0
>
> But in version 3, I get some frustrating results:
>
>> R.Version()$version.string
> [1] "R version 3.0.2 (2013-09-25)"
>> t <- ts(1:10, start = 100, frequency = 10)
>>
>> x <- t
>> y <- do.call(cbind, lapply(x, f))
>> y
> Time Series:
> Start = 0
> End = 0
> Frequency = 1
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>   structure(0, .Tsp = c(0, 0, 1), class = "ts")
> 0                                             0
>>


I get the same results in R-2.14.0 and R-3.02.  They both give the
result shown above with the structures in the output.  I used
"R version 2.14.0 (2011-10-31)".

Try starting a clean session in R 2.14.0 using:

R --vanilla

and try it again.


From simon.urbanek at r-project.org  Sun Oct 27 02:49:52 2013
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Sat, 26 Oct 2013 21:49:52 -0400
Subject: [Rd] R CMD check problem with R 3.0.2
In-Reply-To: <CANROs4c=0JJ0uefWezkPwYvCkZYGTLwszJ7xGJJ1REOjfGLzGA@mail.gmail.com>
References: <CADkZVY7vuQv_nS+H_Xvb25v6k4tS9steZ86RkLhteGxK_9YHug@mail.gmail.com>
	<CANROs4c=0JJ0uefWezkPwYvCkZYGTLwszJ7xGJJ1REOjfGLzGA@mail.gmail.com>
Message-ID: <63F17EA6-66E3-4C6D-9FF6-E17DBB6B084A@r-project.org>

On Oct 25, 2013, at 12:12 PM, Yihui Xie wrote:

> This has been asked soooo many times that I think it may be a good
> idea for R CMD check to just stop when the user passes a directory
> instead of a tar ball to it, or automatically run R CMD build before
> moving on. In my opinion, sometimes an FAQ and a bug are not entirely
> different.
> 

+1 -- and I'd do the same for R CMD INSTALL. If someone insists, there could be --force or something like that for those that really want to work on directories despite all the issues with that, but IMHO the default should be for both INSTALL and check to bail out if not presented with a file -- it would save a lot of people a lot of time spent in chasing ghost issues.

Cheers,
Simon



> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> Department of Statistics, Iowa State University
> 2215 Snedecor Hall, Ames, IA
> 
> 
> On Fri, Oct 25, 2013 at 10:37 AM, Sanford Weisberg <sandy at umn.edu> wrote:
>> Using SUSE Linux, Windows 32 bit and Windows 64 bit R 3.0.2 , I am unable
>> to use R CMD check successfully.  Here is the Windows 64 bit report:
>> 
>> 
>> Z:\R\source\effects>R CMD check pkg
>> * using log directory 'Z:/R/source/effects/pkg.Rcheck'
>> * using R version 3.0.2 (2013-09-25)
>> * using platform: x86_64-w64-mingw32 (64-bit)
>> * using session charset: ISO8859-1
>> * checking for file 'pkg/DESCRIPTION' ... ERROR
>> Required fields missing or empty:
>>  'Author' 'Maintainer'
>> 
>> The file DESCRIPTION looks like this:
>> 
>> Package: effects
>> Version: 2.3-0
>> Date: 2013/10/22
>> Title: Effect Displays for Linear, Generalized Linear, Multinomial-Logit,
>> Proportional-Odds Logit Models and Mixed-Effects Models
>> Authors at R: c(person("John", "Fox", role = c("aut", "cre"), email = "
>> jfox at mcmaster.ca"),
>>    person("Sanford", "Weisberg", role = "aut", email = "sandy at umn.edu"),
>>    person("Michael", "Friendly", role = "aut", email = "friendly at yorku.ca
>> "),
>>    person("Jangman", "Hong", role = "aut"),
>>    person("Robert", "Andersen", role = "ctb"),
>>    person("David", "Firth", role = "ctb"),
>>    person("Steve", "Taylor", role = "ctb"))
>> Depends: lattice, grid, colorspace
>> Suggests: nlme, lme4, MASS, nnet, poLCA, heplots
>> LazyLoad: yes
>> LazyData: yes
>> Description:
>>  Graphical and tabular effect displays, e.g., of interactions, for linear
>>  generalized linear, multinomial-logit, proportional-odds logit models,
>>  mixed-effect models,  polytomous latent-class models and multivariate
>> linear models.
>> License: GPL (>= 2)
>> URL: http://www.r-project.org, http://socserv.socsci.mcmaster.ca/jfox/
>> 
>> The 'Author' and 'Maintainer' fields should be automatically generated.
>> With version 3.0.1, I had no such problem, and my coauthors who use Eciplse
>> and R-studio have no problems with R 3.0.2.  John Fox suggested the
>> following:
>> 
>> When R CMD build creates a package tarball it writes the information from
>> Authors at R into the
>> Author and Maintainer fields. I think that Sandy's
>> problem is produced by checking the package source directory rather than a
>> package source tarball. I use RStudio to check packages, and it
>> automatically builds the tarball first, which is the recommended procedure.
>> R-Forge does that too. Michael uses Eclipse, and if I remember right, it too
>> creates a tarball (but I haven't used it in quite some time).
>> 
>> Is this a bug in R CMD check?
>> 
>> 
>> --
>> Sanford Weisberg, sandy at umn.edu
>> <sandy at umn.edu>
>> For undergraduate matters:  undergrad at stat.umn.edu
>> University of Minnesota, School of Statistics
>> 312 Ford Hall, 224 Church St. SE, Minneapolis, MN  55455
>> 612-625-8355, FAX 612-624-8868
>> 
>>        [[alternative HTML version deleted]]
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From murdoch.duncan at gmail.com  Sun Oct 27 13:56:31 2013
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 27 Oct 2013 08:56:31 -0400
Subject: [Rd] R CMD check problem with R 3.0.2
In-Reply-To: <63F17EA6-66E3-4C6D-9FF6-E17DBB6B084A@r-project.org>
References: <CADkZVY7vuQv_nS+H_Xvb25v6k4tS9steZ86RkLhteGxK_9YHug@mail.gmail.com>	<CANROs4c=0JJ0uefWezkPwYvCkZYGTLwszJ7xGJJ1REOjfGLzGA@mail.gmail.com>
	<63F17EA6-66E3-4C6D-9FF6-E17DBB6B084A@r-project.org>
Message-ID: <526D0D7F.9010707@gmail.com>

On 13-10-26 9:49 PM, Simon Urbanek wrote:
> On Oct 25, 2013, at 12:12 PM, Yihui Xie wrote:
>
>> This has been asked soooo many times that I think it may be a good
>> idea for R CMD check to just stop when the user passes a directory
>> instead of a tar ball to it, or automatically run R CMD build before
>> moving on. In my opinion, sometimes an FAQ and a bug are not entirely
>> different.
>>
>
> +1 -- and I'd do the same for R CMD INSTALL. If someone insists, there could be --force or something like that for those that really want to work on directories despite all the issues with that, but IMHO the default should be for both INSTALL and check to bail out if not presented with a file -- it would save a lot of people a lot of time spent in chasing ghost issues.

That seems like a reasonable suggestion.  I wouldn't want to lose the 
ability to install or check a directory; for development of packages 
like rgl which have a lot of compiled code, installing from a tarball 
takes a lot longer than installing when all of the code has already been 
compiled.

On the other hand, it isn't all that hard to put together an R function 
or shell script to do it (the hardest part is figuring out the name of 
the tarball).  For example:

installpkgdir <- function(dir) {
   x <- system(paste("R CMD build", dir), intern=TRUE)
   cat(x, sep="\n")
   tarball <- grep("^\\* building '", x, value = TRUE)
   if (length(tarball) == 1) {
     tarball <- sub("^\\* building '", "", tarball)
     tarball <- sub("'$", "", tarball)
     system(paste("R CMD INSTALL", tarball))
   }
}

I haven't tested this much, and it doesn't offer options to the build or 
install steps, but it could be the basis of a simple function that 
always builds a tarball before installing a source directory.

Duncan Murdoch


> Cheers,
> Simon
>
>
>
>> Regards,
>> Yihui
>> --
>> Yihui Xie <xieyihui at gmail.com>
>> Web: http://yihui.name
>> Department of Statistics, Iowa State University
>> 2215 Snedecor Hall, Ames, IA
>>
>>
>> On Fri, Oct 25, 2013 at 10:37 AM, Sanford Weisberg <sandy at umn.edu> wrote:
>>> Using SUSE Linux, Windows 32 bit and Windows 64 bit R 3.0.2 , I am unable
>>> to use R CMD check successfully.  Here is the Windows 64 bit report:
>>>
>>>
>>> Z:\R\source\effects>R CMD check pkg
>>> * using log directory 'Z:/R/source/effects/pkg.Rcheck'
>>> * using R version 3.0.2 (2013-09-25)
>>> * using platform: x86_64-w64-mingw32 (64-bit)
>>> * using session charset: ISO8859-1
>>> * checking for file 'pkg/DESCRIPTION' ... ERROR
>>> Required fields missing or empty:
>>>   'Author' 'Maintainer'
>>>
>>> The file DESCRIPTION looks like this:
>>>
>>> Package: effects
>>> Version: 2.3-0
>>> Date: 2013/10/22
>>> Title: Effect Displays for Linear, Generalized Linear, Multinomial-Logit,
>>> Proportional-Odds Logit Models and Mixed-Effects Models
>>> Authors at R: c(person("John", "Fox", role = c("aut", "cre"), email = "
>>> jfox at mcmaster.ca"),
>>>     person("Sanford", "Weisberg", role = "aut", email = "sandy at umn.edu"),
>>>     person("Michael", "Friendly", role = "aut", email = "friendly at yorku.ca
>>> "),
>>>     person("Jangman", "Hong", role = "aut"),
>>>     person("Robert", "Andersen", role = "ctb"),
>>>     person("David", "Firth", role = "ctb"),
>>>     person("Steve", "Taylor", role = "ctb"))
>>> Depends: lattice, grid, colorspace
>>> Suggests: nlme, lme4, MASS, nnet, poLCA, heplots
>>> LazyLoad: yes
>>> LazyData: yes
>>> Description:
>>>   Graphical and tabular effect displays, e.g., of interactions, for linear
>>>   generalized linear, multinomial-logit, proportional-odds logit models,
>>>   mixed-effect models,  polytomous latent-class models and multivariate
>>> linear models.
>>> License: GPL (>= 2)
>>> URL: http://www.r-project.org, http://socserv.socsci.mcmaster.ca/jfox/
>>>
>>> The 'Author' and 'Maintainer' fields should be automatically generated.
>>> With version 3.0.1, I had no such problem, and my coauthors who use Eciplse
>>> and R-studio have no problems with R 3.0.2.  John Fox suggested the
>>> following:
>>>
>>> When R CMD build creates a package tarball it writes the information from
>>> Authors at R into the
>>> Author and Maintainer fields. I think that Sandy's
>>> problem is produced by checking the package source directory rather than a
>>> package source tarball. I use RStudio to check packages, and it
>>> automatically builds the tarball first, which is the recommended procedure.
>>> R-Forge does that too. Michael uses Eclipse, and if I remember right, it too
>>> creates a tarball (but I haven't used it in quite some time).
>>>
>>> Is this a bug in R CMD check?
>>>
>>>
>>> --
>>> Sanford Weisberg, sandy at umn.edu
>>> <sandy at umn.edu>
>>> For undergraduate matters:  undergrad at stat.umn.edu
>>> University of Minnesota, School of Statistics
>>> 312 Ford Hall, 224 Church St. SE, Minneapolis, MN  55455
>>> 612-625-8355, FAX 612-624-8868
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From cmr.pent at gmail.com  Sun Oct 27 14:16:10 2013
From: cmr.pent at gmail.com (=?UTF-8?B?0JDQvdC00YDQtdC5INCf0LDRgNCw0LzQvtC90L7Qsg==?=)
Date: Sun, 27 Oct 2013 17:16:10 +0400
Subject: [Rd] Multivariate time series in R 3 vs R 2
In-Reply-To: <CAP01uRkGRjZ6cYyK2DSddXTjXY1nZ-Mc4ZAnGGw56F74n1yBaQ@mail.gmail.com>
References: <CAC4Co6NmORc1vHY3G2Kd40o-eiDB+pvWHXeVtfoJYivH1-+yMQ@mail.gmail.com>
	<CAP01uRkGRjZ6cYyK2DSddXTjXY1nZ-Mc4ZAnGGw56F74n1yBaQ@mail.gmail.com>
Message-ID: <CAC4Co6OdM2XoPX2eDr-SpM5NscgFZ9dDyTvh-Kwbb0NDrsZkbA@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131027/e8dea7d9/attachment.pl>

From therneau at mayo.edu  Mon Oct 28 14:22:27 2013
From: therneau at mayo.edu (Terry Therneau)
Date: Mon, 28 Oct 2013 08:22:27 -0500
Subject: [Rd] R CMD check issue with R 3.0.2
In-Reply-To: <mailman.13.1382958005.936.r-devel@r-project.org>
References: <mailman.13.1382958005.936.r-devel@r-project.org>
Message-ID: <526E6513.4040801@mayo.edu>



On 10/28/2013 06:00 AM, r-devel-request at r-project.org wrote:
> On 13-10-26 9:49 PM, Simon Urbanek wrote:
>> >  On Oct 25, 2013, at 12:12 PM, Yihui Xie wrote:
>> >
>>> >>  This has been asked soooo many times that I think it may be a good
>>> >>  idea for R CMD check to just stop when the user passes a directory
>>> >>  instead of a tar ball to it, or automatically run R CMD build before
>>> >>  moving on. In my opinion, sometimes an FAQ and a bug are not entirely
>>> >>  different.
>>> >>
>> >
>> >  +1 -- and I'd do the same for R CMD INSTALL. If someone insists, there could be --force or something like that for those that really want to work on directories despite all the issues with that, but IMHO the default should be for both INSTALL and check to bail out if not presented with a file -- it would save a lot of people a lot of time spent in chasing ghost issues.
> That seems like a reasonable suggestion.  I wouldn't want to lose the
> ability to install or check a directory; for development of packages
> like rgl which have a lot of compiled code, installing from a tarball
> takes a lot longer than installing when all of the code has already been
> compiled.

I use R CMD check on directories often.  The survival and coxme pacakges have large test 
suites, and before things are packaged up for R forge there are may be multiple iterations 
to get past all of them.  (Add one new idea, break something old).  Creating the tarball 
is slow due to vignettes.
   Thus I would hate to see it outlawed. Of course I know enough to ignore many of the 
warnings during this testing stage, I do use the tarball for my final run, and I 
understand the noise level that this option incurs on R-devel.

Terry T.


From maechler at stat.math.ethz.ch  Mon Oct 28 18:40:30 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Mon, 28 Oct 2013 18:40:30 +0100
Subject: [Rd] R CMD check problem with R 3.0.2
In-Reply-To: <526D0D7F.9010707@gmail.com>
References: <CADkZVY7vuQv_nS+H_Xvb25v6k4tS9steZ86RkLhteGxK_9YHug@mail.gmail.com>
	<CANROs4c=0JJ0uefWezkPwYvCkZYGTLwszJ7xGJJ1REOjfGLzGA@mail.gmail.com>
	<63F17EA6-66E3-4C6D-9FF6-E17DBB6B084A@r-project.org>
	<526D0D7F.9010707@gmail.com>
Message-ID: <21102.41358.903279.974068@stat.math.ethz.ch>

>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>     on Sun, 27 Oct 2013 08:56:31 -0400 writes:

    > On 13-10-26 9:49 PM, Simon Urbanek wrote:
    >> On Oct 25, 2013, at 12:12 PM, Yihui Xie wrote:
    >> 
    >>> This has been asked soooo many times that I think it may
    >>> be a good idea for R CMD check to just stop when the
    >>> user passes a directory instead of a tar ball to it, or
    >>> automatically run R CMD build before moving on. In my
    >>> opinion, sometimes an FAQ and a bug are not entirely
    >>> different.
    >>> 
    >> 
    >> +1 -- and I'd do the same for R CMD INSTALL. If someone
    >> insists, there could be --force or something like that
    >> for those that really want to work on directories despite
    >> all the issues with that, but IMHO the default should be
    >> for both INSTALL and check to bail out if not presented
    >> with a file -- it would save a lot of people a lot of
    >> time spent in chasing ghost issues.

    > That seems like a reasonable suggestion.  I wouldn't want
    > to lose the ability to install or check a directory; for
    > development of packages like rgl which have a lot of
    > compiled code, installing from a tarball takes a lot
    > longer than installing when all of the code has already
    > been compiled.

Even more extreme for  Matrix, and as you mention other packages
with a considerable portion of compiled code.

R CMD build also does some checks that then are done again, when
you  R CMD check the tarball.
It really adds a considerable amount of time/work to have to do
both and I'd strongl oppose to disable checking of the source
directory of a package.

Actually, I do think that the 'build/check' R code could and should be
modularized so that checking a directory with an 'Authors at R' in DESCRIPTION
((and no 'Maintainer'/'Authors' as they are auto-created)) would
still work fine...


    > On the other hand, it isn't all that hard to put together
    > an R function or shell script to do it (the hardest part
    > is figuring out the name of the tarball).  For example:

    > installpkgdir <- function(dir) { 
    > x <- system(paste("R CMD build", dir), intern=TRUE)
    >  ....
    > }

    > I haven't tested this much, and it doesn't offer options
    > to the build or install steps, but it could be the basis
    > of a simple function that always builds a tarball before
    > installing a source directory.

well, there have been other ways to bundle  "build + check", of
course, but for some developers, package building really is not fast,
notably for people like me with a large library of R packages,
where the all dependent packages incl those in 'Suggests' are
sought and checked for the correct version, etc.
Also, by default the vignette rebuilding; manuals etc take time,
and it used to need other manual manipulations if you disabled those,
and then wanted to check the tarball.

I'd be very much inconvenienced if I'd need to build packages
every time I want to check them during development.  Things are
different shortly before a release.

Martin

    > Duncan Murdoch


    >> Cheers, Simon
    >> 
    >> 
    >> 
    >>> Regards, Yihui
    >>> --
    >>> Yihui Xie <xieyihui at gmail.com> Web: http://yihui.name
    >>> Department of Statistics, Iowa State University 2215
    >>> Snedecor Hall, Ames, IA
    >>> 
    >>> 
    >>> On Fri, Oct 25, 2013 at 10:37 AM, Sanford Weisberg
    >>> <sandy at umn.edu> wrote:
    >>>> Using SUSE Linux, Windows 32 bit and Windows 64 bit R
    >>>> 3.0.2 , I am unable to use R CMD check successfully.
    >>>> Here is the Windows 64 bit report:
    >>>> 
    >>>> 
    >>>> Z:\R\source\effects>R CMD check pkg * using log
    >>>> directory 'Z:/R/source/effects/pkg.Rcheck' * using R
    >>>> version 3.0.2 (2013-09-25) * using platform:
    >>>> x86_64-w64-mingw32 (64-bit) * using session charset:
    >>>> ISO8859-1 * checking for file 'pkg/DESCRIPTION'
    >>>> ... ERROR Required fields missing or empty: 'Author'
    >>>> 'Maintainer'
    >>>> 
    >>>> The file DESCRIPTION looks like this:
    >>>> 
    >>>> Package: effects Version: 2.3-0 Date: 2013/10/22 Title:
    >>>> Effect Displays for Linear, Generalized Linear,
    >>>> Multinomial-Logit, Proportional-Odds Logit Models and
    >>>> Mixed-Effects Models Authors at R: c(person("John", "Fox",
    >>>> role = c("aut", "cre"), email = " jfox at mcmaster.ca"),
    >>>> person("Sanford", "Weisberg", role = "aut", email =
    >>>> "sandy at umn.edu"), person("Michael", "Friendly", role =
    >>>> "aut", email = "friendly at yorku.ca "), person("Jangman",
    >>>> "Hong", role = "aut"), person("Robert", "Andersen",
    >>>> role = "ctb"), person("David", "Firth", role = "ctb"),
    >>>> person("Steve", "Taylor", role = "ctb")) Depends:
    >>>> lattice, grid, colorspace Suggests: nlme, lme4, MASS,
    >>>> nnet, poLCA, heplots LazyLoad: yes LazyData: yes
    >>>> Description: Graphical and tabular effect displays,
    >>>> e.g., of interactions, for linear generalized linear,
    >>>> multinomial-logit, proportional-odds logit models,
    >>>> mixed-effect models, polytomous latent-class models and
    >>>> multivariate linear models.  License: GPL (>= 2) URL:
    >>>> http://www.r-project.org,
    >>>> http://socserv.socsci.mcmaster.ca/jfox/
    >>>> 
    >>>> The 'Author' and 'Maintainer' fields should be
    >>>> automatically generated.  With version 3.0.1, I had no
    >>>> such problem, and my coauthors who use Eciplse and
    >>>> R-studio have no problems with R 3.0.2.  John Fox
    >>>> suggested the following:
    >>>> 
    >>>> When R CMD build creates a package tarball it writes
    >>>> the information from Authors at R into the Author and
    >>>> Maintainer fields. I think that Sandy's problem is
    >>>> produced by checking the package source directory
    >>>> rather than a package source tarball. I use RStudio to
    >>>> check packages, and it automatically builds the tarball
    >>>> first, which is the recommended procedure.  R-Forge
    >>>> does that too. Michael uses Eclipse, and if I remember
    >>>> right, it too creates a tarball (but I haven't used it
    >>>> in quite some time).
    >>>> 
    >>>> Is this a bug in R CMD check?
    >>>> 
    >>>> 
    >>>> --
    >>>> Sanford Weisberg, sandy at umn.edu <sandy at umn.edu> For
    >>>> undergraduate matters: undergrad at stat.umn.edu
    >>>> University of Minnesota, School of Statistics 312 Ford
    >>>> Hall, 224 Church St. SE, Minneapolis, MN 55455
    >>>> 612-625-8355, FAX 612-624-8868
    >>>> 
    >>>> [[alternative HTML version deleted]]
    >>>> 
    >>>> ______________________________________________
    >>>> R-devel at r-project.org mailing list
    >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>> 
    >> 
    >> ______________________________________________
    >> R-devel at r-project.org mailing list
    >> https://stat.ethz.ch/mailman/listinfo/r-devel
    >> 

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From luis.f.rodriguez1 at gmail.com  Mon Oct 28 19:54:48 2013
From: luis.f.rodriguez1 at gmail.com (Luis Rodriguez)
Date: Mon, 28 Oct 2013 13:54:48 -0500
Subject: [Rd] missing documentation entries ... WARNING
In-Reply-To: <525C604B.4040503@gmail.com>
References: <BAF41C96-FB1E-4AF2-A73E-878D15A5853F@yahoo.com>
	<522E2643.6010803@gmail.com>
	<DB7A3056-2B7A-4BC6-AD67-DA6FA0B31488@yahoo.com>
	<525C604B.4040503@gmail.com>
Message-ID: <7B5AEA51-A2E7-4E1B-A3B3-4FE92CD3803F@gmail.com>

Dear Duncan and R-devel,

This advice has cleared my "checking Rd \usage sections" warning?but I am not sure I did a good job taking your advice as I cleared this by modifying the alias statements, but not invoking  \S3method or \S4method.

Thus, I am still a bit stumped on my "checking for missing documentation entries ? WARNING"

It still reads:

***
Undocumented S4 classes:
  ?commcorrelogram?
Undocumented S4 methods:
  generic 'mod' and siglist 'commcorrelogram'
  generic 'plot' and siglist 'commcorrelogram,missing'
All user-level objects in a package (including S4 classes and methods)
should have documentation entries.
See the chapter ?Writing R documentation files? in the ?Writing R
***

My updated \alias and \usage sections are included below.

Based on some archived discussion board material I have read, I am considering adding a section that might read something like this for methods mod and plot, but my logic seems off as the error does not seem to respond to this addition:

\section{Methods}{ 
  \describe{ 
    \item{mod}{\code{signature(object = "commcorrelogram")}: Provides a shortcut method for \code{mod.commcorrelogram}.} 
    } 
}

Does that make sense?

What would you suggest?

I will also work on correcting my approach to invoking \S3 and \S4method.

Thanks!
~luis


****comcorrelogram.Rd \alias and \usage sections****

\name{commcorrelogram}
\docType{class}
\alias{commcorrelogram}

\title{
  Community Correlogram
}
\description{
Function \code{commcorrelogram} computes community correlograms using either the multivariate Mantel statistic (Mantel, 1957) or the ANOSIM R metric (Clarke, 1993), and includes functionality for both directional analyses and combinations of temporal and spatial analyses.  Mantel correlogram proposed by Sokal (1986) and Oden and Sokal (1986). ANOSIM correlogram suggested here.
}
\usage{
commcorrelogram(sampleData,sampleTime=NULL,sampleLocation=NULL,LocationNames=NULL,option=1,metric='anosim',lagNumber,lagSize,lagTol,numTests=999,anisotropic=FALSE,azimuth,azimuthTol,bandwidth,dipAngle,dipTol,dipBandwidth,distmeth='bray',mantmeth='spearman',adj='holm',prog=TRUE,alternative='one.sided')
}

****comcorrelogram.Rd \alias and \usage sections****

****mod.comcorrelogram.Rd \alias and \usage sections****

\name{mod.commcorrelogram}
\alias{mod.commcorrelogram}
\alias{mod}
\title{
Community Correlogram Model
}
\description{
Function mod.commcorrelogram automatically fits a Gaussian curve to the significance plot of a commcorrelogram object and calculates the correlation range of the data.
}
\usage{
mod.commcorrelogram(object,Ch=1,Cc=5,Cw=0.01,plot=T,alpha=0.05,alternative='one.tailed',pw=5,lgpos='topleft',...)
}

****mod.comcorrelogram.Rd \alias and \usage sections****


On Oct 14, 2013, at 4:21 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 13-10-14 1:54 PM, Luis Rodr?guez wrote:
>> Thanks Duncan (and othersin R-devel).
>> 
>> I clearly got away from this project, but I am still quite interested in resolving this issue and getting these codes into the CRAN.
>> 
>> Some attempts to repair the documentation have occurred in the intervening time, so I am including slightly updated error messages and the relevant tops of the Rd files, as requested by Duncan. See below.
>> 
>> Thanks again!
>> 
>> ~luis
>> 
>> 
>> 
>> <<<<my "missing documentation entries">>>>
>> 
>> * checking for missing documentation entries ... WARNING
>> Undocumented S4 classes:
>>   ?commcorrelogram?
>> Undocumented S4 methods:
>>   generic 'mod' and siglist 'commcorrelogram'
>>   generic 'plot' and siglist 'commcorrelogram,missing'
>> All user-level objects in a package (including S4 classes and methods)
>> should have documentation entries.
>> See the chapter ?Writing R documentation files? in the ?Writing R
>> Extensions? manual.
>> 
>> <<<<my "missing documentation entries">>>>
>> 
>> I am also getting a * checking Rd \usage sections ? WARNING, but your message makes me think this is related to the above. JIC, here is that error message:
>> 
>> <<<<my "\usage section" Warning>>>>
>> 
>> * checking Rd \usage sections ... WARNING
>> Objects in \usage without \alias in documentation object 'commcorrelogram':
>>   ?plot.commcorrelogram?
>> 
>> Functions with \usage entries need to have the appropriate \alias
>> entries, and all their arguments documented.
>> The \usage entries must correspond to syntactically valid R code.
>> See the chapter ?Writing R documentation files? in the ?Writing R
>> 
>> <<<<my "\usage section" Warning>>>>
>> 
>> 
>> ****comcorrelogram.Rd \alias and \usage sections****
>> 
>> \name{commcorrelogram}
>> \docType{class}
>> \alias{commcorrelogram}
>> \alias{mod,commcorrelogram}
>> \alias{plot,commcorrelogram,missing}
> 
> Those aliases look like S4 documentation, not S3 as the comment states.
>> 
>> \title{
>>   Community Correlogram
>> }
>> \description{
>> Function \code{commcorrelogram} computes community correlograms using either the multivariate Mantel statistic (Mantel, 1957) or the ANOSIM R metric (Clarke, 1993), and includes functionality for both directional analyses and combinations of temporal and spatial analyses.  Mantel correlogram proposed by Sokal (1986) and Oden and Sokal (1986). ANOSIM correlogram suggested here.
>> }
>> \usage{
>> commcorrelogram(sampleData, sampleTime = NULL, sampleLocation = NULL,
>>     LocationNames = NULL, option = 1, metric = "anosim", lagNumber, lagSize,
>>     lagTol, numTests = 999, anisotropic = FALSE, azimuth, azimuthTol,
>>     bandwidth, dipAngle, dipTol, dipBandwidth, distmeth = "bray",
>>     mantmeth = "spearman", adj = "holm", prog = TRUE, alternative =
>>     "one.sided")
>> 
>> # S3 method for class 'community.correlogram'
>> plot.commcorrelogram(x, y, alpha=0.05, ?)
>> }
> 
> You should use \S3method{plot}{commcorrelogram}(x, y, alpha = 0.05, ...) (or maybe \S4method ...).
> 
> 
>> 
>> ****comcorrelogram.Rd \alias and \usage sections****
>> 
>> ****mod.comcorrelogram.Rd \alias and \usage sections****
>> 
>> \name{mod.commcorrelogram}
>> \alias{mod.commcorrelogram}
>> \alias{mod}
>> \title{
>> Community Correlogram Model
>> }
>> \description{
>> Function mod.commcorrelogram automatically fits a Gaussian curve to the significance plot of a commcorrelogram object and calculates the correlation range of the data.
>> }
>> \usage{
>> mod.commcorrelogram(object,Ch=1,Cc=5,Cw=0.01,plot=T,alpha=0.05
>>   ,alternative='one.tailed',pw=5,lgpos='topleft',...)
>> }
> 
> Again, use \S3method.
> 
>> 
>> ****mod.comcorrelogram.Rd \alias and \usage sections****
>> 
>> 
>> On Sep 9, 2013, at 2:49 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>>> On 09/09/2013 3:23 PM, Luis Rodr?guez wrote:
>>>> Dear R-devel,
>>>> 
>>>> I am a relative novice in R, but I am eager to post a new package my group developed in CRAN, but I am stumped by a set of documentation related warnings created by R CMD check.
>>>> 
>>>> So, my current plan is to recreate the documentation by religiously applying and modifying the skeleton codes that can be generated by R. In the meantime, I thought I'd post to the discussion group to see if maybe someone with more experience had some useful advice. Below you'll see a snippet of the key documentation warnings that we are stumped on.
>>>> 
>>>> lagSelect and mod are functions created by my group, as is commcorrelogram. My belief is that they are clearly documented, but I suspect that our novice source code and documentation is not quite hitting what R CMD check is looking for.
>>> 
>>> This message usually indicates that you don't have the relevant \alias{} defined correctly. If you do, please post the top of one or two of the Rd files, and we can tell you what's missing.  (I'd like to see at least the \alias{} and \usage{} sections.)
>>> 
>>> Duncan Murdoch
>>> 
>>>> 
>>>> If anyone has advice on how to pass R CMD check, it would be greatly appreciated.
>>>> 
>>>> ~luis
>>>> 
>>>> 
>>>> 
>>>> ***
>>>> * checking for missing documentation entries ... WARNING
>>>> Undocumented code objects:
>>>>   ?lagSelect? ?mod?
>>>> Undocumented S4 classes:
>>>>   ?commcorrelogram?
>>>> Undocumented S4 methods:
>>>>   generic 'mod' and siglist 'commcorrelogram'
>>>>   generic 'plot' and siglist 'commcorrelogram,missing'
>>>> 
>>>> ***
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
> 


From luis.f.rodriguez1 at gmail.com  Mon Oct 28 21:00:30 2013
From: luis.f.rodriguez1 at gmail.com (Luis Rodriguez)
Date: Mon, 28 Oct 2013 15:00:30 -0500
Subject: [Rd] missing documentation entries ... WARNING
In-Reply-To: <7B5AEA51-A2E7-4E1B-A3B3-4FE92CD3803F@gmail.com>
References: <BAF41C96-FB1E-4AF2-A73E-878D15A5853F@yahoo.com>
	<522E2643.6010803@gmail.com>
	<DB7A3056-2B7A-4BC6-AD67-DA6FA0B31488@yahoo.com>
	<525C604B.4040503@gmail.com>
	<7B5AEA51-A2E7-4E1B-A3B3-4FE92CD3803F@gmail.com>
Message-ID: <C5AB7AD2-2515-4EAB-966B-1670AA2E8F0F@gmail.com>

Aha? I think I have taken care of this.

My team just realized that a class level documentation Rd file is required? I have created this with calls to the methods section, itemized? and we seem to be good to go.

Thanks!
~luis

On Oct 28, 2013, at 1:54 PM, Luis Rodriguez <luis.f.rodriguez1 at gmail.com> wrote:

> Dear Duncan and R-devel,
> 
> This advice has cleared my "checking Rd \usage sections" warning?but I am not sure I did a good job taking your advice as I cleared this by modifying the alias statements, but not invoking  \S3method or \S4method.
> 
> Thus, I am still a bit stumped on my "checking for missing documentation entries ? WARNING"
> 
> It still reads:
> 
> ***
> Undocumented S4 classes:
>  ?commcorrelogram?
> Undocumented S4 methods:
>  generic 'mod' and siglist 'commcorrelogram'
>  generic 'plot' and siglist 'commcorrelogram,missing'
> All user-level objects in a package (including S4 classes and methods)
> should have documentation entries.
> See the chapter ?Writing R documentation files? in the ?Writing R
> ***
> 
> My updated \alias and \usage sections are included below.
> 
> Based on some archived discussion board material I have read, I am considering adding a section that might read something like this for methods mod and plot, but my logic seems off as the error does not seem to respond to this addition:
> 
> \section{Methods}{ 
>  \describe{ 
>    \item{mod}{\code{signature(object = "commcorrelogram")}: Provides a shortcut method for \code{mod.commcorrelogram}.} 
>    } 
> }
> 
> Does that make sense?
> 
> What would you suggest?
> 
> I will also work on correcting my approach to invoking \S3 and \S4method.
> 
> Thanks!
> ~luis
> 
> 
> ****comcorrelogram.Rd \alias and \usage sections****
> 
> \name{commcorrelogram}
> \docType{class}
> \alias{commcorrelogram}
> 
> \title{
>  Community Correlogram
> }
> \description{
> Function \code{commcorrelogram} computes community correlograms using either the multivariate Mantel statistic (Mantel, 1957) or the ANOSIM R metric (Clarke, 1993), and includes functionality for both directional analyses and combinations of temporal and spatial analyses.  Mantel correlogram proposed by Sokal (1986) and Oden and Sokal (1986). ANOSIM correlogram suggested here.
> }
> \usage{
> commcorrelogram(sampleData,sampleTime=NULL,sampleLocation=NULL,LocationNames=NULL,option=1,metric='anosim',lagNumber,lagSize,lagTol,numTests=999,anisotropic=FALSE,azimuth,azimuthTol,bandwidth,dipAngle,dipTol,dipBandwidth,distmeth='bray',mantmeth='spearman',adj='holm',prog=TRUE,alternative='one.sided')
> }
> 
> ****comcorrelogram.Rd \alias and \usage sections****
> 
> ****mod.comcorrelogram.Rd \alias and \usage sections****
> 
> \name{mod.commcorrelogram}
> \alias{mod.commcorrelogram}
> \alias{mod}
> \title{
> Community Correlogram Model
> }
> \description{
> Function mod.commcorrelogram automatically fits a Gaussian curve to the significance plot of a commcorrelogram object and calculates the correlation range of the data.
> }
> \usage{
> mod.commcorrelogram(object,Ch=1,Cc=5,Cw=0.01,plot=T,alpha=0.05,alternative='one.tailed',pw=5,lgpos='topleft',...)
> }
> 
> ****mod.comcorrelogram.Rd \alias and \usage sections****
> 
> 
> On Oct 14, 2013, at 4:21 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
>> On 13-10-14 1:54 PM, Luis Rodr?guez wrote:
>>> Thanks Duncan (and othersin R-devel).
>>> 
>>> I clearly got away from this project, but I am still quite interested in resolving this issue and getting these codes into the CRAN.
>>> 
>>> Some attempts to repair the documentation have occurred in the intervening time, so I am including slightly updated error messages and the relevant tops of the Rd files, as requested by Duncan. See below.
>>> 
>>> Thanks again!
>>> 
>>> ~luis
>>> 
>>> 
>>> 
>>> <<<<my "missing documentation entries">>>>
>>> 
>>> * checking for missing documentation entries ... WARNING
>>> Undocumented S4 classes:
>>>  ?commcorrelogram?
>>> Undocumented S4 methods:
>>>  generic 'mod' and siglist 'commcorrelogram'
>>>  generic 'plot' and siglist 'commcorrelogram,missing'
>>> All user-level objects in a package (including S4 classes and methods)
>>> should have documentation entries.
>>> See the chapter ?Writing R documentation files? in the ?Writing R
>>> Extensions? manual.
>>> 
>>> <<<<my "missing documentation entries">>>>
>>> 
>>> I am also getting a * checking Rd \usage sections ? WARNING, but your message makes me think this is related to the above. JIC, here is that error message:
>>> 
>>> <<<<my "\usage section" Warning>>>>
>>> 
>>> * checking Rd \usage sections ... WARNING
>>> Objects in \usage without \alias in documentation object 'commcorrelogram':
>>>  ?plot.commcorrelogram?
>>> 
>>> Functions with \usage entries need to have the appropriate \alias
>>> entries, and all their arguments documented.
>>> The \usage entries must correspond to syntactically valid R code.
>>> See the chapter ?Writing R documentation files? in the ?Writing R
>>> 
>>> <<<<my "\usage section" Warning>>>>
>>> 
>>> 
>>> ****comcorrelogram.Rd \alias and \usage sections****
>>> 
>>> \name{commcorrelogram}
>>> \docType{class}
>>> \alias{commcorrelogram}
>>> \alias{mod,commcorrelogram}
>>> \alias{plot,commcorrelogram,missing}
>> 
>> Those aliases look like S4 documentation, not S3 as the comment states.
>>> 
>>> \title{
>>>  Community Correlogram
>>> }
>>> \description{
>>> Function \code{commcorrelogram} computes community correlograms using either the multivariate Mantel statistic (Mantel, 1957) or the ANOSIM R metric (Clarke, 1993), and includes functionality for both directional analyses and combinations of temporal and spatial analyses.  Mantel correlogram proposed by Sokal (1986) and Oden and Sokal (1986). ANOSIM correlogram suggested here.
>>> }
>>> \usage{
>>> commcorrelogram(sampleData, sampleTime = NULL, sampleLocation = NULL,
>>>    LocationNames = NULL, option = 1, metric = "anosim", lagNumber, lagSize,
>>>    lagTol, numTests = 999, anisotropic = FALSE, azimuth, azimuthTol,
>>>    bandwidth, dipAngle, dipTol, dipBandwidth, distmeth = "bray",
>>>    mantmeth = "spearman", adj = "holm", prog = TRUE, alternative =
>>>    "one.sided")
>>> 
>>> # S3 method for class 'community.correlogram'
>>> plot.commcorrelogram(x, y, alpha=0.05, ?)
>>> }
>> 
>> You should use \S3method{plot}{commcorrelogram}(x, y, alpha = 0.05, ...) (or maybe \S4method ...).
>> 
>> 
>>> 
>>> ****comcorrelogram.Rd \alias and \usage sections****
>>> 
>>> ****mod.comcorrelogram.Rd \alias and \usage sections****
>>> 
>>> \name{mod.commcorrelogram}
>>> \alias{mod.commcorrelogram}
>>> \alias{mod}
>>> \title{
>>> Community Correlogram Model
>>> }
>>> \description{
>>> Function mod.commcorrelogram automatically fits a Gaussian curve to the significance plot of a commcorrelogram object and calculates the correlation range of the data.
>>> }
>>> \usage{
>>> mod.commcorrelogram(object,Ch=1,Cc=5,Cw=0.01,plot=T,alpha=0.05
>>>  ,alternative='one.tailed',pw=5,lgpos='topleft',...)
>>> }
>> 
>> Again, use \S3method.
>> 
>>> 
>>> ****mod.comcorrelogram.Rd \alias and \usage sections****
>>> 
>>> 
>>> On Sep 9, 2013, at 2:49 PM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> 
>>>> On 09/09/2013 3:23 PM, Luis Rodr?guez wrote:
>>>>> Dear R-devel,
>>>>> 
>>>>> I am a relative novice in R, but I am eager to post a new package my group developed in CRAN, but I am stumped by a set of documentation related warnings created by R CMD check.
>>>>> 
>>>>> So, my current plan is to recreate the documentation by religiously applying and modifying the skeleton codes that can be generated by R. In the meantime, I thought I'd post to the discussion group to see if maybe someone with more experience had some useful advice. Below you'll see a snippet of the key documentation warnings that we are stumped on.
>>>>> 
>>>>> lagSelect and mod are functions created by my group, as is commcorrelogram. My belief is that they are clearly documented, but I suspect that our novice source code and documentation is not quite hitting what R CMD check is looking for.
>>>> 
>>>> This message usually indicates that you don't have the relevant \alias{} defined correctly. If you do, please post the top of one or two of the Rd files, and we can tell you what's missing.  (I'd like to see at least the \alias{} and \usage{} sections.)
>>>> 
>>>> Duncan Murdoch
>>>> 
>>>>> 
>>>>> If anyone has advice on how to pass R CMD check, it would be greatly appreciated.
>>>>> 
>>>>> ~luis
>>>>> 
>>>>> 
>>>>> 
>>>>> ***
>>>>> * checking for missing documentation entries ... WARNING
>>>>> Undocumented code objects:
>>>>>  ?lagSelect? ?mod?
>>>>> Undocumented S4 classes:
>>>>>  ?commcorrelogram?
>>>>> Undocumented S4 methods:
>>>>>  generic 'mod' and siglist 'commcorrelogram'
>>>>>  generic 'plot' and siglist 'commcorrelogram,missing'
>>>>> 
>>>>> ***
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>> 
>>> 
>> 
> 


From xie at yihui.name  Mon Oct 28 22:17:22 2013
From: xie at yihui.name (Yihui Xie)
Date: Mon, 28 Oct 2013 16:17:22 -0500
Subject: [Rd] R CMD check problem with R 3.0.2
In-Reply-To: <21102.41358.903279.974068@stat.math.ethz.ch>
References: <CADkZVY7vuQv_nS+H_Xvb25v6k4tS9steZ86RkLhteGxK_9YHug@mail.gmail.com>
	<CANROs4c=0JJ0uefWezkPwYvCkZYGTLwszJ7xGJJ1REOjfGLzGA@mail.gmail.com>
	<63F17EA6-66E3-4C6D-9FF6-E17DBB6B084A@r-project.org>
	<526D0D7F.9010707@gmail.com>
	<21102.41358.903279.974068@stat.math.ethz.ch>
Message-ID: <CANROs4d0ZWM++UO4MZ2NgKt5g6cuzs1BQ6TGFNw8_8s7mg1+ZA@mail.gmail.com>

I understand these reasons, and they certainly make sense when a
package has a big/complicated src/ directory. Perhaps one day more
developers will move the building and checking to cloud services (e.g.
I have been using Travis CI), so nobody cares about the
building/checking time spent on local machines any more.

For now, I think either `R CMD check --build` (must build before
checking) or `R CMD check --force` (definitely check without building)
sounds like a reasonable solution.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name
Department of Statistics, Iowa State University
2215 Snedecor Hall, Ames, IA


On Mon, Oct 28, 2013 at 12:40 PM, Martin Maechler
<maechler at stat.math.ethz.ch> wrote:
>>>>>> Duncan Murdoch <murdoch.duncan at gmail.com>
>>>>>>     on Sun, 27 Oct 2013 08:56:31 -0400 writes:
>
>     > On 13-10-26 9:49 PM, Simon Urbanek wrote:
>     >> On Oct 25, 2013, at 12:12 PM, Yihui Xie wrote:
>     >>
>     >>> This has been asked soooo many times that I think it may
>     >>> be a good idea for R CMD check to just stop when the
>     >>> user passes a directory instead of a tar ball to it, or
>     >>> automatically run R CMD build before moving on. In my
>     >>> opinion, sometimes an FAQ and a bug are not entirely
>     >>> different.
>     >>>
>     >>
>     >> +1 -- and I'd do the same for R CMD INSTALL. If someone
>     >> insists, there could be --force or something like that
>     >> for those that really want to work on directories despite
>     >> all the issues with that, but IMHO the default should be
>     >> for both INSTALL and check to bail out if not presented
>     >> with a file -- it would save a lot of people a lot of
>     >> time spent in chasing ghost issues.
>
>     > That seems like a reasonable suggestion.  I wouldn't want
>     > to lose the ability to install or check a directory; for
>     > development of packages like rgl which have a lot of
>     > compiled code, installing from a tarball takes a lot
>     > longer than installing when all of the code has already
>     > been compiled.
>
> Even more extreme for  Matrix, and as you mention other packages
> with a considerable portion of compiled code.
>
> R CMD build also does some checks that then are done again, when
> you  R CMD check the tarball.
> It really adds a considerable amount of time/work to have to do
> both and I'd strongl oppose to disable checking of the source
> directory of a package.
>
> Actually, I do think that the 'build/check' R code could and should be
> modularized so that checking a directory with an 'Authors at R' in DESCRIPTION
> ((and no 'Maintainer'/'Authors' as they are auto-created)) would
> still work fine...
>
>
>     > On the other hand, it isn't all that hard to put together
>     > an R function or shell script to do it (the hardest part
>     > is figuring out the name of the tarball).  For example:
>
>     > installpkgdir <- function(dir) {
>     > x <- system(paste("R CMD build", dir), intern=TRUE)
>     >  ....
>     > }
>
>     > I haven't tested this much, and it doesn't offer options
>     > to the build or install steps, but it could be the basis
>     > of a simple function that always builds a tarball before
>     > installing a source directory.
>
> well, there have been other ways to bundle  "build + check", of
> course, but for some developers, package building really is not fast,
> notably for people like me with a large library of R packages,
> where the all dependent packages incl those in 'Suggests' are
> sought and checked for the correct version, etc.
> Also, by default the vignette rebuilding; manuals etc take time,
> and it used to need other manual manipulations if you disabled those,
> and then wanted to check the tarball.
>
> I'd be very much inconvenienced if I'd need to build packages
> every time I want to check them during development.  Things are
> different shortly before a release.
>
> Martin


From mdsumner at gmail.com  Mon Oct 28 23:24:57 2013
From: mdsumner at gmail.com (Michael Sumner)
Date: Tue, 29 Oct 2013 09:24:57 +1100
Subject: [Rd] interrupting Sweave leaves open sink connection
In-Reply-To: <5267B795.5040906@gmail.com>
References: <CAAcGz9_eB7nUgrDuAroEfP6bwg-mMjXgqMeokVzRXGj0y_jDQQ@mail.gmail.com>
	<52673830.8090405@gmail.com> <5267B795.5040906@gmail.com>
Message-ID: <CAAcGz995bGrfXr+6PNeS5Ev2fN4P3OPzizwgzRyj76Pgs35=DQ@mail.gmail.com>

Thanks very much, confirmed in Windows in R-patched (r64110) and
R-devel (r64116).

Cheers, Mike.

On Wed, Oct 23, 2013 at 10:48 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 13-10-22 10:45 PM, Duncan Murdoch wrote:
>>
>> On 13-10-22 9:45 PM, Michael Sumner wrote:
>>>
>>> Hello, if I interrupt Sweave while it's processing a file it seemingly
>>> leaves an open sink connection that hides printed output.
>>>
>>> Can this be changed to reset the sink on exit?  I've been baffled by
>>> this for years.
>>>
>>> This is seen in Windows (R Under development (unstable) (2013-10-20
>>> r64082))  and an older Linux (R version 3.0.0 (2013-04-03)).
>>>
>>> Run the code below in two parts with a manual interrupt to 1) to see it.
>>
>>
>> That's a bug in the Rweave driver.  It runs the code in try() so that it
>> can catch errors and undo the sink, but try() doesn't catch user
>> interrupts, so it never gets undone.
>>
>> Shouldn't be too hard to fix...
>
>
> It should now be fixed in R-devel and R-patched.
>
> Likely the reason this went unfixed for so long is that the more common way
> to use Sweave is in a separate R session.  If you run it in the current R
> session, the results aren't necessarily reproducible, because they may
> depend on whatever variables you have in your workspace.  It's better to run
> it on its own.  One way is to use the command line version
>
> R CMD Sweave ...
>
> but it can also be done by piping specific commands into an R session. I do
> it that way, because it lets me run some project management code, and lets
> me patch the Synctex information so it points to the .Rnw file.
>
> Duncan Murdoch
>
>
>>
>> Duncan Murdoch
>>
>>>
>>> Cheers, MIke.
>>>
>>> ## 1)
>>>
>>> ## this code creates a temporary file to run Sweave
>>>
>>> ## interrupt this code before Sweave() finishes
>>>
>>> txt <-  c("\\documentclass[a4paper]{article}", "\\title{Sweave bail
>>> out}",
>>> "\\author{M. Sumner}", "\\begin{document}", "\\maketitle", "",
>>> "Run a loop and bail out when Sweave()ing.", "", "<<>>=",
>>> "for (i in seq_len(1e6)) {", "    if (i %% 1000 == 0)
>>> print(sprintf(\"%i\", i))",
>>> "    Sys.sleep(0.5)", "}", "@", "", "\\end{document}")
>>>
>>> f <- tempfile()
>>> writeLines(txt, f)
>>>
>>> Sweave(f)
>>>
>>> ## 2)
>>> ## now no printed output is seen
>>> print(1)
>>> ##
>>>
>>> sink(NULL)
>>>
>>> ## now it's back
>>> print(1)
>>> ## [1] 1
>>>
>>> ## tidy up
>>> ## unlink(f)
>>>
>>>
>>>
>>>
>>>
>>
>



-- 
Michael Sumner
Hobart, Australia
e-mail: mdsumner at gmail.com


From csardi.gabor at gmail.com  Tue Oct 29 01:19:51 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Mon, 28 Oct 2013 20:19:51 -0400
Subject: [Rd] Package size NOTE in R CMD check
Message-ID: <CABtg=K=S_KaeBOQY562j4FxiU8Q7V1bDXc_UktwjvvS8d4af=g@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131028/798c2239/attachment.pl>

From armstrong.whit at gmail.com  Tue Oct 29 03:01:32 2013
From: armstrong.whit at gmail.com (Whit Armstrong)
Date: Mon, 28 Oct 2013 22:01:32 -0400
Subject: [Rd] R 3.1.0 and C++11
In-Reply-To: <21075.11278.577153.103691@max.nulle.part>
References: <21073.63553.888272.510490@max.nulle.part>
	<31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>
	<21075.11278.577153.103691@max.nulle.part>
Message-ID: <CAMi=pg5aRiFG7s+f4bERE6QQe+D7dH1Y_b9Q6AsH3A7Gz0M-qw@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131028/83b8216e/attachment.pl>

From romain at r-enthusiasts.com  Tue Oct 29 06:58:33 2013
From: romain at r-enthusiasts.com (romain at r-enthusiasts.com)
Date: Tue, 29 Oct 2013 06:58:33 +0100
Subject: [Rd] R 3.1.0 and C++11
In-Reply-To: <CAMi=pg5aRiFG7s+f4bERE6QQe+D7dH1Y_b9Q6AsH3A7Gz0M-qw@mail.gmail.com>
References: <21073.63553.888272.510490@max.nulle.part>
	<31E214B6DF75104E942856C2F74953CB0505C0F9@exchange>
	<21075.11278.577153.103691@max.nulle.part>
	<CAMi=pg5aRiFG7s+f4bERE6QQe+D7dH1Y_b9Q6AsH3A7Gz0M-qw@mail.gmail.com>
Message-ID: <478ce69b232b57db8fa74fa93e5a646a@r-enthusiasts.com>

Le 2013-10-29 03:01, Whit Armstrong a ?crit?:
> I would love to see optional c++0x support added for R.

c++0x was the name given for when this was in development. Now c++11 is 
a published standard backed by implementations by major compilers.
people need to stop calling it c++0x

> If there is anything I can do to help, please let me know.

Come here https://github.com/romainfrancois/cpp11_article where I'm 
writing an article on C++11 and what would be the benefits.

Romain

> Sincerely,
> Whit
>
> On Mon, Oct 7, 2013 at 5:47 PM, Dirk Eddelbuettel <edd at debian.org> 
> wrote:
>
>>
>> Hi Martyn,
>>
>> On 7 October 2013 at 21:18, Martyn Plummer wrote:
>> | I don't see any harm in allowing optional C++11 support,
>>
>> That would be a nice step forward.
>>
>> | and it is no trouble to update the documentation to acknowledge 
>> the
>> | existence of C++11 conforming compilers.
>>
>> Indeed.
>>
>> | However, the questions of what is possible, what is recommended, 
>> and what
>> |  is required for CRAN submissions are distinct.
>>
>> You may be aware of the difficulties we as R package developers have 
>> with
>> discussions involving CRAN maintainers.
>>
>> | I have a couple of comments on the macro:
>> | a) Your version implies mandatory C++11 support. One needs
>> | AX_CXX_COMPILE_STDCXX_11(noext,optional) for optional support.
>>
>> I used an existing macros from the GNU autoconf archive. It can 
>> certainly
>> be
>> tweaked. R's stack of configure logic is an impressive piece of work 
>> and I
>> wasn't expecting this to flow through. It was meant to start a 
>> discussion.
>>
>> My principal points are that
>>
>>    i)  we do have compilers now that can support this, and
>>
>>    ii) we can test for their capabilities when R itself is compiled.
>>
>> | b) I find it unhelpful that the macro picks up the partial C++11 
>> support
>> in
>> | gcc 4.7 via the -std=c++0x flag, so I would edit (and rename) the 
>> macro
>> to
>> | remove this.
>>
>> Of course. All this can and should be discussed. I just wanted to 
>> get the
>> ball rolling and had a choice between just emailing Kurt (as the 
>> configure
>> and m4 point man) and emailing here.
>>
>> To the extent that c++0x support is also widely available, I do not 
>> see why
>> one could not allow it either.  But that is a minor issue: I would 
>> really
>> like us to (eventually) move beyond what is going to become a more 
>> and more
>> constraining C++ standard.
>>
>> Optional support for deployments where C++11 is indeed available 
>> seems
>> like a
>> step in the right direction.
>>
>> Thanks for your feedback!
>>
>> Dirk
>>
>> | Martyn
>> | ________________________________________
>> | From: r-devel-bounces at r-project.org 
>> [r-devel-bounces at r-project.org] on
>> behalf of Dirk Eddelbuettel [edd at debian.org]
>> | Sent: 07 October 2013 01:54
>> | To: R-devel org
>> | Subject: [Rd] R 3.1.0 and C++11
>> |
>> | I would like to bring up two issues concerning C++11.
>> |
>> |
>> | First, the R-devel manuals contain incorrect statements regarding 
>> C++11:
>> |
>> |   i)   R-exts.texi:
>> |
>> |        Although there is a 2011 version of the C++ standard, it is 
>> not
>> yet
>> |        fully implemented (nor is it likely to be widely available 
>> for
>> some
>> |        years) and portable C++ code needs to follow the 1998 
>> standard
>> |        (and not use features from C99).
>> |
>> |   ii)  R-ints.texi:
>> |
>> |        The type `R_xlen_t' is made available to packages in C 
>> header
>> |        `Rinternals.h': this should be fine in C code since C99 is
>> |        required.  People do try to use R internals in C++, but 
>> C++98
>> |        compilers are not required to support these types (and 
>> there are
>> |        currently no C++11 compilers).
>> |
>> | But since the summer we have g++ and clang with working C++11
>> implementations:
>> |
>> |   iii) g++ implements C++11:
>> |
>> 
>> http://isocpp.org/blog/2013/05/gcc-4.8.1-released-c11-feature-complete
>> |
>> |   iv)  llvm/clang++ implements C++11:
>> |        http://isocpp.org/blog/2013/06/llvm-3.3-is-released
>> |
>> | I would suggest to change the wording prior to the release of R 
>> 3.1.0
>> next
>> | year as it is likely that even Microsoft will by then have a
>> fully-conformant
>> | compiler (per Herb Sutter at a recent talk in Chicago). If it 
>> helped, I
>> would
>> | be glad to provide minimal patches to the two .texi files.
>> |
>> | Moreover, the C++ Standards Group is working towards closing the 
>> delta
>> | between standards being adopted, and compilers being released. 
>> They
>> expect
>> | corresponding compilers for C++14 (a "patch" release for C++11 
>> expected
>> to be
>> | ready next spring) to be available within a year---possibly during 
>> 2014.
>> |
>> |
>> | Second, the current R Policy regarding C++11 is unnecessarily 
>> strict. I
>> would
>> | propose to treat the availability of C++11 extensions more like 
>> the
>> | availability of OpenMP: something which configure can probe at 
>> build
>> time,
>> | and which can be deployed later via suitable #ifdef tests.
>> |
>> | As a proof of concept, I added this macro from the autoconf 
>> archive to
>> the
>> | m4/ directory of R-devel:
>> |
>> |
>> 
>> http://www.gnu.org/software/autoconf-archive/ax_cxx_compile_stdcxx_11.html
>> |
>> | and made a one-line change to configure.ac (indented two spaces 
>> just
>> for email)
>> |
>> |   edd at max:~/svn/r-devel$ svn di configure.ac
>> |   Index: configure.ac
>> |   
>> ===================================================================
>> |   --- configure.ac      (revision 64031)
>> |   +++ configure.ac      (working copy)
>> |   @@ -906,6 +906,7 @@
>> |
>> |    AC_LANG_PUSH(C++)
>> |    AC_OPENMP
>> |   +AX_CXX_COMPILE_STDCXX_11(noext)
>> |    AC_LANG_POP(C++)
>> |
>> |    ### *** ObjC compiler
>> |   edd at max:~/svn/r-devel$
>> |
>> | After running 'aclocal -Im4; autoheader; autoconf', the configure 
>> test
>> then
>> | properly detected C++11 (or, in one case, C++0x) on four different
>> compilers:
>> |
>> |   [ g++-4.7 case, Ubuntu 13.04 ]
>> |   checking whether g++ supports C++11 features by default... no
>> |   checking whether g++ supports C++11 features with -std=c++11... 
>> no
>> |   checking whether g++ supports C++11 features with -std=c++0x... 
>> yes
>> |
>> |   [ CC=clang CXX=clang++ (3.1), Ubuntu 13.04 ]
>> |   checking whether clang++ accepts -M for generating 
>> dependencies... yes
>> |   checking for clang++ option to support OpenMP... unsupported
>> |   checking whether clang++ supports C++11 features by default... 
>> no
>> |   checking whether clang++ supports C++11 features with 
>> -std=c++11... yes
>> |
>> |   [ g++-4.8 case, Debian testing ]
>> |   checking whether g++ supports C++11 features by default... no
>> |   checking whether g++ supports C++11 features with -std=c++11... 
>> yes
>> |
>> |   [ CC=clang CXX=clang++ (3.2), Debian testing ]
>> |   checking whether clang++ supports C++11 features by default... 
>> no
>> |   checking whether clang++ supports C++11 features with 
>> -std=c++11... yes
>> |
>> | It would be easy to another #define to config.h.in.
>> |
>> |
>> | And of course, I understand that R Core is comprised primarily of 
>> C
>> | programmers.  But to those of us who lean more towards C++ than C, 
>> the
>> step
>> | towards C++11 is a big one, and a very exciting one.  More and 
>> more
>> upstream
>> | authors are considering right now whether to switch to C++11-only. 
>> I
>> expect
>> | such switches to become more common as time pass. C++11 provides a 
>> lot
>> -- and
>> | preventing programmers from using these tools cannot be in our 
>> interest.
>> |
>> | I think that the timing of the next R release will be a good 
>> opportunity
>> to
>> | permit use of C++11 where compilers support it -- as a wide range 
>> of
>> sites
>> | will already be capable of deploying it.
>> |
>> | Thanks, Dirk
>> |
>> | --
>> | Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>> |
>> | ______________________________________________
>> | R-devel at r-project.org mailing list
>> | https://stat.ethz.ch/mailman/listinfo/r-devel
>> | 
>> -----------------------------------------------------------------------
>> | This message and its attachments are strictly confidential. If you 
>> are
>> | not the intended recipient of this message, please immediately 
>> notify
>> | the sender and delete it. Since its integrity cannot be 
>> guaranteed,
>> | its content cannot involve the sender's responsibility. Any 
>> misuse,
>> | any disclosure or publication of its content, either whole or 
>> partial,
>> | is prohibited, exception made of formally approved use
>> | 
>> -----------------------------------------------------------------------
>>
>> --
>> Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Tue Oct 29 07:51:38 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 Oct 2013 06:51:38 +0000
Subject: [Rd] Package size NOTE in R CMD check
In-Reply-To: <CABtg=K=S_KaeBOQY562j4FxiU8Q7V1bDXc_UktwjvvS8d4af=g@mail.gmail.com>
References: <CABtg=K=S_KaeBOQY562j4FxiU8Q7V1bDXc_UktwjvvS8d4af=g@mail.gmail.com>
Message-ID: <526F5AFA.8000903@stats.ox.ac.uk>

On 29/10/2013 00:19, G?bor Cs?rdi wrote:
> How does one "fix" this:
>
> R CMD check --as-cran --timings igraph_0.6.5.999-54.tar.gz
>
>
> ...
>
> * checking installed package size ... NOTE
>    installed size is  5.9Mb
>    sub-directories of 1Mb or more:
>      libs   4.0Mb
>
> ...
>
> Are maintainers expected to break up the package in this case?

No.

> I can see that the NOTE is useful to avoid garbage in the package, but
> since the libs directory is created by R CMD INSTALL, it is relatively hard
> to put garbage there.

Actually people do manage to get garbage in their .so files.

> Not a critical issue, but it would be nice to have a clean check results
> page.

'Clean'?  According to whom?

>
> Best,
> Gabor
>
> 	[[alternative HTML version deleted]]

See the posting guide.
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From csardi.gabor at gmail.com  Tue Oct 29 15:03:38 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Tue, 29 Oct 2013 10:03:38 -0400
Subject: [Rd] Imports, importFrom slow (for Matrix)
Message-ID: <CABtg=KmyKQCp3QBvrar76mF0zUMNayRjT8PtOrKZrmOtAWrS9w@mail.gmail.com>

Dear All,

before its latest version my package had 'Imports: Matrix' in its
DESCRIPTION file, but it did not import anything in NAMESPACE. Rather,
some functions explicitly loaded Matrix, as they needed. The reason
for this was that importing Matrix is really slow, and only very few
igraph functions need it. (I guess Matrix is slow because of the many
registered names, but that is another question.)

# Empty session:
~$ time Rscript -e 'ls()' > /dev/null
real 0m0.251s
user 0m0.196s
sys 0m0.049s

# Without importing from Matrix:
~$ time Rscript -e 'library(igraph); ls()' > /dev/null
Loading required package: methods
real 0m0.419s
user 0m0.363s
sys 0m0.049s

# Adding importFrom(Matrix, sparseMatrix) to NAMESPACE:
~$ time Rscript -e 'library(igraph); ls()' > /dev/null
Loading required package: methods
real 0m2.963s
user 0m2.844s
sys 0m0.115s

This solution was fine with me, especially because other packages
depending on igraph and using Matrix through igraph worked fine on the
CRAN build servers, as igraph brought Matrix with it. (The build
servers don't have recommended packages like Matrix available by
default.)

Recently, R CMD check does not allow me to list Matrix at Imports
without importing something from it. This is understandable, because
it is an inconsistency after all, but caused some headache for me.

A 3s loading time for a package is IMHO much longer than ideal,
especially that loading R itself is ten times faster. So I definitely
don't want to import from Matrix right now.

The solution I settled with was to include Matrix in 'Suggests', and
the load it selectively, as before. Now some packages depending on
igraph are failing on the CRAN build servers, which don't have Matrix
installed for these packages. (Luckily they are probably not failing
for users, because most users do have the recommended packages.)

In summary, it would be great to speed up imports.

Another solution would be some mechanism that allows me to import from
a package as needed, not at the package loading time. Something like a
delayed importFrom().

Just wanted to bring up this issue.

Best,
Gabor


From ripley at stats.ox.ac.uk  Tue Oct 29 15:11:06 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Tue, 29 Oct 2013 14:11:06 +0000
Subject: [Rd] Imports, importFrom slow (for Matrix)
In-Reply-To: <CABtg=KmyKQCp3QBvrar76mF0zUMNayRjT8PtOrKZrmOtAWrS9w@mail.gmail.com>
References: <CABtg=KmyKQCp3QBvrar76mF0zUMNayRjT8PtOrKZrmOtAWrS9w@mail.gmail.com>
Message-ID: <526FC1FA.60200@stats.ox.ac.uk>

On 29/10/2013 14:03, G?bor Cs?rdi wrote:
> Dear All,
>
> before its latest version my package had 'Imports: Matrix' in its
> DESCRIPTION file, but it did not import anything in NAMESPACE. Rather,
> some functions explicitly loaded Matrix, as they needed. The reason
> for this was that importing Matrix is really slow, and only very few
> igraph functions need it. (I guess Matrix is slow because of the many
> registered names, but that is another question.)
>
> # Empty session:
> ~$ time Rscript -e 'ls()' > /dev/null
> real 0m0.251s
> user 0m0.196s
> sys 0m0.049s
>
> # Without importing from Matrix:
> ~$ time Rscript -e 'library(igraph); ls()' > /dev/null
> Loading required package: methods
> real 0m0.419s
> user 0m0.363s
> sys 0m0.049s
>
> # Adding importFrom(Matrix, sparseMatrix) to NAMESPACE:
> ~$ time Rscript -e 'library(igraph); ls()' > /dev/null
> Loading required package: methods
> real 0m2.963s
> user 0m2.844s
> sys 0m0.115s
>
> This solution was fine with me, especially because other packages
> depending on igraph and using Matrix through igraph worked fine on the
> CRAN build servers, as igraph brought Matrix with it. (The build
> servers don't have recommended packages like Matrix available by
> default.)
>
> Recently, R CMD check does not allow me to list Matrix at Imports
> without importing something from it. This is understandable, because
> it is an inconsistency after all, but caused some headache for me.
>
> A 3s loading time for a package is IMHO much longer than ideal,
> especially that loading R itself is ten times faster. So I definitely
> don't want to import from Matrix right now.
>
> The solution I settled with was to include Matrix in 'Suggests', and
> the load it selectively, as before. Now some packages depending on
> igraph are failing on the CRAN build servers, which don't have Matrix
> installed for these packages. (Luckily they are probably not failing
> for users, because most users do have the recommended packages.)
>
> In summary, it would be great to speed up imports.
>
> Another solution would be some mechanism that allows me to import from
> a package as needed, not at the package loading time. Something like a
> delayed importFrom().

That is what Matrix:: does.  There is nothing like enough here for us to 
tell why it would not suffice for you.  (If you want to import something 
occasionally and then use it very many times, make a local copy.)

>
> Just wanted to bring up this issue.
>
> Best,
> Gabor
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From csardi.gabor at gmail.com  Tue Oct 29 15:25:36 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Tue, 29 Oct 2013 10:25:36 -0400
Subject: [Rd] Imports, importFrom slow (for Matrix)
In-Reply-To: <526FC1FA.60200@stats.ox.ac.uk>
References: <CABtg=KmyKQCp3QBvrar76mF0zUMNayRjT8PtOrKZrmOtAWrS9w@mail.gmail.com>
	<526FC1FA.60200@stats.ox.ac.uk>
Message-ID: <CABtg=KnprQ0HeK3vK2=6X4HpZ99NjPu365fX+wZUuQPnbL2NuA@mail.gmail.com>

Unfortunately that seems to be (almost) just as slow.

~$ time Rscript -e 'Matrix::summary; ls()' > /dev/null
real 0m2.785s
user 0m2.668s
sys 0m0.112s

Gabor

On Tue, Oct 29, 2013 at 10:11 AM, Prof Brian Ripley
<ripley at stats.ox.ac.uk> wrote:
> On 29/10/2013 14:03, G?bor Cs?rdi wrote:
>>
>> Dear All,
>>
>> before its latest version my package had 'Imports: Matrix' in its
>> DESCRIPTION file, but it did not import anything in NAMESPACE. Rather,
>> some functions explicitly loaded Matrix, as they needed. The reason
>> for this was that importing Matrix is really slow, and only very few
>> igraph functions need it. (I guess Matrix is slow because of the many
>> registered names, but that is another question.)
>>
>> # Empty session:
>> ~$ time Rscript -e 'ls()' > /dev/null
>> real 0m0.251s
>> user 0m0.196s
>> sys 0m0.049s
>>
>> # Without importing from Matrix:
>> ~$ time Rscript -e 'library(igraph); ls()' > /dev/null
>> Loading required package: methods
>> real 0m0.419s
>> user 0m0.363s
>> sys 0m0.049s
>>
>> # Adding importFrom(Matrix, sparseMatrix) to NAMESPACE:
>> ~$ time Rscript -e 'library(igraph); ls()' > /dev/null
>> Loading required package: methods
>> real 0m2.963s
>> user 0m2.844s
>> sys 0m0.115s
>>
>> This solution was fine with me, especially because other packages
>> depending on igraph and using Matrix through igraph worked fine on the
>> CRAN build servers, as igraph brought Matrix with it. (The build
>> servers don't have recommended packages like Matrix available by
>> default.)
>>
>> Recently, R CMD check does not allow me to list Matrix at Imports
>> without importing something from it. This is understandable, because
>> it is an inconsistency after all, but caused some headache for me.
>>
>> A 3s loading time for a package is IMHO much longer than ideal,
>> especially that loading R itself is ten times faster. So I definitely
>> don't want to import from Matrix right now.
>>
>> The solution I settled with was to include Matrix in 'Suggests', and
>> the load it selectively, as before. Now some packages depending on
>> igraph are failing on the CRAN build servers, which don't have Matrix
>> installed for these packages. (Luckily they are probably not failing
>> for users, because most users do have the recommended packages.)
>>
>> In summary, it would be great to speed up imports.
>>
>> Another solution would be some mechanism that allows me to import from
>> a package as needed, not at the package loading time. Something like a
>> delayed importFrom().
>
>
> That is what Matrix:: does.  There is nothing like enough here for us to
> tell why it would not suffice for you.  (If you want to import something
> occasionally and then use it very many times, make a local copy.)
>
>>
>> Just wanted to bring up this issue.
>>
>> Best,
>> Gabor
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
> University of Oxford,             Tel:  +44 1865 272861 (self)
> 1 South Parks Road,                     +44 1865 272866 (PA)
> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From csardi.gabor at gmail.com  Tue Oct 29 15:31:14 2013
From: csardi.gabor at gmail.com (=?ISO-8859-1?B?R+Fib3IgQ3PhcmRp?=)
Date: Tue, 29 Oct 2013 10:31:14 -0400
Subject: [Rd] Imports, importFrom slow (for Matrix)
In-Reply-To: <CABtg=KnprQ0HeK3vK2=6X4HpZ99NjPu365fX+wZUuQPnbL2NuA@mail.gmail.com>
References: <CABtg=KmyKQCp3QBvrar76mF0zUMNayRjT8PtOrKZrmOtAWrS9w@mail.gmail.com>
	<526FC1FA.60200@stats.ox.ac.uk>
	<CABtg=KnprQ0HeK3vK2=6X4HpZ99NjPu365fX+wZUuQPnbL2NuA@mail.gmail.com>
Message-ID: <CABtg=Km0PF9hRFXShDcm=m2vPnyg4Lm5BJ3JAwVW=YwQQRZc3A@mail.gmail.com>

Oh, you mean to put Matrix:: in the functions that need Matrix, right,
of course. Then yes, this could be a solution. I have some issue with
some new class definitions, but I can probably work them out.

Gabor

On Tue, Oct 29, 2013 at 10:25 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> Unfortunately that seems to be (almost) just as slow.
>
> ~$ time Rscript -e 'Matrix::summary; ls()' > /dev/null
> real 0m2.785s
> user 0m2.668s
> sys 0m0.112s
>
> Gabor
>
> On Tue, Oct 29, 2013 at 10:11 AM, Prof Brian Ripley
> <ripley at stats.ox.ac.uk> wrote:
>> On 29/10/2013 14:03, G?bor Cs?rdi wrote:
>>>
>>> Dear All,
>>>
>>> before its latest version my package had 'Imports: Matrix' in its
>>> DESCRIPTION file, but it did not import anything in NAMESPACE. Rather,
>>> some functions explicitly loaded Matrix, as they needed. The reason
>>> for this was that importing Matrix is really slow, and only very few
>>> igraph functions need it. (I guess Matrix is slow because of the many
>>> registered names, but that is another question.)
>>>
>>> # Empty session:
>>> ~$ time Rscript -e 'ls()' > /dev/null
>>> real 0m0.251s
>>> user 0m0.196s
>>> sys 0m0.049s
>>>
>>> # Without importing from Matrix:
>>> ~$ time Rscript -e 'library(igraph); ls()' > /dev/null
>>> Loading required package: methods
>>> real 0m0.419s
>>> user 0m0.363s
>>> sys 0m0.049s
>>>
>>> # Adding importFrom(Matrix, sparseMatrix) to NAMESPACE:
>>> ~$ time Rscript -e 'library(igraph); ls()' > /dev/null
>>> Loading required package: methods
>>> real 0m2.963s
>>> user 0m2.844s
>>> sys 0m0.115s
>>>
>>> This solution was fine with me, especially because other packages
>>> depending on igraph and using Matrix through igraph worked fine on the
>>> CRAN build servers, as igraph brought Matrix with it. (The build
>>> servers don't have recommended packages like Matrix available by
>>> default.)
>>>
>>> Recently, R CMD check does not allow me to list Matrix at Imports
>>> without importing something from it. This is understandable, because
>>> it is an inconsistency after all, but caused some headache for me.
>>>
>>> A 3s loading time for a package is IMHO much longer than ideal,
>>> especially that loading R itself is ten times faster. So I definitely
>>> don't want to import from Matrix right now.
>>>
>>> The solution I settled with was to include Matrix in 'Suggests', and
>>> the load it selectively, as before. Now some packages depending on
>>> igraph are failing on the CRAN build servers, which don't have Matrix
>>> installed for these packages. (Luckily they are probably not failing
>>> for users, because most users do have the recommended packages.)
>>>
>>> In summary, it would be great to speed up imports.
>>>
>>> Another solution would be some mechanism that allows me to import from
>>> a package as needed, not at the package loading time. Something like a
>>> delayed importFrom().
>>
>>
>> That is what Matrix:: does.  There is nothing like enough here for us to
>> tell why it would not suffice for you.  (If you want to import something
>> occasionally and then use it very many times, make a local copy.)
>>
>>>
>>> Just wanted to bring up this issue.
>>>
>>> Best,
>>> Gabor
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>
>> --
>> Brian D. Ripley,                  ripley at stats.ox.ac.uk
>> Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
>> University of Oxford,             Tel:  +44 1865 272861 (self)
>> 1 South Parks Road,                     +44 1865 272866 (PA)
>> Oxford OX1 3TG, UK                Fax:  +44 1865 272595
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From karl.forner at gmail.com  Tue Oct 29 17:19:40 2013
From: karl.forner at gmail.com (Karl Forner)
Date: Tue, 29 Oct 2013 17:19:40 +0100
Subject: [Rd] unloadNamespace,
	getPackageName and "Created a package name xxx " warning
Message-ID: <CAMd4_AfUrHaEx0ofnW+YdCxqzFkGm5-O6k3fWTbx+vpYqNKbug@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131029/8fb68615/attachment.pl>

From jmc at r-project.org  Tue Oct 29 17:54:44 2013
From: jmc at r-project.org (John Chambers)
Date: Tue, 29 Oct 2013 09:54:44 -0700
Subject: [Rd] unloadNamespace,
 getPackageName and "Created a package name xxx " warning
In-Reply-To: <CAMd4_AfUrHaEx0ofnW+YdCxqzFkGm5-O6k3fWTbx+vpYqNKbug@mail.gmail.com>
References: <CAMd4_AfUrHaEx0ofnW+YdCxqzFkGm5-O6k3fWTbx+vpYqNKbug@mail.gmail.com>
Message-ID: <526FE854.9040603@r-project.org>

This was previously reported and fixed.  See the NEWS file and bug 
report 15481.

On 10/29/13 9:19 AM, Karl Forner wrote:
> Dear all,
>
> Consider this code:
>> library("data.table")
>> unloadNamespace('data.table')
>
> It produces some warnings
> Warning in FUN(X[[1L]], ...) :
>    Created a package name, ?2013-10-29 17:05:51?, when none found
> Warning in FUN(X[[1L]], ...) :
>    Created a package name, ?2013-10-29 17:05:51?, when none found
> ...
>
> The warning is produced by the getPackageName() function.
> e.g.
> getPackageName(parent.env(getNamespace('data.table')))
>
> I was wondering what could be done to get rid of these warnings, which I
> believe in the case "unloadNamespace" case are irrelevant.
>
> The stack of calls is:
> # where 3: sapply(where, getPackageName)
> # where 4: findClass(what, classWhere)
> # where 5: .removeSuperclassBackRefs(cl, cldef, searchWhere)
> # where 6: methods:::cacheMetaData(ns, FALSE, ns)
> # where 7: unloadNamespace(pkgname)
>
> So for instance:
>> findClass('data.frame', getNamespace('data.table'))
> generates a warning which once again seems irrelevant.
>
> On the top of my head, I could imagine adding an extra argument to
> getPackageName, say warning = TRUE, which would be set to FALSE in the
> getPackageName call in findClass() body.
>
> I also wonder if in the case of import namespaces, getPackageName() could
> not find a more appropriate name:
>> parent.env(getNamespace('data.table'))
> <environment: 0x7f6ce4d04040>
> attr(,"name")
> [1] "imports:data.table"
>
> This namespace has a name that might be used to generate the package name.
>
> My question is: what should be done ?
>
> Thanks for your attention.
>
> Karl Forner
>
> 	[[alternative HTML version deleted]]
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jouni.helske at jyu.fi  Wed Oct 30 09:05:32 2013
From: jouni.helske at jyu.fi (Helske Jouni)
Date: Wed, 30 Oct 2013 08:05:32 +0000
Subject: [Rd] unique(1:3,nmax=1) freezes R
Message-ID: <7FC11B33B8C53E4EB9510C0BAA73EAE32B713971@mbs1.ad.jyu.fi>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131030/69b7a0b0/attachment.pl>

From maechler at stat.math.ethz.ch  Wed Oct 30 11:35:32 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 30 Oct 2013 11:35:32 +0100
Subject: [Rd] Imports, importFrom slow (for Matrix)
In-Reply-To: <CABtg=Km0PF9hRFXShDcm=m2vPnyg4Lm5BJ3JAwVW=YwQQRZc3A@mail.gmail.com>
References: <CABtg=KmyKQCp3QBvrar76mF0zUMNayRjT8PtOrKZrmOtAWrS9w@mail.gmail.com>
	<526FC1FA.60200@stats.ox.ac.uk>
	<CABtg=KnprQ0HeK3vK2=6X4HpZ99NjPu365fX+wZUuQPnbL2NuA@mail.gmail.com>
	<CABtg=Km0PF9hRFXShDcm=m2vPnyg4Lm5BJ3JAwVW=YwQQRZc3A@mail.gmail.com>
Message-ID: <21104.57588.159866.762076@stat.math.ethz.ch>

>>>>> G?bor Cs?rdi <csardi.gabor at gmail.com>
>>>>>     on Tue, 29 Oct 2013 10:31:14 -0400 writes:

    > Oh, you mean to put Matrix:: in the functions that need
    > Matrix, right, of course. Then yes, this could be a
    > solution. I have some issue with some new class
    > definitions, but I can probably work them out.

    > Gabor

otherwise, please contact  Matrix-authors at r-project.org 
(me being one of the two).

To the whole issue in the 'Subject':  Yes, indeed importing from
Matrix i.e., loading the Matrix namespace, is slow notably compared to many other parts of R including its startup.

I have not had time to investigate, but I even have a vague
feeling that it got considerably slower than it used to be a
couple of R (and Matrix) versions ago.

Note that your timings below are a bit biased because you use
Rscript which unfortunately does not pre-[load + attach] the
'methods' package.
But your bias is only about 0.1 second from my measurements;
the time increases from 0.35 to 0.45  not sure if this is still
a good enough reason to omit  'methods' from Rscript.

Martin



    > On Tue, Oct 29, 2013 at 10:25 AM, G?bor Cs?rdi
    > <csardi.gabor at gmail.com> wrote:
    >> Unfortunately that seems to be (almost) just as slow.
    >> 
    >> ~$ time Rscript -e 'Matrix::summary; ls()' > /dev/null
    >> real 0m2.785s user 0m2.668s sys 0m0.112s
    >> 
    >> Gabor
    >> 
    >> On Tue, Oct 29, 2013 at 10:11 AM, Prof Brian Ripley
    >> <ripley at stats.ox.ac.uk> wrote:
    >>> On 29/10/2013 14:03, G?bor Cs?rdi wrote:
    >>>> 
    >>>> Dear All,
    >>>> 
    >>>> before its latest version my package had 'Imports:
    >>>> Matrix' in its DESCRIPTION file, but it did not import
    >>>> anything in NAMESPACE. Rather, some functions
    >>>> explicitly loaded Matrix, as they needed. The reason
    >>>> for this was that importing Matrix is really slow, and
    >>>> only very few igraph functions need it. (I guess Matrix
    >>>> is slow because of the many registered names, but that
    >>>> is another question.)
    >>>> 
    >>>> # Empty session: ~$ time Rscript -e 'ls()' > /dev/null
    >>>> real 0m0.251s user 0m0.196s sys 0m0.049s
    >>>> 
    >>>> # Without importing from Matrix: ~$ time Rscript -e
    >>>> 'library(igraph); ls()' > /dev/null Loading required
    >>>> package: methods real 0m0.419s user 0m0.363s sys
    >>>> 0m0.049s
    >>>> 
    >>>> # Adding importFrom(Matrix, sparseMatrix) to NAMESPACE:
    >>>> ~$ time Rscript -e 'library(igraph); ls()' > /dev/null
    >>>> Loading required package: methods real 0m2.963s user
    >>>> 0m2.844s sys 0m0.115s
    >>>> 
    >>>> This solution was fine with me, especially because
    >>>> other packages depending on igraph and using Matrix
    >>>> through igraph worked fine on the CRAN build servers,
    >>>> as igraph brought Matrix with it. (The build servers
    >>>> don't have recommended packages like Matrix available
    >>>> by default.)
    >>>> 
    >>>> Recently, R CMD check does not allow me to list Matrix
    >>>> at Imports without importing something from it. This is
    >>>> understandable, because it is an inconsistency after
    >>>> all, but caused some headache for me.
    >>>> 
    >>>> A 3s loading time for a package is IMHO much longer
    >>>> than ideal, especially that loading R itself is ten
    >>>> times faster. So I definitely don't want to import from
    >>>> Matrix right now.
    >>>> 
    >>>> The solution I settled with was to include Matrix in
    >>>> 'Suggests', and the load it selectively, as before. Now
    >>>> some packages depending on igraph are failing on the
    >>>> CRAN build servers, which don't have Matrix installed
    >>>> for these packages. (Luckily they are probably not
    >>>> failing for users, because most users do have the
    >>>> recommended packages.)
    >>>> 
    >>>> In summary, it would be great to speed up imports.
    >>>> 
    >>>> Another solution would be some mechanism that allows me
    >>>> to import from a package as needed, not at the package
    >>>> loading time. Something like a delayed importFrom().
    >>> 
    >>> 
    >>> That is what Matrix:: does.  There is nothing like
    >>> enough here for us to tell why it would not suffice for
    >>> you.  (If you want to import something occasionally and
    >>> then use it very many times, make a local copy.)
    >>> 
    >>>> 
    >>>> Just wanted to bring up this issue.
    >>>> 
    >>>> Best, Gabor
    >>>> 
    >>>> ______________________________________________
    >>>> R-devel at r-project.org mailing list
    >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>>> 
    >>> 
    >>> 
    >>> --
    >>> Brian D. Ripley, ripley at stats.ox.ac.uk Professor of
    >>> Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
    >>> University of Oxford, Tel: +44 1865 272861 (self) 1
    >>> South Parks Road, +44 1865 272866 (PA) Oxford OX1 3TG,
    >>> UK Fax: +44 1865 272595
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at stat.math.ethz.ch  Wed Oct 30 11:48:20 2013
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Wed, 30 Oct 2013 11:48:20 +0100
Subject: [Rd] Imports, importFrom slow (for Matrix)
In-Reply-To: <CABtg=Km0PF9hRFXShDcm=m2vPnyg4Lm5BJ3JAwVW=YwQQRZc3A@mail.gmail.com>
References: <CABtg=KmyKQCp3QBvrar76mF0zUMNayRjT8PtOrKZrmOtAWrS9w@mail.gmail.com>
	<526FC1FA.60200@stats.ox.ac.uk>
	<CABtg=KnprQ0HeK3vK2=6X4HpZ99NjPu365fX+wZUuQPnbL2NuA@mail.gmail.com>
	<CABtg=Km0PF9hRFXShDcm=m2vPnyg4Lm5BJ3JAwVW=YwQQRZc3A@mail.gmail.com>
Message-ID: <21104.58356.650792.197838@stat.math.ethz.ch>

>>>>> G?bor Cs?rdi <csardi.gabor at gmail.com>
>>>>>     on Tue, 29 Oct 2013 10:31:14 -0400 writes:

    > Oh, you mean to put Matrix:: in the functions that need
    > Matrix, right, of course. Then yes, this could be a
    > solution. I have some issue with some new class
    > definitions, but I can probably work them out.

    > Gabor

otherwise, please contact  Matrix-authors at r-project.org 
(me being one of the two).

To the whole issue in the 'Subject':  Yes, indeed importing from
Matrix i.e., loading the Matrix namespace, is slow notably compared to many other parts of R including its startup.

I have not had time to investigate, but I even have a vague
feeling that it got slower than it used to be a
couple of R (and Matrix) versions ago.

Note that your timings below are a bit biased because you use
Rscript which unfortunately does not pre-[load + attach] the
'methods' package.  But then your bias is only about 0.1 seconds
from my measurements (the time increases from 0.35 to 0.45; not
sure if this is still a good enough reason to omit  'methods'
from Rscript by default). 

And ... yes, R is free (aka "libre") software, and proposals for
changes that speedup the loadNamespace("Matrix") without having
to change the R code inside Matrix much are highly appreciated.

Martin Maechler, 
ETH Zurich



    > On Tue, Oct 29, 2013 at 10:25 AM, G?bor Cs?rdi
    > <csardi.gabor at gmail.com> wrote:
    >> Unfortunately that seems to be (almost) just as slow.
    >> 
    >> ~$ time Rscript -e 'Matrix::summary; ls()' > /dev/null
    >> real 0m2.785s user 0m2.668s sys 0m0.112s
    >> 
    >> Gabor
    >> 
    >> On Tue, Oct 29, 2013 at 10:11 AM, Prof Brian Ripley
    >> <ripley at stats.ox.ac.uk> wrote:
    >>> On 29/10/2013 14:03, G?bor Cs?rdi wrote:
    >>>> 
    >>>> Dear All,
    >>>> 
    >>>> before its latest version my package had 'Imports:
    >>>> Matrix' in its DESCRIPTION file, but it did not import
    >>>> anything in NAMESPACE. Rather, some functions
    >>>> explicitly loaded Matrix, as they needed. The reason
    >>>> for this was that importing Matrix is really slow, and
    >>>> only very few igraph functions need it. (I guess Matrix
    >>>> is slow because of the many registered names, but that
    >>>> is another question.)
    >>>> 
    >>>> # Empty session: ~$ time Rscript -e 'ls()' > /dev/null
    >>>> real 0m0.251s user 0m0.196s sys 0m0.049s
    >>>> 
    >>>> # Without importing from Matrix: ~$ time Rscript -e
    >>>> 'library(igraph); ls()' > /dev/null Loading required
    >>>> package: methods real 0m0.419s user 0m0.363s sys
    >>>> 0m0.049s
    >>>> 
    >>>> # Adding importFrom(Matrix, sparseMatrix) to NAMESPACE:
    >>>> ~$ time Rscript -e 'library(igraph); ls()' > /dev/null
    >>>> Loading required package: methods real 0m2.963s user
    >>>> 0m2.844s sys 0m0.115s
    >>>> 
    >>>> This solution was fine with me, especially because
    >>>> other packages depending on igraph and using Matrix
    >>>> through igraph worked fine on the CRAN build servers,
    >>>> as igraph brought Matrix with it. (The build servers
    >>>> don't have recommended packages like Matrix available
    >>>> by default.)
    >>>> 
    >>>> Recently, R CMD check does not allow me to list Matrix
    >>>> at Imports without importing something from it. This is
    >>>> understandable, because it is an inconsistency after
    >>>> all, but caused some headache for me.
    >>>> 
    >>>> A 3s loading time for a package is IMHO much longer
    >>>> than ideal, especially that loading R itself is ten
    >>>> times faster. So I definitely don't want to import from
    >>>> Matrix right now.
    >>>> 
    >>>> The solution I settled with was to include Matrix in
    >>>> 'Suggests', and the load it selectively, as before. Now
    >>>> some packages depending on igraph are failing on the
    >>>> CRAN build servers, which don't have Matrix installed
    >>>> for these packages. (Luckily they are probably not
    >>>> failing for users, because most users do have the
    >>>> recommended packages.)
    >>>> 
    >>>> In summary, it would be great to speed up imports.
    >>>> 
    >>>> Another solution would be some mechanism that allows me
    >>>> to import from a package as needed, not at the package
    >>>> loading time. Something like a delayed importFrom().
    >>> 
    >>> 
    >>> That is what Matrix:: does.  There is nothing like
    >>> enough here for us to tell why it would not suffice for
    >>> you.  (If you want to import something occasionally and
    >>> then use it very many times, make a local copy.)
    >>> 
    >>>> 
    >>>> Just wanted to bring up this issue.
    >>>> 
    >>>> Best, Gabor
    >>>> 
    >>>> ______________________________________________
    >>>> R-devel at r-project.org mailing list
    >>>> https://stat.ethz.ch/mailman/listinfo/r-devel
    >>>> 
    >>> 
    >>> 
    >>> --
    >>> Brian D. Ripley, ripley at stats.ox.ac.uk Professor of
    >>> Applied Statistics, http://www.stats.ox.ac.uk/~ripley/
    >>> University of Oxford, Tel: +44 1865 272861 (self) 1
    >>> South Parks Road, +44 1865 272866 (PA) Oxford OX1 3TG,
    >>> UK Fax: +44 1865 272595
    >>> 
    >>> ______________________________________________
    >>> R-devel at r-project.org mailing list
    >>> https://stat.ethz.ch/mailman/listinfo/r-devel

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From jorismeys at gmail.com  Wed Oct 30 12:04:56 2013
From: jorismeys at gmail.com (Joris Meys)
Date: Wed, 30 Oct 2013 12:04:56 +0100
Subject: [Rd] unique(1:3,nmax=1) freezes R
In-Reply-To: <7FC11B33B8C53E4EB9510C0BAA73EAE32B713971@mbs1.ad.jyu.fi>
References: <7FC11B33B8C53E4EB9510C0BAA73EAE32B713971@mbs1.ad.jyu.fi>
Message-ID: <CAO1zAVao+2nZ4ZByDicjo8X5b8aAko=wiL_stbn-sho=y1gZog@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131030/e074fbb4/attachment.pl>

From jgrn at illinois.edu  Wed Oct 30 19:54:03 2013
From: jgrn at illinois.edu (Jonathan Greenberg)
Date: Wed, 30 Oct 2013 13:54:03 -0500
Subject: [Rd] Where to drop a python script?
Message-ID: <CABG0rfvUzodJ6c22tU6E+yS_Z1NxieQE+afOAHZ4m+wvjcW2Dg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131030/3f052879/attachment.pl>

From marc_schwartz at me.com  Wed Oct 30 20:15:19 2013
From: marc_schwartz at me.com (Marc Schwartz)
Date: Wed, 30 Oct 2013 14:15:19 -0500
Subject: [Rd] Where to drop a python script?
In-Reply-To: <CABG0rfvUzodJ6c22tU6E+yS_Z1NxieQE+afOAHZ4m+wvjcW2Dg@mail.gmail.com>
References: <CABG0rfvUzodJ6c22tU6E+yS_Z1NxieQE+afOAHZ4m+wvjcW2Dg@mail.gmail.com>
Message-ID: <7ABC1D6C-D5B1-4F5D-AE6C-7421BBCE6B49@me.com>


On Oct 30, 2013, at 1:54 PM, Jonathan Greenberg <jgrn at illinois.edu> wrote:

> R-developers:
> 
> I have a small python script that I'd like to include in an R package I'm
> developing, but I'm a bit unclear about which subfolder it should go in.  R
> will be calling the script via a system() call.  Thanks!
> 
> --j


See Writing R Extensions Manual, section 1.1.7:

  http://cran.r-project.org/doc/manuals/r-release/R-exts.html#Non_002dR-scripts-in-packages

If you want to see a package example, my WriteXLS package uses Perl, but the concepts will be the same:

  https://github.com/marcschwartz/WriteXLS

If you look at WriteXLS.R around line 130, you can see an example of getting the $PATH to the included Perl scripts that I use, which are in the 'inst/Perl' folder. Further down around line 230, is where the script is called via system(). Note the use of shQuote() for some arguments.

Regards,

Marc Schwartz


From edd at debian.org  Wed Oct 30 20:15:59 2013
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 30 Oct 2013 14:15:59 -0500
Subject: [Rd] Where to drop a python script?
In-Reply-To: <CABG0rfvUzodJ6c22tU6E+yS_Z1NxieQE+afOAHZ4m+wvjcW2Dg@mail.gmail.com>
References: <CABG0rfvUzodJ6c22tU6E+yS_Z1NxieQE+afOAHZ4m+wvjcW2Dg@mail.gmail.com>
Message-ID: <21105.23279.974154.140323@max.nulle.part>


On 30 October 2013 at 13:54, Jonathan Greenberg wrote:
| R-developers:
| 
| I have a small python script that I'd like to include in an R package I'm
| developing, but I'm a bit unclear about which subfolder it should go in.  R
| will be calling the script via a system() call.  Thanks!

Up to you as you control the path. As "Writing R Extensions" explains,
everything below the (source) directory inst/ will get installed.  I like
inst/extScripts/ (or similar) as it denotes that it is an external script.

As an example, the gdata package has Perl code for xls reading/writing below a
directory inst/perl/ -- and I think there are more packages doing this.

Dirk


-- 
Dirk Eddelbuettel | edd at debian.org | http://dirk.eddelbuettel.com


From h.wickham at gmail.com  Wed Oct 30 23:22:40 2013
From: h.wickham at gmail.com (Hadley Wickham)
Date: Wed, 30 Oct 2013 17:22:40 -0500
Subject: [Rd] Huge performance difference between implicit and explicit print
Message-ID: <CABdHhvEkfACu91SD5p01kgJJiqNUwtQK-fnbgmFOYqFo9ScS9Q@mail.gmail.com>

Hi all,

Can anyone help me understand why an implicit print (i.e. just typing
df at the console), is so much slower than an explicit print (i.e.
print(df)) in the example below?  I see the difference in both Rstudio
and in a terminal.

# Construct large df as quickly as possible
dummy <- 1:18e6
df <- lapply(1:10, function(x) dummy)
names(df) <- letters[1:10]
class(df) <- c("myobj", "data.frame")
attr(df, "row.names") <- .set_row_names(18e6)

print.myobj <- function(x, ...) {
  print.data.frame(head(x, 2))
}

start <- proc.time(); df; flush.console(); proc.time() - start
#  user  system elapsed
# 0.408   0.557   0.965
start <- proc.time(); print(df); flush.console(); proc.time() - start
#  user  system elapsed
# 0.019   0.002   0.020

sessionInfo()
# R version 3.0.2 (2013-09-25)
# Platform: x86_64-apple-darwin10.8.0 (64-bit)
#
# locale:
# [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
#
# attached base packages:
# [1] stats     graphics  grDevices utils     datasets  methods   base

Thanks!

Hadley

-- 
Chief Scientist, RStudio
http://had.co.nz/


From ggrothendieck at gmail.com  Thu Oct 31 00:14:18 2013
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Wed, 30 Oct 2013 19:14:18 -0400
Subject: [Rd] Huge performance difference between implicit and explicit
	print
In-Reply-To: <CABdHhvEkfACu91SD5p01kgJJiqNUwtQK-fnbgmFOYqFo9ScS9Q@mail.gmail.com>
References: <CABdHhvEkfACu91SD5p01kgJJiqNUwtQK-fnbgmFOYqFo9ScS9Q@mail.gmail.com>
Message-ID: <CAP01uRnOqOuknCNsnCopuy5Kxj3-JJG656C_e59m8fXo4kKc5w@mail.gmail.com>

On Wed, Oct 30, 2013 at 6:22 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
> Hi all,
>
> Can anyone help me understand why an implicit print (i.e. just typing
> df at the console), is so much slower than an explicit print (i.e.
> print(df)) in the example below?  I see the difference in both Rstudio
> and in a terminal.
>
> # Construct large df as quickly as possible
> dummy <- 1:18e6
> df <- lapply(1:10, function(x) dummy)
> names(df) <- letters[1:10]
> class(df) <- c("myobj", "data.frame")
> attr(df, "row.names") <- .set_row_names(18e6)
>
> print.myobj <- function(x, ...) {
>   print.data.frame(head(x, 2))
> }
>
> start <- proc.time(); df; flush.console(); proc.time() - start
> #  user  system elapsed
> # 0.408   0.557   0.965
> start <- proc.time(); print(df); flush.console(); proc.time() - start
> #  user  system elapsed
> # 0.019   0.002   0.020

If I change print(df) to print.data.frame(df) it hangs.

R version 3.0.2 Patched (2013-10-06 r64031) -- "Frisbee Sailing"
Copyright (C) 2013 The R Foundation for Statistical Computing
Platform: x86_64-w64-mingw32/x64 (64-bit)


From gmbecker at ucdavis.edu  Thu Oct 31 00:32:43 2013
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Wed, 30 Oct 2013 16:32:43 -0700
Subject: [Rd] Huge performance difference between implicit and explicit
	print
In-Reply-To: <CABdHhvEkfACu91SD5p01kgJJiqNUwtQK-fnbgmFOYqFo9ScS9Q@mail.gmail.com>
References: <CABdHhvEkfACu91SD5p01kgJJiqNUwtQK-fnbgmFOYqFo9ScS9Q@mail.gmail.com>
Message-ID: <CADwqtCPSHHfQOURZdh23msB1fo58bwHeecUoUGa_x=bspy61Vg@mail.gmail.com>

An embedded and charset-unspecified text was scrubbed...
Name: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20131030/eb749b68/attachment.pl>

From pgilbert902 at gmail.com  Thu Oct 31 01:40:23 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Wed, 30 Oct 2013 20:40:23 -0400
Subject: [Rd] Where to drop a python script?
In-Reply-To: <21105.23279.974154.140323@max.nulle.part>
References: <CABG0rfvUzodJ6c22tU6E+yS_Z1NxieQE+afOAHZ4m+wvjcW2Dg@mail.gmail.com>
	<21105.23279.974154.140323@max.nulle.part>
Message-ID: <5271A6F7.8070904@gmail.com>

The old convention was that it went in the exec/ directory, but as you 
can see at 
http://cran.at.r-project.org/doc/manuals/r-devel/R-exts.html#Non_002dR-scripts-in-packages 
  it can be in inst/anyName/. A minor convenience of exec/ is that the 
directory has the same name in source and when installed, whereas 
inst/anyName gets moved to anyName/, so debugging can be a tiny bit 
easier with exec/.

Having just put a package (TSjson) on CRAN with a python script, here 
are a few other pointers for getting it on CRAN:

-SystemRequirements: should indicate if a particular version of python 
is needed, and any non-default modules that are needed. (My package does 
not work with Python 3 because some modules are not available.) Some of 
the libraries have changed, so it could be a bit tricky to make 
something work easily with both 2 and 3.

-You need a README to explain how to install Python. (If you look at or 
use mine, please let me know if you find problems.)

-The Linux and Sun CRAN test machines have Python 2 whereas winbuilder 
has Python 3. Be prepared to explain that the package will not work on 
one or the other.

Another option to system() is pipe()

Paul

On 13-10-30 03:15 PM, Dirk Eddelbuettel wrote:
>
> On 30 October 2013 at 13:54, Jonathan Greenberg wrote:
> | R-developers:
> |
> | I have a small python script that I'd like to include in an R package I'm
> | developing, but I'm a bit unclear about which subfolder it should go in.  R
> | will be calling the script via a system() call.  Thanks!
>
> Up to you as you control the path. As "Writing R Extensions" explains,
> everything below the (source) directory inst/ will get installed.  I like
> inst/extScripts/ (or similar) as it denotes that it is an external script.
>
> As an example, the gdata package has Perl code for xls reading/writing below a
> directory inst/perl/ -- and I think there are more packages doing this.
>
> Dirk
>
>


From ripley at stats.ox.ac.uk  Thu Oct 31 08:01:06 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 31 Oct 2013 07:01:06 +0000
Subject: [Rd] Where to drop a python script?
In-Reply-To: <5271A6F7.8070904@gmail.com>
References: <CABG0rfvUzodJ6c22tU6E+yS_Z1NxieQE+afOAHZ4m+wvjcW2Dg@mail.gmail.com>	<21105.23279.974154.140323@max.nulle.part>
	<5271A6F7.8070904@gmail.com>
Message-ID: <52720032.5060702@stats.ox.ac.uk>

On 31/10/2013 00:40, Paul Gilbert wrote:
> The old convention was that it went in the exec/ directory, but as you
> can see at
> http://cran.at.r-project.org/doc/manuals/r-devel/R-exts.html#Non_002dR-scripts-in-packages
>   it can be in inst/anyName/. A minor convenience of exec/ is that the
> directory has the same name in source and when installed, whereas
> inst/anyName gets moved to anyName/, so debugging can be a tiny bit
> easier with exec/.
>
> Having just put a package (TSjson) on CRAN with a python script, here
> are a few other pointers for getting it on CRAN:
>
> -SystemRequirements: should indicate if a particular version of python
> is needed, and any non-default modules that are needed. (My package does
> not work with Python 3 because some modules are not available.) Some of
> the libraries have changed, so it could be a bit tricky to make
> something work easily with both 2 and 3.
>
> -You need a README to explain how to install Python. (If you look at or
> use mine, please let me know if you find problems.)

Better to describe exactly what you need: installation instructions go 
stale very easily.

> -The Linux and Sun CRAN test machines have Python 2 whereas winbuilder
> has Python 3. Be prepared to explain that the package will not work on
> one or the other.

Not true.  Linux and Solaris (sic) have both: the Solaris machines have 
2.6 and 3.3.  Please do not spread misinformation about machines you do 
not have any access to.

>
> Another option to system() is pipe()
>
> Paul
>
> On 13-10-30 03:15 PM, Dirk Eddelbuettel wrote:
>>
>> On 30 October 2013 at 13:54, Jonathan Greenberg wrote:
>> | R-developers:
>> |
>> | I have a small python script that I'd like to include in an R
>> package I'm
>> | developing, but I'm a bit unclear about which subfolder it should go
>> in.  R
>> | will be calling the script via a system() call.  Thanks!
>>
>> Up to you as you control the path. As "Writing R Extensions" explains,
>> everything below the (source) directory inst/ will get installed.  I like
>> inst/extScripts/ (or similar) as it denotes that it is an external
>> script.
>>
>> As an example, the gdata package has Perl code for xls reading/writing
>> below a
>> directory inst/perl/ -- and I think there are more packages doing this.
>>
>> Dirk
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From seanpor at acm.org  Thu Oct 31 08:46:52 2013
From: seanpor at acm.org (Sean O'Riordain)
Date: Thu, 31 Oct 2013 07:46:52 +0000
Subject: [Rd] Huge performance difference between implicit and explicit
	print
In-Reply-To: <CADwqtCPSHHfQOURZdh23msB1fo58bwHeecUoUGa_x=bspy61Vg@mail.gmail.com>
References: <CABdHhvEkfACu91SD5p01kgJJiqNUwtQK-fnbgmFOYqFo9ScS9Q@mail.gmail.com>
	<CADwqtCPSHHfQOURZdh23msB1fo58bwHeecUoUGa_x=bspy61Vg@mail.gmail.com>
Message-ID: <CA+MmmT+2p3e9NG5zCXXpk+QUxOWBsYLxm-qe2xC0QaNGu9LB5g@mail.gmail.com>

Minor point and probably not relevant to the speed issue, but df() is
the density function for the F distribution, so I have (recently)
stopped using it for referring to data.frames.

Sean


On 30 October 2013 23:32, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> Hadley,
>
> As far as I can tell from a quick look, it is because implicit printing
> uses a different mechanism which does a fair bit more work.
>
> >From comments in  print.c in the R sources:
>
> *  print.default()  ->     do_printdefault (with call tree below)
>  *
>  *  auto-printing   ->  PrintValueEnv
>  *                      -> PrintValueRec
>  *                      -> call print() for objects
>  *  Note that auto-printing does not call print.default.
>  *  PrintValue, R_PV are similar to auto-printing.
>
> PrintValueEnv includes, among other things, checks for functions, S4
> objects, and s3 objects before constructing (in C code) an R call to print
> for S3 objects and show for S4 objects  and evaluating it using Rf_eval. So
> there is an extra trip to the R evaluator.
>
> I imagine that extra work is where the hangup is but that is a
> slightly-informed guess as I haven't done any detailed timings or checks.
>
> Basically my understanding of the processes is as follows:
>
> print(df)
> print call is evaluated, S3 dispatch happens, print.default in C is called,
> result printed to terminal, print call returns
>
> df
> expression "df" evaluated, auto-print initiated, type of object returned by
> expression is determined, print call is constructed in C code, print call
> is evaluated in C code, THEN all the stuff above happens.
>
> I dunno if that helps or not as I can't speak to how to change/fix it atm.
>
> ~G
>
>
>
> On Wed, Oct 30, 2013 at 3:22 PM, Hadley Wickham <h.wickham at gmail.com> wrote:
>
>> Hi all,
>>
>> Can anyone help me understand why an implicit print (i.e. just typing
>> df at the console), is so much slower than an explicit print (i.e.
>> print(df)) in the example below?  I see the difference in both Rstudio
>> and in a terminal.
>>
>> # Construct large df as quickly as possible
>> dummy <- 1:18e6
>> df <- lapply(1:10, function(x) dummy)
>> names(df) <- letters[1:10]
>> class(df) <- c("myobj", "data.frame")
>> attr(df, "row.names") <- .set_row_names(18e6)
>>
>> print.myobj <- function(x, ...) {
>>   print.data.frame(head(x, 2))
>> }
>>
>> start <- proc.time(); df; flush.console(); proc.time() - start
>> #  user  system elapsed
>> # 0.408   0.557   0.965
>> start <- proc.time(); print(df); flush.console(); proc.time() - start
>> #  user  system elapsed
>> # 0.019   0.002   0.020
>>
>> sessionInfo()
>> # R version 3.0.2 (2013-09-25)
>> # Platform: x86_64-apple-darwin10.8.0 (64-bit)
>> #
>> # locale:
>> # [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
>> #
>> # attached base packages:
>> # [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> Thanks!
>>
>> Hadley
>>
>> --
>> Chief Scientist, RStudio
>> http://had.co.nz/
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>
>
> --
> Gabriel Becker
> Graduate Student
> Statistics Department
> University of California, Davis
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From mtmorgan at fhcrc.org  Thu Oct 31 12:27:45 2013
From: mtmorgan at fhcrc.org (Martin Morgan)
Date: Thu, 31 Oct 2013 04:27:45 -0700
Subject: [Rd] tar warnings in R-3.0.2 RC when R is installed by a
 different (non-root) user
In-Reply-To: <5240B844.1080701@stats.ox.ac.uk>
References: <220141431.876438.1379966140031.JavaMail.root@fhcrc.org>
	<5240B844.1080701@stats.ox.ac.uk>
Message-ID: <52723EB1.1050908@fhcrc.org>

On 09/23/2013 02:53 PM, Prof Brian Ripley wrote:
> The issue is not the ownership (uname) but the uid.  A tarball can only store
> uids up to 'nobody' (usually 32767), and certainly larger ones cannot be
> unpacked portably.

The many identical warnings can obscure useful messages, e.g., about invalid 
permissions on files. Can these be collapsed to a single warning, or one for 
each of uid / gid?

>
> The warnings did not occur before, but the tarball produced could cause problems
> when unpacking with other tools.
>
> On 23/09/2013 20:55, Dan Tenenbaum wrote:
>> Hi,
>>
>> I created a package as follows:
>>
>>> a = 1
>>> package.skeleton()
>>
>> Then I got the following output when building the package:
>>
>> * checking for file ?anRpackage/DESCRIPTION? ... OK
>> * preparing ?anRpackage?:
>> * checking DESCRIPTION meta-information ... OK
>> * checking for LF line-endings in source and make files
>> * checking for empty or unneeded directories
>> * looking to see if a ?data/datalist? file should be added
>> * building ?anRpackage_1.0.tar.gz?
>> Warning: invalid uid value replaced by that for user 'nobody'
>> Warning: invalid uid value replaced by that for user 'nobody'
>> Warning: invalid uid value replaced by that for user 'nobody'
>> Warning: invalid uid value replaced by that for user 'nobody'
>> Warning: invalid uid value replaced by that for user 'nobody'
>> Warning: invalid uid value replaced by that for user 'nobody'
>> Warning: invalid uid value replaced by that for user 'nobody'
>>
>> One thing to note is that I am logged in as 'pkgbuild' and R was installed by
>> the user 'biocbuild'. I explicitly point to the R that was installed by
>> 'biocbuild' when building the package above. (I used the command
>> "~biocbuild/bbs-2.13-bioc/R/bin/R CMD build anRpackage").
>>
>> There doesn't seem to be anything wrong with the ownership of the files in
>> anRpackage:
>>
>> $ ls -lR anRpackage
>> anRpackage:
>> total 20
>> drwxr-xr-x 2 pkgbuild users 4096 Sep 23 12:42 data
>> -rw-r--r-- 1 pkgbuild users  283 Sep 23 12:42 DESCRIPTION
>> drwxr-xr-x 2 pkgbuild users 4096 Sep 23 12:42 man
>> -rw-r--r-- 1 pkgbuild users   31 Sep 23 12:42 NAMESPACE
>> -rw-r--r-- 1 pkgbuild users  420 Sep 23 12:42 Read-and-delete-me
>>
>> anRpackage/data:
>> total 4
>> -rw-r--r-- 1 pkgbuild users 59 Sep 23 12:42 a.rda
>>
>> anRpackage/man:
>> total 8
>> -rw-r--r-- 1 pkgbuild users 1051 Sep 23 12:42 anRpackage-package.Rd
>> -rw-r--r-- 1 pkgbuild users  503 Sep 23 12:42 a.Rd
>>
>> These warnings did not appear with an earlier version of R-patched (r63824).
>>
>> Thanks,
>> Dan
>>
>>
>>
>>> sessionInfo()
>> R version 3.0.2 RC (2013-09-17 r63944)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>>
>> locale:
>>   [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>>   [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
>>   [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>>   [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>>   [9] LC_ADDRESS=C               LC_TELEPHONE=C
>> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>>
>> attached base packages:
>> [1] stats     graphics  grDevices utils     datasets  methods   base
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From pgilbert902 at gmail.com  Thu Oct 31 16:33:38 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Thu, 31 Oct 2013 11:33:38 -0400
Subject: [Rd] Where to drop a python script?
In-Reply-To: <52720032.5060702@stats.ox.ac.uk>
References: <CABG0rfvUzodJ6c22tU6E+yS_Z1NxieQE+afOAHZ4m+wvjcW2Dg@mail.gmail.com>	<21105.23279.974154.140323@max.nulle.part>	<5271A6F7.8070904@gmail.com>
	<52720032.5060702@stats.ox.ac.uk>
Message-ID: <52727852.4000008@gmail.com>



On 13-10-31 03:01 AM, Prof Brian Ripley wrote:
> On 31/10/2013 00:40, Paul Gilbert wrote:
>> The old convention was that it went in the exec/ directory, but as you
>> can see at
>> http://cran.at.r-project.org/doc/manuals/r-devel/R-exts.html#Non_002dR-scripts-in-packages
>>
>>   it can be in inst/anyName/. A minor convenience of exec/ is that the
>> directory has the same name in source and when installed, whereas
>> inst/anyName gets moved to anyName/, so debugging can be a tiny bit
>> easier with exec/.
>>
>> Having just put a package (TSjson) on CRAN with a python script, here
>> are a few other pointers for getting it on CRAN:
>>
>> -SystemRequirements: should indicate if a particular version of python
>> is needed, and any non-default modules that are needed. (My package does
>> not work with Python 3 because some modules are not available.) Some of
>> the libraries have changed, so it could be a bit tricky to make
>> something work easily with both 2 and 3.
>>
>> -You need a README to explain how to install Python. (If you look at or
>> use mine, please let me know if you find problems.)
>
> Better to describe exactly what you need: installation instructions go
> stale very easily.
>
>> -The Linux and Sun CRAN test machines have Python 2 whereas winbuilder
>> has Python 3. Be prepared to explain that the package will not work on
>> one or the other.
>
> Not true.  Linux and Solaris (sic) have both: the Solaris machines have
> 2.6 and 3.3.

For an R package how does one go about specifying which should be used?

> Please do not spread misinformation about machines you do
> not have any access to.
>
>>
>> Another option to system() is pipe()
>>
>> Paul
>>
>> On 13-10-30 03:15 PM, Dirk Eddelbuettel wrote:
>>>
>>> On 30 October 2013 at 13:54, Jonathan Greenberg wrote:
>>> | R-developers:
>>> |
>>> | I have a small python script that I'd like to include in an R
>>> package I'm
>>> | developing, but I'm a bit unclear about which subfolder it should go
>>> in.  R
>>> | will be calling the script via a system() call.  Thanks!
>>>
>>> Up to you as you control the path. As "Writing R Extensions" explains,
>>> everything below the (source) directory inst/ will get installed.  I
>>> like
>>> inst/extScripts/ (or similar) as it denotes that it is an external
>>> script.
>>>
>>> As an example, the gdata package has Perl code for xls reading/writing
>>> below a
>>> directory inst/perl/ -- and I think there are more packages doing this.
>>>
>>> Dirk
>>>
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From ripley at stats.ox.ac.uk  Thu Oct 31 18:16:17 2013
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 31 Oct 2013 17:16:17 +0000
Subject: [Rd] Where to drop a python script?
In-Reply-To: <52727852.4000008@gmail.com>
References: <CABG0rfvUzodJ6c22tU6E+yS_Z1NxieQE+afOAHZ4m+wvjcW2Dg@mail.gmail.com>	<21105.23279.974154.140323@max.nulle.part>	<5271A6F7.8070904@gmail.com>
	<52720032.5060702@stats.ox.ac.uk> <52727852.4000008@gmail.com>
Message-ID: <52729061.4050504@stats.ox.ac.uk>

On 31/10/2013 15:33, Paul Gilbert wrote:
>
>
> On 13-10-31 03:01 AM, Prof Brian Ripley wrote:
>> On 31/10/2013 00:40, Paul Gilbert wrote:
>>> The old convention was that it went in the exec/ directory, but as you
>>> can see at
>>> http://cran.at.r-project.org/doc/manuals/r-devel/R-exts.html#Non_002dR-scripts-in-packages
>>>
>>>
>>>   it can be in inst/anyName/. A minor convenience of exec/ is that the
>>> directory has the same name in source and when installed, whereas
>>> inst/anyName gets moved to anyName/, so debugging can be a tiny bit
>>> easier with exec/.
>>>
>>> Having just put a package (TSjson) on CRAN with a python script, here
>>> are a few other pointers for getting it on CRAN:
>>>
>>> -SystemRequirements: should indicate if a particular version of python
>>> is needed, and any non-default modules that are needed. (My package does
>>> not work with Python 3 because some modules are not available.) Some of
>>> the libraries have changed, so it could be a bit tricky to make
>>> something work easily with both 2 and 3.
>>>
>>> -You need a README to explain how to install Python. (If you look at or
>>> use mine, please let me know if you find problems.)
>>
>> Better to describe exactly what you need: installation instructions go
>> stale very easily.
>>
>>> -The Linux and Sun CRAN test machines have Python 2 whereas winbuilder
>>> has Python 3. Be prepared to explain that the package will not work on
>>> one or the other.
>>
>> Not true.  Linux and Solaris (sic) have both: the Solaris machines have
>> 2.6 and 3.3.
>
> For an R package how does one go about specifying which should be used?

You ask the user to tell you the path or at least the command name, e.g. 
by an environment variable or R function argument.  Just like any other 
external program such as GhostScript.

>
>> Please do not spread misinformation about machines you do
>> not have any access to.
>>
>>>
>>> Another option to system() is pipe()
>>>
>>> Paul
>>>
>>> On 13-10-30 03:15 PM, Dirk Eddelbuettel wrote:
>>>>
>>>> On 30 October 2013 at 13:54, Jonathan Greenberg wrote:
>>>> | R-developers:
>>>> |
>>>> | I have a small python script that I'd like to include in an R
>>>> package I'm
>>>> | developing, but I'm a bit unclear about which subfolder it should go
>>>> in.  R
>>>> | will be calling the script via a system() call.  Thanks!
>>>>
>>>> Up to you as you control the path. As "Writing R Extensions" explains,
>>>> everything below the (source) directory inst/ will get installed.  I
>>>> like
>>>> inst/extScripts/ (or similar) as it denotes that it is an external
>>>> script.
>>>>
>>>> As an example, the gdata package has Perl code for xls reading/writing
>>>> below a
>>>> directory inst/perl/ -- and I think there are more packages doing this.
>>>>
>>>> Dirk
>>>>
>>>>
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Professor of Applied Statistics,  http://www.stats.ox.ac.uk/~ripley/
University of Oxford,             Tel:  +44 1865 272861 (self)
1 South Parks Road,                     +44 1865 272866 (PA)
Oxford OX1 3TG, UK                Fax:  +44 1865 272595


From pgilbert902 at gmail.com  Thu Oct 31 18:45:29 2013
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Thu, 31 Oct 2013 13:45:29 -0400
Subject: [Rd] Where to drop a python script?
In-Reply-To: <52729061.4050504@stats.ox.ac.uk>
References: <CABG0rfvUzodJ6c22tU6E+yS_Z1NxieQE+afOAHZ4m+wvjcW2Dg@mail.gmail.com>	<21105.23279.974154.140323@max.nulle.part>	<5271A6F7.8070904@gmail.com>
	<52720032.5060702@stats.ox.ac.uk> <52727852.4000008@gmail.com>
	<52729061.4050504@stats.ox.ac.uk>
Message-ID: <52729739.4050401@gmail.com>



On 13-10-31 01:16 PM, Prof Brian Ripley wrote:
> On 31/10/2013 15:33, Paul Gilbert wrote:
>>
>>
>> On 13-10-31 03:01 AM, Prof Brian Ripley wrote:
>>> On 31/10/2013 00:40, Paul Gilbert wrote:
>>>> The old convention was that it went in the exec/ directory, but as you
>>>> can see at
>>>> http://cran.at.r-project.org/doc/manuals/r-devel/R-exts.html#Non_002dR-scripts-in-packages
>>>>
>>>>
>>>>
>>>>   it can be in inst/anyName/. A minor convenience of exec/ is that the
>>>> directory has the same name in source and when installed, whereas
>>>> inst/anyName gets moved to anyName/, so debugging can be a tiny bit
>>>> easier with exec/.
>>>>
>>>> Having just put a package (TSjson) on CRAN with a python script, here
>>>> are a few other pointers for getting it on CRAN:
>>>>
>>>> -SystemRequirements: should indicate if a particular version of python
>>>> is needed, and any non-default modules that are needed. (My package
>>>> does
>>>> not work with Python 3 because some modules are not available.) Some of
>>>> the libraries have changed, so it could be a bit tricky to make
>>>> something work easily with both 2 and 3.
>>>>
>>>> -You need a README to explain how to install Python. (If you look at or
>>>> use mine, please let me know if you find problems.)
>>>
>>> Better to describe exactly what you need: installation instructions go
>>> stale very easily.
>>>
>>>> -The Linux and Sun CRAN test machines have Python 2 whereas winbuilder
>>>> has Python 3. Be prepared to explain that the package will not work on
>>>> one or the other.
>>>
>>> Not true.  Linux and Solaris (sic) have both: the Solaris machines have
>>> 2.6 and 3.3.
>>
>> For an R package how does one go about specifying which should be used?
>
> You ask the user to tell you the path or at least the command name, e.g.
> by an environment variable or R function argument.  Just like any other
> external program such as GhostScript.

Yes, but since I don't have direct access to the CRAN test machines, 
specifically, on the CRAN test machines, how do I specify to use Python 
2 or Python 3? (That is, I think you are the user when CRAN tests are 
done on Solaris, so I am asking you.)

>
>>
>>> Please do not spread misinformation about machines you do
>>> not have any access to.
>>>
>>>>
>>>> Another option to system() is pipe()
>>>>
>>>> Paul
>>>>
>>>> On 13-10-30 03:15 PM, Dirk Eddelbuettel wrote:
>>>>>
>>>>> On 30 October 2013 at 13:54, Jonathan Greenberg wrote:
>>>>> | R-developers:
>>>>> |
>>>>> | I have a small python script that I'd like to include in an R
>>>>> package I'm
>>>>> | developing, but I'm a bit unclear about which subfolder it should go
>>>>> in.  R
>>>>> | will be calling the script via a system() call.  Thanks!
>>>>>
>>>>> Up to you as you control the path. As "Writing R Extensions" explains,
>>>>> everything below the (source) directory inst/ will get installed.  I
>>>>> like
>>>>> inst/extScripts/ (or similar) as it denotes that it is an external
>>>>> script.
>>>>>
>>>>> As an example, the gdata package has Perl code for xls reading/writing
>>>>> below a
>>>>> directory inst/perl/ -- and I think there are more packages doing
>>>>> this.
>>>>>
>>>>> Dirk
>>>>>
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>>
>
>


