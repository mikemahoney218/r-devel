From lawrence.michael at gene.com  Fri May  1 23:30:21 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 1 May 2015 14:30:21 -0700
Subject: [Rd] Add first() and last() to utils?
In-Reply-To: <CAKorm_sj04vU-zZCrcL7f2ATworD4MkSuACbP92nPfBvnMC_VQ@mail.gmail.com>
References: <CAKorm_sj04vU-zZCrcL7f2ATworD4MkSuACbP92nPfBvnMC_VQ@mail.gmail.com>
Message-ID: <CAOQ5Nyf=HncLYzgDUeWe7B27G1B0xHq9CNF72KWe-zCLc+3c9g@mail.gmail.com>

I would argue that it should be:

first <- function(x, ...) head(x, n=1L, ...)

So it's simpler and we don't have people using first() and head()
interchangeably for non-default 'n'. first() should mean "the" first. That
also avoids forcing 'n' to be in the formals of every generic+method. Of
course, there is still the problem of conflicting semantics with existing
functions. For example, GenomicAlignments has first() meaning the first
sequence alignment for all pairs, whereas with these semantics it would be
the first alignment of the dataset, if that makes any sense. Of course, we
could rename those to something, but this might not be the only case...




On Tue, Apr 28, 2015 at 12:11 PM, Gregory Warnes <greg at warnes.net> wrote:

> Hi all,
>
> I've been using first() and last() for some time instead of x[1] and
> x[length(x)] for vectors, and I gradually added methods for lists,
> matrices, and data.frames.
>
> In preparing the next release of the 'gdata' package (2.16.1) I settled on
> these definitions, which harness the existing methods for head() and
> tail():
>
> # Simply call 'first' or 'last' with a different default value for 'n'.
> first <- function(x, n=1, ...) head(x, n=n, ...)
> last  <- function(x, n=1, ...) tail(x, n=n, ...)
>
>
> This works nicely, but Brian noted that packages 'data.table' and 'xts'
> also provide functions/S3 methods for head() and/or tail().
>
> Would it make sense to add these definitions to package 'utils' to make
> them generally available?
>
> -Greg
>
> --
> "Whereas true religion and good morals are the only solid foundations of
> public liberty and happiness . . . it is hereby earnestly recommended to
> the several States to take the most effectual measures for the
> encouragement thereof." Continental Congress, 1778
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Sat May  2 01:24:04 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Fri, 1 May 2015 19:24:04 -0400
Subject: [Rd] R CMD check and missing imports from base packages
In-Reply-To: <21825.56681.241681.166313@stat.math.ethz.ch>
References: <CABtg=K=iq7XVY8NksW-gQq_zr7wk4329Sh67c55JxrFF2HDosQ@mail.gmail.com>
	<55413E1A.9030804@fredhutch.org>
	<CAF8bMcb_3SuzLLwNg-znVByO2XtXsxwGnObMZ_4jmvv9oSHXLQ@mail.gmail.com>
	<5541737A.10205@gmail.com>
	<CABtg=KnThd61TgaFmRutS=eOPUFXsPnLzHJK=Vg_T60gcP-yWA@mail.gmail.com>
	<21825.56681.241681.166313@stat.math.ethz.ch>
Message-ID: <CABtg=KnOsnaER=X7V9uYehrGySPiY3LVVtB14m-5jjOnea5RXA@mail.gmail.com>

On Thu, Apr 30, 2015 at 3:44 AM, Martin Maechler <
maechler at lynne.stat.math.ethz.ch> wrote:
[...]

>
> If I have understood your main point correctly, you are
> suggesting that  'R CMD check' should start putting out a NOTE
> when package code calls a function from one of a set of
> "standard packages" (*) and the package author failed to use an
>         importFrom(<standard pkg>, <function>)
> in his/her NAMESPACE.
>

Yes, correct.

I agree that this would be useful.
> Actually, I think we have something like this in place already...
> but maybe not strictly enough (?)
>

It is in place for non-standard packages. But not for the standard ones.
This code
calls a function from all base packages that are loaded by default:
https://github.com/gaborcsardi/baseimports/blob/master/R/baseimports.R#L11
and it generates these checks on R-release and R-devel, both without NOTEs
or WARNINGs:
https://travis-ci.org/gaborcsardi/baseimports/jobs/60903983
https://travis-ci.org/gaborcsardi/baseimports/jobs/60903984

Gabor


>
> (*) IIUC, you suggested to use
>    "standard packages" := packages which are attached by default
>    in R, apart from package 'base' because that does come
>    immediately after the imports anyway (and because you cannot
>    explicity import from base).
>
>
> Martin Maechler
> ETH Zurich
>

	[[alternative HTML version deleted]]


From lgautier at gmail.com  Sun May  3 22:34:31 2015
From: lgautier at gmail.com (Laurent Gautier)
Date: Sun, 3 May 2015 16:34:31 -0400
Subject: [Rd] C-API: check whether R has been initialized ?
Message-ID: <CA+JCgN12YVXnWggr1PTfp81U6Bg3=4ARatOdfNh8wZXM_Aes8g@mail.gmail.com>

Hi,

There appear to be no way to check whether R has already been initialized.

Could a function like "Rf_isinitialized" be added to the API ?


Best,


Laurent

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon May  4 00:12:43 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 03 May 2015 18:12:43 -0400
Subject: [Rd] C-API: check whether R has been initialized ?
In-Reply-To: <CA+JCgN12YVXnWggr1PTfp81U6Bg3=4ARatOdfNh8wZXM_Aes8g@mail.gmail.com>
References: <CA+JCgN12YVXnWggr1PTfp81U6Bg3=4ARatOdfNh8wZXM_Aes8g@mail.gmail.com>
Message-ID: <55469D5B.5030701@gmail.com>

On 03/05/2015 4:34 PM, Laurent Gautier wrote:
> Hi,
> 
> There appear to be no way to check whether R has already been initialized.
> 
> Could a function like "Rf_isinitialized" be added to the API ?
> 

Surely any program that needs to know that could keep its own flag.
You'll need to give a much longer argument about why this is necessary
for what you're doing.

Duncan Murdoch


From lgautier at gmail.com  Mon May  4 01:02:28 2015
From: lgautier at gmail.com (Laurent Gautier)
Date: Sun, 3 May 2015 19:02:28 -0400
Subject: [Rd] C-API: check whether R has been initialized ?
In-Reply-To: <55469D5B.5030701@gmail.com>
References: <CA+JCgN12YVXnWggr1PTfp81U6Bg3=4ARatOdfNh8wZXM_Aes8g@mail.gmail.com>
	<55469D5B.5030701@gmail.com>
Message-ID: <CA+JCgN3VW3qe+dDMyfSRJEAUdv-kjjG--HHwwbZk5isH8=oVAQ@mail.gmail.com>

Beside the possible argumentation that with an API elegance and convenience
might sometimes be superior to necessity, the suggested pattern ("every
program, including R itself, keeping its own flag") does no work too well
when the nested embedding of R is involved.

A concrete example is:
```
$ R -q
> library('rPython'); python.exec('import rpy2.robjects')
R is already initialized
```

https://bitbucket.org/rpy2/rpy2/issue/278/r-in-python-via-rpy2-in-r-via-rpython#comment-17843761

2015-05-03 18:12 GMT-04:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 03/05/2015 4:34 PM, Laurent Gautier wrote:
> > Hi,
> >
> > There appear to be no way to check whether R has already been
> initialized.
> >
> > Could a function like "Rf_isinitialized" be added to the API ?
> >
>
> Surely any program that needs to know that could keep its own flag.
> You'll need to give a much longer argument about why this is necessary
> for what you're doing.
>
> Duncan Murdoch
>
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon May  4 01:48:07 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 03 May 2015 19:48:07 -0400
Subject: [Rd] C-API: check whether R has been initialized ?
In-Reply-To: <CA+JCgN3VW3qe+dDMyfSRJEAUdv-kjjG--HHwwbZk5isH8=oVAQ@mail.gmail.com>
References: <CA+JCgN12YVXnWggr1PTfp81U6Bg3=4ARatOdfNh8wZXM_Aes8g@mail.gmail.com>	<55469D5B.5030701@gmail.com>
	<CA+JCgN3VW3qe+dDMyfSRJEAUdv-kjjG--HHwwbZk5isH8=oVAQ@mail.gmail.com>
Message-ID: <5546B3B7.4010407@gmail.com>

On 03/05/2015 7:02 PM, Laurent Gautier wrote:
> Beside the possible argumentation that with an API elegance and
> convenience might sometimes be superior to necessity, the suggested
> pattern ("every program, including R itself, keeping its own flag") does
> no work too well when the nested embedding of R is involved.
> 
> A concrete example is:
> ```
> $ R -q
>> library('rPython'); python.exec('import rpy2.robjects')
> R is already initialized
> ```

I don't know rPython at all, but surely this is an rPython bug.  When
the package is loaded by "library('rPython')", R is obviously
initialized.  You don't need to query it to ask that.

The standard R front-ends don't need a flag to know if it is
initialized.  They initialize, then go into the read-eval-print loop.
If they are in that loop, R is initialized.  If it failed to initialize,
they would never get to that loop.

Other front-ends may do other things besides run R, so they do need to
know if it is initialized, but surely they can keep a flag telling them
whether they've succeeded in initializing it.

Duncan Murdoch


From lgautier at gmail.com  Mon May  4 02:07:30 2015
From: lgautier at gmail.com (Laurent Gautier)
Date: Sun, 3 May 2015 20:07:30 -0400
Subject: [Rd] C-API: check whether R has been initialized ?
In-Reply-To: <5546B3B7.4010407@gmail.com>
References: <CA+JCgN12YVXnWggr1PTfp81U6Bg3=4ARatOdfNh8wZXM_Aes8g@mail.gmail.com>
	<55469D5B.5030701@gmail.com>
	<CA+JCgN3VW3qe+dDMyfSRJEAUdv-kjjG--HHwwbZk5isH8=oVAQ@mail.gmail.com>
	<5546B3B7.4010407@gmail.com>
Message-ID: <CA+JCgN131Ar-1phKdNX7yqxO4QmmEZUQdFLZ8JGg6nrev0Tp2g@mail.gmail.com>

rPython appears to provide an interface from R to Python by embedding
Python and I'd think that it can safely assume that R has been initialized,
but might not be the point here.

The issue is that a Python package embedding itself R (here rpy2) appears
to have no way to know that earlier in the life of the process R was
initialized.

2015-05-03 19:48 GMT-04:00 Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 03/05/2015 7:02 PM, Laurent Gautier wrote:
> > Beside the possible argumentation that with an API elegance and
> > convenience might sometimes be superior to necessity, the suggested
> > pattern ("every program, including R itself, keeping its own flag") does
> > no work too well when the nested embedding of R is involved.
> >
> > A concrete example is:
> > ```
> > $ R -q
> >> library('rPython'); python.exec('import rpy2.robjects')
> > R is already initialized
> > ```
>
> I don't know rPython at all, but surely this is an rPython bug.  When
> the package is loaded by "library('rPython')", R is obviously
> initialized.  You don't need to query it to ask that.
>
> The standard R front-ends don't need a flag to know if it is
> initialized.  They initialize, then go into the read-eval-print loop.
> If they are in that loop, R is initialized.  If it failed to initialize,
> they would never get to that loop.
>
> Other front-ends may do other things besides run R, so they do need to
> know if it is initialized, but surely they can keep a flag telling them
> whether they've succeeded in initializing it.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From simon.urbanek at r-project.org  Mon May  4 06:06:50 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 4 May 2015 00:06:50 -0400
Subject: [Rd] C-API: check whether R has been initialized ?
In-Reply-To: <CA+JCgN131Ar-1phKdNX7yqxO4QmmEZUQdFLZ8JGg6nrev0Tp2g@mail.gmail.com>
References: <CA+JCgN12YVXnWggr1PTfp81U6Bg3=4ARatOdfNh8wZXM_Aes8g@mail.gmail.com>
	<55469D5B.5030701@gmail.com>
	<CA+JCgN3VW3qe+dDMyfSRJEAUdv-kjjG--HHwwbZk5isH8=oVAQ@mail.gmail.com>
	<5546B3B7.4010407@gmail.com>
	<CA+JCgN131Ar-1phKdNX7yqxO4QmmEZUQdFLZ8JGg6nrev0Tp2g@mail.gmail.com>
Message-ID: <C1374C0D-7F92-4268-A8CD-69E4631823DC@r-project.org>

Laurent,

On May 3, 2015, at 8:07 PM, Laurent Gautier <lgautier at gmail.com> wrote:

> rPython appears to provide an interface from R to Python by embedding
> Python and I'd think that it can safely assume that R has been initialized,
> but might not be the point here.
> 
> The issue is that a Python package embedding itself R (here rpy2) appears
> to have no way to know that earlier in the life of the process R was
> initialized.
> 

Duncan's point was that it has - since it would have to embed R itself and thus record the initialization. I suppose you're asking about a case where you want to detect that something else already started R so you can't embed it yourself anymore and thus have to abort -- one side-effect check is to see if R_NilValue is NULL since that would only be the case if R was not started yet. Note, however, that if you didn't initialize it you can't embed it.

Cheers,
Simon

PS: there are much better interfaces to Python than rPython (which is mostly dysfunctional) - see
http://www.omegahat.org/RSPython
https://github.com/s-u/rpython

PPS: I wish you didn't hide the capsulling in rpy2 since that prevents us from having common references that rpy2 can use (please contact me off the list).


> 2015-05-03 19:48 GMT-04:00 Duncan Murdoch <murdoch.duncan at gmail.com>:
> 
>> On 03/05/2015 7:02 PM, Laurent Gautier wrote:
>>> Beside the possible argumentation that with an API elegance and
>>> convenience might sometimes be superior to necessity, the suggested
>>> pattern ("every program, including R itself, keeping its own flag") does
>>> no work too well when the nested embedding of R is involved.
>>> 
>>> A concrete example is:
>>> ```
>>> $ R -q
>>>> library('rPython'); python.exec('import rpy2.robjects')
>>> R is already initialized
>>> ```
>> 
>> I don't know rPython at all, but surely this is an rPython bug.  When
>> the package is loaded by "library('rPython')", R is obviously
>> initialized.  You don't need to query it to ask that.
>> 
>> The standard R front-ends don't need a flag to know if it is
>> initialized.  They initialize, then go into the read-eval-print loop.
>> If they are in that loop, R is initialized.  If it failed to initialize,
>> they would never get to that loop.
>> 
>> Other front-ends may do other things besides run R, so they do need to
>> know if it is initialized, but surely they can keep a flag telling them
>> whether they've succeeded in initializing it.
>> 
>> Duncan Murdoch
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From soeren.vogel at posteo.ch  Mon May  4 14:52:56 2015
From: soeren.vogel at posteo.ch (soeren.vogel at posteo.ch)
Date: Mon, 4 May 2015 14:52:56 +0200
Subject: [Rd] Define replacement functions
Message-ID: <925F72C7-1611-4AE5-911B-D4DA89D180B9@posteo.ch>

Hello

I tried to define replacement functions for the class "mylist". When I test them in an active R session, they work -- however, when I put them into a package, they don't. Why and how to fix?


make_my_list <- function( x, y ) {
	return(structure(list(x, y, class="mylist")))
}
mylist <- make_my_list(1:4, letters[3:7])
mylist
mylist[['x']] <- 4:6
mylist
"[[<-" <- function(x, field, value) {
	UseMethod('[[<-', x)
}
"[[<-.mylist" <- function(x, field, value) {
	stop( "Do not assign." )
}
mylist[['x']] <- 1:10
mylist
mylist$y <- LETTERS[1:3]
mylist
"$<-" <- function(x, field, value) {
	UseMethod('$<-', x)
}
"$<-.mylist" <- function(x, field, value) {
	stop( "Do not assign." )
}
mylist$y <- LETTERS[10:15]


Thanks for help
S?ren

From h.wickham at gmail.com  Mon May  4 16:17:35 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 4 May 2015 09:17:35 -0500
Subject: [Rd] Define replacement functions
In-Reply-To: <925F72C7-1611-4AE5-911B-D4DA89D180B9@posteo.ch>
References: <925F72C7-1611-4AE5-911B-D4DA89D180B9@posteo.ch>
Message-ID: <CABdHhvHPs07Khh1PATxg_NgxcB0byox-vm5rxq=s-gr1GxhUnA@mail.gmail.com>

Did you export the S3 methods in the NAMESPACE?

Hadley

On Mon, May 4, 2015 at 7:52 AM,  <soeren.vogel at posteo.ch> wrote:
> Hello
>
> I tried to define replacement functions for the class "mylist". When I test them in an active R session, they work -- however, when I put them into a package, they don't. Why and how to fix?
>
>
> make_my_list <- function( x, y ) {
>         return(structure(list(x, y, class="mylist")))
> }
> mylist <- make_my_list(1:4, letters[3:7])
> mylist
> mylist[['x']] <- 4:6
> mylist
> "[[<-" <- function(x, field, value) {
>         UseMethod('[[<-', x)
> }
> "[[<-.mylist" <- function(x, field, value) {
>         stop( "Do not assign." )
> }
> mylist[['x']] <- 1:10
> mylist
> mylist$y <- LETTERS[1:3]
> mylist
> "$<-" <- function(x, field, value) {
>         UseMethod('$<-', x)
> }
> "$<-.mylist" <- function(x, field, value) {
>         stop( "Do not assign." )
> }
> mylist$y <- LETTERS[10:15]
>
>
> Thanks for help
> S?ren
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


From thierry.onkelinx at inbo.be  Mon May  4 17:10:30 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 4 May 2015 17:10:30 +0200
Subject: [Rd] Problem with adding slots to S4 object
Message-ID: <CAJuCY5xcMALnB6tLnMXoeTjsCrCDhkxy508ad+f+AX5Lr1amtA@mail.gmail.com>

Dear all,

I'm trying to create a virtual S4 class with some subclasses. I noticed
that adding slots to this class increases the memory use and slows the
functions down. Note that I'm adding very small slots (integer or character
both of length 1).

I've made a reproducible example at
https://github.com/ThierryO/testvirtualclass. The R CMD check --as-cran
fails on the tests.

Some of the output of R CMD check

* using R version 3.2.0 (2015-04-16)
* using platform: i386-w64-mingw32 (32-bit)
* using session charset: ISO8859-1
* using option '--as-cran'
* checking tests ...
  Running 'testthat.R' [125s]
 ERROR
Running the tests in 'tests/testthat.R' failed.
Last 13 lines of output:
  Execution halted
  Error: C stack usage  16583636 is too close to the limit

at that point R crashes and uses about 3.7 GB RAM

Any ideas on what is going wrong? Am I using the virual classes in the
wrong way?

Best regards,

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

	[[alternative HTML version deleted]]


From tdhock5 at gmail.com  Mon May  4 17:52:01 2015
From: tdhock5 at gmail.com (Toby Hocking)
Date: Mon, 4 May 2015 11:52:01 -0400
Subject: [Rd] Print output during long tests?
Message-ID: <CALK03d3j0uZh_YK9dP9kdZ6JVmO44=gSGe6_+7ikjk-uKm-JMA@mail.gmail.com>

I am the author of R package animint which uses testthat for unit tests.

This means that there is a single test file (animint/tests/testthat.R) and
during R CMD check we will see the following output

* checking tests ...
Running ?testthat.R?

I run these tests on Travis, which has a policy that if no output is
received after 10 minutes, it will kill the check. Because animint's
testthat tests take a total of over 10 minutes, Travis kills the R CMD
check job before it has finished all the tests. This is a problem since we
would like to run animint tests on Travis.

One solution to this problem would be if R CMD check could output more
lines other than just Running testthat.R. Can I give some command line
switch to R CMD check or set some environment variable, so that some more
verbose test output could be shown on R CMD check?

	[[alternative HTML version deleted]]


From thierry.onkelinx at inbo.be  Mon May  4 18:39:50 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Mon, 4 May 2015 18:39:50 +0200
Subject: [Rd] Print output during long tests?
In-Reply-To: <CAJuCY5xOtaNiiqnn_Q_VLno+byQgqtdYxmgzCa+jBqFrzYUdrQ@mail.gmail.com>
References: <CALK03d3j0uZh_YK9dP9kdZ6JVmO44=gSGe6_+7ikjk-uKm-JMA@mail.gmail.com>
	<CAJuCY5xOtaNiiqnn_Q_VLno+byQgqtdYxmgzCa+jBqFrzYUdrQ@mail.gmail.com>
Message-ID: <CAJuCY5xcbpe-p+vPLP4aSxJB2VChZcPtSXi-sOjuaC822WF5dw@mail.gmail.com>

Dear Toby,

Have you tried adding output to the tests with the context() function?

Best regards,

Thierry
Op 4 mei 2015 18:28 schreef "Toby Hocking" <tdhock5 at gmail.com>:

I am the author of R package animint which uses testthat for unit tests.

This means that there is a single test file (animint/tests/testthat.R) and
during R CMD check we will see the following output

* checking tests ...
Running ?testthat.R?

I run these tests on Travis, which has a policy that if no output is
received after 10 minutes, it will kill the check. Because animint's
testthat tests take a total of over 10 minutes, Travis kills the R CMD
check job before it has finished all the tests. This is a problem since we
would like to run animint tests on Travis.

One solution to this problem would be if R CMD check could output more
lines other than just Running testthat.R. Can I give some command line
switch to R CMD check or set some environment variable, so that some more
verbose test output could be shown on R CMD check?

        [[alternative HTML version deleted]]

______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From lgautier at gmail.com  Mon May  4 18:46:22 2015
From: lgautier at gmail.com (Laurent Gautier)
Date: Mon, 4 May 2015 12:46:22 -0400
Subject: [Rd] C-API: check whether R has been initialized ?
In-Reply-To: <C1374C0D-7F92-4268-A8CD-69E4631823DC@r-project.org>
References: <CA+JCgN12YVXnWggr1PTfp81U6Bg3=4ARatOdfNh8wZXM_Aes8g@mail.gmail.com>
	<55469D5B.5030701@gmail.com>
	<CA+JCgN3VW3qe+dDMyfSRJEAUdv-kjjG--HHwwbZk5isH8=oVAQ@mail.gmail.com>
	<5546B3B7.4010407@gmail.com>
	<CA+JCgN131Ar-1phKdNX7yqxO4QmmEZUQdFLZ8JGg6nrev0Tp2g@mail.gmail.com>
	<C1374C0D-7F92-4268-A8CD-69E4631823DC@r-project.org>
Message-ID: <CA+JCgN1ZbteMNqMEmZP_TWRvbXDVrXxxdEMvEAE-vYJoOHWhng@mail.gmail.com>

On May 4, 2015 12:06 AM, "Simon Urbanek" <simon.urbanek at r-project.org>
wrote:
>
> Laurent,
>
> On May 3, 2015, at 8:07 PM, Laurent Gautier <lgautier at gmail.com> wrote:
>
> > rPython appears to provide an interface from R to Python by embedding
> > Python and I'd think that it can safely assume that R has been
initialized,
> > but might not be the point here.
> >
> > The issue is that a Python package embedding itself R (here rpy2)
appears
> > to have no way to know that earlier in the life of the process R was
> > initialized.
> >
>
> Duncan's point was that it has - since it would have to embed R itself
and thus record the initialization. I suppose you're asking about a case
where you want to detect that something else already started R so you can't
embed it yourself anymore and thus have to abort -- one side-effect check
is to see if R_NilValue is NULL since that would only be the case if R was
not started yet.

The nesting of embedded Rs is obviously conceptual since the R C library
will only be found once in a process address space. The testing would allow
to keep that coherence (as far as rpy2 is concerned R is embedded, although
if coming from say rPython R has already been started).

If checking R_NilValue is the way to test whether R has been initialized,
why isn't R using it rather than have its own variable (and that variable
jealously made unreadable from this thread) ?

Also, I would necessarily want to abort if R has already been initialized.
One can think about it as a stateful library, and I should be able to just
skip the initialization and go on.

> Note, however, that if you didn't initialize it you can't embed it.
>
> Cheers,
> Simon
>
> PS: there are much better interfaces to Python than rPython (which is
mostly dysfunctional) - see
> http://www.omegahat.org/RSPython
> https://github.com/s-u/rpython

I am seeing rpy2 as way to run R code from Python, and while I may have
preferences about how and what to run I am trying to make running any R
code possible.

> PPS: I wish you didn't hide the capsulling in rpy2 since that prevents us
from having common references that rpy2 can use (please contact me off the
list).

The way it is generally working is that you contact me about wishes for
rpy2.

Think of the precedent it would make and the rather entertaining replies to
posts such as "I wish feature X in R was different, please contact me at
your earliest convenience with a proposal and an aggressive timeline"
blooming on R-dev would trigger.
;-)

Joke aside, personal email is fine but unless there is a reason not to I
like to use the issue tracker on bitbucket so the discussion and reason for
a decision can be consulted by all.

PS: I have unpublished code playing with R's internals from Python were the
opacity of the capsule made me provide access to pointers. May be I should
clean that up and try to integrate it.
>
> > 2015-05-03 19:48 GMT-04:00 Duncan Murdoch <murdoch.duncan at gmail.com>:
> >
> >> On 03/05/2015 7:02 PM, Laurent Gautier wrote:
> >>> Beside the possible argumentation that with an API elegance and
> >>> convenience might sometimes be superior to necessity, the suggested
> >>> pattern ("every program, including R itself, keeping its own flag")
does
> >>> no work too well when the nested embedding of R is involved.
> >>>
> >>> A concrete example is:
> >>> ```
> >>> $ R -q
> >>>> library('rPython'); python.exec('import rpy2.robjects')
> >>> R is already initialized
> >>> ```
> >>
> >> I don't know rPython at all, but surely this is an rPython bug.  When
> >> the package is loaded by "library('rPython')", R is obviously
> >> initialized.  You don't need to query it to ask that.
> >>
> >> The standard R front-ends don't need a flag to know if it is
> >> initialized.  They initialize, then go into the read-eval-print loop.
> >> If they are in that loop, R is initialized.  If it failed to
initialize,
> >> they would never get to that loop.
> >>
> >> Other front-ends may do other things besides run R, so they do need to
> >> know if it is initialized, but surely they can keep a flag telling them
> >> whether they've succeeded in initializing it.
> >>
> >> Duncan Murdoch
> >>
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Mon May  4 18:54:12 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 4 May 2015 18:54:12 +0200
Subject: [Rd] Print output during long tests?
In-Reply-To: <CALK03d3j0uZh_YK9dP9kdZ6JVmO44=gSGe6_+7ikjk-uKm-JMA@mail.gmail.com>
References: <CALK03d3j0uZh_YK9dP9kdZ6JVmO44=gSGe6_+7ikjk-uKm-JMA@mail.gmail.com>
Message-ID: <AAD066A6-6D80-4651-B7DC-F3F4D506FE60@gmail.com>

I really can't see it as a job for R to circumvent hare-brained sysadmin schemes like this....

You're not telling us who or what Travis is. I expect travis-ci.org has some clues, but in general, people on this list won't know. If it doesn't support setting parameters for the timeout, and it is anything Unix-like, can't you just set up a background process to echo a line every five minutes? As in

(for i in 1 2 3 4 ; do sleep 10 ; echo "ping" ; done ) & R ; kill %

(for larger values of 10, obviously; just showing the basic idea.)

- Peter D.

On 04 May 2015, at 17:52 , Toby Hocking <tdhock5 at gmail.com> wrote:

> I am the author of R package animint which uses testthat for unit tests.
> 
> This means that there is a single test file (animint/tests/testthat.R) and
> during R CMD check we will see the following output
> 
> * checking tests ...
> Running ?testthat.R?
> 
> I run these tests on Travis, which has a policy that if no output is
> received after 10 minutes, it will kill the check. Because animint's
> testthat tests take a total of over 10 minutes, Travis kills the R CMD
> check job before it has finished all the tests. This is a problem since we
> would like to run animint tests on Travis.
> 
> One solution to this problem would be if R CMD check could output more
> lines other than just Running testthat.R. Can I give some command line
> switch to R CMD check or set some environment variable, so that some more
> verbose test output could be shown on R CMD check?
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From soeren.vogel at posteo.ch  Mon May  4 19:06:22 2015
From: soeren.vogel at posteo.ch (soeren.vogel at posteo.ch)
Date: Mon, 4 May 2015 19:06:22 +0200
Subject: [Rd] Define replacement functions
In-Reply-To: <CABdHhvHPs07Khh1PATxg_NgxcB0byox-vm5rxq=s-gr1GxhUnA@mail.gmail.com>
References: <925F72C7-1611-4AE5-911B-D4DA89D180B9@posteo.ch>
	<CABdHhvHPs07Khh1PATxg_NgxcB0byox-vm5rxq=s-gr1GxhUnA@mail.gmail.com>
Message-ID: <77F37290-0264-45DC-9604-7D0CD327C132@posteo.ch>

No. I fixed that, the NAMESPACE file now contains:

S3method("[[<-", mylist)
S3method("$<-", mylist)

It still does not work. I also created a print method (print.mylist) which did work out of the box, regardless of being in the NAMESPACE file or not. Could it be somehow in here (also in my NAMESPACE file):

exportPattern("^[[:alpha:]]+")

Or could it be that the type of quoting causes the problems? Like in the NAMESPACE I used double quotes for function definition. Do I need single quotes or back-ticks?

Or is there a package where I can look how others implemented this kind of functionality?

S?ren

> On 04.05.2015, at 16:17, Hadley Wickham <h.wickham at gmail.com> wrote:
> 
> Did you export the S3 methods in the NAMESPACE?
> 
> Hadley
> 
> On Mon, May 4, 2015 at 7:52 AM,  <soeren.vogel at posteo.ch> wrote:
>> Hello
>> 
>> I tried to define replacement functions for the class "mylist". When I test them in an active R session, they work -- however, when I put them into a package, they don't. Why and how to fix?
>> 
>> 
>> make_my_list <- function( x, y ) {
>>        return(structure(list(x, y, class="mylist")))
>> }
>> mylist <- make_my_list(1:4, letters[3:7])
>> mylist
>> mylist[['x']] <- 4:6
>> mylist
>> "[[<-" <- function(x, field, value) {
>>        UseMethod('[[<-', x)
>> }
>> "[[<-.mylist" <- function(x, field, value) {
>>        stop( "Do not assign." )
>> }
>> mylist[['x']] <- 1:10
>> mylist
>> mylist$y <- LETTERS[1:3]
>> mylist
>> "$<-" <- function(x, field, value) {
>>        UseMethod('$<-', x)
>> }
>> "$<-.mylist" <- function(x, field, value) {
>>        stop( "Do not assign." )
>> }
>> mylist$y <- LETTERS[10:15]
>> 
>> 
>> Thanks for help
>> S?ren
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 
> 
> -- 
> http://had.co.nz/


From pgilbert902 at gmail.com  Mon May  4 19:38:52 2015
From: pgilbert902 at gmail.com (Paul Gilbert)
Date: Mon, 04 May 2015 13:38:52 -0400
Subject: [Rd] Print output during long tests?
In-Reply-To: <CALK03d3j0uZh_YK9dP9kdZ6JVmO44=gSGe6_+7ikjk-uKm-JMA@mail.gmail.com>
References: <CALK03d3j0uZh_YK9dP9kdZ6JVmO44=gSGe6_+7ikjk-uKm-JMA@mail.gmail.com>
Message-ID: <5547AEAC.1000406@gmail.com>

If your tests can be divided into multiple files in the tests/ directory 
then you will get lines like

  * checking tests ...
  Running ?test1.R?
  Running ?test2.R?
  Running ?test3.R?
  ...

Paul

On 05/04/2015 11:52 AM, Toby Hocking wrote:
> I am the author of R package animint which uses testthat for unit tests.
>
> This means that there is a single test file (animint/tests/testthat.R) and
> during R CMD check we will see the following output
>
> * checking tests ...
> Running ?testthat.R?
>
> I run these tests on Travis, which has a policy that if no output is
> received after 10 minutes, it will kill the check. Because animint's
> testthat tests take a total of over 10 minutes, Travis kills the R CMD
> check job before it has finished all the tests. This is a problem since we
> would like to run animint tests on Travis.
>
> One solution to this problem would be if R CMD check could output more
> lines other than just Running testthat.R. Can I give some command line
> switch to R CMD check or set some environment variable, so that some more
> verbose test output could be shown on R CMD check?
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From h.wickham at gmail.com  Mon May  4 20:16:23 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Mon, 4 May 2015 13:16:23 -0500
Subject: [Rd] Define replacement functions
In-Reply-To: <77F37290-0264-45DC-9604-7D0CD327C132@posteo.ch>
References: <925F72C7-1611-4AE5-911B-D4DA89D180B9@posteo.ch>
	<CABdHhvHPs07Khh1PATxg_NgxcB0byox-vm5rxq=s-gr1GxhUnA@mail.gmail.com>
	<77F37290-0264-45DC-9604-7D0CD327C132@posteo.ch>
Message-ID: <CABdHhvEiksqat8m6RMhL-zWCXBZ375HDg7t2frQU=oS6n_CgtQ@mail.gmail.com>

On Mon, May 4, 2015 at 12:06 PM,  <soeren.vogel at posteo.ch> wrote:
> No. I fixed that, the NAMESPACE file now contains:
>
> S3method("[[<-", mylist)
> S3method("$<-", mylist)
>
> It still does not work. I also created a print method (print.mylist) which did work out of the box, regardless of being in the NAMESPACE file or not. Could it be somehow in here (also in my NAMESPACE file):
>
> exportPattern("^[[:alpha:]]+")
>
> Or could it be that the type of quoting causes the problems? Like in the NAMESPACE I used double quotes for function definition. Do I need single quotes or back-ticks?
>
> Or is there a package where I can look how others implemented this kind of functionality?

Over 1,500 packages: https://github.com/search?q=user%3Acran+S3method&type=Code

Hadley

-- 
http://had.co.nz/


From by.hook.or at gmail.com  Mon May  4 19:59:10 2015
From: by.hook.or at gmail.com (franknarf)
Date: Mon, 4 May 2015 10:59:10 -0700 (PDT)
Subject: [Rd] Why is the diag function so slow (for extraction)?
Message-ID: <1430762350040-4706780.post@n4.nabble.com>

(I  asked this question on StackOverflow
<http://stackoverflow.com/q/30035939/1191259>   a short time ago; sorry if
you're seeing it again. Feel free to answer there as well if you like. The
code formatting and such on that site can be nice.)

I benchmarked matrix and vector subsetting to extract the diagonal of a
square matrix against the diag() function, and the latter lost by a wide
margin:

nc  <- 1e4
set.seed(1)
m <- matrix(sample(letters,nc^2,replace=TRUE), ncol = nc)

microbenchmark(
  diag = diag(m),
  cond = m[row(m)==col(m)],
  vec  = m[(1:nc-1L)*nc+1:nc],
  mat  = m[cbind(1:nc,1:nc)],
times=10)

# results
Unit: microseconds
 expr         min          lq         mean       median          uq        
max neval
 diag  604343.469  629819.260  710371.3320  706842.3890  793144.019 
837115.504    10
 cond 3862039.512 3985784.025 4175724.0390 4186317.5260 4312493.742
4617117.706    10
  vec     317.088     329.017     432.9099     350.1005     629.460    
651.376    10
  mat     272.147     292.953     441.7045     345.9400     637.506    
706.860    10

Looking in the diag() function, I suspect the fault is mostly due to its
core operation of c(m)[v], where v is the vector in the "vec" benchmark
above. This code seems to confirm it:

v <- (1:nc-1L)*nc+1:nc
microbenchmark(diaglike=c(m)[v],vec=m[v])
# Unit: microseconds
#      expr        min          lq        mean     median          uq       
max neval
#  diaglike 579224.436 664853.7450 720372.8105 712649.706 767281.5070
931976.707   100
#       vec    334.843    339.8365    568.7808    646.799    663.5825  
1445.067   100

But I'm still wondering why diag() uses c()...? With it being so slow, I'd
be inclined to write a qdiag() without the c() and just use that the next
time I need matrix algebra. Any insight would be appreciated; thanks!




--
View this message in context: http://r.789695.n4.nabble.com/Why-is-the-diag-function-so-slow-for-extraction-tp4706780.html
Sent from the R devel mailing list archive at Nabble.com.


From henrik.bengtsson at ucsf.edu  Mon May  4 21:20:44 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Mon, 4 May 2015 12:20:44 -0700
Subject: [Rd] Shouldn't vector indexing with negative out-of-range index
	give an error?
Message-ID: <CAFDcVCRRXT8KaiVwuQSTBWpi_WZL5Tvix7Ra9b8n2KzTPA23vQ@mail.gmail.com>

In Section 'Indexing by vectors' of 'R Language Definition'
(http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Indexing-by-vectors)
it says:

"Integer. All elements of i must have the same sign. If they are
positive, the elements of x with those index numbers are selected. If
i contains negative elements, all elements except those indicated are
selected.

If i is positive and exceeds length(x) then the corresponding
selection is NA. A negative out of bounds value for i causes an error.

A special case is the zero index, which has null effects: x[0] is an
empty vector and otherwise including zeros among positive or negative
indices has the same effect as if they were omitted."

However, that "A negative out of bounds value for i causes an error"
in the second paragraph does not seem to apply.  Instead, R silently
ignore negative indices that are out of range.  For example:

> x <- 1:4
> x[-9L]
[1] 1 2 3 4
> x[-c(1:9)]
integer(0)
> x[-c(3:9)]
[1] 1 2

> y <- as.list(1:4)
> y[-c(1:9)]
list()

Is the observed non-error the correct behavior and therefore the
documentation is incorrect, or is it vice verse?  (...or is it me
missing something)

I get the above on R devel, R 3.2.0, and as far back as R 2.11.0
(haven't check earlier versions).

Thank you,

Henrik


From by.hook.or at gmail.com  Mon May  4 23:02:54 2015
From: by.hook.or at gmail.com (franknarf)
Date: Mon, 4 May 2015 14:02:54 -0700 (PDT)
Subject: [Rd] Matlab Program to R
In-Reply-To: <1429636888503-4706207.post@n4.nabble.com>
References: <1429636888503-4706207.post@n4.nabble.com>
Message-ID: <1430773374060-4706801.post@n4.nabble.com>

R rounds. Perhaps Matlab avoids doing so here. It's hard to say because your
code is too long for anyone to read through.

Maybe you could post a smaller reproducible example to pinpoint the result
you see here. If you can do that, I think you may also find that the R-help
mailing list is a better fit for your question. See a description of the
mailing lists here: http://www.r-project.org/mail.html



--
View this message in context: http://r.789695.n4.nabble.com/Matlab-Program-to-R-tp4706207p4706801.html
Sent from the R devel mailing list archive at Nabble.com.


From pdalgd at gmail.com  Tue May  5 00:24:08 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Tue, 5 May 2015 00:24:08 +0200
Subject: [Rd] Why is the diag function so slow (for extraction)?
In-Reply-To: <1430762350040-4706780.post@n4.nabble.com>
References: <1430762350040-4706780.post@n4.nabble.com>
Message-ID: <06F749E7-5096-438D-A299-667C7A77B477@gmail.com>


> On 04 May 2015, at 19:59 , franknarf <by.hook.or at gmail.com> wrote:
> 
> But I'm still wondering why diag() uses c()...? With it being so slow, I'd
> be inclined to write a qdiag() without the c() and just use that the next
> time I need matrix algebra. Any insight would be appreciated; thanks!

Well, there are two possibilities: Either it is deliberate or it isn't. 

The latter isn't too unlikely, given that the effect is seen for large matrices. I would appear to be a matter of O(n) (picking out n items) vs. O(n^2) (copying an n x n matrix), but this might drown out in a context involving matrix multiplication and/or inversion, both of which are O(n^3). 

If it is deliberate, the question is why. There could be devils in the details; notice in particular that c() strips off non-name attributes. However, I'm not aware of a situation where such attributes could cause trouble.

-pd

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From thierry.onkelinx at inbo.be  Tue May  5 10:04:36 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Tue, 5 May 2015 10:04:36 +0200
Subject: [Rd] Problem with adding slots to S4 object
In-Reply-To: <CAJuCY5xcMALnB6tLnMXoeTjsCrCDhkxy508ad+f+AX5Lr1amtA@mail.gmail.com>
References: <CAJuCY5xcMALnB6tLnMXoeTjsCrCDhkxy508ad+f+AX5Lr1amtA@mail.gmail.com>
Message-ID: <CAJuCY5zffRZ=vzFCoDH7m4wd+sSg=bnmbxFYvU7UnWRipXva=A@mail.gmail.com>

Dear all,

I did some more work in this.

- put all the metadata in a dedicated subclass (see metadataclass branch in
github repository). This doesn't solve the problem.
- test the code under R 3.1.2. This gives the same problem. So this is NOT
a bug introduced by R 3.2.0 :-)
- Profiling the code. Below the summary (code is on GitHub). It seems like
most of the time is spent by paste(). Note that my code doesn't use paste()
so it used in the internals of R. Could someone with more understanding of
S4 enlight me on what is happening. And on what I am doing wrong?

Best regards,

Thierry

$by.self
                        self.time self.pct total.time total.pct
"paste"                    166.06    90.98     170.54     93.44
".findInheritedMethods"      9.30     5.10     182.38     99.92
"rep.int"                    2.24     1.23       4.48      2.45
":"                          2.24     1.23       2.24      1.23
"unique.default"             1.42     0.78       1.42      0.78
"match"                      0.58     0.32       0.58      0.32
"[["                         0.54     0.30       0.54      0.30
".getClassFromCache"         0.08     0.04       0.08      0.04
"loadMethod"                 0.06     0.03       0.06      0.03

$by.total
                           total.time total.pct self.time self.pct
"eval"                         182.52    100.00      0.00     0.00
"my_lmer"                      182.52    100.00      0.00     0.00
"source"                       182.52    100.00      0.00     0.00
"standardGeneric"              182.52    100.00      0.00     0.00
"withVisible"                  182.52    100.00      0.00     0.00
".findInheritedMethods"        182.38     99.92      9.30     5.10
"<Anonymous>"                  182.38     99.92      0.00     0.00
"paste"                        170.54     93.44    166.06    90.98
"outerLabels"                  170.54     93.44      0.00     0.00
"rep.int"                        4.48      2.45      2.24     1.23
":"                              2.24      1.23      2.24     1.23
"unique.default"                 1.42      0.78      1.42     0.78
"unique"                         1.42      0.78      0.00     0.00
"match"                          0.58      0.32      0.58     0.32
"[["                             0.54      0.30      0.54     0.30
".inheritedArgsExpression"       0.54      0.30      0.00     0.00
"extends"                        0.54      0.30      0.00     0.00
".getClassFromCache"             0.08      0.04      0.08     0.04
"getClassDef"                    0.08      0.04      0.00     0.00
"initialize"                     0.08      0.04      0.00     0.00
"new"                            0.08      0.04      0.00     0.00
"loadMethod"                     0.06      0.03      0.06     0.03

$sample.interval
[1] 0.02

$sampling.time
[1] 182.52

>

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-04 17:10 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:

> Dear all,
>
> I'm trying to create a virtual S4 class with some subclasses. I noticed
> that adding slots to this class increases the memory use and slows the
> functions down. Note that I'm adding very small slots (integer or character
> both of length 1).
>
> I've made a reproducible example at
> https://github.com/ThierryO/testvirtualclass. The R CMD check --as-cran
> fails on the tests.
>
> Some of the output of R CMD check
>
> * using R version 3.2.0 (2015-04-16)
> * using platform: i386-w64-mingw32 (32-bit)
> * using session charset: ISO8859-1
> * using option '--as-cran'
> * checking tests ...
>   Running 'testthat.R' [125s]
>  ERROR
> Running the tests in 'tests/testthat.R' failed.
> Last 13 lines of output:
>   Execution halted
>   Error: C stack usage  16583636 is too close to the limit
>
> at that point R crashes and uses about 3.7 GB RAM
>
> Any ideas on what is going wrong? Am I using the virual classes in the
> wrong way?
>
> Best regards,
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>

	[[alternative HTML version deleted]]


From luke-tierney at uiowa.edu  Tue May  5 15:46:45 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Tue, 5 May 2015 08:46:45 -0500
Subject: [Rd] Why is the diag function so slow (for extraction)?
In-Reply-To: <06F749E7-5096-438D-A299-667C7A77B477@gmail.com>
References: <1430762350040-4706780.post@n4.nabble.com>
	<06F749E7-5096-438D-A299-667C7A77B477@gmail.com>
Message-ID: <alpine.DEB.2.10.1505050844470.2460@luke-Latitude>

Looks like the c(x)[...] bit used to be as.matrix(x)[...]. Not sure
why the change was made many years ago, but this was before names were
handled explicitly. It would definitely be better to not force the
duplicate, at least in the case where we are sure c() and [ would not
dispatch.

Best,

luke

On Mon, 4 May 2015, peter dalgaard wrote:

>
>> On 04 May 2015, at 19:59 , franknarf <by.hook.or at gmail.com> wrote:
>>
>> But I'm still wondering why diag() uses c()...? With it being so slow, I'd
>> be inclined to write a qdiag() without the c() and just use that the next
>> time I need matrix algebra. Any insight would be appreciated; thanks!
>
> Well, there are two possibilities: Either it is deliberate or it isn't.
>
> The latter isn't too unlikely, given that the effect is seen for large matrices. I would appear to be a matter of O(n) (picking out n items) vs. O(n^2) (copying an n x n matrix), but this might drown out in a context involving matrix multiplication and/or inversion, both of which are O(n^3).
>
> If it is deliberate, the question is why. There could be devils in the details; notice in particular that c() strips off non-name attributes. However, I'm not aware of a situation where such attributes could cause trouble.
>
> -pd
>
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From maechler at lynne.stat.math.ethz.ch  Tue May  5 16:01:17 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 5 May 2015 16:01:17 +0200
Subject: [Rd] Shouldn't vector indexing with negative out-of-range
	index	give an error?
In-Reply-To: <CAFDcVCRRXT8KaiVwuQSTBWpi_WZL5Tvix7Ra9b8n2KzTPA23vQ@mail.gmail.com>
References: <CAFDcVCRRXT8KaiVwuQSTBWpi_WZL5Tvix7Ra9b8n2KzTPA23vQ@mail.gmail.com>
Message-ID: <21832.52525.513010.447339@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <henrik.bengtsson at ucsf.edu>
>>>>>     on Mon, 4 May 2015 12:20:44 -0700 writes:

    > In Section 'Indexing by vectors' of 'R Language Definition'
    > (http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Indexing-by-vectors)
    > it says:

    > "Integer. All elements of i must have the same sign. If they are
    > positive, the elements of x with those index numbers are selected. If
    > i contains negative elements, all elements except those indicated are
    > selected.

    > If i is positive and exceeds length(x) then the corresponding
    > selection is NA. A negative out of bounds value for i causes an error.

    > A special case is the zero index, which has null effects: x[0] is an
    > empty vector and otherwise including zeros among positive or negative
    > indices has the same effect as if they were omitted."

    > However, that "A negative out of bounds value for i causes an error"
    > in the second paragraph does not seem to apply.  Instead, R silently
    > ignore negative indices that are out of range.  For example:

    >> x <- 1:4
    >> x[-9L]
    > [1] 1 2 3 4
    >> x[-c(1:9)]
    > integer(0)
    >> x[-c(3:9)]
    > [1] 1 2

    >> y <- as.list(1:4)
    >> y[-c(1:9)]
    > list()

    > Is the observed non-error the correct behavior and therefore the
    > documentation is incorrect, or is it vice verse?  (...or is it me
    > missing something)

    > I get the above on R devel, R 3.2.0, and as far back as R 2.11.0
    > (haven't check earlier versions).

Thank you, Henrik!

I've checked further back: The change happened between R 2.5.1 and R 2.6.0.

The previous behavior was

  > (1:3)[-(3:5)]
  Error: subscript out of bounds

If you start reading NEWS.2, you see a *lot* of new features
(and bug fixes) in the 2.6.0 news, but from my browsing, none of
them mentioned the new behavior as feature.

Let's -- for a moment -- declare it a bug in the code, i.e., not
in the documentation:

- As 2.6.0  happened quite a while ago (Oct. 2007),  
  we could wonder how much R code will break if we fix the bug.

- Is the R package authors' community willing to do the necessary
  cleanup in their packages ?

---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- 


Now, after reading the source code for a while, and looking at
the changes, I've found the log entry

------------------------------------------------------------------------
r42123 | ihaka | 2007-07-05 02:00:05 +0200 (Thu, 05 Jul 2007) | 4 lines

Changed the behaviour of out-of-bounds negative
subscripts to match that of S.  Such values are
now ignored rather than tripping an error.

------------------------------------------------------------------------

So, it was changed on purpose, by one of the true "R"s, very
much on purpose.

Making it a *warning* instead of the original error
may have been both more cautious and more helpful for
detecting programming errors.

OTOH, John Chambers, the father of S and hence grandfather of R,
may have had good reasons why it seemed more logical to silently
ignore such out of bound negative indices:
One could argue that

   x[-5]  means  "leave away the 5-th element of x"

and if there is no 5-th element of x, leaving it away should be a no-op.

After all this musing and history detection, my gut decision
would be to only change the documentation which Ross forgot to change.

But of course, it may be interesting to hear other programmeR's feedback on this.

Martin


From jmc at r-project.org  Tue May  5 17:45:30 2015
From: jmc at r-project.org (John Chambers)
Date: Tue, 5 May 2015 08:45:30 -0700
Subject: [Rd] Shouldn't vector indexing with negative out-of-range index
	give an error?
In-Reply-To: <21832.52525.513010.447339@stat.math.ethz.ch>
References: <CAFDcVCRRXT8KaiVwuQSTBWpi_WZL5Tvix7Ra9b8n2KzTPA23vQ@mail.gmail.com>
	<21832.52525.513010.447339@stat.math.ethz.ch>
Message-ID: <B887FF72-1913-4936-B0A3-CE4CA5A29E7A@r-project.org>

When someone suggests that we "might have had a reason" for some peculiarity in the original S, my usual reaction is "Or else we never thought of the problem".

In this case, however, there is a relevant statement in the 1988 "blue book".  In the discussion of subscripting (p 358) the definition for negative i says: "the indices consist of the elements of seq(along=x) that do not match any elements in -i".

Suggesting that no bounds checking on -i takes place.

John


On May 5, 2015, at 7:01 AM, Martin Maechler <maechler at lynne.stat.math.ethz.ch> wrote:

>>>>>> Henrik Bengtsson <henrik.bengtsson at ucsf.edu>
>>>>>>   on Mon, 4 May 2015 12:20:44 -0700 writes:
> 
>> In Section 'Indexing by vectors' of 'R Language Definition'
>> (http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Indexing-by-vectors)
>> it says:
> 
>> "Integer. All elements of i must have the same sign. If they are
>> positive, the elements of x with those index numbers are selected. If
>> i contains negative elements, all elements except those indicated are
>> selected.
> 
>> If i is positive and exceeds length(x) then the corresponding
>> selection is NA. A negative out of bounds value for i causes an error.
> 
>> A special case is the zero index, which has null effects: x[0] is an
>> empty vector and otherwise including zeros among positive or negative
>> indices has the same effect as if they were omitted."
> 
>> However, that "A negative out of bounds value for i causes an error"
>> in the second paragraph does not seem to apply.  Instead, R silently
>> ignore negative indices that are out of range.  For example:
> 
>>> x <- 1:4
>>> x[-9L]
>> [1] 1 2 3 4
>>> x[-c(1:9)]
>> integer(0)
>>> x[-c(3:9)]
>> [1] 1 2
> 
>>> y <- as.list(1:4)
>>> y[-c(1:9)]
>> list()
> 
>> Is the observed non-error the correct behavior and therefore the
>> documentation is incorrect, or is it vice verse?  (...or is it me
>> missing something)
> 
>> I get the above on R devel, R 3.2.0, and as far back as R 2.11.0
>> (haven't check earlier versions).
> 
> Thank you, Henrik!
> 
> I've checked further back: The change happened between R 2.5.1 and R 2.6.0.
> 
> The previous behavior was
> 
>> (1:3)[-(3:5)]
> Error: subscript out of bounds
> 
> If you start reading NEWS.2, you see a *lot* of new features
> (and bug fixes) in the 2.6.0 news, but from my browsing, none of
> them mentioned the new behavior as feature.
> 
> Let's -- for a moment -- declare it a bug in the code, i.e., not
> in the documentation:
> 
> - As 2.6.0  happened quite a while ago (Oct. 2007),  
> we could wonder how much R code will break if we fix the bug.
> 
> - Is the R package authors' community willing to do the necessary
> cleanup in their packages ?
> 
> ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- 
> 
> 
> Now, after reading the source code for a while, and looking at
> the changes, I've found the log entry
> 
> ------------------------------------------------------------------------
> r42123 | ihaka | 2007-07-05 02:00:05 +0200 (Thu, 05 Jul 2007) | 4 lines
> 
> Changed the behaviour of out-of-bounds negative
> subscripts to match that of S.  Such values are
> now ignored rather than tripping an error.
> 
> ------------------------------------------------------------------------
> 
> So, it was changed on purpose, by one of the true "R"s, very
> much on purpose.
> 
> Making it a *warning* instead of the original error
> may have been both more cautious and more helpful for
> detecting programming errors.
> 
> OTOH, John Chambers, the father of S and hence grandfather of R,
> may have had good reasons why it seemed more logical to silently
> ignore such out of bound negative indices:
> One could argue that
> 
>  x[-5]  means  "leave away the 5-th element of x"
> 
> and if there is no 5-th element of x, leaving it away should be a no-op.
> 
> After all this musing and history detection, my gut decision
> would be to only change the documentation which Ross forgot to change.
> 
> But of course, it may be interesting to hear other programmeR's feedback on this.
> 
> Martin


From mail at florianlosch.de  Tue May  5 19:38:02 2015
From: mail at florianlosch.de (Florian Losch)
Date: Tue, 5 May 2015 10:38:02 -0700 (PDT)
Subject: [Rd] Integrate R in perl6
Message-ID: <1430847482626-4706844.post@n4.nabble.com>

Hi there,

perl6 offers with the NativeCall package a great tool to implement other
languages into perl scripts. This has already been done with python, C(++)
and perl5. For my use cases - lots of data munging and statistical analyses
(climatology/meteorology) - it would be perfect to parse data and call/run
models from perl6 and then to do plotting and analyses in R. I saw R does
have some C-interface so an implementation should be possible, right? I'm
not good in that kind of programming, so is there maybe someone out there,
that likes the idea of a perl6 Inline:R-package and knows how the R-C
interface works? I would of course help in what ever way I can^^

greetings Flo 



--
View this message in context: http://r.789695.n4.nabble.com/Integrate-R-in-perl6-tp4706844.html
Sent from the R devel mailing list archive at Nabble.com.


From csardi.gabor at gmail.com  Tue May  5 23:26:00 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 5 May 2015 17:26:00 -0400
Subject: [Rd] R SVN server is down
Message-ID: <CABtg=K=p5W8NAWXptzT10E7irjpL5vHmA6LpnnZB+JZt4O0j1Q@mail.gmail.com>

It seems. FYI. Gabor

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Wed May  6 00:50:03 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Tue, 5 May 2015 15:50:03 -0700
Subject: [Rd] Problem with adding slots to S4 object
In-Reply-To: <CAJuCY5zffRZ=vzFCoDH7m4wd+sSg=bnmbxFYvU7UnWRipXva=A@mail.gmail.com>
References: <CAJuCY5xcMALnB6tLnMXoeTjsCrCDhkxy508ad+f+AX5Lr1amtA@mail.gmail.com>
	<CAJuCY5zffRZ=vzFCoDH7m4wd+sSg=bnmbxFYvU7UnWRipXva=A@mail.gmail.com>
Message-ID: <CAOQ5Nyeq4Ub-RiH61CiOj_1GU-GQAjPfJLBp8jC827xEip1HjA@mail.gmail.com>

There are too many arguments in the signature of the my_inla generic. The
signature defaults to every argument in the formals, which are probably
already over-specified. Typically, one defines a generic with the formals
(x, ...), or perhaps in this case (x, model, ...), but more on that below

Unrelated to this issue, the my_inla generic is defined incorrectly. It
should call standardGeneric("my_inla"), not standard.generic(my_inla). When
you pass a generic definition that does not contain a call to
standardGeneric(), it is taken as the default (ANY) method, so the generic
still works in this case, but the ANY method is broken.

The ANY method that is separately defined should probably be defined on
"data.frame,missing", since otherwise it will break. If you really want an
ANY method, consider coercing the input to data.frame, but you can do that
without a generic.

Instead of having the my_inla and my_inla_model classes, you could have
model.fit be an optional slot in my_inla. Then my_inla() does not have to
be a generic anymore. To make an optional slot, use a class union of the
slot class with NULL.

Also, I think it's sort of the convention that class names be upper camel
case.

The reason it calls paste() so many times is that the methods package
searches for every possible combination of classes (and their parent
classes), which in this case, is many, since the generic signature is so
long, and the Matrix package adds several classes above "integer".
Obviously, this is not very efficient, however, thanks to caching it only
happens once for each target signature, so in practice (and with more
reasonable generic signatures), this is not an issue.

Hope this helps and sorry for the lack of S4 documentation.

Michael


On Tue, May 5, 2015 at 1:04 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be>
wrote:

> Dear all,
>
> I did some more work in this.
>
> - put all the metadata in a dedicated subclass (see metadataclass branch in
> github repository). This doesn't solve the problem.
> - test the code under R 3.1.2. This gives the same problem. So this is NOT
> a bug introduced by R 3.2.0 :-)
> - Profiling the code. Below the summary (code is on GitHub). It seems like
> most of the time is spent by paste(). Note that my code doesn't use paste()
> so it used in the internals of R. Could someone with more understanding of
> S4 enlight me on what is happening. And on what I am doing wrong?
>
> Best regards,
>
> Thierry
>
> $by.self
>                         self.time self.pct total.time total.pct
> "paste"                    166.06    90.98     170.54     93.44
> ".findInheritedMethods"      9.30     5.10     182.38     99.92
> "rep.int"                    2.24     1.23       4.48      2.45
> ":"                          2.24     1.23       2.24      1.23
> "unique.default"             1.42     0.78       1.42      0.78
> "match"                      0.58     0.32       0.58      0.32
> "[["                         0.54     0.30       0.54      0.30
> ".getClassFromCache"         0.08     0.04       0.08      0.04
> "loadMethod"                 0.06     0.03       0.06      0.03
>
> $by.total
>                            total.time total.pct self.time self.pct
> "eval"                         182.52    100.00      0.00     0.00
> "my_lmer"                      182.52    100.00      0.00     0.00
> "source"                       182.52    100.00      0.00     0.00
> "standardGeneric"              182.52    100.00      0.00     0.00
> "withVisible"                  182.52    100.00      0.00     0.00
> ".findInheritedMethods"        182.38     99.92      9.30     5.10
> "<Anonymous>"                  182.38     99.92      0.00     0.00
> "paste"                        170.54     93.44    166.06    90.98
> "outerLabels"                  170.54     93.44      0.00     0.00
> "rep.int"                        4.48      2.45      2.24     1.23
> ":"                              2.24      1.23      2.24     1.23
> "unique.default"                 1.42      0.78      1.42     0.78
> "unique"                         1.42      0.78      0.00     0.00
> "match"                          0.58      0.32      0.58     0.32
> "[["                             0.54      0.30      0.54     0.30
> ".inheritedArgsExpression"       0.54      0.30      0.00     0.00
> "extends"                        0.54      0.30      0.00     0.00
> ".getClassFromCache"             0.08      0.04      0.08     0.04
> "getClassDef"                    0.08      0.04      0.00     0.00
> "initialize"                     0.08      0.04      0.00     0.00
> "new"                            0.08      0.04      0.00     0.00
> "loadMethod"                     0.06      0.03      0.06     0.03
>
> $sample.interval
> [1] 0.02
>
> $sampling.time
> [1] 182.52
>
> >
>
> ir. Thierry Onkelinx
> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
> Forest
> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> Kliniekstraat 25
> 1070 Anderlecht
> Belgium
>
> To call in the statistician after the experiment is done may be no more
> than asking him to perform a post-mortem examination: he may be able to say
> what the experiment died of. ~ Sir Ronald Aylmer Fisher
> The plural of anecdote is not data. ~ Roger Brinner
> The combination of some data and an aching desire for an answer does not
> ensure that a reasonable answer can be extracted from a given body of data.
> ~ John Tukey
>
> 2015-05-04 17:10 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>
> > Dear all,
> >
> > I'm trying to create a virtual S4 class with some subclasses. I noticed
> > that adding slots to this class increases the memory use and slows the
> > functions down. Note that I'm adding very small slots (integer or
> character
> > both of length 1).
> >
> > I've made a reproducible example at
> > https://github.com/ThierryO/testvirtualclass. The R CMD check --as-cran
> > fails on the tests.
> >
> > Some of the output of R CMD check
> >
> > * using R version 3.2.0 (2015-04-16)
> > * using platform: i386-w64-mingw32 (32-bit)
> > * using session charset: ISO8859-1
> > * using option '--as-cran'
> > * checking tests ...
> >   Running 'testthat.R' [125s]
> >  ERROR
> > Running the tests in 'tests/testthat.R' failed.
> > Last 13 lines of output:
> >   Execution halted
> >   Error: C stack usage  16583636 is too close to the limit
> >
> > at that point R crashes and uses about 3.7 GB RAM
> >
> > Any ideas on what is going wrong? Am I using the virual classes in the
> > wrong way?
> >
> > Best regards,
> >
> > ir. Thierry Onkelinx
> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
> and
> > Forest
> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
> > Kliniekstraat 25
> > 1070 Anderlecht
> > Belgium
> >
> > To call in the statistician after the experiment is done may be no more
> > than asking him to perform a post-mortem examination: he may be able to
> say
> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
> > The plural of anecdote is not data. ~ Roger Brinner
> > The combination of some data and an aching desire for an answer does not
> > ensure that a reasonable answer can be extracted from a given body of
> data.
> > ~ John Tukey
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From maechler at lynne.stat.math.ethz.ch  Wed May  6 10:33:50 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 6 May 2015 10:33:50 +0200
Subject: [Rd] Shouldn't vector indexing with negative out-of-range index
	give an error?
In-Reply-To: <6637F7E1-41F8-44DF-8057-1239291F08E9@stat.stanford.edu>
References: <CAFDcVCRRXT8KaiVwuQSTBWpi_WZL5Tvix7Ra9b8n2KzTPA23vQ@mail.gmail.com>
	<21832.52525.513010.447339@stat.math.ethz.ch>
	<6637F7E1-41F8-44DF-8057-1239291F08E9@stat.stanford.edu>
Message-ID: <21833.53742.122759.695834@stat.math.ethz.ch>

>>>>> John Chambers <jmc at stat.stanford.edu>
>>>>>     on Tue, 5 May 2015 08:39:46 -0700 writes:

    > When someone suggests that we "might have had a reason" for some peculiarity in the original S, my usual reaction is "Or else we never thought of the problem".
    > In this case, however, there is a relevant statement in the 1988 "blue book".  In the discussion of subscripting (p 358) the definition for negative i says: "the indices consist of the elements of seq(along=x) that do not match any elements in -i".

    > Suggesting that no bounds checking on -i takes place.

    > John

Indeed!  
Thanks a lot John, for the perspective and clarification!

I'm committing a patch to the documentation now.
Martin


    > On May 5, 2015, at 7:01 AM, Martin Maechler <maechler at lynne.stat.math.ethz.ch> wrote:

    >>>>>>> Henrik Bengtsson <henrik.bengtsson at ucsf.edu>
    >>>>>>> on Mon, 4 May 2015 12:20:44 -0700 writes:
    >> 
    >>> In Section 'Indexing by vectors' of 'R Language Definition'
    >>> (http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Indexing-by-vectors)
    >>> it says:
    >> 
    >>> "Integer. All elements of i must have the same sign. If they are
    >>> positive, the elements of x with those index numbers are selected. If
    >>> i contains negative elements, all elements except those indicated are
    >>> selected.
    >> 
    >>> If i is positive and exceeds length(x) then the corresponding
    >>> selection is NA. A negative out of bounds value for i causes an error.
    >> 
    >>> A special case is the zero index, which has null effects: x[0] is an
    >>> empty vector and otherwise including zeros among positive or negative
    >>> indices has the same effect as if they were omitted."
    >> 
    >>> However, that "A negative out of bounds value for i causes an error"
    >>> in the second paragraph does not seem to apply.  Instead, R silently
    >>> ignore negative indices that are out of range.  For example:
    >> 
    >>>> x <- 1:4
    >>>> x[-9L]
    >>> [1] 1 2 3 4
    >>>> x[-c(1:9)]
    >>> integer(0)
    >>>> x[-c(3:9)]
    >>> [1] 1 2
    >> 
    >>>> y <- as.list(1:4)
    >>>> y[-c(1:9)]
    >>> list()
    >> 
    >>> Is the observed non-error the correct behavior and therefore the
    >>> documentation is incorrect, or is it vice verse?  (...or is it me
    >>> missing something)
    >> 
    >>> I get the above on R devel, R 3.2.0, and as far back as R 2.11.0
    >>> (haven't check earlier versions).
    >> 
    >> Thank you, Henrik!
    >> 
    >> I've checked further back: The change happened between R 2.5.1 and R 2.6.0.
    >> 
    >> The previous behavior was
    >> 
    >>> (1:3)[-(3:5)]
    >> Error: subscript out of bounds
    >> 
    >> If you start reading NEWS.2, you see a *lot* of new features
    >> (and bug fixes) in the 2.6.0 news, but from my browsing, none of
    >> them mentioned the new behavior as feature.
    >> 
    >> Let's -- for a moment -- declare it a bug in the code, i.e., not
    >> in the documentation:
    >> 
    >> - As 2.6.0  happened quite a while ago (Oct. 2007),  
    >> we could wonder how much R code will break if we fix the bug.
    >> 
    >> - Is the R package authors' community willing to do the necessary
    >> cleanup in their packages ?
    >> 
    >> ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- 
    >> 
    >> 
    >> Now, after reading the source code for a while, and looking at
    >> the changes, I've found the log entry
    >> 
    >> ------------------------------------------------------------------------
    >> r42123 | ihaka | 2007-07-05 02:00:05 +0200 (Thu, 05 Jul 2007) | 4 lines
    >> 
    >> Changed the behaviour of out-of-bounds negative
    >> subscripts to match that of S.  Such values are
    >> now ignored rather than tripping an error.
    >> 
    >> ------------------------------------------------------------------------
    >> 
    >> So, it was changed on purpose, by one of the true "R"s, very
    >> much on purpose.
    >> 
    >> Making it a *warning* instead of the original error
    >> may have been both more cautious and more helpful for
    >> detecting programming errors.
    >> 
    >> OTOH, John Chambers, the father of S and hence grandfather of R,
    >> may have had good reasons why it seemed more logical to silently
    >> ignore such out of bound negative indices:
    >> One could argue that
    >> 
    >> x[-5]  means  "leave away the 5-th element of x"
    >> 
    >> and if there is no 5-th element of x, leaving it away should be a no-op.
    >> 
    >> After all this musing and history detection, my gut decision
    >> would be to only change the documentation which Ross forgot to change.
    >> 
    >> But of course, it may be interesting to hear other programmeR's feedback on this.
    >> 
    >> Martin


From thierry.onkelinx at inbo.be  Wed May  6 11:45:10 2015
From: thierry.onkelinx at inbo.be (Thierry Onkelinx)
Date: Wed, 6 May 2015 11:45:10 +0200
Subject: [Rd] Problem with adding slots to S4 object
In-Reply-To: <CAOQ5Nyeq4Ub-RiH61CiOj_1GU-GQAjPfJLBp8jC827xEip1HjA@mail.gmail.com>
References: <CAJuCY5xcMALnB6tLnMXoeTjsCrCDhkxy508ad+f+AX5Lr1amtA@mail.gmail.com>
	<CAJuCY5zffRZ=vzFCoDH7m4wd+sSg=bnmbxFYvU7UnWRipXva=A@mail.gmail.com>
	<CAOQ5Nyeq4Ub-RiH61CiOj_1GU-GQAjPfJLBp8jC827xEip1HjA@mail.gmail.com>
Message-ID: <CAJuCY5yTQNRKwxghBqsFJiBus7dc7c4yRPunRuWGr7LXAz-r0Q@mail.gmail.com>

Dear Michael,

Thank you very much for your reply. It helped me to solve the problem and
increased my understanding of S4 objects. I've updated the github
repository in case someone else might be interested.

Best regards,

Thierry

ir. Thierry Onkelinx
Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
Forest
team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
Kliniekstraat 25
1070 Anderlecht
Belgium

To call in the statistician after the experiment is done may be no more
than asking him to perform a post-mortem examination: he may be able to say
what the experiment died of. ~ Sir Ronald Aylmer Fisher
The plural of anecdote is not data. ~ Roger Brinner
The combination of some data and an aching desire for an answer does not
ensure that a reasonable answer can be extracted from a given body of data.
~ John Tukey

2015-05-06 0:50 GMT+02:00 Michael Lawrence <lawrence.michael at gene.com>:

> There are too many arguments in the signature of the my_inla generic. The
> signature defaults to every argument in the formals, which are probably
> already over-specified. Typically, one defines a generic with the formals
> (x, ...), or perhaps in this case (x, model, ...), but more on that below
>
> Unrelated to this issue, the my_inla generic is defined incorrectly. It
> should call standardGeneric("my_inla"), not standard.generic(my_inla). When
> you pass a generic definition that does not contain a call to
> standardGeneric(), it is taken as the default (ANY) method, so the generic
> still works in this case, but the ANY method is broken.
>
> The ANY method that is separately defined should probably be defined on
> "data.frame,missing", since otherwise it will break. If you really want an
> ANY method, consider coercing the input to data.frame, but you can do that
> without a generic.
>
> Instead of having the my_inla and my_inla_model classes, you could have
> model.fit be an optional slot in my_inla. Then my_inla() does not have to
> be a generic anymore. To make an optional slot, use a class union of the
> slot class with NULL.
>
> Also, I think it's sort of the convention that class names be upper camel
> case.
>
> The reason it calls paste() so many times is that the methods package
> searches for every possible combination of classes (and their parent
> classes), which in this case, is many, since the generic signature is so
> long, and the Matrix package adds several classes above "integer".
> Obviously, this is not very efficient, however, thanks to caching it only
> happens once for each target signature, so in practice (and with more
> reasonable generic signatures), this is not an issue.
>
> Hope this helps and sorry for the lack of S4 documentation.
>
> Michael
>
>
> On Tue, May 5, 2015 at 1:04 AM, Thierry Onkelinx <thierry.onkelinx at inbo.be
> > wrote:
>
>> Dear all,
>>
>> I did some more work in this.
>>
>> - put all the metadata in a dedicated subclass (see metadataclass branch
>> in
>> github repository). This doesn't solve the problem.
>> - test the code under R 3.1.2. This gives the same problem. So this is NOT
>> a bug introduced by R 3.2.0 :-)
>> - Profiling the code. Below the summary (code is on GitHub). It seems like
>> most of the time is spent by paste(). Note that my code doesn't use
>> paste()
>> so it used in the internals of R. Could someone with more understanding of
>> S4 enlight me on what is happening. And on what I am doing wrong?
>>
>> Best regards,
>>
>> Thierry
>>
>> $by.self
>>                         self.time self.pct total.time total.pct
>> "paste"                    166.06    90.98     170.54     93.44
>> ".findInheritedMethods"      9.30     5.10     182.38     99.92
>> "rep.int"                    2.24     1.23       4.48      2.45
>> ":"                          2.24     1.23       2.24      1.23
>> "unique.default"             1.42     0.78       1.42      0.78
>> "match"                      0.58     0.32       0.58      0.32
>> "[["                         0.54     0.30       0.54      0.30
>> ".getClassFromCache"         0.08     0.04       0.08      0.04
>> "loadMethod"                 0.06     0.03       0.06      0.03
>>
>> $by.total
>>                            total.time total.pct self.time self.pct
>> "eval"                         182.52    100.00      0.00     0.00
>> "my_lmer"                      182.52    100.00      0.00     0.00
>> "source"                       182.52    100.00      0.00     0.00
>> "standardGeneric"              182.52    100.00      0.00     0.00
>> "withVisible"                  182.52    100.00      0.00     0.00
>> ".findInheritedMethods"        182.38     99.92      9.30     5.10
>> "<Anonymous>"                  182.38     99.92      0.00     0.00
>> "paste"                        170.54     93.44    166.06    90.98
>> "outerLabels"                  170.54     93.44      0.00     0.00
>> "rep.int"                        4.48      2.45      2.24     1.23
>> ":"                              2.24      1.23      2.24     1.23
>> "unique.default"                 1.42      0.78      1.42     0.78
>> "unique"                         1.42      0.78      0.00     0.00
>> "match"                          0.58      0.32      0.58     0.32
>> "[["                             0.54      0.30      0.54     0.30
>> ".inheritedArgsExpression"       0.54      0.30      0.00     0.00
>> "extends"                        0.54      0.30      0.00     0.00
>> ".getClassFromCache"             0.08      0.04      0.08     0.04
>> "getClassDef"                    0.08      0.04      0.00     0.00
>> "initialize"                     0.08      0.04      0.00     0.00
>> "new"                            0.08      0.04      0.00     0.00
>> "loadMethod"                     0.06      0.03      0.06     0.03
>>
>> $sample.interval
>> [1] 0.02
>>
>> $sampling.time
>> [1] 182.52
>>
>> >
>>
>> ir. Thierry Onkelinx
>> Instituut voor natuur- en bosonderzoek / Research Institute for Nature and
>> Forest
>> team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> Kliniekstraat 25
>> 1070 Anderlecht
>> Belgium
>>
>> To call in the statistician after the experiment is done may be no more
>> than asking him to perform a post-mortem examination: he may be able to
>> say
>> what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> The plural of anecdote is not data. ~ Roger Brinner
>> The combination of some data and an aching desire for an answer does not
>> ensure that a reasonable answer can be extracted from a given body of
>> data.
>> ~ John Tukey
>>
>> 2015-05-04 17:10 GMT+02:00 Thierry Onkelinx <thierry.onkelinx at inbo.be>:
>>
>> > Dear all,
>> >
>> > I'm trying to create a virtual S4 class with some subclasses. I noticed
>> > that adding slots to this class increases the memory use and slows the
>> > functions down. Note that I'm adding very small slots (integer or
>> character
>> > both of length 1).
>> >
>> > I've made a reproducible example at
>> > https://github.com/ThierryO/testvirtualclass. The R CMD check --as-cran
>> > fails on the tests.
>> >
>> > Some of the output of R CMD check
>> >
>> > * using R version 3.2.0 (2015-04-16)
>> > * using platform: i386-w64-mingw32 (32-bit)
>> > * using session charset: ISO8859-1
>> > * using option '--as-cran'
>> > * checking tests ...
>> >   Running 'testthat.R' [125s]
>> >  ERROR
>> > Running the tests in 'tests/testthat.R' failed.
>> > Last 13 lines of output:
>> >   Execution halted
>> >   Error: C stack usage  16583636 is too close to the limit
>> >
>> > at that point R crashes and uses about 3.7 GB RAM
>> >
>> > Any ideas on what is going wrong? Am I using the virual classes in the
>> > wrong way?
>> >
>> > Best regards,
>> >
>> > ir. Thierry Onkelinx
>> > Instituut voor natuur- en bosonderzoek / Research Institute for Nature
>> and
>> > Forest
>> > team Biometrie & Kwaliteitszorg / team Biometrics & Quality Assurance
>> > Kliniekstraat 25
>> > 1070 Anderlecht
>> > Belgium
>> >
>> > To call in the statistician after the experiment is done may be no more
>> > than asking him to perform a post-mortem examination: he may be able to
>> say
>> > what the experiment died of. ~ Sir Ronald Aylmer Fisher
>> > The plural of anecdote is not data. ~ Roger Brinner
>> > The combination of some data and an aching desire for an answer does not
>> > ensure that a reasonable answer can be extracted from a given body of
>> data.
>> > ~ John Tukey
>> >
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From grondilu at yahoo.fr  Wed May  6 13:16:00 2015
From: grondilu at yahoo.fr (grondilu)
Date: Wed, 6 May 2015 04:16:00 -0700 (PDT)
Subject: [Rd] Integrate R in perl6
In-Reply-To: <1430847482626-4706844.post@n4.nabble.com>
References: <1430847482626-4706844.post@n4.nabble.com>
Message-ID: <1430910960104-4706879.post@n4.nabble.com>

Perl6 is not great to do maths, even at basic level.  So a dedicated
sub-language ("slang" in perl6 linguo) would make a lot of sense indeed, and
R would be a natural choice (other possibilities are octave and J).

I don't know much about R, I've used it a little bit once but have forgotten
pretty much everything since then.

I know Perl 6 much better, but I'm not familiar with all subtleties of
NativeCall, nor with how to create sublangs (we should take Inline::Perl5 as
an example, though).

If R has a C API (does it?), it should totally doable.

First step would be to create a github repo, wouldn't it?



--
View this message in context: http://r.789695.n4.nabble.com/Integrate-R-in-perl6-tp4706844p4706879.html
Sent from the R devel mailing list archive at Nabble.com.


From vinhdizzo at gmail.com  Wed May  6 16:57:55 2015
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Wed, 6 May 2015 07:57:55 -0700
Subject: [Rd] IdntoAscii issue with KERNEL32.dll on 64-bit R on Windows
 Server 2003 x64 SP2
Message-ID: <CA+2DmwiKdiqOumutZPpGRjYvBV6T69pYs6bHTMPCbjWJe-nsXg@mail.gmail.com>

Dear list,

With the new R 3.2.0 on the aforementioned platform, I get the following
pop-up error when I enter "?update.packages" using R64:

"The procedure entry point IdnToAscii could not be located in the dynamic
link library KERNEL32.dll"

That is, my command never gets executed.  This does NOT happen with R32.

I previously noticed this error starting with R 3.0.0 with the RCurl
package (1.95-4.5): I get the same issue when I execute "library(RCurl)" in
R64.  This happened subsequently for every version > 3.  I always thought
it was an RCurl issue so I just dropped to R 2.15.1 whenever I needed to
use it.

However, I now see this error with R 3.2.0 with the simple command
(?update.packages as it tries to access internet.dll).

My guess is this is specific to Windows Server 2003 x64 as it does not
happen on my Windows 7 machine and that I did not find anything when
searching for this issue.  I thought I'd reach out just in case anyone has
any ideas on how to fix it.  I'm stuck on Windows Server 2003 because it is
a work server.  Thanks so much for your help.

-- Vinh

	[[alternative HTML version deleted]]


From henrik.bengtsson at ucsf.edu  Wed May  6 18:04:21 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Wed, 6 May 2015 09:04:21 -0700
Subject: [Rd] Shouldn't vector indexing with negative out-of-range index
 give an error?
In-Reply-To: <21833.53742.122759.695834@stat.math.ethz.ch>
References: <CAFDcVCRRXT8KaiVwuQSTBWpi_WZL5Tvix7Ra9b8n2KzTPA23vQ@mail.gmail.com>
	<21832.52525.513010.447339@stat.math.ethz.ch>
	<6637F7E1-41F8-44DF-8057-1239291F08E9@stat.stanford.edu>
	<21833.53742.122759.695834@stat.math.ethz.ch>
Message-ID: <CAFDcVCRxJDeGOG=7u96saFZWz7kTmaKQa0=vuf0MLGtvQbenYA@mail.gmail.com>

On Wed, May 6, 2015 at 1:33 AM, Martin Maechler
<maechler at lynne.stat.math.ethz.ch> wrote:
>>>>>> John Chambers <jmc at stat.stanford.edu>
>>>>>>     on Tue, 5 May 2015 08:39:46 -0700 writes:
>
>     > When someone suggests that we "might have had a reason" for some peculiarity in the original S, my usual reaction is "Or else we never thought of the problem".
>     > In this case, however, there is a relevant statement in the 1988 "blue book".  In the discussion of subscripting (p 358) the definition for negative i says: "the indices consist of the elements of seq(along=x) that do not match any elements in -i".
>
>     > Suggesting that no bounds checking on -i takes place.
>
>     > John
>
> Indeed!
> Thanks a lot John, for the perspective and clarification!
>
> I'm committing a patch to the documentation now.

Thank you both and also credits to Dongcan Jiang for pointing out to
me that errors were indeed not generated in this case.

I agree with the decision. It's interesting to notice that now the
only way an error is generated is when index-vector subsetting is done
using mixed positive and negative indices, e.g. x[c(-1,1)].

/Henrik

> Martin
>
>
>     > On May 5, 2015, at 7:01 AM, Martin Maechler <maechler at lynne.stat.math.ethz.ch> wrote:
>
>     >>>>>>> Henrik Bengtsson <henrik.bengtsson at ucsf.edu>
>     >>>>>>> on Mon, 4 May 2015 12:20:44 -0700 writes:
>     >>
>     >>> In Section 'Indexing by vectors' of 'R Language Definition'
>     >>> (http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Indexing-by-vectors)
>     >>> it says:
>     >>
>     >>> "Integer. All elements of i must have the same sign. If they are
>     >>> positive, the elements of x with those index numbers are selected. If
>     >>> i contains negative elements, all elements except those indicated are
>     >>> selected.
>     >>
>     >>> If i is positive and exceeds length(x) then the corresponding
>     >>> selection is NA. A negative out of bounds value for i causes an error.
>     >>
>     >>> A special case is the zero index, which has null effects: x[0] is an
>     >>> empty vector and otherwise including zeros among positive or negative
>     >>> indices has the same effect as if they were omitted."
>     >>
>     >>> However, that "A negative out of bounds value for i causes an error"
>     >>> in the second paragraph does not seem to apply.  Instead, R silently
>     >>> ignore negative indices that are out of range.  For example:
>     >>
>     >>>> x <- 1:4
>     >>>> x[-9L]
>     >>> [1] 1 2 3 4
>     >>>> x[-c(1:9)]
>     >>> integer(0)
>     >>>> x[-c(3:9)]
>     >>> [1] 1 2
>     >>
>     >>>> y <- as.list(1:4)
>     >>>> y[-c(1:9)]
>     >>> list()
>     >>
>     >>> Is the observed non-error the correct behavior and therefore the
>     >>> documentation is incorrect, or is it vice verse?  (...or is it me
>     >>> missing something)
>     >>
>     >>> I get the above on R devel, R 3.2.0, and as far back as R 2.11.0
>     >>> (haven't check earlier versions).
>     >>
>     >> Thank you, Henrik!
>     >>
>     >> I've checked further back: The change happened between R 2.5.1 and R 2.6.0.
>     >>
>     >> The previous behavior was
>     >>
>     >>> (1:3)[-(3:5)]
>     >> Error: subscript out of bounds
>     >>
>     >> If you start reading NEWS.2, you see a *lot* of new features
>     >> (and bug fixes) in the 2.6.0 news, but from my browsing, none of
>     >> them mentioned the new behavior as feature.
>     >>
>     >> Let's -- for a moment -- declare it a bug in the code, i.e., not
>     >> in the documentation:
>     >>
>     >> - As 2.6.0  happened quite a while ago (Oct. 2007),
>     >> we could wonder how much R code will break if we fix the bug.
>     >>
>     >> - Is the R package authors' community willing to do the necessary
>     >> cleanup in their packages ?
>     >>
>     >> ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
>     >>
>     >>
>     >> Now, after reading the source code for a while, and looking at
>     >> the changes, I've found the log entry
>     >>
>     >> ------------------------------------------------------------------------
>     >> r42123 | ihaka | 2007-07-05 02:00:05 +0200 (Thu, 05 Jul 2007) | 4 lines
>     >>
>     >> Changed the behaviour of out-of-bounds negative
>     >> subscripts to match that of S.  Such values are
>     >> now ignored rather than tripping an error.
>     >>
>     >> ------------------------------------------------------------------------
>     >>
>     >> So, it was changed on purpose, by one of the true "R"s, very
>     >> much on purpose.
>     >>
>     >> Making it a *warning* instead of the original error
>     >> may have been both more cautious and more helpful for
>     >> detecting programming errors.
>     >>
>     >> OTOH, John Chambers, the father of S and hence grandfather of R,
>     >> may have had good reasons why it seemed more logical to silently
>     >> ignore such out of bound negative indices:
>     >> One could argue that
>     >>
>     >> x[-5]  means  "leave away the 5-th element of x"
>     >>
>     >> and if there is no 5-th element of x, leaving it away should be a no-op.
>     >>
>     >> After all this musing and history detection, my gut decision
>     >> would be to only change the documentation which Ross forgot to change.
>     >>
>     >> But of course, it may be interesting to hear other programmeR's feedback on this.
>     >>
>     >> Martin
>


From murdoch.duncan at gmail.com  Wed May  6 18:44:44 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 06 May 2015 12:44:44 -0400
Subject: [Rd] IdntoAscii issue with KERNEL32.dll on 64-bit R on Windows
 Server 2003 x64 SP2
In-Reply-To: <CA+2DmwiKdiqOumutZPpGRjYvBV6T69pYs6bHTMPCbjWJe-nsXg@mail.gmail.com>
References: <CA+2DmwiKdiqOumutZPpGRjYvBV6T69pYs6bHTMPCbjWJe-nsXg@mail.gmail.com>
Message-ID: <554A44FC.8060206@gmail.com>

On 06/05/2015 10:57 AM, Vinh Nguyen wrote:
> Dear list,
>
> With the new R 3.2.0 on the aforementioned platform, I get the following
> pop-up error when I enter "?update.packages" using R64:
>
> "The procedure entry point IdnToAscii could not be located in the dynamic
> link library KERNEL32.dll"
>
> That is, my command never gets executed.  This does NOT happen with R32.
>
> I previously noticed this error starting with R 3.0.0 with the RCurl
> package (1.95-4.5): I get the same issue when I execute "library(RCurl)" in
> R64.  This happened subsequently for every version > 3.  I always thought
> it was an RCurl issue so I just dropped to R 2.15.1 whenever I needed to
> use it.
>
> However, I now see this error with R 3.2.0 with the simple command
> (?update.packages as it tries to access internet.dll).
>
> My guess is this is specific to Windows Server 2003 x64 as it does not
> happen on my Windows 7 machine and that I did not find anything when
> searching for this issue.  I thought I'd reach out just in case anyone has
> any ideas on how to fix it.  I'm stuck on Windows Server 2003 because it is
> a work server.  Thanks so much for your help.

On the MSDN page for that function, it mentions that you need a header 
file and DLL to use it in XP or Server 2003.   You might try downloading 
the DLL to see if it works for you automagically; I think it's unlikely 
we will put in code to special case that version in the general release 
of R, as Microsoft is abandoning it as of July this year.

Duncan Murdoch


From hpages at fredhutch.org  Wed May  6 19:53:27 2015
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Wed, 06 May 2015 10:53:27 -0700
Subject: [Rd] Shouldn't vector indexing with negative out-of-range index
 give an error?
In-Reply-To: <CAFDcVCRxJDeGOG=7u96saFZWz7kTmaKQa0=vuf0MLGtvQbenYA@mail.gmail.com>
References: <CAFDcVCRRXT8KaiVwuQSTBWpi_WZL5Tvix7Ra9b8n2KzTPA23vQ@mail.gmail.com>	<21832.52525.513010.447339@stat.math.ethz.ch>	<6637F7E1-41F8-44DF-8057-1239291F08E9@stat.stanford.edu>	<21833.53742.122759.695834@stat.math.ethz.ch>
	<CAFDcVCRxJDeGOG=7u96saFZWz7kTmaKQa0=vuf0MLGtvQbenYA@mail.gmail.com>
Message-ID: <554A5517.7080600@fredhutch.org>

Hi,

On 05/06/2015 09:04 AM, Henrik Bengtsson wrote:
> On Wed, May 6, 2015 at 1:33 AM, Martin Maechler
> <maechler at lynne.stat.math.ethz.ch> wrote:
>>>>>>> John Chambers <jmc at stat.stanford.edu>
>>>>>>>      on Tue, 5 May 2015 08:39:46 -0700 writes:
>>
>>      > When someone suggests that we "might have had a reason" for some peculiarity in the original S, my usual reaction is "Or else we never thought of the problem".
>>      > In this case, however, there is a relevant statement in the 1988 "blue book".  In the discussion of subscripting (p 358) the definition for negative i says: "the indices consist of the elements of seq(along=x) that do not match any elements in -i".
>>
>>      > Suggesting that no bounds checking on -i takes place.
>>
>>      > John
>>
>> Indeed!
>> Thanks a lot John, for the perspective and clarification!
>>
>> I'm committing a patch to the documentation now.
>
> Thank you both and also credits to Dongcan Jiang for pointing out to
> me that errors were indeed not generated in this case.
>
> I agree with the decision. It's interesting to notice that now the
> only way an error is generated is when index-vector subsetting is done
> using mixed positive and negative indices, e.g. x[c(-1,1)].

This is why in situations where I need to extract a single element from
an atomic vector I use [[ instead of [. It's safer (performs 
bound-checking), a little bit faster (at least last time I checked), and
drops the name of the element.

BTW did you know that one can use a negative index with [[ on a
vector of length 2?

   > c(a=2, b=6)[[-1]]
   [1] 6
   > c(a=2, b=6)[[-2]]
   [1] 2
   > list(a=22, b=6:5)[[-1]]
   [1] 6 5
   > list(a=22, b=6:5)[[-2]]
   [1] 22
   > list(a=22, b=6:5)[[c(-1, -2)]]
   [1] 6
   > list(a=22, b=6:5)[[c(-1, -1)]]

Also works with [[<-:

   > x <- list(a=22, b=6:5)
   > x[[c(-1, -2)]] <- 99L
   > x
   $a
   [1] 22

   $b
   [1] 99  5

Not that I ever needed that "feature" though...

Cheers,
H.

>
> /Henrik
>
>> Martin
>>
>>
>>      > On May 5, 2015, at 7:01 AM, Martin Maechler <maechler at lynne.stat.math.ethz.ch> wrote:
>>
>>      >>>>>>> Henrik Bengtsson <henrik.bengtsson at ucsf.edu>
>>      >>>>>>> on Mon, 4 May 2015 12:20:44 -0700 writes:
>>      >>
>>      >>> In Section 'Indexing by vectors' of 'R Language Definition'
>>      >>> (http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Indexing-by-vectors)
>>      >>> it says:
>>      >>
>>      >>> "Integer. All elements of i must have the same sign. If they are
>>      >>> positive, the elements of x with those index numbers are selected. If
>>      >>> i contains negative elements, all elements except those indicated are
>>      >>> selected.
>>      >>
>>      >>> If i is positive and exceeds length(x) then the corresponding
>>      >>> selection is NA. A negative out of bounds value for i causes an error.
>>      >>
>>      >>> A special case is the zero index, which has null effects: x[0] is an
>>      >>> empty vector and otherwise including zeros among positive or negative
>>      >>> indices has the same effect as if they were omitted."
>>      >>
>>      >>> However, that "A negative out of bounds value for i causes an error"
>>      >>> in the second paragraph does not seem to apply.  Instead, R silently
>>      >>> ignore negative indices that are out of range.  For example:
>>      >>
>>      >>>> x <- 1:4
>>      >>>> x[-9L]
>>      >>> [1] 1 2 3 4
>>      >>>> x[-c(1:9)]
>>      >>> integer(0)
>>      >>>> x[-c(3:9)]
>>      >>> [1] 1 2
>>      >>
>>      >>>> y <- as.list(1:4)
>>      >>>> y[-c(1:9)]
>>      >>> list()
>>      >>
>>      >>> Is the observed non-error the correct behavior and therefore the
>>      >>> documentation is incorrect, or is it vice verse?  (...or is it me
>>      >>> missing something)
>>      >>
>>      >>> I get the above on R devel, R 3.2.0, and as far back as R 2.11.0
>>      >>> (haven't check earlier versions).
>>      >>
>>      >> Thank you, Henrik!
>>      >>
>>      >> I've checked further back: The change happened between R 2.5.1 and R 2.6.0.
>>      >>
>>      >> The previous behavior was
>>      >>
>>      >>> (1:3)[-(3:5)]
>>      >> Error: subscript out of bounds
>>      >>
>>      >> If you start reading NEWS.2, you see a *lot* of new features
>>      >> (and bug fixes) in the 2.6.0 news, but from my browsing, none of
>>      >> them mentioned the new behavior as feature.
>>      >>
>>      >> Let's -- for a moment -- declare it a bug in the code, i.e., not
>>      >> in the documentation:
>>      >>
>>      >> - As 2.6.0  happened quite a while ago (Oct. 2007),
>>      >> we could wonder how much R code will break if we fix the bug.
>>      >>
>>      >> - Is the R package authors' community willing to do the necessary
>>      >> cleanup in their packages ?
>>      >>
>>      >> ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ---- ----
>>      >>
>>      >>
>>      >> Now, after reading the source code for a while, and looking at
>>      >> the changes, I've found the log entry
>>      >>
>>      >> ------------------------------------------------------------------------
>>      >> r42123 | ihaka | 2007-07-05 02:00:05 +0200 (Thu, 05 Jul 2007) | 4 lines
>>      >>
>>      >> Changed the behaviour of out-of-bounds negative
>>      >> subscripts to match that of S.  Such values are
>>      >> now ignored rather than tripping an error.
>>      >>
>>      >> ------------------------------------------------------------------------
>>      >>
>>      >> So, it was changed on purpose, by one of the true "R"s, very
>>      >> much on purpose.
>>      >>
>>      >> Making it a *warning* instead of the original error
>>      >> may have been both more cautious and more helpful for
>>      >> detecting programming errors.
>>      >>
>>      >> OTOH, John Chambers, the father of S and hence grandfather of R,
>>      >> may have had good reasons why it seemed more logical to silently
>>      >> ignore such out of bound negative indices:
>>      >> One could argue that
>>      >>
>>      >> x[-5]  means  "leave away the 5-th element of x"
>>      >>
>>      >> and if there is no 5-th element of x, leaving it away should be a no-op.
>>      >>
>>      >> After all this musing and history detection, my gut decision
>>      >> would be to only change the documentation which Ross forgot to change.
>>      >>
>>      >> But of course, it may be interesting to hear other programmeR's feedback on this.
>>      >>
>>      >> Martin
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From vinhdizzo at gmail.com  Wed May  6 20:38:18 2015
From: vinhdizzo at gmail.com (Vinh Nguyen)
Date: Wed, 6 May 2015 11:38:18 -0700
Subject: [Rd] IdntoAscii issue with KERNEL32.dll on 64-bit R on Windows
 Server 2003 x64 SP2
In-Reply-To: <554A44FC.8060206@gmail.com>
References: <CA+2DmwiKdiqOumutZPpGRjYvBV6T69pYs6bHTMPCbjWJe-nsXg@mail.gmail.com>
	<554A44FC.8060206@gmail.com>
Message-ID: <CA+2Dmwi_f1XQvBeTf5+w3DA2KxzTMJAiZ7BiaoR36GyQcow1Jw@mail.gmail.com>

On Wed, May 6, 2015 at 9:44 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>
> On the MSDN page for that function, it mentions that you need a header file and DLL to use it in XP or Server 2003.   You might try downloading the DLL to see if it works for you automagically; I think it's unlikely we will put in code to special case that version in the general release of R, as Microsoft is abandoning it as of July this year.

Thanks Duncan.  I downloaded the files from
https://msdn.microsoft.com/en-us/library/windows/desktop/dd318149%28v=vs.85%29.aspx,
extracted, and installed (idndl.amd64.exe); don't think the header
files were copied/moved anywhere.  The error still persists after
restarting the server.

Any other thoughts?  Thanks.


-- Vinh


From murdoch.duncan at gmail.com  Wed May  6 20:54:13 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 06 May 2015 14:54:13 -0400
Subject: [Rd] IdntoAscii issue with KERNEL32.dll on 64-bit R on Windows
 Server 2003 x64 SP2
In-Reply-To: <CA+2Dmwi_f1XQvBeTf5+w3DA2KxzTMJAiZ7BiaoR36GyQcow1Jw@mail.gmail.com>
References: <CA+2DmwiKdiqOumutZPpGRjYvBV6T69pYs6bHTMPCbjWJe-nsXg@mail.gmail.com>
	<554A44FC.8060206@gmail.com>
	<CA+2Dmwi_f1XQvBeTf5+w3DA2KxzTMJAiZ7BiaoR36GyQcow1Jw@mail.gmail.com>
Message-ID: <554A6355.9030707@gmail.com>

On 06/05/2015 2:38 PM, Vinh Nguyen wrote:
> On Wed, May 6, 2015 at 9:44 AM, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> >
> > On the MSDN page for that function, it mentions that you need a header file and DLL to use it in XP or Server 2003.   You might try downloading the DLL to see if it works for you automagically; I think it's unlikely we will put in code to special case that version in the general release of R, as Microsoft is abandoning it as of July this year.
>
> Thanks Duncan.  I downloaded the files from
> https://msdn.microsoft.com/en-us/library/windows/desktop/dd318149%28v=vs.85%29.aspx,
> extracted, and installed (idndl.amd64.exe); don't think the header
> files were copied/moved anywhere.  The error still persists after
> restarting the server.
>
> Any other thoughts?  Thanks.

Only some not so helpful suggestions:
  - use the 32 bit version,
  - update your OS
  - figure out where to patch the 64 bit version, and build a custom one 
for yourself.

Duncan Murdoch


From henrik.bengtsson at ucsf.edu  Wed May  6 22:37:26 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Wed, 6 May 2015 13:37:26 -0700
Subject: [Rd] capabilities("X11"): Force refresh from within R? (... and
 minor documentation issue)
Message-ID: <CAFDcVCTkbvw6JnUO-zsCrUHMUgfuo2-JQKUNr4HgpspsesVvTw@mail.gmail.com>

Is there a way to refresh capabilities("X11") without restarting R
such that it reflects the enabling/disabling of X11?


BACKGROUND:

If I launch R with X11 server disabled (e.g. ssh -X / ssh -Y to remote
Linux but forgot to enable Xming on local Windows), then I get:

> capabilities("X11")
  X11
FALSE

> x11()
Error in .External2(C_X11, d$display, d$width, d$height, d$pointsize,  :
  unable to start device X11cairo
In addition: Warning message:
In x11() : unable to open connection to X11 display ''

So far so good.  However, if I then enable the X11 server (e.g. start
Xming on Windows), I still get:

> capabilities("X11")
  X11
FALSE

but

> x11()

successfully opens an X11 plot window.  In other words, the value of
capabilities("X11") is not reflecting the availability of X11; from
?capabilities:

     X11: Are the 'X11' graphics device and the X11-based data editor
          available?  This loads the X11 module if not already loaded,
          and checks that the default display can be contacted unless a
          'X11' device has already been used.

Not sure what that last "...unless a 'X11' device has already been
used" actually means here; is it a disclaimer for the above behavior?

If I restart R, the I get:

> capabilities("X11")
  X11
TRUE

I came up with the following approach that launches another R session
querying the availability of X11:

capabilitiesX11 <- function() {
  bin <- file.path(R.home("bin"), "Rscript")
  cmd <- "cat(capabilities('X11'))"
  value <- system2(bin, args=c("-e", dQuote(cmd)), stdout=TRUE)
  as.logical(value)
}

> capabilitiesX11()
[1] TRUE

but it's certainly feels like a hack.

Is there a way to force a refresh of capabilities("X11") without restarting R?

BTW, the description of ?capabilities says: "Report on the optional
features which have been compiled into this build of R."  The
"compiled into this build" part seems too specific; the above shows
that capabilities() also reflects run-time availabilities.  Other
"properties" does this as well.


Thanks,

Henrik


From sbronder at stevebronder.com  Thu May  7 17:49:49 2015
From: sbronder at stevebronder.com (Steve Bronder)
Date: Thu, 7 May 2015 11:49:49 -0400
Subject: [Rd] Why is the diag function so slow (for extraction)?
In-Reply-To: <alpine.DEB.2.10.1505050844470.2460@luke-Latitude>
References: <1430762350040-4706780.post@n4.nabble.com>
	<06F749E7-5096-438D-A299-667C7A77B477@gmail.com>
	<alpine.DEB.2.10.1505050844470.2460@luke-Latitude>
Message-ID: <CAAVP=akUU10FPvkYhNBVQzi9jsMkCma-VVGgSqjGMpKF+G_4zA@mail.gmail.com>

Is it possible to replace c() with .subset()? Example below

####
####

library(microbenchmark)


diag2 <- function(x,nrow, ncol){
  if (is.matrix(x)) {
    if (nargs() > 1L)
      stop("'nrow' or 'ncol' cannot be specified when 'x' is a matrix")
    if ((m <- min(dim(x))) == 0L)
      return(vector(typeof(x), 0L))
    # replace this part
    y <- .subset(x,1 + 0L:(m - 1L) * (dim(x)[1L] + 1))
    nms <- dimnames(x)
    if (is.list(nms) && !any(sapply(nms, is.null)) && identical((nm <-
nms[[1L]][seq_len(m)]),

nms[[2L]][seq_len(m)]))
      names(y) <- nm
    return(y)
  }
  if (is.array(x) && length(dim(x)) != 1L)
    stop("'x' is an array, but not one-dimensional.")
  if (missing(x))
    n <- nrow
  else if (length(x) == 1L && nargs() == 1L) {
    n <- as.integer(x)
    x <- 1
  }
  else n <- length(x)
  if (!missing(nrow))
    n <- nrow
  if (missing(ncol))
    ncol <- n
}

nc  <- 10

set.seed(1)
m <- matrix(sample(letters,nc^2,replace=TRUE), ncol = nc)


runoff <- microbenchmark(
  diaga = diag(m),
  diagb = diag2(m)
)

Regards,

Steve Bronder
Website: stevebronder.com
Phone: 412-719-1282
Email: sbronder at stevebronder.com


On Tue, May 5, 2015 at 9:46 AM, <luke-tierney at uiowa.edu> wrote:

> Looks like the c(x)[...] bit used to be as.matrix(x)[...]. Not sure
> why the change was made many years ago, but this was before names were
> handled explicitly. It would definitely be better to not force the
> duplicate, at least in the case where we are sure c() and [ would not
> dispatch.
>
> Best,
>
> luke
>
> On Mon, 4 May 2015, peter dalgaard wrote:
>
>
>>  On 04 May 2015, at 19:59 , franknarf <by.hook.or at gmail.com> wrote:
>>>
>>> But I'm still wondering why diag() uses c()...? With it being so slow,
>>> I'd
>>> be inclined to write a qdiag() without the c() and just use that the next
>>> time I need matrix algebra. Any insight would be appreciated; thanks!
>>>
>>
>> Well, there are two possibilities: Either it is deliberate or it isn't.
>>
>> The latter isn't too unlikely, given that the effect is seen for large
>> matrices. I would appear to be a matter of O(n) (picking out n items) vs.
>> O(n^2) (copying an n x n matrix), but this might drown out in a context
>> involving matrix multiplication and/or inversion, both of which are O(n^3).
>>
>> If it is deliberate, the question is why. There could be devils in the
>> details; notice in particular that c() strips off non-name attributes.
>> However, I'm not aware of a situation where such attributes could cause
>> trouble.
>>
>> -pd
>>
>>
>>
> --
> Luke Tierney
> Ralph E. Wareham Professor of Mathematical Sciences
> University of Iowa                  Phone:             319-335-3386
> Department of Statistics and        Fax:               319-335-3017
>    Actuarial Science
> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From soeren.vogel at posteo.ch  Thu May  7 21:17:59 2015
From: soeren.vogel at posteo.ch (=?utf-8?Q?S=C3=B6ren_Vogel?=)
Date: Thu, 7 May 2015 21:17:59 +0200
Subject: [Rd] Package check error: cannot extract package
Message-ID: <73552547-A8DC-4BFE-A999-E59CE0803897@posteo.ch>

Hi

Compilation failed for package GUTS for r-oldrel Windows, saying cannot extract package:

http://www.r-project.org/nosvn/R.check/r-oldrel-windows-ix86+x86_64/GUTS-00check.html

1. What does that mean?
2. Should I fix this (what are consequences if, or if not)?
3. How can I fix this?

Thanks
S?ren


From ligges at statistik.tu-dortmund.de  Thu May  7 23:11:11 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Thu, 07 May 2015 23:11:11 +0200
Subject: [Rd] Package check error: cannot extract package
In-Reply-To: <73552547-A8DC-4BFE-A999-E59CE0803897@posteo.ch>
References: <73552547-A8DC-4BFE-A999-E59CE0803897@posteo.ch>
Message-ID: <554BD4EF.4030807@statistik.tu-dortmund.de>



On 07.05.2015 21:17, S?ren Vogel wrote:
> Hi
>
> Compilation failed for package GUTS for r-oldrel Windows, saying cannot extract package:
>
> http://www.r-project.org/nosvn/R.check/r-oldrel-windows-ix86+x86_64/GUTS-00check.html
>
> 1. What does that mean?
> 2. Should I fix this (what are consequences if, or if not)?
> 3. How can I fix this?

By telling us. :-)
Seems to be a hicc up of the CRAN machine that builds the bianries. Will 
work on it. Should be resolved within a day or so.

Best,
Uwe Ligges

>
> Thanks
> S?ren
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From karl.forner at gmail.com  Fri May  8 17:09:44 2015
From: karl.forner at gmail.com (Karl Forner)
Date: Fri, 8 May 2015 17:09:44 +0200
Subject: [Rd] MAX_NUM_DLLS too low ?
Message-ID: <CAMd4_AeeMxsSPcYzT9v7J+M1FChOZrvuKT4dD7XEiYAfcKqy5w@mail.gmail.com>

Hello,

My problem is that I hit the hard-coded MAX_NUM_DLLS (100) limit of the
number of loaded DLLs.
I have a number of custom packages which interface and integrate a lot of
CRAN and Bioconductor packages.

For example, on my installation:
 Rscript -e 'library(crlmm);print(length(getLoadedDLLs()))'
gives 28 loaded DLLs.

I am currently trying to work-around that by putting external packages in
Suggests: instead of Imports:, and lazy-load them, but still I am wondering
if that threshold value of 100 is still relevant nowadays, or would it be
possible to increase it.

Thanks,

Karl Forner

	[[alternative HTML version deleted]]


From henrik.bengtsson at ucsf.edu  Sat May  9 02:53:15 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Fri, 8 May 2015 17:53:15 -0700
Subject: [Rd] R Language Definition: Subsetting matrices with negative
 indices is *not* an error
Message-ID: <CAFDcVCQdx0XQaBgw8rNrN0ayB8fxbiFPanXRPgfwys93zpBG8A@mail.gmail.com>

Hi,

I spotted what looks like another(*) mistake in 'R Language
Definition' on how subsetting should work.  In Section 'Indexing
matrices and arrays'
[http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Indexing-matrices-and-arrays]
one can read

   "Negative indices are not allowed in indexing matrices."

but this is not true, e.g.

> x <- matrix(1:12, nrow=4)
> x
     [,1] [,2] [,3]
[1,]    1    5    9
[2,]    2    6   10
[3,]    3    7   11
[4,]    4    8   12

> x[c(-2,-4),]
     [,1] [,2] [,3]
[1,]    1    5    9
[2,]    3    7   11

/Henrik

(*) https://stat.ethz.ch/pipermail/r-devel/2015-May/071091.html [docs
have been fixed]


From pdalgd at gmail.com  Sat May  9 09:55:44 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 9 May 2015 09:55:44 +0200
Subject: [Rd] R Language Definition: Subsetting matrices with negative
	indices is *not* an error
In-Reply-To: <CAFDcVCQdx0XQaBgw8rNrN0ayB8fxbiFPanXRPgfwys93zpBG8A@mail.gmail.com>
References: <CAFDcVCQdx0XQaBgw8rNrN0ayB8fxbiFPanXRPgfwys93zpBG8A@mail.gmail.com>
Message-ID: <FFEC09E0-0FF0-48F0-8238-4FD01E5E6A6E@gmail.com>


> On 09 May 2015, at 02:53 , Henrik Bengtsson <henrik.bengtsson at ucsf.edu> wrote:
> 
> Hi,
> 
> I spotted what looks like another(*) mistake in 'R Language
> Definition' on how subsetting should work.  In Section 'Indexing
> matrices and arrays'
> [http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Indexing-matrices-and-arrays]
> one can read
> 
>   "Negative indices are not allowed in indexing matrices."

Parse error: I believe that this is intended to mean

"Indexing matrices may not contain negative indices"

not

"You cannot use negative indices when indexing matrices".

This is consistent with the help page:

"
     A third form of indexing is via a numeric matrix with the one
     column for each dimension: each row of the index matrix then
     selects a single element of the array, and the result is a vector.
     Negative indices are not allowed in the index matrix. 
"

Rephrasing would seem to be in order....

-pd

> 
> but this is not true, e.g.
> 
>> x <- matrix(1:12, nrow=4)
>> x
>     [,1] [,2] [,3]
> [1,]    1    5    9
> [2,]    2    6   10
> [3,]    3    7   11
> [4,]    4    8   12
> 
>> x[c(-2,-4),]
>     [,1] [,2] [,3]
> [1,]    1    5    9
> [2,]    3    7   11
> 
> /Henrik
> 
> (*) https://stat.ethz.ch/pipermail/r-devel/2015-May/071091.html [docs
> have been fixed]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From henrik.bengtsson at ucsf.edu  Sat May  9 22:33:46 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Sat, 9 May 2015 13:33:46 -0700
Subject: [Rd] R Language Definition: Subsetting matrices with negative
 indices is *not* an error
In-Reply-To: <FFEC09E0-0FF0-48F0-8238-4FD01E5E6A6E@gmail.com>
References: <CAFDcVCQdx0XQaBgw8rNrN0ayB8fxbiFPanXRPgfwys93zpBG8A@mail.gmail.com>
	<FFEC09E0-0FF0-48F0-8238-4FD01E5E6A6E@gmail.com>
Message-ID: <CAFDcVCTPxo3gPoH8KOZOkH45xxAisLNeLmkw3-Ejf89Be0z9PQ@mail.gmail.com>

On Sat, May 9, 2015 at 12:55 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>
>> On 09 May 2015, at 02:53 , Henrik Bengtsson <henrik.bengtsson at ucsf.edu> wrote:
>>
>> Hi,
>>
>> I spotted what looks like another(*) mistake in 'R Language
>> Definition' on how subsetting should work.  In Section 'Indexing
>> matrices and arrays'
>> [http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Indexing-matrices-and-arrays]
>> one can read
>>
>>   "Negative indices are not allowed in indexing matrices."
>
> Parse error: I believe that this is intended to mean
>
> "Indexing matrices may not contain negative indices"
>
> not
>
> "You cannot use negative indices when indexing matrices".
>
> This is consistent with the help page:
>
> "
>      A third form of indexing is via a numeric matrix with the one
>      column for each dimension: each row of the index matrix then
>      selects a single element of the array, and the result is a vector.
>      Negative indices are not allowed in the index matrix.
> "
>
> Rephrasing would seem to be in order....

Ah... definitely a "parse error" (I read it as a new paragraph).  I
second rephrasing this; your ""Indexing matrices may not contain
negative indices" is non-ambiguous.

Thanks Peter

/Henrik

>
> -pd
>
>>
>> but this is not true, e.g.
>>
>>> x <- matrix(1:12, nrow=4)
>>> x
>>     [,1] [,2] [,3]
>> [1,]    1    5    9
>> [2,]    2    6   10
>> [3,]    3    7   11
>> [4,]    4    8   12
>>
>>> x[c(-2,-4),]
>>     [,1] [,2] [,3]
>> [1,]    1    5    9
>> [2,]    3    7   11
>>
>> /Henrik
>>
>> (*) https://stat.ethz.ch/pipermail/r-devel/2015-May/071091.html [docs
>> have been fixed]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>


From gunter.berton at gene.com  Sat May  9 22:50:21 2015
From: gunter.berton at gene.com (Bert Gunter)
Date: Sat, 9 May 2015 13:50:21 -0700
Subject: [Rd] R Language Definition: Subsetting matrices with negative
 indices is *not* an error
In-Reply-To: <CAFDcVCTPxo3gPoH8KOZOkH45xxAisLNeLmkw3-Ejf89Be0z9PQ@mail.gmail.com>
References: <CAFDcVCQdx0XQaBgw8rNrN0ayB8fxbiFPanXRPgfwys93zpBG8A@mail.gmail.com>
	<FFEC09E0-0FF0-48F0-8238-4FD01E5E6A6E@gmail.com>
	<CAFDcVCTPxo3gPoH8KOZOkH45xxAisLNeLmkw3-Ejf89Be0z9PQ@mail.gmail.com>
Message-ID: <CACk-te1F8_ocFxftUKTapJo6ArWkXjB-iP+F4wnQcpqwF27CVA@mail.gmail.com>

Ah, the woes of English word order -- even this native English speaker
frequently gets messed up!

(but maybe I'm just a bear of little brain).

Best,
Bert

Bert Gunter
Genentech Nonclinical Biostatistics
(650) 467-7374

"Data is not information. Information is not knowledge. And knowledge
is certainly not wisdom."
Clifford Stoll




On Sat, May 9, 2015 at 1:33 PM, Henrik Bengtsson
<henrik.bengtsson at ucsf.edu> wrote:
> On Sat, May 9, 2015 at 12:55 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>>
>>> On 09 May 2015, at 02:53 , Henrik Bengtsson <henrik.bengtsson at ucsf.edu> wrote:
>>>
>>> Hi,
>>>
>>> I spotted what looks like another(*) mistake in 'R Language
>>> Definition' on how subsetting should work.  In Section 'Indexing
>>> matrices and arrays'
>>> [http://cran.r-project.org/doc/manuals/r-release/R-lang.html#Indexing-matrices-and-arrays]
>>> one can read
>>>
>>>   "Negative indices are not allowed in indexing matrices."
>>
>> Parse error: I believe that this is intended to mean
>>
>> "Indexing matrices may not contain negative indices"
>>
>> not
>>
>> "You cannot use negative indices when indexing matrices".
>>
>> This is consistent with the help page:
>>
>> "
>>      A third form of indexing is via a numeric matrix with the one
>>      column for each dimension: each row of the index matrix then
>>      selects a single element of the array, and the result is a vector.
>>      Negative indices are not allowed in the index matrix.
>> "
>>
>> Rephrasing would seem to be in order....
>
> Ah... definitely a "parse error" (I read it as a new paragraph).  I
> second rephrasing this; your ""Indexing matrices may not contain
> negative indices" is non-ambiguous.
>
> Thanks Peter
>
> /Henrik
>
>>
>> -pd
>>
>>>
>>> but this is not true, e.g.
>>>
>>>> x <- matrix(1:12, nrow=4)
>>>> x
>>>     [,1] [,2] [,3]
>>> [1,]    1    5    9
>>> [2,]    2    6   10
>>> [3,]    3    7   11
>>> [4,]    4    8   12
>>>
>>>> x[c(-2,-4),]
>>>     [,1] [,2] [,3]
>>> [1,]    1    5    9
>>> [2,]    3    7   11
>>>
>>> /Henrik
>>>
>>> (*) https://stat.ethz.ch/pipermail/r-devel/2015-May/071091.html [docs
>>> have been fixed]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> --
>> Peter Dalgaard, Professor,
>> Center for Statistics, Copenhagen Business School
>> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
>> Phone: (+45)38153501
>> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>>
>>
>>
>>
>>
>>
>>
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From henrik.bengtsson at ucsf.edu  Sat May  9 22:57:12 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Sat, 9 May 2015 13:57:12 -0700
Subject: [Rd] PATCH: library(...,
 quietly=TRUE) still outputs "Loading required package: ..." (forgot
 to pass down 'quietly')
Message-ID: <CAFDcVCRTQPHR1NB1Cy-gfw8NYSQhAL_58nHvVNojiyr9RXDr3g@mail.gmail.com>

Calling library(..., quietly=TRUE) may still output:

   Loading required package: <other pkg>

in some cases, e.g.

> library("R.utils", quietly=TRUE)
Loading required package: R.methodsS3
[...]

I traced this to base:::.getRequiredPackages2(), which forgets to pass
'quietly' to an internal library() call:

if (!attached) {
    if (!quietly)
        packageStartupMessage(gettextf("Loading required package: %s",
          pkg), domain = NA)
    library(pkg, character.only = TRUE, logical.return = TRUE,
        lib.loc = lib.loc) || stop(gettextf("package %s could not be loaded",

        sQuote(pkg)), call. = FALSE, domain = NA)
}

It's from that library() call the message is generated.


Here's a patch:

$ svn diff src\library\base\R\library.R
Index: src/library/base/R/library.R
===================================================================
--- src/library/base/R/library.R        (revision 68345)
+++ src/library/base/R/library.R        (working copy)
@@ -871,7 +871,7 @@
                 packageStartupMessage(gettextf("Loading required package: %s",
                                                pkg), domain = NA)
             library(pkg, character.only = TRUE, logical.return = TRUE,
-                    lib.loc = lib.loc) ||
+                    lib.loc = lib.loc, quietly = quietly) ||
                 stop(gettextf("package %s could not be loaded", sQuote(pkg)),
                      call. = FALSE, domain = NA)
         }

I can submit it via http://bugs.r-project.org/ if preferred.


Thanks,

Henrik


From pdalgd at gmail.com  Sat May  9 23:17:13 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 9 May 2015 23:17:13 +0200
Subject: [Rd] R Language Definition: Subsetting matrices with negative
	indices is *not* an error
In-Reply-To: <CAFDcVCTPxo3gPoH8KOZOkH45xxAisLNeLmkw3-Ejf89Be0z9PQ@mail.gmail.com>
References: <CAFDcVCQdx0XQaBgw8rNrN0ayB8fxbiFPanXRPgfwys93zpBG8A@mail.gmail.com>
	<FFEC09E0-0FF0-48F0-8238-4FD01E5E6A6E@gmail.com>
	<CAFDcVCTPxo3gPoH8KOZOkH45xxAisLNeLmkw3-Ejf89Be0z9PQ@mail.gmail.com>
Message-ID: <59AF8973-BDDB-4B75-B400-6A7D4DE3D953@gmail.com>


> On 09 May 2015, at 22:33 , Henrik Bengtsson <henrik.bengtsson at ucsf.edu> wrote:
> 
> On Sat, May 9, 2015 at 12:55 AM, peter dalgaard <pdalgd at gmail.com> wrote:
>> 
>> 
>> Rephrasing would seem to be in order....
> 
> Ah... definitely a "parse error" (I read it as a new paragraph).  I
> second rephrasing this; your ""Indexing matrices may not contain
> negative indices" is non-ambiguous.

Now in R-devel.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From mtmorgan at fredhutch.org  Sun May 10 17:19:07 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Sun, 10 May 2015 08:19:07 -0700
Subject: [Rd] S4 method dispatch sometimes leads to incorrect when object
 loaded from file?
Message-ID: <554F76EB.3020804@fredhutch.org>

Loading an S4 object from a file without first loading the library sometimes (?, 
the example below and actual example involves a virtual base class and the show 
generic) leads to incorrect dispatch (to the base class method).

The attached package reproduces the problem. It has

setClass("A")
setClass("B", contains="A")
setMethod("show", "A", function(object) cat("A\n"))
setMethod("show", "B", function(object) cat("B\n"))

with NAMESPACE

import(methods)
exportClasses(A, B)
exportMethods(show)

This creates the object and illustrated expected behavior

   ~/tmp$ R --vanilla --slave -e "library(PkgA); b = new('B'); save(b, 
file='b.Rda'); b"
   B

Loading PkgA before the object leads to correct dispatch

   ~/tmp$ R --vanilla --slave -e "library(PkgA); load(file='b.Rda'); b"
   B

but loading the object without first loading PkgA leads to dispatch to 
show,A-method.

   ~/tmp$ R --vanilla --slave -e "load(file='b.Rda'); b"
   Loading required package: PkgA
   A

Martin Morgan
-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793

From tal.galili at gmail.com  Sun May 10 22:13:09 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Sun, 10 May 2015 23:13:09 +0300
Subject: [Rd] Wrong MD5 checksums in R 3.2.0
Message-ID: <CANdJ3dU=D8qriq2wO7tZb+UYWi3oiLxmC+TdV1yLQBJAOdf5Tg@mail.gmail.com>

Dear R-devel members,

Several R user recently reported
<https://github.com/talgalili/installr/issues/30> (while using the installr
<http://cran.r-project.org/web/packages/installr>package) that when running
MD5 checksums on a recent R installation (R 3.2.0), they get that the files
?bin/R.exe?, ?bin/Rscript.exe?
have the wrong MD5 checksums on Windows.

I intend to remove the test for these files in the next version of
installr, but I thought this might interest people to know.

With regards,
Tal

	[[alternative HTML version deleted]]


From maechler at lynne.stat.math.ethz.ch  Mon May 11 09:53:55 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 11 May 2015 09:53:55 +0200
Subject: [Rd] Wrongly checked MD5 checksums in R 3.2.0's windows binary
In-Reply-To: <CANdJ3dU=D8qriq2wO7tZb+UYWi3oiLxmC+TdV1yLQBJAOdf5Tg@mail.gmail.com>
References: <CANdJ3dU=D8qriq2wO7tZb+UYWi3oiLxmC+TdV1yLQBJAOdf5Tg@mail.gmail.com>
Message-ID: <21840.24595.738590.906123@stat.math.ethz.ch>

>>>>> Tal Galili <tal.galili at gmail.com>
>>>>>     on Sun, 10 May 2015 23:13:09 +0300 writes:

    > Dear R-devel members, Several R user recently reported
    > <https://github.com/talgalili/installr/issues/30> (while
    > using the installr
    > <http://cran.r-project.org/web/packages/installr>package)
    > that when running MD5 checksums on a recent R installation
    > (R 3.2.0), they get that the files ?bin/R.exe?,
    > ?bin/Rscript.exe? have the wrong MD5 checksums on Windows.

    > I intend to remove the test for these files in the next
    > version of installr, but I thought this might interest
    > people to know.

Well, one could argue that this is a bug in your package.

Here is what I do on our CRAN mirror, inside the
  bin/windows/base  directory :

$ md5sum R-3.2.0-win.exe
c3f8654826ce772d0105373b85804b0d  R-3.2.0-win.exe
$ cat md5sum.txt
c3f8654826ce772d0105373b85804b0d *R-3.2.0-win.exe

and so I conclude that the MD5 sum is correct.
In case of doubt, I rather trust a human than an algorithm, but
it seems that I'm slowly becoming part of a minority .. ;-( ;-)

So the bug might be that your package code gets upset by the "*"
before the R  ?
.... and that may also be the glitch on the CRAN maintainer side..


    > With regards, Tal

    > 	[[alternative HTML version deleted]]
          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

I know that you know better, Tal ;-)

Best regards,
Martin


From pdalgd at gmail.com  Mon May 11 10:31:43 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 11 May 2015 10:31:43 +0200
Subject: [Rd] Wrongly checked MD5 checksums in R 3.2.0's windows binary
In-Reply-To: <21840.24595.738590.906123@stat.math.ethz.ch>
References: <CANdJ3dU=D8qriq2wO7tZb+UYWi3oiLxmC+TdV1yLQBJAOdf5Tg@mail.gmail.com>
	<21840.24595.738590.906123@stat.math.ethz.ch>
Message-ID: <70B6F453-1F65-4C23-89CB-52597D3476E4@gmail.com>


On 11 May 2015, at 09:53 , Martin Maechler <maechler at lynne.stat.math.ethz.ch> wrote:

>>>>>> Tal Galili <tal.galili at gmail.com>
>>>>>>    on Sun, 10 May 2015 23:13:09 +0300 writes:
> 
>> Dear R-devel members, Several R user recently reported
>> <https://github.com/talgalili/installr/issues/30> (while
>> using the installr
>> <http://cran.r-project.org/web/packages/installr>package)
>> that when running MD5 checksums on a recent R installation
>> (R 3.2.0), they get that the files ?bin/R.exe?,
>> ?bin/Rscript.exe? have the wrong MD5 checksums on Windows.
> 
>> I intend to remove the test for these files in the next
>> version of installr, but I thought this might interest
>> people to know.
> 
> Well, one could argue that this is a bug in your package.
> 

...especially since this seems to be about executable files _after_ install, not the installer binaries. I don't think we provide the md5sums for those, do we?

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From murdoch.duncan at gmail.com  Mon May 11 11:06:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 11 May 2015 05:06:45 -0400
Subject: [Rd] Wrongly checked MD5 checksums in R 3.2.0's windows binary
In-Reply-To: <70B6F453-1F65-4C23-89CB-52597D3476E4@gmail.com>
References: <CANdJ3dU=D8qriq2wO7tZb+UYWi3oiLxmC+TdV1yLQBJAOdf5Tg@mail.gmail.com>	<21840.24595.738590.906123@stat.math.ethz.ch>
	<70B6F453-1F65-4C23-89CB-52597D3476E4@gmail.com>
Message-ID: <55507125.20100@gmail.com>

On 11/05/2015 4:31 AM, peter dalgaard wrote:
> 
> On 11 May 2015, at 09:53 , Martin Maechler <maechler at lynne.stat.math.ethz.ch> wrote:
> 
>>>>>>> Tal Galili <tal.galili at gmail.com>
>>>>>>>    on Sun, 10 May 2015 23:13:09 +0300 writes:
>>
>>> Dear R-devel members, Several R user recently reported
>>> <https://github.com/talgalili/installr/issues/30> (while
>>> using the installr
>>> <http://cran.r-project.org/web/packages/installr>package)
>>> that when running MD5 checksums on a recent R installation
>>> (R 3.2.0), they get that the files ?bin/R.exe?,
>>> ?bin/Rscript.exe? have the wrong MD5 checksums on Windows.
>>
>>> I intend to remove the test for these files in the next
>>> version of installr, but I thought this might interest
>>> people to know.
>>
>> Well, one could argue that this is a bug in your package.
>>
> 
> ...especially since this seems to be about executable files _after_ install, not the installer binaries. I don't think we provide the md5sums for those, do we?
> 

Yes, they're in the MD5 file in the top level directory after installing.

The issue with files in the bin directory is that they depend on whether
it's a 32 bit or 64 bit install, but the MD5 sums are computed only for
the 32 bit files.  Those two files should be identical to each other,
and to one of i386/Rfe.exe or x64/Rfe.exe.  They need to be special-cased.

Duncan Murdoch


From tal.galili at gmail.com  Mon May 11 14:35:52 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 11 May 2015 15:35:52 +0300
Subject: [Rd] Wrongly checked MD5 checksums in R 3.2.0's windows binary
In-Reply-To: <55507125.20100@gmail.com>
References: <CANdJ3dU=D8qriq2wO7tZb+UYWi3oiLxmC+TdV1yLQBJAOdf5Tg@mail.gmail.com>
	<21840.24595.738590.906123@stat.math.ethz.ch>
	<70B6F453-1F65-4C23-89CB-52597D3476E4@gmail.com>
	<55507125.20100@gmail.com>
Message-ID: <CANdJ3dXCh7-BxF6Xii3Wa1UuHeUCoGJOdNepEzrwzRDBRcEB6A@mail.gmail.com>

Thank you Duncan, Peter and Martin for the responses.

Just to mention that the code is based on tools::md5sum, and the issue can
be reproduced (in Windows) using:

if(!require(installr)) install.packages("installr")
installr::checkMD5sums2(dir=R.home())


With regards,
Tal

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon May 11 15:18:16 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 11 May 2015 09:18:16 -0400
Subject: [Rd] Wrongly checked MD5 checksums in R 3.2.0's windows binary
In-Reply-To: <CANdJ3dXCh7-BxF6Xii3Wa1UuHeUCoGJOdNepEzrwzRDBRcEB6A@mail.gmail.com>
References: <CANdJ3dU=D8qriq2wO7tZb+UYWi3oiLxmC+TdV1yLQBJAOdf5Tg@mail.gmail.com>
	<21840.24595.738590.906123@stat.math.ethz.ch>
	<70B6F453-1F65-4C23-89CB-52597D3476E4@gmail.com>
	<55507125.20100@gmail.com>
	<CANdJ3dXCh7-BxF6Xii3Wa1UuHeUCoGJOdNepEzrwzRDBRcEB6A@mail.gmail.com>
Message-ID: <5550AC18.6080706@gmail.com>

On 11/05/2015 8:35 AM, Tal Galili wrote:
> Thank you Duncan, Peter and Martin for the responses.
>
> Just to mention that the code is based on tools::md5sum, and the issue 
> can be reproduced (in Windows) using:
>
> if(!require(installr)) install.packages("installr")
> installr::checkMD5sums2(dir=R.home())
>
I think you didn't understand my post.  It's a bug in your code: you 
need to compare the md5sum value to the ones I mentioned, not just to 
the one listed in the MD5 file.

Duncan Murdoch


From tal.galili at gmail.com  Mon May 11 15:35:30 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 11 May 2015 16:35:30 +0300
Subject: [Rd] Wrongly checked MD5 checksums in R 3.2.0's windows binary
In-Reply-To: <5550AC18.6080706@gmail.com>
References: <CANdJ3dU=D8qriq2wO7tZb+UYWi3oiLxmC+TdV1yLQBJAOdf5Tg@mail.gmail.com>
	<21840.24595.738590.906123@stat.math.ethz.ch>
	<70B6F453-1F65-4C23-89CB-52597D3476E4@gmail.com>
	<55507125.20100@gmail.com>
	<CANdJ3dXCh7-BxF6Xii3Wa1UuHeUCoGJOdNepEzrwzRDBRcEB6A@mail.gmail.com>
	<5550AC18.6080706@gmail.com>
Message-ID: <CANdJ3dWSaYQJ3avnwNaoduc08wBKzpNGBga=gkMy7MsrSiyX8Q@mail.gmail.com>

Hi Duncan,
Thank you for the clarification. :)

I ended up removing these files from being scanned in the updated version
of installr. I would rather focus on supporting an MD5 scan that is based
on what is listed in MD5 file itself (ignoring exceptions that are not
clearly stated in the file).









----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------


On Mon, May 11, 2015 at 4:18 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:

> On 11/05/2015 8:35 AM, Tal Galili wrote:
>
>> Thank you Duncan, Peter and Martin for the responses.
>>
>> Just to mention that the code is based on tools::md5sum, and the issue
>> can be reproduced (in Windows) using:
>>
>> if(!require(installr)) install.packages("installr")
>> installr::checkMD5sums2(dir=R.home())
>>
>>  I think you didn't understand my post.  It's a bug in your code: you
> need to compare the md5sum value to the ones I mentioned, not just to the
> one listed in the MD5 file.
>
> Duncan Murdoch
>

	[[alternative HTML version deleted]]


From simonbyrne at gmail.com  Mon May 11 15:37:21 2015
From: simonbyrne at gmail.com (Simon Byrne)
Date: Mon, 11 May 2015 14:37:21 +0100
Subject: [Rd] Windows environmental variables
Message-ID: <CAHn2Xjf2CGNWg9GWmE+depnKZ8-90xskvQiSC+vhOs4HSYNFcg@mail.gmail.com>

Hi,

I recently had some difficulty getting an embedded R session running
on Windows, due to the way that R Sys.getenv works, which I would
consider a bug. Even if you do not agree, then you may still want to
document it for future users who might be bitten.

As outlined in R-exts (?8.2.2):
http://cran.r-project.org/doc/manuals/r-release/R-exts.html#Calling-R_002edll-directly
R_HOME/bin needs to be in the PATH environmental variable (by the way,
I actually found that I needed R_HOME/binR_ARCH instead: you may want
to update this).

There are 2 ways to get & set environmental variables in Windows (I
just discuss the UTF16 "widechar" methods):

1) the Win32 interface, using GetEnvironmentVariableW, SetEnvironmentVariableW
https://msdn.microsoft.com/en-us/library/windows/desktop/ms683188%28v=vs.85%29.aspx

2) the POSIX-style interface, using _wgetenv, _wputenv
https://msdn.microsoft.com/en-us/library/tehxacec.aspx

The problem arises due to the fact that these don't quite do the same
thing: the POSIX-style interface, used by R, operates at the runtime
level (msvcrt), which makes its own copy of the environmental
variables.

Now, this is not a problem when R is running by itself, as it uses the
interface in a consistent manner. The problem arises when you try to
run R embedded within another program: as the copy is made at the
start of the process (i.e. the calling program), any subsequent
changes (such as setting the PATH variable as required) won't be
reflected in the msvcrt copy (used by R). Further complications could
arise if there are multiple msvcrt libraries loaded (not an uncommon
situation, unfortunately).

This is all a long-winded way of saying: for ease of embedding R, it
would probably be better to use the Win32 interface, instead of the
current POSIX-style interface on Windows.

Best,
Simon


From murdoch.duncan at gmail.com  Mon May 11 15:53:30 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 11 May 2015 09:53:30 -0400
Subject: [Rd] Wrongly checked MD5 checksums in R 3.2.0's windows binary
In-Reply-To: <CANdJ3dWSaYQJ3avnwNaoduc08wBKzpNGBga=gkMy7MsrSiyX8Q@mail.gmail.com>
References: <CANdJ3dU=D8qriq2wO7tZb+UYWi3oiLxmC+TdV1yLQBJAOdf5Tg@mail.gmail.com>
	<21840.24595.738590.906123@stat.math.ethz.ch>
	<70B6F453-1F65-4C23-89CB-52597D3476E4@gmail.com>
	<55507125.20100@gmail.com>
	<CANdJ3dXCh7-BxF6Xii3Wa1UuHeUCoGJOdNepEzrwzRDBRcEB6A@mail.gmail.com>
	<5550AC18.6080706@gmail.com>
	<CANdJ3dWSaYQJ3avnwNaoduc08wBKzpNGBga=gkMy7MsrSiyX8Q@mail.gmail.com>
Message-ID: <5550B45A.7040504@gmail.com>

On 11/05/2015 9:35 AM, Tal Galili wrote:
> Hi Duncan,
> Thank you for the clarification. :)
>
> I ended up removing these files from being scanned in the updated 
> version of installr. I would rather focus on supporting an MD5 scan 
> that is based on what is listed in MD5 file itself (ignoring 
> exceptions that are not clearly stated in the file).
>

I'm not sure what the purpose is of your test, but if it is to detect 
modified files, that might not be a good strategy.  A malicious agent 
could install fake bin/R.exe or bin/Rscript.exe and not be caught.

Of course, if they knew to modify those two files but not any others, 
they would know enough to also install a fake MD5 file, and then there's 
basically nothing you could do.

Duncan


From pdalgd at gmail.com  Mon May 11 17:00:48 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Mon, 11 May 2015 17:00:48 +0200
Subject: [Rd] Wrongly checked MD5 checksums in R 3.2.0's windows binary
In-Reply-To: <5550B45A.7040504@gmail.com>
References: <CANdJ3dU=D8qriq2wO7tZb+UYWi3oiLxmC+TdV1yLQBJAOdf5Tg@mail.gmail.com>
	<21840.24595.738590.906123@stat.math.ethz.ch>
	<70B6F453-1F65-4C23-89CB-52597D3476E4@gmail.com>
	<55507125.20100@gmail.com>
	<CANdJ3dXCh7-BxF6Xii3Wa1UuHeUCoGJOdNepEzrwzRDBRcEB6A@mail.gmail.com>
	<5550AC18.6080706@gmail.com>
	<CANdJ3dWSaYQJ3avnwNaoduc08wBKzpNGBga=gkMy7MsrSiyX8Q@mail.gmail.com>
	<5550B45A.7040504@gmail.com>
Message-ID: <83A03E80-691B-4B15-A80F-5A7111DB0C29@gmail.com>


> On 11 May 2015, at 15:53 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 11/05/2015 9:35 AM, Tal Galili wrote:
>> Hi Duncan,
>> Thank you for the clarification. :)
>> 
>> I ended up removing these files from being scanned in the updated version of installr. I would rather focus on supporting an MD5 scan that is based on what is listed in MD5 file itself (ignoring exceptions that are not clearly stated in the file).
>> 
> 
> I'm not sure what the purpose is of your test, but if it is to detect modified files, that might not be a good strategy.  A malicious agent could install fake bin/R.exe or bin/Rscript.exe and not be caught.
> 
> Of course, if they knew to modify those two files but not any others, they would know enough to also install a fake MD5 file, and then there's basically nothing you could do.
> 
> Duncan

As a general matter, checksumming is useless against tampering if you ship the checksums with the files (that's why I put the checksums in the release announcements: so that they travel alon a different route to the user). If you do, they only make sense as safeguards against technical errors (such as the infamous CR/CRLF conversions).

I still don't get why Tal refuses to work out the apparently quite simple logic that decides which checksums should be used to check the installed R.exe and Rscript.exe.

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From ripley at stats.ox.ac.uk  Mon May 11 17:19:35 2015
From: ripley at stats.ox.ac.uk (Brian Ripley)
Date: Mon, 11 May 2015 16:19:35 +0100
Subject: [Rd] Wrongly checked MD5 checksums in R 3.2.0's windows binary
In-Reply-To: <83A03E80-691B-4B15-A80F-5A7111DB0C29@gmail.com>
References: <CANdJ3dU=D8qriq2wO7tZb+UYWi3oiLxmC+TdV1yLQBJAOdf5Tg@mail.gmail.com>
	<21840.24595.738590.906123@stat.math.ethz.ch>
	<70B6F453-1F65-4C23-89CB-52597D3476E4@gmail.com>
	<55507125.20100@gmail.com>
	<CANdJ3dXCh7-BxF6Xii3Wa1UuHeUCoGJOdNepEzrwzRDBRcEB6A@mail.gmail.com>
	<5550AC18.6080706@gmail.com>
	<CANdJ3dWSaYQJ3avnwNaoduc08wBKzpNGBga=gkMy7MsrSiyX8Q@mail.gmail.com>
	<5550B45A.7040504@gmail.com>
	<83A03E80-691B-4B15-A80F-5A7111DB0C29@gmail.com>
Message-ID: <455470B4-922F-4EBC-8D68-058AC9D09CCC@stats.ox.ac.uk>



> On 11 May 2015, at 16:00, peter dalgaard <pdalgd at gmail.com> wrote:
> 
> 
>> On 11 May 2015, at 15:53 , Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> 
>> On 11/05/2015 9:35 AM, Tal Galili wrote:
>>> Hi Duncan,
>>> Thank you for the clarification. :)
>>> 
>>> I ended up removing these files from being scanned in the updated version of installr. I would rather focus on supporting an MD5 scan that is based on what is listed in MD5 file itself (ignoring exceptions that are not clearly stated in the file).
>> 
>> I'm not sure what the purpose is of your test, but if it is to detect modified files, that might not be a good strategy.  A malicious agent could install fake bin/R.exe or bin/Rscript.exe and not be caught.
>> 
>> Of course, if they knew to modify those two files but not any others, they would know enough to also install a fake MD5 file, and then there's basically nothing you could do.
>> 
>> Duncan
> 
> As a general matter, checksumming is useless against tampering if you ship the checksums with the files (that's why I put the checksums in the release announcements: so that they travel alon a different route to the user). If you do, they only make sense as safeguards against technical errors (such as the infamous CR/CRLF conversions).

And that (including unpacking errors by rogue unzip clients) is precisely what they are there in the binary packages for.

> 
> I still don't get why Tal refuses to work out the apparently quite simple logic that decides which checksums should be used to check the installed R.exe and Rscript.exe.
> 
> -- 
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at lynne.stat.math.ethz.ch  Mon May 11 17:53:40 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 11 May 2015 17:53:40 +0200
Subject: [Rd] PATCH: library(...,
 quietly=TRUE) still outputs "Loading required package: ..." (forgot
 to pass down 'quietly')
In-Reply-To: <CAFDcVCRTQPHR1NB1Cy-gfw8NYSQhAL_58nHvVNojiyr9RXDr3g@mail.gmail.com>
References: <CAFDcVCRTQPHR1NB1Cy-gfw8NYSQhAL_58nHvVNojiyr9RXDr3g@mail.gmail.com>
Message-ID: <21840.53380.90208.47505@stat.math.ethz.ch>

>>>>> Henrik Bengtsson <henrik.bengtsson at ucsf.edu>
>>>>>     on Sat, 9 May 2015 13:57:12 -0700 writes:

    > Calling library(..., quietly=TRUE) may still output:
    > Loading required package: <other pkg>

    > in some cases, e.g.

    >> library("R.utils", quietly=TRUE)
    > Loading required package: R.methodsS3
    > [...]

    > I traced this to base:::.getRequiredPackages2(), which forgets to pass
    > 'quietly' to an internal library() call:

    > if (!attached) {
    > if (!quietly)
    > packageStartupMessage(gettextf("Loading required package: %s",
    > pkg), domain = NA)
    > library(pkg, character.only = TRUE, logical.return = TRUE,
    > lib.loc = lib.loc) || stop(gettextf("package %s could not be loaded",

    > sQuote(pkg)), call. = FALSE, domain = NA)
    > }

    > It's from that library() call the message is generated.


    > Here's a patch:

    > $ svn diff src\library\base\R\library.R
    > Index: src/library/base/R/library.R
    > ===================================================================
    > --- src/library/base/R/library.R        (revision 68345)
    > +++ src/library/base/R/library.R        (working copy)
    > @@ -871,7 +871,7 @@
    > packageStartupMessage(gettextf("Loading required package: %s",
    > pkg), domain = NA)
    > library(pkg, character.only = TRUE, logical.return = TRUE,
    > -                    lib.loc = lib.loc) ||
    > +                    lib.loc = lib.loc, quietly = quietly) ||
    > stop(gettextf("package %s could not be loaded", sQuote(pkg)),
    > call. = FALSE, domain = NA)
    > }

    > I can submit it via http://bugs.r-project.org/ if preferred.

No. It's easier that way -- already in the R-devel sources,
thank you Henrik.

Martin

    > Thanks,
    > Henrik


From james.f.hester at gmail.com  Mon May 11 18:28:29 2015
From: james.f.hester at gmail.com (Jim Hester)
Date: Mon, 11 May 2015 12:28:29 -0400
Subject: [Rd] LDFLAGS defined in R_MAKEVARS_USER file is ignored for R CMD
	SHLIB on Windows
Message-ID: <CAD6tx97zP3ZLQTf+vt9de7Z9rWzm2UneYLn5UtuE4ZiNPPau1A@mail.gmail.com>

Example input and output to reproduce this can be found at
https://gist.github.com/jimhester/b7f05f50794c88e44b17.

I tested this attempting to compile the [digest](
http://cran.r-project.org/web/packages/digest/index.html) package, `run.sh`
and `run.bat` were both run in the package source directory on Ubuntu 14.01
and Windows 7 respectively.

In particular while the `CFLAGS` values were properly passed to the
compiler on both Linux and Windows, the `LDFLAGS` value was only passed to
the linker on Linux, which caused the subsequent linking errors on Windows.

Perhaps this is intended behavior, if so is there a different compiler
variable I can use to pass flags to the linker on Windows?

	[[alternative HTML version deleted]]


From sbronder at stevebronder.com  Mon May 11 19:10:02 2015
From: sbronder at stevebronder.com (Steve Bronder)
Date: Mon, 11 May 2015 13:10:02 -0400
Subject: [Rd] Why is the diag function so slow (for extraction)?
In-Reply-To: <CAAVP=akUU10FPvkYhNBVQzi9jsMkCma-VVGgSqjGMpKF+G_4zA@mail.gmail.com>
References: <1430762350040-4706780.post@n4.nabble.com>
	<06F749E7-5096-438D-A299-667C7A77B477@gmail.com>
	<alpine.DEB.2.10.1505050844470.2460@luke-Latitude>
	<CAAVP=akUU10FPvkYhNBVQzi9jsMkCma-VVGgSqjGMpKF+G_4zA@mail.gmail.com>
Message-ID: <CAAVP=amB6b+EnMpnFMnsNHc_hVJ+U6XjFBCE1WPZ8U4fQzQh2g@mail.gmail.com>

Sorry if this is a re-post, not sure if my original message got though. Is
it possible to replace c() with .subset()? Or would this throw errors
because of something specific in c() or as.matrix()? There's a pretty nice
speed up by replacing c() with the .subset().

Ex.
----
library(microbenchmark)


diag2 <- function(x,nrow, ncol){
  if (is.matrix(x)) {
    if (nargs() > 1L)
      stop("'nrow' or 'ncol' cannot be specified when 'x' is a matrix")
    if ((m <- min(dim(x))) == 0L)
      return(vector(typeof(x), 0L))
    # replace this part
    y <- .subset(x,1 + 0L:(m - 1L) * (dim(x)[1L] + 1))
    nms <- dimnames(x)
    if (is.list(nms) && !any(sapply(nms, is.null)) && identical((nm <-
nms[[1L]][seq_len(m)]),

nms[[2L]][seq_len(m)]))
      names(y) <- nm
    return(y)
  }
  if (is.array(x) && length(dim(x)) != 1L)
    stop("'x' is an array, but not one-dimensional.")
  if (missing(x))
    n <- nrow
  else if (length(x) == 1L && nargs() == 1L) {
    n <- as.integer(x)
    x <- 1
  }
  else n <- length(x)
  if (!missing(nrow))
    n <- nrow
  if (missing(ncol))
    ncol <- n
}

# Tests

nc  <- 1e04

set.seed(1)
m <- matrix(sample(letters,nc^2,replace=TRUE), ncol = nc)

runoff <- microbenchmark(
  diaga <- diag(m),
  diagb <- diag2(m)
)

runoff

Unit: microseconds
expr        min         lq        mean      median        uq        max
neval
diaga 429033.896 434186.694 512143.6728 503355.5865 572811.11 656035.584
100
diagb    216.112    251.445    536.8531    688.3595    706.98   2437.921
100


Regards,

Steve Bronder
Website: stevebronder.com
Phone: 412-719-1282
Email: sbronder at stevebronder.com


On Thu, May 7, 2015 at 11:49 AM, Steve Bronder <sbronder at stevebronder.com>
wrote:

> Is it possible to replace c() with .subset()? Example below
>
> ####
> ####
>
> library(microbenchmark)
>
>
> diag2 <- function(x,nrow, ncol){
>   if (is.matrix(x)) {
>     if (nargs() > 1L)
>       stop("'nrow' or 'ncol' cannot be specified when 'x' is a matrix")
>     if ((m <- min(dim(x))) == 0L)
>       return(vector(typeof(x), 0L))
>     # replace this part
>     y <- .subset(x,1 + 0L:(m - 1L) * (dim(x)[1L] + 1))
>     nms <- dimnames(x)
>     if (is.list(nms) && !any(sapply(nms, is.null)) && identical((nm <-
> nms[[1L]][seq_len(m)]),
>
> nms[[2L]][seq_len(m)]))
>       names(y) <- nm
>     return(y)
>   }
>   if (is.array(x) && length(dim(x)) != 1L)
>     stop("'x' is an array, but not one-dimensional.")
>   if (missing(x))
>     n <- nrow
>   else if (length(x) == 1L && nargs() == 1L) {
>     n <- as.integer(x)
>     x <- 1
>   }
>   else n <- length(x)
>   if (!missing(nrow))
>     n <- nrow
>   if (missing(ncol))
>     ncol <- n
> }
>
> nc  <- 10
>
> set.seed(1)
> m <- matrix(sample(letters,nc^2,replace=TRUE), ncol = nc)
>
>
> runoff <- microbenchmark(
>   diaga = diag(m),
>   diagb = diag2(m)
> )
>
> Regards,
>
> Steve Bronder
> Website: stevebronder.com
> Phone: 412-719-1282
> Email: sbronder at stevebronder.com
>
>
> On Tue, May 5, 2015 at 9:46 AM, <luke-tierney at uiowa.edu> wrote:
>
>> Looks like the c(x)[...] bit used to be as.matrix(x)[...]. Not sure
>> why the change was made many years ago, but this was before names were
>> handled explicitly. It would definitely be better to not force the
>> duplicate, at least in the case where we are sure c() and [ would not
>> dispatch.
>>
>> Best,
>>
>> luke
>>
>> On Mon, 4 May 2015, peter dalgaard wrote:
>>
>>
>>>  On 04 May 2015, at 19:59 , franknarf <by.hook.or at gmail.com> wrote:
>>>>
>>>> But I'm still wondering why diag() uses c()...? With it being so slow,
>>>> I'd
>>>> be inclined to write a qdiag() without the c() and just use that the
>>>> next
>>>> time I need matrix algebra. Any insight would be appreciated; thanks!
>>>>
>>>
>>> Well, there are two possibilities: Either it is deliberate or it isn't.
>>>
>>> The latter isn't too unlikely, given that the effect is seen for large
>>> matrices. I would appear to be a matter of O(n) (picking out n items) vs.
>>> O(n^2) (copying an n x n matrix), but this might drown out in a context
>>> involving matrix multiplication and/or inversion, both of which are O(n^3).
>>>
>>> If it is deliberate, the question is why. There could be devils in the
>>> details; notice in particular that c() strips off non-name attributes.
>>> However, I'm not aware of a situation where such attributes could cause
>>> trouble.
>>>
>>> -pd
>>>
>>>
>>>
>> --
>> Luke Tierney
>> Ralph E. Wareham Professor of Mathematical Sciences
>> University of Iowa                  Phone:             319-335-3386
>> Department of Statistics and        Fax:               319-335-3017
>>    Actuarial Science
>> 241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
>> Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>
>

	[[alternative HTML version deleted]]


From mtmorgan at fredhutch.org  Mon May 11 19:18:07 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Mon, 11 May 2015 10:18:07 -0700
Subject: [Rd] S4 method dispatch sometimes leads to incorrect when
 object loaded from file?
In-Reply-To: <554F76EB.3020804@fredhutch.org>
References: <554F76EB.3020804@fredhutch.org>
Message-ID: <5550E44F.1000807@fredhutch.org>

On 05/10/2015 08:19 AM, Martin Morgan wrote:
> Loading an S4 object from a file without first loading the library sometimes (?,
> the example below and actual example involves a virtual base class and the show
> generic) leads to incorrect dispatch (to the base class method).
>
> The attached package reproduces the problem. It has

The package was attached but stripped; a version is at

   https://github.com/mtmorgan/PkgA

FWIW the sent mail was a multi-part MIME with the header on the package part

Content-Type: application/gzip;
  name="PkgA.tar.gz"
Content-Transfer-Encoding: base64
Content-Disposition: attachment;
  filename="PkgA.tar.gz"

 From http://www.r-project.org/mail.html#instructions "we allow application/pdf, 
application/postscript, and image/png (and x-tar and gzip on R-devel)" so I 
thought that this mime type would not be stripped?

Martin Morgan

>
> setClass("A")
> setClass("B", contains="A")
> setMethod("show", "A", function(object) cat("A\n"))
> setMethod("show", "B", function(object) cat("B\n"))
>
> with NAMESPACE
>
> import(methods)
> exportClasses(A, B)
> exportMethods(show)
>
> This creates the object and illustrated expected behavior
>
>    ~/tmp$ R --vanilla --slave -e "library(PkgA); b = new('B'); save(b,
> file='b.Rda'); b"
>    B
>
> Loading PkgA before the object leads to correct dispatch
>
>    ~/tmp$ R --vanilla --slave -e "library(PkgA); load(file='b.Rda'); b"
>    B
>
> but loading the object without first loading PkgA leads to dispatch to
> show,A-method.
>
>    ~/tmp$ R --vanilla --slave -e "load(file='b.Rda'); b"
>    Loading required package: PkgA
>    A
>
> Martin Morgan


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From maechler at lynne.stat.math.ethz.ch  Tue May 12 14:31:11 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 12 May 2015 14:31:11 +0200
Subject: [Rd] S4 method dispatch sometimes leads to incorrect when
 object loaded from file?
In-Reply-To: <5550E44F.1000807@fredhutch.org>
References: <554F76EB.3020804@fredhutch.org> <5550E44F.1000807@fredhutch.org>
Message-ID: <21841.62095.431262.917177@stat.math.ethz.ch>

>>>>> Martin Morgan <mtmorgan at fredhutch.org>
>>>>>     on Mon, 11 May 2015 10:18:07 -0700 writes:

    > On 05/10/2015 08:19 AM, Martin Morgan wrote:
    >> Loading an S4 object from a file without first loading the library sometimes (?,
    >> the example below and actual example involves a virtual base class and the show
    >> generic) leads to incorrect dispatch (to the base class method).

"Of course", this is not as desired.

Other code automatically does try and typically succeed to load the package
(yes "package" ! ;-)) when 'needed', right,  so  show() is an
exception here, no ?


    >> The attached package reproduces the problem. It has

    > The package was attached but stripped; a version is at

    > https://github.com/mtmorgan/PkgA

    > FWIW the sent mail was a multi-part MIME with the header on the package part

    > Content-Type: application/gzip;
    > name="PkgA.tar.gz"
    > Content-Transfer-Encoding: base64
    > Content-Disposition: attachment;
    > filename="PkgA.tar.gz"

    > From http://www.r-project.org/mail.html#instructions "we allow application/pdf, 
    > application/postscript, and image/png (and x-tar and gzip on R-devel)" so I 
    > thought that this mime type would not be stripped?

You were alright in your assumptions -- but unfortunately, the
accepted type has been  application/x-gzip instead of .../gzip.
I now *have* added the 2nd one as well.

Sorry for that.
The other Martin M..

    > Martin Morgan

    >> 
    >> setClass("A")
    >> setClass("B", contains="A")
    >> setMethod("show", "A", function(object) cat("A\n"))
    >> setMethod("show", "B", function(object) cat("B\n"))
    >> 
    >> with NAMESPACE
    >> 
    >> import(methods)
    >> exportClasses(A, B)
    >> exportMethods(show)
    >> 
    >> This creates the object and illustrated expected behavior
    >> 
    >> ~/tmp$ R --vanilla --slave -e "library(PkgA); b = new('B'); save(b,
    >> file='b.Rda'); b"
    >> B
    >> 
    >> Loading PkgA before the object leads to correct dispatch
    >> 
    >> ~/tmp$ R --vanilla --slave -e "library(PkgA); load(file='b.Rda'); b"
    >> B
    >> 
    >> but loading the object without first loading PkgA leads to dispatch to
    >> show,A-method.
    >> 
    >> ~/tmp$ R --vanilla --slave -e "load(file='b.Rda'); b"
    >> Loading required package: PkgA
    >> A
    >> 
    >> Martin Morgan


    > -- 
    > Computational Biology / Fred Hutchinson Cancer Research Center
    > 1100 Fairview Ave. N.
    > PO Box 19024 Seattle, WA 98109

    > Location: Arnold Building M1 B861
    > Phone: (206) 667-2793

    > ______________________________________________
    > R-devel at r-project.org mailing list
    > https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at lynne.stat.math.ethz.ch  Tue May 12 14:33:48 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Tue, 12 May 2015 14:33:48 +0200
Subject: [Rd] Why is the diag function so slow (for extraction)?
In-Reply-To: <CAAVP=akUU10FPvkYhNBVQzi9jsMkCma-VVGgSqjGMpKF+G_4zA@mail.gmail.com>
References: <1430762350040-4706780.post@n4.nabble.com>
	<06F749E7-5096-438D-A299-667C7A77B477@gmail.com>
	<alpine.DEB.2.10.1505050844470.2460@luke-Latitude>
	<CAAVP=akUU10FPvkYhNBVQzi9jsMkCma-VVGgSqjGMpKF+G_4zA@mail.gmail.com>
Message-ID: <21841.62252.436947.835265@stat.math.ethz.ch>

>>>>> Steve Bronder <sbronder at stevebronder.com>
>>>>>     on Thu, 7 May 2015 11:49:49 -0400 writes:

    > Is it possible to replace c() with .subset()? 

It would be possible, but I think "entirely" wrong.

.subset() is documented to be an internal function not to be
used "lightly" and more to the point it is documented to *NOT*
dispatch at all.

If you read and understood what Peter and Luke wrote, you'd not
special case here:

diag() should not work only for pure matrices, but for all
"matrix-like" objects for which ``the usual methods'' work, such
as
   as.vector(.), c(.)

That's why there has been the c(.) in there.

You can always make code faster if you write the code so it only
has to work in one special case .. and work there very fast.


    > Example below
    > ####
    > ####

    > library(microbenchmark)


From mtmorgan at fredhutch.org  Tue May 12 17:11:58 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Tue, 12 May 2015 08:11:58 -0700
Subject: [Rd] S4 method dispatch sometimes leads to incorrect when
 object loaded from file?
In-Reply-To: <21841.62095.431262.917177@stat.math.ethz.ch>
References: <554F76EB.3020804@fredhutch.org>	<5550E44F.1000807@fredhutch.org>
	<21841.62095.431262.917177@stat.math.ethz.ch>
Message-ID: <5552183E.1070209@fredhutch.org>

On 05/12/2015 05:31 AM, Martin Maechler wrote:
>>>>>> Martin Morgan <mtmorgan at fredhutch.org>
>>>>>>      on Mon, 11 May 2015 10:18:07 -0700 writes:
>
>      > On 05/10/2015 08:19 AM, Martin Morgan wrote:
>      >> Loading an S4 object from a file without first loading the library sometimes (?,
>      >> the example below and actual example involves a virtual base class and the show
>      >> generic) leads to incorrect dispatch (to the base class method).
>
> "Of course", this is not as desired.
>
> Other code automatically does try and typically succeed to load the package
> (yes "package" ! ;-)) when 'needed', right,  so  show() is an
> exception here, no ?

I added dim() methods, which also misbehave (differently)

   setMethod("dim", "A", function(x) "A-dim")
   setMethod("dim", "B", function(x) "B-dim")

~/tmp$ R --vanilla --slave -e "load('b.Rda'); dim(b)"
Loading required package: PkgA
NULL
~/tmp$ R --vanilla --slave -e "require('PkgA'); load('b.Rda'); dim(b)"
[1] "B-dim"

but sort of auto-heal (versus show, which is corrupted)

~/tmp$ R --vanilla --slave -e "load('b.Rda'); dim(b); dim(b)"
Loading required package: PkgA
NULL
[1] "B-dim"
~/tmp$ R --vanilla --slave -e "load('b.Rda'); b; b"
Loading required package: PkgA
A
A

>
>
>      >> The attached package reproduces the problem. It has
>
>      > The package was attached but stripped; a version is at
>
>      > https://github.com/mtmorgan/PkgA
>
>      > FWIW the sent mail was a multi-part MIME with the header on the package part
>
>      > Content-Type: application/gzip;
>      > name="PkgA.tar.gz"
>      > Content-Transfer-Encoding: base64
>      > Content-Disposition: attachment;
>      > filename="PkgA.tar.gz"
>
>      > From http://www.r-project.org/mail.html#instructions "we allow application/pdf,
>      > application/postscript, and image/png (and x-tar and gzip on R-devel)" so I
>      > thought that this mime type would not be stripped?
>
> You were alright in your assumptions -- but unfortunately, the
> accepted type has been  application/x-gzip instead of .../gzip.
> I now *have* added the 2nd one as well.
>
> Sorry for that.
> The other Martin M..
>
>      > Martin Morgan
>
>      >>
>      >> setClass("A")
>      >> setClass("B", contains="A")
>      >> setMethod("show", "A", function(object) cat("A\n"))
>      >> setMethod("show", "B", function(object) cat("B\n"))
>      >>
>      >> with NAMESPACE
>      >>
>      >> import(methods)
>      >> exportClasses(A, B)
>      >> exportMethods(show)
>      >>
>      >> This creates the object and illustrated expected behavior
>      >>
>      >> ~/tmp$ R --vanilla --slave -e "library(PkgA); b = new('B'); save(b,
>      >> file='b.Rda'); b"
>      >> B
>      >>
>      >> Loading PkgA before the object leads to correct dispatch
>      >>
>      >> ~/tmp$ R --vanilla --slave -e "library(PkgA); load(file='b.Rda'); b"
>      >> B
>      >>
>      >> but loading the object without first loading PkgA leads to dispatch to
>      >> show,A-method.
>      >>
>      >> ~/tmp$ R --vanilla --slave -e "load(file='b.Rda'); b"
>      >> Loading required package: PkgA
>      >> A
>      >>
>      >> Martin Morgan
>
>
>      > --
>      > Computational Biology / Fred Hutchinson Cancer Research Center
>      > 1100 Fairview Ave. N.
>      > PO Box 19024 Seattle, WA 98109
>
>      > Location: Arnold Building M1 B861
>      > Phone: (206) 667-2793
>
>      > ______________________________________________
>      > R-devel at r-project.org mailing list
>      > https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From hpages at fredhutch.org  Wed May 13 00:18:42 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Tue, 12 May 2015 15:18:42 -0700
Subject: [Rd] Unexpected failure when calling new() with unnamed arg and
Message-ID: <55527C42.7090707@fredhutch.org>

Hi,

The man page for new() suggests that if 'a' is an object with slots
"slot1" and "slot2" and C is a class that extends the class of 'a',
then the 2 following calls should be equivalent:

   new("C", a, ...)
   new("C", slot1=a at slot1, slot2=a at slot2, ...)

This is generally the case but I just ran into a situation where it's
not. In the following example the former fails while the latter works:

   setClass("A", representation(slot1="numeric", slot2="logical"))
   setClass("B", contains="A", representation(design="formula"))
   setClass("C", contains="B")
   a <- new("A", slot1=77, slot2=TRUE)

   new("C", a, design=x ~ y)  # fails
   new("C", slot1=a at slot1, slot2=a at slot2, design=x ~ y)  # works

Note that new("B", a, design=x ~ y) works so the 3-level class
hierarchy is really needed in order to reproduce.

Probably related to this, I also noted that new("B") and/or new("C")
return invalid objects:

   c <- new("C")

   validObject(c)
   # Error in validObject(c) :
   #  invalid class ?C? object: invalid object for slot "design"
   #  in class "C": got class "S4", should be or extend class "formula"

   is(c at design, "formula")
   # [1] FALSE

   class(c at design)
   # [1] "S4"

Note that 'c' can be fixed:

   c at design <- formula(NULL)

   validObject(c)
   # [1] TRUE

Maybe something that the default "initialize" method should take care
of?

Another singularity that is maybe at the root of all of this is that
the "formula" S4 class is virtual:

   showClass("formula")
   # Virtual Class "formula" [package "methods"]
   #
   # Slots:
   #
   # Name:   .S3Class
   # Class: character
   #
   # Extends: "oldClass"

so a bare call to new("formula") fails:

   new("formula")
   # Error in new("formula") :
   #   trying to generate an object from a virtual class ("formula")

Shouldn't new("formula") just return an "empty" S3 formula (like
formula(NULL) does), in the same way that new("integer") returns
an empty ordinary integer vector?

Thanks,
H.

 > sessionInfo()
R version 3.2.0 Patched (2015-04-17 r68202)
Platform: x86_64-unknown-linux-gnu (64-bit)
Running under: Ubuntu 14.04.2 LTS

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=en_US.UTF-8
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods   base

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From henrik.bengtsson at ucsf.edu  Wed May 13 02:17:22 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Tue, 12 May 2015 17:17:22 -0700
Subject: [Rd] WISH: A more informative abor message than "aborting ..."
Message-ID: <CAFDcVCTcMbYY5dXtSi07kNp1UVB7OO_aPCoCUq5+-LS58vodKw@mail.gmail.com>

When R aborts ("core dumps"), it outputs:

  "aborting ..."

This message is rather generic and can be hard to track back to R
itself, i.e. it is not always clear whether it is R itself that
aborted or some other piece of code that caused the abort/core dump
and outputted that message.

May I suggest to expand the message to clarify that it is R that
aborts and that make it explicit that it is the very last message that
is generated by R, e.g.

  "An exception occurred that R could not recover from. The R session
is now aborting ..."

The code that needs to be updated is in
https://svn.r-project.org/R/trunk/src/main/main.c.  Here's a patch for
the above suggestion:

$ svn diff src/main/main.c
Index: src/main/main.c
===================================================================
--- src/main/main.c     (revision 68355)
+++ src/main/main.c     (working copy)
@@ -594,7 +594,7 @@
            }
        }
     }
-    REprintf("aborting ...\n");
+    REprintf("An exception occurred that R could not recover from.
The R session is now aborting ...\n");
     R_CleanTempDir();
     /* now do normal behaviour, e.g. core dump */
     signal(signum, SIG_DFL);

FYI, after signal(), raise(signum) is called and I think that's it from R.

Thanks,

Henrik


From henrik.bengtsson at ucsf.edu  Wed May 13 05:24:55 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Tue, 12 May 2015 20:24:55 -0700
Subject: [Rd] Why is the diag function so slow (for extraction)?
In-Reply-To: <21841.62252.436947.835265@stat.math.ethz.ch>
References: <1430762350040-4706780.post@n4.nabble.com>
	<06F749E7-5096-438D-A299-667C7A77B477@gmail.com>
	<alpine.DEB.2.10.1505050844470.2460@luke-Latitude>
	<CAAVP=akUU10FPvkYhNBVQzi9jsMkCma-VVGgSqjGMpKF+G_4zA@mail.gmail.com>
	<21841.62252.436947.835265@stat.math.ethz.ch>
Message-ID: <CAFDcVCQKCpJxkXq-gKcKg0UkAWS16mp8UJEQec83=42bQuFy2g@mail.gmail.com>

Along Luke's lines, would(n't) it be enough to look for existence of
attribute 'class' to decide whether to dispatch or not, i.e. if c() is
needed or not?  Even without .subset(), there is a remarkable
improvement.  I think it's worth condition the code on dispatch or
not.  For example:

[HB-X201]{hb}: svn diff diag.R
Index: diag.R
===================================================================
--- diag.R      (revision 68345)
+++ diag.R      (working copy)
@@ -23,9 +23,11 @@
             stop("'nrow' or 'ncol' cannot be specified when 'x' is a matrix")

         if((m <- min(dim(x))) == 0L) return(vector(typeof(x), 0L))
+        nms <- dimnames(x)
+        nrow <- dim(x)[1L]
         ## NB: need double index to avoid overflows.
-        y <- c(x)[1 + 0L:(m - 1L) * (dim(x)[1L] + 1)]
-        nms <- dimnames(x)
+        if (!is.null(attr(x, "class"))) x <- c(x)
+        y <- x[1 + 0L:(m - 1L) * (nrow + 1)]
         if (is.list(nms) && !any(sapply(nms, is.null)) &&
             identical((nm <- nms[[1L]][seq_len(m)]), nms[[2L]][seq_len(m)]))
             names(y) <- nm

?

/Henrik

On Tue, May 12, 2015 at 5:33 AM, Martin Maechler
<maechler at lynne.stat.math.ethz.ch> wrote:
>>>>>> Steve Bronder <sbronder at stevebronder.com>
>>>>>>     on Thu, 7 May 2015 11:49:49 -0400 writes:
>
>     > Is it possible to replace c() with .subset()?
>
> It would be possible, but I think "entirely" wrong.
>
> .subset() is documented to be an internal function not to be
> used "lightly" and more to the point it is documented to *NOT*
> dispatch at all.
>
> If you read and understood what Peter and Luke wrote, you'd not
> special case here:
>
> diag() should not work only for pure matrices, but for all
> "matrix-like" objects for which ``the usual methods'' work, such
> as
>    as.vector(.), c(.)
>
> That's why there has been the c(.) in there.
>
> You can always make code faster if you write the code so it only
> has to work in one special case .. and work there very fast.
>
>
>     > Example below
>     > ####
>     > ####
>
>     > library(microbenchmark)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at lynne.stat.math.ethz.ch  Wed May 13 12:57:46 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 13 May 2015 12:57:46 +0200
Subject: [Rd] Unexpected failure when calling new() with unnamed arg and
In-Reply-To: <55527C42.7090707@fredhutch.org>
References: <55527C42.7090707@fredhutch.org>
Message-ID: <21843.11818.477419.434062@stat.math.ethz.ch>

>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>     on Tue, 12 May 2015 15:18:42 -0700 writes:

> Hi,

> The man page for new() suggests that if 'a' is an object with slots
> "slot1" and "slot2" and C is a class that extends the class of 'a',
> then the 2 following calls should be equivalent:

>    new("C", a, ...)
>    new("C", slot1=a at slot1, slot2=a at slot2, ...)

> This is generally the case but I just ran into a situation where it's
> not. In the following example the former fails while the latter works:

>    setClass("A", representation(slot1="numeric", slot2="logical"))
>    setClass("B", contains="A", representation(design="formula"))
>    setClass("C", contains="B")
>    a <- new("A", slot1=77, slot2=TRUE)

>    new("C", a, design=x ~ y)  # fails
>    new("C", slot1=a at slot1, slot2=a at slot2, design=x ~ y)  # works

> Note that new("B", a, design=x ~ y) works so the 3-level class
> hierarchy is really needed in order to reproduce.

> Probably related to this, I also noted that new("B") and/or new("C")
> return invalid objects:

>    c <- new("C")

>    validObject(c)
>    # Error in validObject(c) :
>    #  invalid class ?C? object: invalid object for slot "design"
>    #  in class "C": got class "S4", should be or extend class "formula"

>    is(c at design, "formula")
>    # [1] FALSE

>    class(c at design)
>    # [1] "S4"

> Note that 'c' can be fixed:

>    c at design <- formula(NULL)

>    validObject(c)
>    # [1] TRUE

> Maybe something that the default "initialize" method should take care
> of?

> Another singularity that is maybe at the root of all of this is that
> the "formula" S4 class is virtual:

>    showClass("formula")
>    # Virtual Class "formula" [package "methods"]
>    #
>    # Slots:
>    #
>    # Name:   .S3Class
>    # Class: character
>    #
>    # Extends: "oldClass"

> so a bare call to new("formula") fails:

>    new("formula")
>    # Error in new("formula") :
>    #   trying to generate an object from a virtual class ("formula")

> Shouldn't new("formula") just return an "empty" S3 formula (like
> formula(NULL) does), in the same way that new("integer") returns
> an empty ordinary integer vector?

Interesting .. and at least worth following.

One problem and historical reason for the current setup seems
that the "formula" S3 class is not from 'base' but 'stats' :

R's source, src/library/methods/R/BasicClasses.R,
lines 524 ff has the following comment block

|  .OldClassesPrototypes is a list of S3 classes for which prototype
|  objects are known & reasonable.  The classes will reappear in
|  .OldClassesList, but will have been initialized first in
|  .InitBasicClasses.  NB:  the methods package will NOT set up
|  prototypes for S3 classes except those in package base and for "ts"
|  (and would rather not do those either).  The package that owns the
|  S3 class should have code to call setOldClass in its
|  initialization.

So, when John Chambers wrote this, he envisioned that the
'stats' package would do "the correct thing" for its own classes.
OTOH, as history went, the stats package was never allowed to
depend on methods.
There are many other S3 classes from 'stats' which also end up
similarly, being defined via  setOldClass() and that itself
produces a VIRTUAL class.
Also, another part of the (R source) comment above is no longer
quite accurate, e.g., "data.frame" is in .OldClassesPrototypes
but not in .OldClassesList ...

As I do agree that "formula" is much more basic than these other classes,
I'm currently looking at tweaks to the methods (and stats) code,
to get this to work.... as indeed - you mentioned above -  we
already allow "empty S3 formula" objects anyway.

... half an hour later : Indeed, I've been able to use the above information
such that  new("formula") and new("formula", y ~ x)  
work.

However, your code above now --- with my changes --- would  fail :

 > setClass("A", representation(slot1="numeric", slot2="logical"))
 > setClass("B", contains="A", representation(design="formula"))
 > setClass("C", contains="B")
 Error in reconcilePropertiesAndPrototype(name, slots, prototype, superClasses,  : 
   "B" is not eligible to be the data part of another class (must be a basic class or a virtual class with no slots)
 > 

So, I am not yet committing my changes to R-devel.
Hopefully more on this, later today.

Martin Maechler,
ETH Zurich


> Thanks,
> H.

>  > sessionInfo()
> R version 3.2.0 Patched (2015-04-17 r68202)
> Platform: x86_64-unknown-linux-gnu (64-bit)
> Running under: Ubuntu 14.04.2 LTS

> -- 
> Herv? Pag?s
> Fred Hutchinson Cancer Research Center

 [..................]


From rhelp at eoos.dds.nl  Wed May 13 17:27:50 2015
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Wed, 13 May 2015 17:27:50 +0200
Subject: [Rd] Alternative for wildcard gnu extension in Makevars
Message-ID: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>


I have some cpp-files from another library (boost) in a subdirectory  
in my src directory (src/boost_src). I include these using the  
following two lines in my Makevars:

SOURCES = $(wildcard *.cpp boost_src/*.cpp)
OBJECTS = $(SOURCES:.cpp=.o)

However, R CMD check complains about my use of 'wildcard'. How do I  
handle this without any gnu extensions?

Thanks.
Jan


From edd at debian.org  Wed May 13 17:53:05 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 13 May 2015 10:53:05 -0500
Subject: [Rd] Alternative for wildcard gnu extension in Makevars
In-Reply-To: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>
References: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>
Message-ID: <21843.29537.86236.300996@max.nulle.part>


On 13 May 2015 at 17:27, Jan van der Laan wrote:
| 
| I have some cpp-files from another library (boost) in a subdirectory  
| in my src directory (src/boost_src). I include these using the  
| following two lines in my Makevars:
| 
| SOURCES = $(wildcard *.cpp boost_src/*.cpp)
| OBJECTS = $(SOURCES:.cpp=.o)
| 
| However, R CMD check complains about my use of 'wildcard'. How do I  
| handle this without any gnu extensions?

I looked into this a few weeks (months?) ago, and it would appear that you
cannot.

I would recommend the alternative offered in Writing R Extensions: renamed it
GNUmakefile or add a SystemRequirements: GNU make.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From rhelp at eoos.dds.nl  Wed May 13 18:05:09 2015
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Wed, 13 May 2015 18:05:09 +0200
Subject: [Rd] Alternative for wildcard gnu extension in Makevars
In-Reply-To: <21843.29537.86236.300996@max.nulle.part>
References: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>
	<21843.29537.86236.300996@max.nulle.part>
Message-ID: <20150513180509.Horde.AU5NdWEwhY5VU3Y1ROC1FeA@webmailnew.dds.nl>


Dirk Eddelbuettel <edd at debian.org> schreef:

> On 13 May 2015 at 17:27, Jan van der Laan wrote:
> |
> | I have some cpp-files from another library (boost) in a subdirectory
> | in my src directory (src/boost_src). I include these using the
> | following two lines in my Makevars:
> |
> | SOURCES = $(wildcard *.cpp boost_src/*.cpp)
> | OBJECTS = $(SOURCES:.cpp=.o)
> |
> | However, R CMD check complains about my use of 'wildcard'. How do I
> | handle this without any gnu extensions?
>
> I looked into this a few weeks (months?) ago, and it would appear that you
> cannot.
>
> I would recommend the alternative offered in Writing R Extensions: renamed it
> GNUmakefile or add a SystemRequirements: GNU make.

Too bad. Since it is only a handful of files, I will probably move  
them directly into the src directory and prefix them. It would have  
been nice to have been able to keep them separate.

Thanks!
Jan


From csardi.gabor at gmail.com  Wed May 13 18:08:31 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 13 May 2015 12:08:31 -0400
Subject: [Rd] Alternative for wildcard gnu extension in Makevars
In-Reply-To: <20150513180509.Horde.AU5NdWEwhY5VU3Y1ROC1FeA@webmailnew.dds.nl>
References: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>
	<21843.29537.86236.300996@max.nulle.part>
	<20150513180509.Horde.AU5NdWEwhY5VU3Y1ROC1FeA@webmailnew.dds.nl>
Message-ID: <CABtg=KkyH5qj2wC_oeinru10+vVqfhD+rriDAj5TdeZnSkhekQ@mail.gmail.com>

On Wed, May 13, 2015 at 12:05 PM, Jan van der Laan <rhelp at eoos.dds.nl>
wrote:
[...]

> Too bad. Since it is only a handful of files, I will probably move them
> directly into the src directory and prefix them. It would have been nice to
> have been able to keep them separate.
>

If it is a couple of files, then you can also just list them in SOURCES (or
even just OBJECTS, with a .o suffix), and leave them where they are.

Gabor

[...]

	[[alternative HTML version deleted]]


From henrik.bengtsson at ucsf.edu  Wed May 13 18:20:43 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Wed, 13 May 2015 09:20:43 -0700
Subject: [Rd] Why is the diag function so slow (for extraction)?
In-Reply-To: <CAFDcVCQKCpJxkXq-gKcKg0UkAWS16mp8UJEQec83=42bQuFy2g@mail.gmail.com>
References: <1430762350040-4706780.post@n4.nabble.com>
	<06F749E7-5096-438D-A299-667C7A77B477@gmail.com>
	<alpine.DEB.2.10.1505050844470.2460@luke-Latitude>
	<CAAVP=akUU10FPvkYhNBVQzi9jsMkCma-VVGgSqjGMpKF+G_4zA@mail.gmail.com>
	<21841.62252.436947.835265@stat.math.ethz.ch>
	<CAFDcVCQKCpJxkXq-gKcKg0UkAWS16mp8UJEQec83=42bQuFy2g@mail.gmail.com>
Message-ID: <CAFDcVCTs+EXzjfNJAygaq2-oe19-EvVjwZgLHfxLGDA9i_fstQ@mail.gmail.com>

As kindly pointed out to me (oh my decaying gray matter), is.object()
is better suited for this test;

$ svn diff src/library/base/R/diag.R
Index: src/library/base/R/diag.R
===================================================================
--- src/library/base/R/diag.R   (revision 68345)
+++ src/library/base/R/diag.R   (working copy)
@@ -23,9 +23,11 @@
             stop("'nrow' or 'ncol' cannot be specified when 'x' is a matrix")

         if((m <- min(dim(x))) == 0L) return(vector(typeof(x), 0L))
+        nms <- dimnames(x)
+        nrow <- dim(x)[1L]
         ## NB: need double index to avoid overflows.
-        y <- c(x)[1 + 0L:(m - 1L) * (dim(x)[1L] + 1)]
-        nms <- dimnames(x)
+        if (is.object(x)) x <- c(x)

/Henrik

On Tue, May 12, 2015 at 8:24 PM, Henrik Bengtsson
<henrik.bengtsson at ucsf.edu> wrote:
> Along Luke's lines, would(n't) it be enough to look for existence of
> attribute 'class' to decide whether to dispatch or not, i.e. if c() is
> needed or not?  Even without .subset(), there is a remarkable
> improvement.  I think it's worth condition the code on dispatch or
> not.  For example:
>
> [HB-X201]{hb}: svn diff diag.R
> Index: diag.R
> ===================================================================
> --- diag.R      (revision 68345)
> +++ diag.R      (working copy)
> @@ -23,9 +23,11 @@
>              stop("'nrow' or 'ncol' cannot be specified when 'x' is a matrix")
>
>          if((m <- min(dim(x))) == 0L) return(vector(typeof(x), 0L))
> +        nms <- dimnames(x)
> +        nrow <- dim(x)[1L]
>          ## NB: need double index to avoid overflows.
> -        y <- c(x)[1 + 0L:(m - 1L) * (dim(x)[1L] + 1)]
> -        nms <- dimnames(x)
> +        if (!is.null(attr(x, "class"))) x <- c(x)
> +        y <- x[1 + 0L:(m - 1L) * (nrow + 1)]
>          if (is.list(nms) && !any(sapply(nms, is.null)) &&
>              identical((nm <- nms[[1L]][seq_len(m)]), nms[[2L]][seq_len(m)]))
>              names(y) <- nm
>
> ?
>
> /Henrik
>
> On Tue, May 12, 2015 at 5:33 AM, Martin Maechler
> <maechler at lynne.stat.math.ethz.ch> wrote:
>>>>>>> Steve Bronder <sbronder at stevebronder.com>
>>>>>>>     on Thu, 7 May 2015 11:49:49 -0400 writes:
>>
>>     > Is it possible to replace c() with .subset()?
>>
>> It would be possible, but I think "entirely" wrong.
>>
>> .subset() is documented to be an internal function not to be
>> used "lightly" and more to the point it is documented to *NOT*
>> dispatch at all.
>>
>> If you read and understood what Peter and Luke wrote, you'd not
>> special case here:
>>
>> diag() should not work only for pure matrices, but for all
>> "matrix-like" objects for which ``the usual methods'' work, such
>> as
>>    as.vector(.), c(.)
>>
>> That's why there has been the c(.) in there.
>>
>> You can always make code faster if you write the code so it only
>> has to work in one special case .. and work there very fast.
>>
>>
>>     > Example below
>>     > ####
>>     > ####
>>
>>     > library(microbenchmark)
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From kevinushey at gmail.com  Wed May 13 19:10:49 2015
From: kevinushey at gmail.com (Kevin Ushey)
Date: Wed, 13 May 2015 10:10:49 -0700
Subject: [Rd] Alternative for wildcard gnu extension in Makevars
In-Reply-To: <CABtg=KkyH5qj2wC_oeinru10+vVqfhD+rriDAj5TdeZnSkhekQ@mail.gmail.com>
References: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>
	<21843.29537.86236.300996@max.nulle.part>
	<20150513180509.Horde.AU5NdWEwhY5VU3Y1ROC1FeA@webmailnew.dds.nl>
	<CABtg=KkyH5qj2wC_oeinru10+vVqfhD+rriDAj5TdeZnSkhekQ@mail.gmail.com>
Message-ID: <CAJXgQP1NnY1WXgnGj87qcxPkamMYasLOUnFZ9VkRC2uK5Ec9nQ@mail.gmail.com>

One other solution that's only a little crazy: you could have a R
function within your package that generates the appropriate (portable)
Makevars, and within the package `configure` script call that
function. For example"

    R --vanilla --slave -e "source('R/makevars.R'); makevars()"

And that 'makevars()' function could generate portable
'Makevars(.win)' files for your package.

Kevin

On Wed, May 13, 2015 at 9:08 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> On Wed, May 13, 2015 at 12:05 PM, Jan van der Laan <rhelp at eoos.dds.nl>
> wrote:
> [...]
>
>> Too bad. Since it is only a handful of files, I will probably move them
>> directly into the src directory and prefix them. It would have been nice to
>> have been able to keep them separate.
>>
>
> If it is a couple of files, then you can also just list them in SOURCES (or
> even just OBJECTS, with a .o suffix), and leave them where they are.
>
> Gabor
>
> [...]
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From radford at cs.toronto.edu  Wed May 13 19:31:17 2015
From: radford at cs.toronto.edu (Radford Neal)
Date: Wed, 13 May 2015 13:31:17 -0400
Subject: [Rd] Why is the diag function so slow (for extraction)?
In-Reply-To: <mailman.21.1431511203.5843.r-devel@r-project.org>
References: <mailman.21.1431511203.5843.r-devel@r-project.org>
Message-ID: <20150513173117.GA31260@cs.toronto.edu>

> From: Martin Maechler <maechler at lynne.stat.math.ethz.ch>

> diag() should not work only for pure matrices, but for all
> "matrix-like" objects for which ``the usual methods'' work, such
> as
>    as.vector(.), c(.)
> 
> That's why there has been the c(.) in there.
> 
> You can always make code faster if you write the code so it only
> has to work in one special case .. and work there very fast.

help(diag) gives no hint whatever that diag(x) will work for
objects that are "matrix-like", but aren't actual matrices.

help(c) explicitly says that methods for it are NOT required to
convert matrices to vectors.

So you're advocating slowing down all ordinary uses of diag to
accommodate a usage that nobody thought was important enough to
actually document.

   Radford Neal


From edd at debian.org  Wed May 13 19:45:51 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Wed, 13 May 2015 12:45:51 -0500
Subject: [Rd] Alternative for wildcard gnu extension in Makevars
In-Reply-To: <CAJXgQP1NnY1WXgnGj87qcxPkamMYasLOUnFZ9VkRC2uK5Ec9nQ@mail.gmail.com>
References: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>
	<21843.29537.86236.300996@max.nulle.part>
	<20150513180509.Horde.AU5NdWEwhY5VU3Y1ROC1FeA@webmailnew.dds.nl>
	<CABtg=KkyH5qj2wC_oeinru10+vVqfhD+rriDAj5TdeZnSkhekQ@mail.gmail.com>
	<CAJXgQP1NnY1WXgnGj87qcxPkamMYasLOUnFZ9VkRC2uK5Ec9nQ@mail.gmail.com>
Message-ID: <21843.36303.612911.855609@max.nulle.part>


On 13 May 2015 at 10:10, Kevin Ushey wrote:
| One other solution that's only a little crazy: you could have a R
| function within your package that generates the appropriate (portable)
| Makevars, and within the package `configure` script call that
| function. For example"
| 
|     R --vanilla --slave -e "source('R/makevars.R'); makevars()"
| 
| And that 'makevars()' function could generate portable
| 'Makevars(.win)' files for your package.

Seconded.  I do exactly that in another recent package where I needed another
"verboten" idiom available only in the widespread and feature-rich GNU make
but not the so-much-more constrained basic make: if statements.

See https://github.com/eddelbuettel/Rblpapi/blob/master/configure where I
need to encode 32 or 64 in the name of shared library.  By relying on Rscript
I code around the constraint of not having GNU make.   [ That is still a
non-CRAN package but for an unrelated, different reason. ]

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From rhelp at eoos.dds.nl  Wed May 13 20:28:51 2015
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Wed, 13 May 2015 20:28:51 +0200
Subject: [Rd] Alternative for wildcard gnu extension in Makevars
In-Reply-To: <CABtg=KkyH5qj2wC_oeinru10+vVqfhD+rriDAj5TdeZnSkhekQ@mail.gmail.com>
References: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>	<21843.29537.86236.300996@max.nulle.part>	<20150513180509.Horde.AU5NdWEwhY5VU3Y1ROC1FeA@webmailnew.dds.nl>
	<CABtg=KkyH5qj2wC_oeinru10+vVqfhD+rriDAj5TdeZnSkhekQ@mail.gmail.com>
Message-ID: <555397E3.4090901@eoos.dds.nl>



On 13-05-15 18:08, G?bor Cs?rdi wrote:
> On Wed, May 13, 2015 at 12:05 PM, Jan van der Laan <rhelp at eoos.dds.nl
> <mailto:rhelp at eoos.dds.nl>> wrote:
> [...]
>
>     Too bad. Since it is only a handful of files, I will probably move
>     them directly into the src directory and prefix them. It would have
>     been nice to have been able to keep them separate.
>
>
> If it is a couple of files, then you can also just list them in SOURCES
> (or even just OBJECTS, with a .o suffix), and leave them where they are.
>


That would be a nice solution, but it is a couple (~10) files in the 
src/boost_src directory. Directly under the src directory there are much 
more files, and the names and number of these will frequently change so 
I don't want to keep maintaining this list. Although I could add the 
generation of Makevars to my build script.

Thanks for the suggestion.

Jan


From henrik.bengtsson at ucsf.edu  Wed May 13 20:28:13 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Wed, 13 May 2015 11:28:13 -0700
Subject: [Rd] Alternative for wildcard gnu extension in Makevars
In-Reply-To: <CAJXgQP1NnY1WXgnGj87qcxPkamMYasLOUnFZ9VkRC2uK5Ec9nQ@mail.gmail.com>
References: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>
	<21843.29537.86236.300996@max.nulle.part>
	<20150513180509.Horde.AU5NdWEwhY5VU3Y1ROC1FeA@webmailnew.dds.nl>
	<CABtg=KkyH5qj2wC_oeinru10+vVqfhD+rriDAj5TdeZnSkhekQ@mail.gmail.com>
	<CAJXgQP1NnY1WXgnGj87qcxPkamMYasLOUnFZ9VkRC2uK5Ec9nQ@mail.gmail.com>
Message-ID: <CAFDcVCSmrMqQBKpSiXFimEp_RHg4DavQ5fNtxv306_+3Kmy4Jw@mail.gmail.com>

While at it:  'Makevars' is an R invention (i.e. documentation of it
is only available through the R docs), correct?  /Henrik

On Wed, May 13, 2015 at 10:10 AM, Kevin Ushey <kevinushey at gmail.com> wrote:
> One other solution that's only a little crazy: you could have a R
> function within your package that generates the appropriate (portable)
> Makevars, and within the package `configure` script call that
> function. For example"
>
>     R --vanilla --slave -e "source('R/makevars.R'); makevars()"
>
> And that 'makevars()' function could generate portable
> 'Makevars(.win)' files for your package.
>
> Kevin
>
> On Wed, May 13, 2015 at 9:08 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>> On Wed, May 13, 2015 at 12:05 PM, Jan van der Laan <rhelp at eoos.dds.nl>
>> wrote:
>> [...]
>>
>>> Too bad. Since it is only a handful of files, I will probably move them
>>> directly into the src directory and prefix them. It would have been nice to
>>> have been able to keep them separate.
>>>
>>
>> If it is a couple of files, then you can also just list them in SOURCES (or
>> even just OBJECTS, with a .o suffix), and leave them where they are.
>>
>> Gabor
>>
>> [...]
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cdetermanjr at gmail.com  Wed May 13 20:31:36 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Wed, 13 May 2015 13:31:36 -0500
Subject: [Rd] example fails during R CMD CHECK but works interactively?
Message-ID: <CAKxd1KNtOjyq5DYEVmvw=NQUrnL5LVZYuSt=1cyfE=QQQquCLw@mail.gmail.com>

Greetings,

I am collaborating with developing the bigmemory package and have run in to
a strange problem when we run R CMD CHECK.  For some reason that isn't
clear to us one of the examples crashes stating:

Error:  memory could not be allocated for instance of type big.matrix

You can see the output on the Travis CI page at
https://travis-ci.org/kaneplusplus/bigmemory where the error starts at line
1035.  This is completely reproducible when running
devtools::check(args='--as-cran') locally.  The part that is confusing is
that the calls work perfectly when called interactively.

Hadley comments on the 'check' page of his R packages website (
http://r-pkgs.had.co.nz/check.html) regarding test failing following R CMD
check:

Occasionally you may have a problem where the tests pass when run
interactively with devtools::test(), but fail when in R CMD check. This
usually indicates that you?ve made a faulty assumption about the testing
environment, and it?s often hard to figure it out.

Any thoughts on how to troubleshoot this problem?  I have no idea what
assumption we could have made.

Regards,
Charles

	[[alternative HTML version deleted]]


From dtenenba at fredhutch.org  Wed May 13 20:51:19 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Wed, 13 May 2015 11:51:19 -0700 (PDT)
Subject: [Rd] example fails during R CMD CHECK but works interactively?
In-Reply-To: <CAKxd1KNtOjyq5DYEVmvw=NQUrnL5LVZYuSt=1cyfE=QQQquCLw@mail.gmail.com>
Message-ID: <1612739531.2387533.1431543079541.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "Charles Determan" <cdetermanjr at gmail.com>
> To: r-devel at r-project.org
> Sent: Wednesday, May 13, 2015 11:31:36 AM
> Subject: [Rd] example fails during R CMD CHECK but works interactively?
> 
> Greetings,
> 
> I am collaborating with developing the bigmemory package and have run
> in to
> a strange problem when we run R CMD CHECK.  For some reason that
> isn't
> clear to us one of the examples crashes stating:
> 
> Error:  memory could not be allocated for instance of type big.matrix
> 
> You can see the output on the Travis CI page at
> https://travis-ci.org/kaneplusplus/bigmemory where the error starts
> at line
> 1035.  This is completely reproducible when running
> devtools::check(args='--as-cran') locally.  The part that is
> confusing is
> that the calls work perfectly when called interactively.
> 
> Hadley comments on the 'check' page of his R packages website (
> http://r-pkgs.had.co.nz/check.html) regarding test failing following
> R CMD
> check:
> 
> Occasionally you may have a problem where the tests pass when run
> interactively with devtools::test(), but fail when in R CMD check.
> This
> usually indicates that you?ve made a faulty assumption about the
> testing
> environment, and it?s often hard to figure it out.
> 
> Any thoughts on how to troubleshoot this problem?  I have no idea
> what
> assumption we could have made.

Note that R CMD check runs R with environment variables set as follows (at least on my system; you can check $R_HOME/bin/check to see what it does on yours):

 R_DEFAULT_PACKAGES= LC_COLLATE=C 

So try staring R like this:

 R_DEFAULT_PACKAGES= LC_COLLATE=C  R

And see if that reproduces the test failure. The locale setting could affect tests of sort order, and the default package setting could potentially affect other things.

Dan



> 
> Regards,
> Charles
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From cdetermanjr at gmail.com  Wed May 13 20:57:51 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Wed, 13 May 2015 13:57:51 -0500
Subject: [Rd] example fails during R CMD CHECK but works interactively?
In-Reply-To: <1612739531.2387533.1431543079541.JavaMail.root@fredhutch.org>
References: <CAKxd1KNtOjyq5DYEVmvw=NQUrnL5LVZYuSt=1cyfE=QQQquCLw@mail.gmail.com>
	<1612739531.2387533.1431543079541.JavaMail.root@fredhutch.org>
Message-ID: <CAKxd1KMgT700+uKmD8v-QJoG5NmpeA+t3rSR-gg1L19=NbpzPw@mail.gmail.com>

Thank you Dan but it isn't my tests that are failing (all of them pass
without problem) but one of the examples from the inst/examples directory.
I did try, however, to start R with the environmental variables as you
suggest but it had no effect on my tests.

Charles

On Wed, May 13, 2015 at 1:51 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
wrote:

>
>
> ----- Original Message -----
> > From: "Charles Determan" <cdetermanjr at gmail.com>
> > To: r-devel at r-project.org
> > Sent: Wednesday, May 13, 2015 11:31:36 AM
> > Subject: [Rd] example fails during R CMD CHECK but works interactively?
> >
> > Greetings,
> >
> > I am collaborating with developing the bigmemory package and have run
> > in to
> > a strange problem when we run R CMD CHECK.  For some reason that
> > isn't
> > clear to us one of the examples crashes stating:
> >
> > Error:  memory could not be allocated for instance of type big.matrix
> >
> > You can see the output on the Travis CI page at
> > https://travis-ci.org/kaneplusplus/bigmemory where the error starts
> > at line
> > 1035.  This is completely reproducible when running
> > devtools::check(args='--as-cran') locally.  The part that is
> > confusing is
> > that the calls work perfectly when called interactively.
> >
> > Hadley comments on the 'check' page of his R packages website (
> > http://r-pkgs.had.co.nz/check.html) regarding test failing following
> > R CMD
> > check:
> >
> > Occasionally you may have a problem where the tests pass when run
> > interactively with devtools::test(), but fail when in R CMD check.
> > This
> > usually indicates that you?ve made a faulty assumption about the
> > testing
> > environment, and it?s often hard to figure it out.
> >
> > Any thoughts on how to troubleshoot this problem?  I have no idea
> > what
> > assumption we could have made.
>
> Note that R CMD check runs R with environment variables set as follows (at
> least on my system; you can check $R_HOME/bin/check to see what it does on
> yours):
>
>  R_DEFAULT_PACKAGES= LC_COLLATE=C
>
> So try staring R like this:
>
>  R_DEFAULT_PACKAGES= LC_COLLATE=C  R
>
> And see if that reproduces the test failure. The locale setting could
> affect tests of sort order, and the default package setting could
> potentially affect other things.
>
> Dan
>
>
>
> >
> > Regards,
> > Charles
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed May 13 21:48:06 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 13 May 2015 21:48:06 +0200
Subject: [Rd] CRAN check for package on Sparc Solaris
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0C217F64@UM-MAIL4112.unimaas.nl>

Dear All,

The metafor package currently fails CRAN checks on Sparc Solaris:

http://cran.r-project.org/web/checks/check_results_metafor.html

The problem is probably due to an unintended (= stupid) use of identical() in a couple tests. I have changed that to more appropriate tests using all.equal(). However, before I resubmit the package to CRAN, I would really like to make sure that the updated package passes all checks also on Sparc Solaris.

The issue/question of how to test packages on Sparc Solaris has come up before:

https://stat.ethz.ch/pipermail/r-devel/2010-September/058538.html
https://stat.ethz.ch/pipermail/r-devel/2011-November/062430.html

Unless anything has changed in the meantime, it seems like the help of kind volunteers is still the only option to conduct such tests. So, is there anybody out there with access to a Sparc machine running Solaris willing to run 'R CMD check --as-cran' on the updated tarball? Would be very much appreciated!

Best,
Wolfgang

From csardi.gabor at gmail.com  Wed May 13 21:53:55 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Wed, 13 May 2015 15:53:55 -0400
Subject: [Rd] CRAN check for package on Sparc Solaris
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F0C217F64@UM-MAIL4112.unimaas.nl>
References: <077E31A57DA26E46AB0D493C9966AC730F0C217F64@UM-MAIL4112.unimaas.nl>
Message-ID: <CABtg=KmNuZ2aC8+7fv8ETtb-+dVfTZ99QTjn3OaL0iFtU9_-mA@mail.gmail.com>

Hi Wolfgang, I can test your package, please send it to me in private.

Btw. I only have an x86 machine, and no sparc, so if your problem is
sparc-specific, then my test is probably useless.

Gabor

On Wed, May 13, 2015 at 3:48 PM, Viechtbauer Wolfgang (STAT) <
wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

> Dear All,
>
> The metafor package currently fails CRAN checks on Sparc Solaris:
>
> http://cran.r-project.org/web/checks/check_results_metafor.html
>
> The problem is probably due to an unintended (= stupid) use of identical()
> in a couple tests. I have changed that to more appropriate tests using
> all.equal(). However, before I resubmit the package to CRAN, I would really
> like to make sure that the updated package passes all checks also on Sparc
> Solaris.
>
> The issue/question of how to test packages on Sparc Solaris has come up
> before:
>
> https://stat.ethz.ch/pipermail/r-devel/2010-September/058538.html
> https://stat.ethz.ch/pipermail/r-devel/2011-November/062430.html
>
> Unless anything has changed in the meantime, it seems like the help of
> kind volunteers is still the only option to conduct such tests. So, is
> there anybody out there with access to a Sparc machine running Solaris
> willing to run 'R CMD check --as-cran' on the updated tarball? Would be
> very much appreciated!
>
> Best,
> Wolfgang
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From wolfgang.viechtbauer at maastrichtuniversity.nl  Wed May 13 22:11:22 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Wed, 13 May 2015 22:11:22 +0200
Subject: [Rd] CRAN check for package on Sparc Solaris
In-Reply-To: <CABtg=KmNuZ2aC8+7fv8ETtb-+dVfTZ99QTjn3OaL0iFtU9_-mA@mail.gmail.com>
References: <077E31A57DA26E46AB0D493C9966AC730F0C217F64@UM-MAIL4112.unimaas.nl>,
	<CABtg=KmNuZ2aC8+7fv8ETtb-+dVfTZ99QTjn3OaL0iFtU9_-mA@mail.gmail.com>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0C217F65@UM-MAIL4112.unimaas.nl>

Thank you for the kind offer! Unfortunately, the problem is really Sparc Solaris:

http://cran.r-project.org/web/checks/check_results_metafor.html

On Solaris x86 and all other flavors, it passes without errors.

Best,
Wolfgang

From: G?bor Cs?rdi [csardi.gabor at gmail.com]
Sent: Wednesday, May 13, 2015 9:53 PM
To: Viechtbauer Wolfgang (STAT)
Cc: r-devel at r-project.org
Subject: Re: [Rd] CRAN check for package on Sparc Solaris

Hi Wolfgang, I can test your package, please send it to me in private.  

Btw. I only have an x86 machine, and no sparc, so if your problem is sparc-specific, then my test is probably useless. 


Gabor


On Wed, May 13, 2015 at 3:48 PM, Viechtbauer Wolfgang (STAT) <wolfgang.viechtbauer at maastrichtuniversity.nl> wrote:

Dear All,

The metafor package currently fails CRAN checks on Sparc Solaris:

http://cran.r-project.org/web/checks/check_results_metafor.html

The problem is probably due to an unintended (= stupid) use of identical() in a couple tests. I have changed that to more appropriate tests using all.equal(). However, before I resubmit the package to CRAN, I would really like to make sure that the updated package passes all checks also on Sparc Solaris.

The issue/question of how to test packages on Sparc Solaris has come up before:

https://stat.ethz.ch/pipermail/r-devel/2010-September/058538.html
https://stat.ethz.ch/pipermail/r-devel/2011-November/062430.html

Unless anything has changed in the meantime, it seems like the help of kind volunteers is still the only option to conduct such tests. So, is there anybody out there with access to a Sparc machine running Solaris willing to run 'R CMD check --as-cran' on the updated tarball? Would be very much appreciated!

Best,
Wolfgang
______________________________________________
R-devel at r-project.org mailing list
https://stat.ethz.ch/mailman/listinfo/r-devel

From james.f.hester at gmail.com  Wed May 13 23:38:14 2015
From: james.f.hester at gmail.com (Jim Hester)
Date: Wed, 13 May 2015 17:38:14 -0400
Subject: [Rd] LDFLAGS defined in R_MAKEVARS_USER file is ignored for R
 CMD SHLIB on Windows
In-Reply-To: <CAD6tx97zP3ZLQTf+vt9de7Z9rWzm2UneYLn5UtuE4ZiNPPau1A@mail.gmail.com>
References: <CAD6tx97zP3ZLQTf+vt9de7Z9rWzm2UneYLn5UtuE4ZiNPPau1A@mail.gmail.com>
Message-ID: <CAD6tx96EcYZLRUiEY59XQCDgFxEcbArhkjsHg9JMdGutaZywYQ@mail.gmail.com>

I have tracked this discrepancy down to the use of `SHLIB_LD` rather than
`SHLIB_LINK` in share/make/winshlib.mk
<https://github.com/wch/r-source/blob/7348d71d1cb18e9c4b55950fd57198e8d2abcc8b/share/make/winshlib.mk>.
This variable has been used in winshlib.mk since svn r47953
<https://github.com/wch/r-source/commit/3ebd185c0745bdc7cb8dd185bd7df5ff7f827f18>,
however the corresponding shlib.mk for linux has always used `SHLIB_LINK`
instead.

The attached patch updates the variables in winshlib.mk to use `SHLIB_LINK`
and makes the behavior consistent across platforms, which fixes my issue.

On Mon, May 11, 2015 at 12:28 PM, Jim Hester <james.f.hester at gmail.com>
wrote:

> Example input and output to reproduce this can be found at
> https://gist.github.com/jimhester/b7f05f50794c88e44b17.
>
> I tested this attempting to compile the [digest](
> http://cran.r-project.org/web/packages/digest/index.html) package,
> `run.sh` and `run.bat` were both run in the package source directory on
> Ubuntu 14.01 and Windows 7 respectively.
>
> In particular while the `CFLAGS` values were properly passed to the
> compiler on both Linux and Windows, the `LDFLAGS` value was only passed to
> the linker on Linux, which caused the subsequent linking errors on Windows.
>
> Perhaps this is intended behavior, if so is there a different compiler
> variable I can use to pass flags to the linker on Windows?
>
-------------- next part --------------
A non-text attachment was scrubbed...
Name: SHLIB_LINK.patch
Type: text/x-patch
Size: 1134 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150513/bec77f6e/attachment.bin>

From hpages at fredhutch.org  Thu May 14 00:13:27 2015
From: hpages at fredhutch.org (=?UTF-8?B?SGVydsOpIFBhZ8Oocw==?=)
Date: Wed, 13 May 2015 15:13:27 -0700
Subject: [Rd] Unexpected failure when calling new() with unnamed arg and
In-Reply-To: <21843.11818.477419.434062@stat.math.ethz.ch>
References: <55527C42.7090707@fredhutch.org>
	<21843.11818.477419.434062@stat.math.ethz.ch>
Message-ID: <5553CC87.7080402@fredhutch.org>

Thanks Martin for looking into this.  H.

On 05/13/2015 03:57 AM, Martin Maechler wrote:
>>>>>> Herv? Pag?s <hpages at fredhutch.org>
>>>>>>      on Tue, 12 May 2015 15:18:42 -0700 writes:
>
>> Hi,
>
>> The man page for new() suggests that if 'a' is an object with slots
>> "slot1" and "slot2" and C is a class that extends the class of 'a',
>> then the 2 following calls should be equivalent:
>
>>     new("C", a, ...)
>>     new("C", slot1=a at slot1, slot2=a at slot2, ...)
>
>> This is generally the case but I just ran into a situation where it's
>> not. In the following example the former fails while the latter works:
>
>>     setClass("A", representation(slot1="numeric", slot2="logical"))
>>     setClass("B", contains="A", representation(design="formula"))
>>     setClass("C", contains="B")
>>     a <- new("A", slot1=77, slot2=TRUE)
>
>>     new("C", a, design=x ~ y)  # fails
>>     new("C", slot1=a at slot1, slot2=a at slot2, design=x ~ y)  # works
>
>> Note that new("B", a, design=x ~ y) works so the 3-level class
>> hierarchy is really needed in order to reproduce.
>
>> Probably related to this, I also noted that new("B") and/or new("C")
>> return invalid objects:
>
>>     c <- new("C")
>
>>     validObject(c)
>>     # Error in validObject(c) :
>>     #  invalid class ?C? object: invalid object for slot "design"
>>     #  in class "C": got class "S4", should be or extend class "formula"
>
>>     is(c at design, "formula")
>>     # [1] FALSE
>
>>     class(c at design)
>>     # [1] "S4"
>
>> Note that 'c' can be fixed:
>
>>     c at design <- formula(NULL)
>
>>     validObject(c)
>>     # [1] TRUE
>
>> Maybe something that the default "initialize" method should take care
>> of?
>
>> Another singularity that is maybe at the root of all of this is that
>> the "formula" S4 class is virtual:
>
>>     showClass("formula")
>>     # Virtual Class "formula" [package "methods"]
>>     #
>>     # Slots:
>>     #
>>     # Name:   .S3Class
>>     # Class: character
>>     #
>>     # Extends: "oldClass"
>
>> so a bare call to new("formula") fails:
>
>>     new("formula")
>>     # Error in new("formula") :
>>     #   trying to generate an object from a virtual class ("formula")
>
>> Shouldn't new("formula") just return an "empty" S3 formula (like
>> formula(NULL) does), in the same way that new("integer") returns
>> an empty ordinary integer vector?
>
> Interesting .. and at least worth following.
>
> One problem and historical reason for the current setup seems
> that the "formula" S3 class is not from 'base' but 'stats' :
>
> R's source, src/library/methods/R/BasicClasses.R,
> lines 524 ff has the following comment block
>
> |  .OldClassesPrototypes is a list of S3 classes for which prototype
> |  objects are known & reasonable.  The classes will reappear in
> |  .OldClassesList, but will have been initialized first in
> |  .InitBasicClasses.  NB:  the methods package will NOT set up
> |  prototypes for S3 classes except those in package base and for "ts"
> |  (and would rather not do those either).  The package that owns the
> |  S3 class should have code to call setOldClass in its
> |  initialization.
>
> So, when John Chambers wrote this, he envisioned that the
> 'stats' package would do "the correct thing" for its own classes.
> OTOH, as history went, the stats package was never allowed to
> depend on methods.
> There are many other S3 classes from 'stats' which also end up
> similarly, being defined via  setOldClass() and that itself
> produces a VIRTUAL class.
> Also, another part of the (R source) comment above is no longer
> quite accurate, e.g., "data.frame" is in .OldClassesPrototypes
> but not in .OldClassesList ...
>
> As I do agree that "formula" is much more basic than these other classes,
> I'm currently looking at tweaks to the methods (and stats) code,
> to get this to work.... as indeed - you mentioned above -  we
> already allow "empty S3 formula" objects anyway.
>
> ... half an hour later : Indeed, I've been able to use the above information
> such that  new("formula") and new("formula", y ~ x)
> work.
>
> However, your code above now --- with my changes --- would  fail :
>
>   > setClass("A", representation(slot1="numeric", slot2="logical"))
>   > setClass("B", contains="A", representation(design="formula"))
>   > setClass("C", contains="B")
>   Error in reconcilePropertiesAndPrototype(name, slots, prototype, superClasses,  :
>     "B" is not eligible to be the data part of another class (must be a basic class or a virtual class with no slots)
>   >
>
> So, I am not yet committing my changes to R-devel.
> Hopefully more on this, later today.
>
> Martin Maechler,
> ETH Zurich
>
>
>> Thanks,
>> H.
>
>>   > sessionInfo()
>> R version 3.2.0 Patched (2015-04-17 r68202)
>> Platform: x86_64-unknown-linux-gnu (64-bit)
>> Running under: Ubuntu 14.04.2 LTS
>
>> --
>> Herv? Pag?s
>> Fred Hutchinson Cancer Research Center
>
>   [..................]
>
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From jeroen.ooms at stat.ucla.edu  Thu May 14 02:24:42 2015
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Wed, 13 May 2015 17:24:42 -0700
Subject: [Rd] Reading exit code of pipe()
Message-ID: <CABFfbXv7OzDSt3n9HwkG3Oat0sH3t47LYQZT7ja7QBJQOY9sGw@mail.gmail.com>

Is there a way to get the status code of a pipe() command? The
documentation suggests that it might be returned by close, however
this does not seem to be the case.

  con <- pipe("cat /etc/passwd", "r")
  stream <- readLines(con, n = 10)
  err <- close(con)
  print(err)


From kevinushey at gmail.com  Thu May 14 07:27:23 2015
From: kevinushey at gmail.com (Kevin Ushey)
Date: Wed, 13 May 2015 22:27:23 -0700
Subject: [Rd] Reading exit code of pipe()
In-Reply-To: <CABFfbXv7OzDSt3n9HwkG3Oat0sH3t47LYQZT7ja7QBJQOY9sGw@mail.gmail.com>
References: <CABFfbXv7OzDSt3n9HwkG3Oat0sH3t47LYQZT7ja7QBJQOY9sGw@mail.gmail.com>
Message-ID: <CAJXgQP3TH2xmyhBCoOow9XzxXzQdvAL0RnLCof8=zd1s1kLXQw@mail.gmail.com>

Hi Jeroen,

I think `pipe` might just be returning the status code of the
underlying command executed; for example, I get a status code of '0'
when I test a pipe on `ls`:

    conn <- pipe("ls")
    stream <- readLines(conn)
    print(close(conn))

Similarly, I get an error code if I try to `ls` a non-existent
directory (512 in my case), e.g.

    conn <- pipe("ls /no/path/here/sir")
    stream <- readLines(conn)
    print(close(conn))

So maybe `cat` just doesn't set a status code, and so there's nothing
for R to forward back (ergo -- NULL)?

Kevin

On Wed, May 13, 2015 at 5:24 PM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu> wrote:
> Is there a way to get the status code of a pipe() command? The
> documentation suggests that it might be returned by close, however
> this does not seem to be the case.
>
>   con <- pipe("cat /etc/passwd", "r")
>   stream <- readLines(con, n = 10)
>   err <- close(con)
>   print(err)
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ripley at stats.ox.ac.uk  Thu May 14 08:06:17 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Thu, 14 May 2015 07:06:17 +0100
Subject: [Rd] CRAN check for package on Sparc Solaris
In-Reply-To: <077E31A57DA26E46AB0D493C9966AC730F0C217F64@UM-MAIL4112.unimaas.nl>
References: <077E31A57DA26E46AB0D493C9966AC730F0C217F64@UM-MAIL4112.unimaas.nl>
Message-ID: <55543B59.5060903@stats.ox.ac.uk>

This issue is discussed in 
http://cran.r-project.org/doc/manuals/r-release/R-exts.html#Writing-portable-packages, 
to which he was referred by the CRAN report.  It fails in the same way 
with --disable-long-double on an x86_64 Linux box (as he was told).

On 13/05/2015 20:48, Viechtbauer Wolfgang (STAT) wrote:
> Dear All,
>
> The metafor package currently fails CRAN checks on Sparc Solaris:
>
> http://cran.r-project.org/web/checks/check_results_metafor.html
>
> The problem is probably due to an unintended (= stupid) use of identical() in a couple tests. I have changed that to more appropriate tests using all.equal(). However, before I resubmit the package to CRAN, I would really like to make sure that the updated package passes all checks also on Sparc Solaris.
>
> The issue/question of how to test packages on Sparc Solaris has come up before:
>
> https://stat.ethz.ch/pipermail/r-devel/2010-September/058538.html
> https://stat.ethz.ch/pipermail/r-devel/2011-November/062430.html
>
> Unless anything has changed in the meantime, it seems like the help of kind volunteers is still the only option to conduct such tests. So, is there anybody out there with access to a Sparc machine running Solaris willing to run 'R CMD check --as-cran' on the updated tarball? Would be very much appreciated!
>
> Best,
> Wolfgang
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From pdalgd at gmail.com  Thu May 14 09:30:19 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 14 May 2015 09:30:19 +0200
Subject: [Rd] Why is the diag function so slow (for extraction)?
In-Reply-To: <20150513173117.GA31260@cs.toronto.edu>
References: <mailman.21.1431511203.5843.r-devel@r-project.org>
	<20150513173117.GA31260@cs.toronto.edu>
Message-ID: <3110C39E-A22E-46D7-984D-EC902621F0C6@gmail.com>


> On 13 May 2015, at 19:31 , Radford Neal <radford at cs.toronto.edu> wrote:
> 
>> From: Martin Maechler <maechler at lynne.stat.math.ethz.ch>
> 
>> diag() should not work only for pure matrices, but for all
>> "matrix-like" objects for which ``the usual methods'' work, such
>> as
>>   as.vector(.), c(.)
>> 
>> That's why there has been the c(.) in there.
>> 
>> You can always make code faster if you write the code so it only
>> has to work in one special case .. and work there very fast.
> 
> help(diag) gives no hint whatever that diag(x) will work for
> objects that are "matrix-like", but aren't actual matrices.
> 
> help(c) explicitly says that methods for it are NOT required to
> convert matrices to vectors.
> 
> So you're advocating slowing down all ordinary uses of diag to
> accommodate a usage that nobody thought was important enough to
> actually document.


That's not really the point, Radford. The point is that we want to be very careful when changing a function to work less generally than it used to do. I.e., if we just change diag() by removing the c(), there's a risk of finding out the hard way, at the public release, why it was there to begin with. We can check against CRAN before release, but not all existing user scripts. 

As I pointed out earlier, avoiding a matrix copy before extracting the diagonal may be an impressive speedup in isolation: O(N) vs O(N^2), but you're not going to do much with large matrices without other operations being O(N^2) or O(N^3). The user-impact of a change could be quite small.

That being said, it is not like we're too good at making diag() work with matrix-like objects as it is:

> df <- as.data.frame(matrix(1:9,3))
> diag(df)
Error in diag(df) : (list) object cannot be coerced to type 'double'

(It's not like I actually want diag() to work on a data frame, it was just the first matrix-like non-matrix object that came to mind.)

The only case where the c() inside diag() has an effect is where 
M[i,j] != M[(i-1)*m+j] 
AND c(M) will stringize M in column-major order, so that 
M[i,j] == c(M)[(i-1)*m+j].

The former is not true for ordinary matrices (i.e., single-index extraction just works), and the latter does not hold for data frames. The 10000$ question is whether there actually are cases for which both are true, and if so, which are they?


-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From csardi.gabor at gmail.com  Thu May 14 15:27:27 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Thu, 14 May 2015 09:27:27 -0400
Subject: [Rd] Reading exit code of pipe()
In-Reply-To: <CAJXgQP3TH2xmyhBCoOow9XzxXzQdvAL0RnLCof8=zd1s1kLXQw@mail.gmail.com>
References: <CABFfbXv7OzDSt3n9HwkG3Oat0sH3t47LYQZT7ja7QBJQOY9sGw@mail.gmail.com>
	<CAJXgQP3TH2xmyhBCoOow9XzxXzQdvAL0RnLCof8=zd1s1kLXQw@mail.gmail.com>
Message-ID: <CABtg=KmZEcWA2NpVOMB+WdLyootQsKEjC89SDa7_GwcWG3YaOw@mail.gmail.com>

On Thu, May 14, 2015 at 1:27 AM, Kevin Ushey <kevinushey at gmail.com> wrote:
[...]

> So maybe `cat` just doesn't set a status code, and so there's nothing
> for R to forward back (ergo -- NULL)?
>

cat definitely sets the status. IMHO every command sets the exit status, by
definition, at least on Unix/Linux.

/tmp$ touch x
/tmp$ cat x
/tmp$ echo $?
0
/tmp$ cat y
cat: y: No such file or directory
/tmp$ echo $?
1

Gabor

[...]

	[[alternative HTML version deleted]]


From wdunlap at tibco.com  Thu May 14 16:30:58 2015
From: wdunlap at tibco.com (William Dunlap)
Date: Thu, 14 May 2015 07:30:58 -0700
Subject: [Rd] Reading exit code of pipe()
In-Reply-To: <CAJXgQP3TH2xmyhBCoOow9XzxXzQdvAL0RnLCof8=zd1s1kLXQw@mail.gmail.com>
References: <CABFfbXv7OzDSt3n9HwkG3Oat0sH3t47LYQZT7ja7QBJQOY9sGw@mail.gmail.com>
	<CAJXgQP3TH2xmyhBCoOow9XzxXzQdvAL0RnLCof8=zd1s1kLXQw@mail.gmail.com>
Message-ID: <CAF8bMcZkKrhafAmWuywyPiTXiiJNFwCcXdWyXR3kJmz+mnQBPQ@mail.gmail.com>

The difference in the return value of close(pipeConnectionObject)
seems to depend on whether the pipe connection was opened via
the pipe() or open() functions (close() returns NULL)
   > con <- pipe("ls")
   > open(con, "r")
   > readLines(con, n=1)
   [1] "1032.R"
   > print(close(con))
   NULL
   > con <- pipe("ls", "r")
   > scan(con, n=1, what="")
  Read 1 item
  [1] "1032.R"
  > print(close(con))
  NULL
or via something like readLines() or scan() (close() returns status
integer).
  > con <- pipe("ls")
  > scan(con, n=1, what="")
  Read 1 item
  [1] "1032.R"
  > print(close(con))
  [1] 36096
  > sprintf("0x%x", .Last.value)
  [1] "0x8d00"






Bill Dunlap
TIBCO Software
wdunlap tibco.com

On Wed, May 13, 2015 at 10:27 PM, Kevin Ushey <kevinushey at gmail.com> wrote:

> Hi Jeroen,
>
> I think `pipe` might just be returning the status code of the
> underlying command executed; for example, I get a status code of '0'
> when I test a pipe on `ls`:
>
>     conn <- pipe("ls")
>     stream <- readLines(conn)
>     print(close(conn))
>
> Similarly, I get an error code if I try to `ls` a non-existent
> directory (512 in my case), e.g.
>
>     conn <- pipe("ls /no/path/here/sir")
>     stream <- readLines(conn)
>     print(close(conn))
>
> So maybe `cat` just doesn't set a status code, and so there's nothing
> for R to forward back (ergo -- NULL)?
>
> Kevin
>
> On Wed, May 13, 2015 at 5:24 PM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu>
> wrote:
> > Is there a way to get the status code of a pipe() command? The
> > documentation suggests that it might be returned by close, however
> > this does not seem to be the case.
> >
> >   con <- pipe("cat /etc/passwd", "r")
> >   stream <- readLines(con, n = 10)
> >   err <- close(con)
> >   print(err)
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From tkeitt at gmail.com  Thu May 14 18:16:15 2015
From: tkeitt at gmail.com (Tim Keitt)
Date: Thu, 14 May 2015 11:16:15 -0500
Subject: [Rd] Reading exit code of pipe()
In-Reply-To: <CAF8bMcZkKrhafAmWuywyPiTXiiJNFwCcXdWyXR3kJmz+mnQBPQ@mail.gmail.com>
References: <CABFfbXv7OzDSt3n9HwkG3Oat0sH3t47LYQZT7ja7QBJQOY9sGw@mail.gmail.com>
	<CAJXgQP3TH2xmyhBCoOow9XzxXzQdvAL0RnLCof8=zd1s1kLXQw@mail.gmail.com>
	<CAF8bMcZkKrhafAmWuywyPiTXiiJNFwCcXdWyXR3kJmz+mnQBPQ@mail.gmail.com>
Message-ID: <CANnL8goP+SZwzeaFBSKA7Uub5_1CP6P27Vs0J_i1tdoSzOYTWw@mail.gmail.com>

Not sure if it helps for your use case, but I have an experimental package
for controlling bidirectional pipe streams from R. Just thought I'd mention
it. Its at

https://github.com/thk686/pipestreamr

THK

On Thu, May 14, 2015 at 9:30 AM, William Dunlap <wdunlap at tibco.com> wrote:

> The difference in the return value of close(pipeConnectionObject)
> seems to depend on whether the pipe connection was opened via
> the pipe() or open() functions (close() returns NULL)
>    > con <- pipe("ls")
>    > open(con, "r")
>    > readLines(con, n=1)
>    [1] "1032.R"
>    > print(close(con))
>    NULL
>    > con <- pipe("ls", "r")
>    > scan(con, n=1, what="")
>   Read 1 item
>   [1] "1032.R"
>   > print(close(con))
>   NULL
> or via something like readLines() or scan() (close() returns status
> integer).
>   > con <- pipe("ls")
>   > scan(con, n=1, what="")
>   Read 1 item
>   [1] "1032.R"
>   > print(close(con))
>   [1] 36096
>   > sprintf("0x%x", .Last.value)
>   [1] "0x8d00"
>
>
>
>
>
>
> Bill Dunlap
> TIBCO Software
> wdunlap tibco.com
>
> On Wed, May 13, 2015 at 10:27 PM, Kevin Ushey <kevinushey at gmail.com>
> wrote:
>
> > Hi Jeroen,
> >
> > I think `pipe` might just be returning the status code of the
> > underlying command executed; for example, I get a status code of '0'
> > when I test a pipe on `ls`:
> >
> >     conn <- pipe("ls")
> >     stream <- readLines(conn)
> >     print(close(conn))
> >
> > Similarly, I get an error code if I try to `ls` a non-existent
> > directory (512 in my case), e.g.
> >
> >     conn <- pipe("ls /no/path/here/sir")
> >     stream <- readLines(conn)
> >     print(close(conn))
> >
> > So maybe `cat` just doesn't set a status code, and so there's nothing
> > for R to forward back (ergo -- NULL)?
> >
> > Kevin
> >
> > On Wed, May 13, 2015 at 5:24 PM, Jeroen Ooms <jeroen.ooms at stat.ucla.edu>
> > wrote:
> > > Is there a way to get the status code of a pipe() command? The
> > > documentation suggests that it might be returned by close, however
> > > this does not seem to be the case.
> > >
> > >   con <- pipe("cat /etc/passwd", "r")
> > >   stream <- readLines(con, n = 10)
> > >   err <- close(con)
> > >   print(err)
> > >
> > > ______________________________________________
> > > R-devel at r-project.org mailing list
> > > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Timothy H. Keitt
http://www.keittlab.org/

	[[alternative HTML version deleted]]


From jeroen.ooms at stat.ucla.edu  Thu May 14 19:07:30 2015
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Thu, 14 May 2015 10:07:30 -0700
Subject: [Rd] Reading exit code of pipe()
In-Reply-To: <CAF8bMcZkKrhafAmWuywyPiTXiiJNFwCcXdWyXR3kJmz+mnQBPQ@mail.gmail.com>
References: <CABFfbXv7OzDSt3n9HwkG3Oat0sH3t47LYQZT7ja7QBJQOY9sGw@mail.gmail.com>
	<CAJXgQP3TH2xmyhBCoOow9XzxXzQdvAL0RnLCof8=zd1s1kLXQw@mail.gmail.com>
	<CAF8bMcZkKrhafAmWuywyPiTXiiJNFwCcXdWyXR3kJmz+mnQBPQ@mail.gmail.com>
Message-ID: <CABFfbXuVaXdoW16kw5nUQtpg+=zg+F=B1xwFT6Z9hFjnAR1FZQ@mail.gmail.com>

On Thu, May 14, 2015 at 7:30 AM, William Dunlap <wdunlap at tibco.com> wrote:
> The difference in the return value of close(pipeConnectionObject) seems to depend on whether the pipe connection was opened via the pipe() or open() functions (close() returns NULL) or via something like readLines() or scan() (close() returns status integer).

Hmm interesting. It doesn't help me though; the connection has to be
explicitly opened to support streaming otherwise it keeps running the
command over and over again:

 con <- pipe("ls -ltr /")
 readLines(con, n = 3)
 readLines(con, n = 3)
 readLines(con, n = 3)
 isOpen(con)

Under the hood, R distinguishes "closing" and "destroying" the
connection. The R function close actually means destroy. It seems like
the pipe exit code is only properly returned if the connection was
already closed but not destroyed by the time close() was called.


From january.weiner at gmail.com  Fri May 15 00:04:32 2015
From: january.weiner at gmail.com (January Weiner)
Date: Fri, 15 May 2015 00:04:32 +0200
Subject: [Rd] Creating a vignette which depends on a non-distributable file
Message-ID: <CA+A1kV5uemT7obxhpYu6JA5t2Dpoq7UVVowCOYKV6+dfou0qeA@mail.gmail.com>

Dear all,

I am writing a vignette that requires a file which I am not allowed to
distribute, but which the user can easily download manually. Moreover, it
is not possible to download this file automatically from R: downloading
requires a (free) registration that seems to work only through a browser.
(I'm talking here about the MSigDB from the Broad Institute,
http://www.broadinstitute.org/gsea/msigdb/index.jsp).

In the vignette, I tell the user to download the file and then show how it
can be parsed and used in R. Thus, I can compile the vignette only if this
file is present in the vignettes/ directory of the package. However, it
would then get included in the package -- which I am not allowed to do.

What should I do?

(1) finding an alternative to MSigDB is not a solution -- there simply is
no alternative.
(2) I could enter the code (and the results) in a verbatim environment
instead of using Sweave. This has obvious drawbacks (for one thing, it
would look incosistent).
(3) I could build vignette outside of the package and put it into the
inst/doc directory. This also has obvious drawbacks.
(4) Leaving this example out defies the purpose of my package.

I am tending towards solution (2). What do you think?

Kind regards,

j.



--
-------- January Weiner --------------------------------------

	[[alternative HTML version deleted]]


From henrik.bengtsson at ucsf.edu  Fri May 15 01:33:52 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Thu, 14 May 2015 16:33:52 -0700
Subject: [Rd] Creating a vignette which depends on a non-distributable
	file
In-Reply-To: <CA+A1kV5uemT7obxhpYu6JA5t2Dpoq7UVVowCOYKV6+dfou0qeA@mail.gmail.com>
References: <CA+A1kV5uemT7obxhpYu6JA5t2Dpoq7UVVowCOYKV6+dfou0qeA@mail.gmail.com>
Message-ID: <CAFDcVCS7_2LQNtje3H9iNQ=_mLmk1cWqGNLiDzG1KuvxduhDcw@mail.gmail.com>

On May 14, 2015 15:04, "January Weiner" <january.weiner at gmail.com> wrote:
>
> Dear all,
>
> I am writing a vignette that requires a file which I am not allowed to
> distribute, but which the user can easily download manually. Moreover, it
> is not possible to download this file automatically from R: downloading
> requires a (free) registration that seems to work only through a browser.
> (I'm talking here about the MSigDB from the Broad Institute,
> http://www.broadinstitute.org/gsea/msigdb/index.jsp).
>
> In the vignette, I tell the user to download the file and then show how it
> can be parsed and used in R. Thus, I can compile the vignette only if this
> file is present in the vignettes/ directory of the package. However, it
> would then get included in the package -- which I am not allowed to do.
>
> What should I do?
>
> (1) finding an alternative to MSigDB is not a solution -- there simply is
> no alternative.
> (2) I could enter the code (and the results) in a verbatim environment
> instead of using Sweave. This has obvious drawbacks (for one thing, it
> would look incosistent).
> (3) I could build vignette outside of the package and put it into the
> inst/doc directory. This also has obvious drawbacks.
> (4) Leaving this example out defies the purpose of my package.
>
> I am tending towards solution (2). What do you think?

Not clear how big of a static piece you're taking about, but maybe you
could set it up such that you use (2) as a fallback, i.e. have the vignette
include a static/pre-generated piece (which is clearly marked as such) only
if the external dependency is not available.

Just a thought

Henrik

>
> Kind regards,
>
> j.
>
>
>
> --
> -------- January Weiner --------------------------------------
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From mtmorgan at fredhutch.org  Fri May 15 01:50:45 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Thu, 14 May 2015 16:50:45 -0700
Subject: [Rd] Creating a vignette which depends on a non-distributable
 file
In-Reply-To: <CAFDcVCS7_2LQNtje3H9iNQ=_mLmk1cWqGNLiDzG1KuvxduhDcw@mail.gmail.com>
References: <CA+A1kV5uemT7obxhpYu6JA5t2Dpoq7UVVowCOYKV6+dfou0qeA@mail.gmail.com>
	<CAFDcVCS7_2LQNtje3H9iNQ=_mLmk1cWqGNLiDzG1KuvxduhDcw@mail.gmail.com>
Message-ID: <555534D5.1020803@fredhutch.org>

On 05/14/2015 04:33 PM, Henrik Bengtsson wrote:
> On May 14, 2015 15:04, "January Weiner" <january.weiner at gmail.com> wrote:
>>
>> Dear all,
>>
>> I am writing a vignette that requires a file which I am not allowed to
>> distribute, but which the user can easily download manually. Moreover, it
>> is not possible to download this file automatically from R: downloading
>> requires a (free) registration that seems to work only through a browser.
>> (I'm talking here about the MSigDB from the Broad Institute,
>> http://www.broadinstitute.org/gsea/msigdb/index.jsp).
>>
>> In the vignette, I tell the user to download the file and then show how it
>> can be parsed and used in R. Thus, I can compile the vignette only if this
>> file is present in the vignettes/ directory of the package. However, it
>> would then get included in the package -- which I am not allowed to do.
>>
>> What should I do?
>>
>> (1) finding an alternative to MSigDB is not a solution -- there simply is
>> no alternative.
>> (2) I could enter the code (and the results) in a verbatim environment
>> instead of using Sweave. This has obvious drawbacks (for one thing, it
>> would look incosistent).

use the chunk argument eval=FALSE instead of placing the code in a verbatim 
argument. See ?RweaveLatex if you're compiling a PDF vignette from Rnw or the 
knitr documentation for (much nicer for users of your vignette, in my opinion) 
Rmd vignettes processed to HTML.

A common pattern is to process chunks 1, 2, 3, 4, and then there is a 'leap of 
faith' in chunk 5 (with eval=FALSE) and a second chunk (maybe with echo=FALSE, 
eval=TRUE) that reads the _result_ that would have been produced by chunk 5 from 
a serialized instance into the R session for processing in chunks 6, 7, 8...

Also very often while it might make sense to analyse an entire data set as part 
of a typical work flow, for illustrative purposes a much smaller subset or 
simulated data might be relevant; again a strategy would be to illustrate the 
problematic steps with simulated data, and then resume the narrative with the 
analyzed full data.

A secondary consideration may be that if your package _requires_ MSigDB to 
function, then it can't be automatically tested by repository build machines -- 
you'll want to have unit tests or other approaches to ensure that 'bit rot' does 
not set in without you being aware of it.

If this is a Bioconductor package, then it's appropriate to ask on the 
Bioconductor devel mailing list.

   http://bioconductor.org/developers/

http://bioconductor.org/packages/BiocStyle/ might be your friend for producing 
stylish vignettes.

Martin

>> (3) I could build vignette outside of the package and put it into the
>> inst/doc directory. This also has obvious drawbacks.
>> (4) Leaving this example out defies the purpose of my package.
>>
>> I am tending towards solution (2). What do you think?
>
> Not clear how big of a static piece you're taking about, but maybe you
> could set it up such that you use (2) as a fallback, i.e. have the vignette
> include a static/pre-generated piece (which is clearly marked as such) only
> if the external dependency is not available.
>
> Just a thought
>
> Henrik
>
>>
>> Kind regards,
>>
>> j.
>>
>>
>>
>> --
>> -------- January Weiner --------------------------------------
>>
>>          [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From Virgil.Smith at flir.com  Fri May 15 02:19:10 2015
From: Virgil.Smith at flir.com (Smith, Virgil)
Date: Fri, 15 May 2015 00:19:10 +0000
Subject: [Rd] Installation using iconv from glibc
Message-ID: <F14AEF751653024287138321000C846AF48222D4@BOS-DAG1.zone1.flir.net>

The R Installation and Administration manual section A.1 states that glibc should provide a suitable iconv function, but I can't get R's configure script to accept/validate iconv on a Linux platform I need to support using glibc 2.20.

Is glibc is actually compatible (and/or is gnu libiconv essentially the only path)?

If glibc should work, what should I check to troubleshoot my environment?

The configure error I get is
    checking iconv.h usability... yes
    checking iconv.h presence... yes
    checking for iconv.h... yes
    checking for iconv... yes
    checking whether iconv accepts "UTF-8", "latin1", "ASCII" and "UCS-*"... no
    configure: error: a suitable iconv is essential

My full list of installed glibc / libc packages is
    glibc-binary-localedata-en-gb - 2.20-r0
    glibc-binary-localedata-en-us - 2.20-r0
    glibc-gconv - 2.20-r0
    glibc-gconv-utf-16 - 2.20-r0
    glibc-locale-en-gb - 2.20-r0
    libc6 - 2.20-r0
    libc6-dev - 2.20-r0
    libc6-extra-nss - 2.20-r0
    libc6-thread-db - 2.20-r0

This is for a custom Linux build, not a major distro, so unfortunately I cannot use pre-packaged configurations.


________________________________

Notice to recipient: This email is meant for only the intended recipient of the transmission, and may be a communication privileged by law, subject to export control restrictions or that otherwise contains proprietary information. If you receive this email by mistake, please notify us immediately by replying to this message and then destroy it and do not review, disclose, copy or distribute it. Thank you in advance for your cooperation.


From ripley at stats.ox.ac.uk  Fri May 15 09:41:39 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Fri, 15 May 2015 08:41:39 +0100
Subject: [Rd] Installation using iconv from glibc
In-Reply-To: <F14AEF751653024287138321000C846AF48222D4@BOS-DAG1.zone1.flir.net>
References: <F14AEF751653024287138321000C846AF48222D4@BOS-DAG1.zone1.flir.net>
Message-ID: <5555A333.9090801@stats.ox.ac.uk>

On 15/05/2015 01:19, Smith, Virgil wrote:
> The R Installation and Administration manual section A.1 states that glibc should provide a suitable iconv function, but I can't get R's configure script to accept/validate iconv on a Linux platform I need to support using glibc 2.20.
>
> Is glibc is actually compatible (and/or is gnu libiconv essentially the only path)?

R is built daily on Fedora 21 Linux which uses glibc 2.20 and has been 
for at least a decade with that and earlier versions of glibc.  No 
problems with installing using glibc have been reported in all that time 
(and many dialects of Linux have been used successfully).

> If glibc should work, what should I check to troubleshoot my environment?
>
> The configure error I get is
>      checking iconv.h usability... yes
>      checking iconv.h presence... yes
>      checking for iconv.h... yes
>      checking for iconv... yes
>      checking whether iconv accepts "UTF-8", "latin1", "ASCII" and "UCS-*"... no
>      configure: error: a suitable iconv is essential

You look in config.log for the details we cannot even guess at.

>
> My full list of installed glibc / libc packages is
>      glibc-binary-localedata-en-gb - 2.20-r0
>      glibc-binary-localedata-en-us - 2.20-r0
>      glibc-gconv - 2.20-r0
>      glibc-gconv-utf-16 - 2.20-r0
>      glibc-locale-en-gb - 2.20-r0
>      libc6 - 2.20-r0
>      libc6-dev - 2.20-r0
>      libc6-extra-nss - 2.20-r0
>      libc6-thread-db - 2.20-r0
>
> This is for a custom Linux build, not a major distro, so unfortunately I cannot use pre-packaged configurations.



-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From cgenolin at u-paris10.fr  Fri May 15 11:32:42 2015
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Fri, 15 May 2015 11:32:42 +0200
Subject: [Rd] Defining Constant variable in a package
Message-ID: <5555BD3A.5000707@u-paris10.fr>

Hi all,

In my package, I define some constant. In the previous version of R, I just define then in 
"/data/constants.R" but it seems that it is no longer possible. Instead, I am asked to "define them 
in the namespace". I am not sure to understand what it means. Shall I define them in the NAMESPACE 
file?

Christophe


From barronawebster at gmail.com  Fri May 15 06:35:53 2015
From: barronawebster at gmail.com (bw1984)
Date: Thu, 14 May 2015 21:35:53 -0700 (PDT)
Subject: [Rd] Error when comparing two variables within a dataframe and
 print relevant observations
Message-ID: <1431664553968-4707240.post@n4.nabble.com>

I'm trying to use a nested ifelse condition to compare two lines. 

Input: 


Code: 


Expected Output: 



Actual Output: 



Any idea what might be causing this problem?



--
View this message in context: http://r.789695.n4.nabble.com/Error-when-comparing-two-variables-within-a-dataframe-and-print-relevant-observations-tp4707240.html
Sent from the R devel mailing list archive at Nabble.com.


From wolfgang.viechtbauer at maastrichtuniversity.nl  Fri May 15 11:57:27 2015
From: wolfgang.viechtbauer at maastrichtuniversity.nl (Viechtbauer Wolfgang (STAT))
Date: Fri, 15 May 2015 11:57:27 +0200
Subject: [Rd] CRAN check for package on Sparc Solaris
In-Reply-To: <55543B59.5060903@stats.ox.ac.uk>
References: <077E31A57DA26E46AB0D493C9966AC730F0C217F64@UM-MAIL4112.unimaas.nl>
	<55543B59.5060903@stats.ox.ac.uk>
Message-ID: <077E31A57DA26E46AB0D493C9966AC730F0C6CEC26@UM-MAIL4112.unimaas.nl>

Yes, I did read that part but it doesn't say anything about who to contact in case one doesn't have access to a Sparc Solaris machine, but one still wants to run the tests on that architecture. As I said, I think I got the issue resolved, but before I resubmit, I would prefer to check this -- I am ultimately just trying to avoid potentially wasting people's time here.

As for Linux x86_64 without long doubles. Is this something that is part of the checks here?

http://cran.r-project.org/web/checks/check_results_metafor.html

Doesn't seem that way. But is this still part of the CRAN checks?

I can of course simply assume/hope that the issue, which is now hopefully resolved on Sparc Solaris, is the same that caused problems for Linux x86_64 without long doubles and that is then also hopefully resolved. Or I could hope that another kind soul with a compiled version of R on Linux x86_64 with --disable-long-double is willing to give the new tarball a whirl.

> -----Original Message-----
> From: R-devel [mailto:r-devel-bounces at r-project.org] On Behalf Of Prof
> Brian Ripley
> Sent: Thursday, May 14, 2015 08:06
> To: r-devel at r-project.org
> Subject: Re: [Rd] CRAN check for package on Sparc Solaris
> 
> This issue is discussed in
> http://cran.r-project.org/doc/manuals/r-release/R-exts.html#Writing-
> portable-packages,
> to which he was referred by the CRAN report.  It fails in the same way
> with --disable-long-double on an x86_64 Linux box (as he was told).
> 
> On 13/05/2015 20:48, Viechtbauer Wolfgang (STAT) wrote:
> > Dear All,
> >
> > The metafor package currently fails CRAN checks on Sparc Solaris:
> >
> > http://cran.r-project.org/web/checks/check_results_metafor.html
> >
> > The problem is probably due to an unintended (= stupid) use of
> identical() in a couple tests. I have changed that to more appropriate
> tests using all.equal(). However, before I resubmit the package to CRAN,
> I would really like to make sure that the updated package passes all
> checks also on Sparc Solaris.
> >
> > The issue/question of how to test packages on Sparc Solaris has come up
> before:
> >
> > https://stat.ethz.ch/pipermail/r-devel/2010-September/058538.html
> > https://stat.ethz.ch/pipermail/r-devel/2011-November/062430.html
> >
> > Unless anything has changed in the meantime, it seems like the help of
> kind volunteers is still the only option to conduct such tests. So, is
> there anybody out there with access to a Sparc machine running Solaris
> willing to run 'R CMD check --as-cran' on the updated tarball? Would be
> very much appreciated!
> >
> > Best,
> > Wolfgang
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
> 
> 
> --
> Brian D. Ripley,                  ripley at stats.ox.ac.uk
> Emeritus Professor of Applied Statistics, University of Oxford
> 1 South Parks Road, Oxford OX1 3TG, UK
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From Keith.Jewell at campdenbri.co.uk  Fri May 15 12:54:29 2015
From: Keith.Jewell at campdenbri.co.uk (Keith Jewell)
Date: Fri, 15 May 2015 11:54:29 +0100
Subject: [Rd] Error when comparing two variables within a dataframe and
 print relevant observations
In-Reply-To: <1431664553968-4707240.post@n4.nabble.com>
References: <1431664553968-4707240.post@n4.nabble.com>
Message-ID: <mj4j95$2nu$1@ger.gmane.org>

On 15/05/2015 05:35, bw1984 wrote:
> I'm trying to use a nested ifelse condition to compare two lines.
>
> Input:
>
>
> Code:
>
>
> Expected Output:
>
>
>
> Actual Output:
>
>
>
> Any idea what might be causing this problem?
>
>
>
> --
> View this message in context: http://r.789695.n4.nabble.com/Error-when-comparing-two-variables-within-a-dataframe-and-print-relevant-observations-tp4707240.html
> Sent from the R devel mailing list archive at Nabble.com.
>
I had to look at Nabble to see the detail. Even that omitted an error 
message:

 > Transfers2 <- subset(Transfers, ChangeType != "No Change"))
Error: unexpected ')' in "Transfers2 <- subset(Transfers, ChangeType != 
"No Change"))"

When I omitted the extra closing bracket it worked.


From cdetermanjr at gmail.com  Fri May 15 14:05:18 2015
From: cdetermanjr at gmail.com (Charles Determan)
Date: Fri, 15 May 2015 07:05:18 -0500
Subject: [Rd] example fails during R CMD CHECK but works interactively?
In-Reply-To: <CAKxd1KMgT700+uKmD8v-QJoG5NmpeA+t3rSR-gg1L19=NbpzPw@mail.gmail.com>
References: <CAKxd1KNtOjyq5DYEVmvw=NQUrnL5LVZYuSt=1cyfE=QQQquCLw@mail.gmail.com>
	<1612739531.2387533.1431543079541.JavaMail.root@fredhutch.org>
	<CAKxd1KMgT700+uKmD8v-QJoG5NmpeA+t3rSR-gg1L19=NbpzPw@mail.gmail.com>
Message-ID: <CAKxd1KMkW6mx9hYdDwtQ6k9R7BnvufZspFs8fJPovYJXXgW75Q@mail.gmail.com>

Does anyone else have any thoughts about troubleshooting the R CMD check
environment?

Charles

On Wed, May 13, 2015 at 1:57 PM, Charles Determan <cdetermanjr at gmail.com>
wrote:

> Thank you Dan but it isn't my tests that are failing (all of them pass
> without problem) but one of the examples from the inst/examples directory.
> I did try, however, to start R with the environmental variables as you
> suggest but it had no effect on my tests.
>
> Charles
>
> On Wed, May 13, 2015 at 1:51 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
> wrote:
>
>>
>>
>> ----- Original Message -----
>> > From: "Charles Determan" <cdetermanjr at gmail.com>
>> > To: r-devel at r-project.org
>> > Sent: Wednesday, May 13, 2015 11:31:36 AM
>> > Subject: [Rd] example fails during R CMD CHECK but works interactively?
>> >
>> > Greetings,
>> >
>> > I am collaborating with developing the bigmemory package and have run
>> > in to
>> > a strange problem when we run R CMD CHECK.  For some reason that
>> > isn't
>> > clear to us one of the examples crashes stating:
>> >
>> > Error:  memory could not be allocated for instance of type big.matrix
>> >
>> > You can see the output on the Travis CI page at
>> > https://travis-ci.org/kaneplusplus/bigmemory where the error starts
>> > at line
>> > 1035.  This is completely reproducible when running
>> > devtools::check(args='--as-cran') locally.  The part that is
>> > confusing is
>> > that the calls work perfectly when called interactively.
>> >
>> > Hadley comments on the 'check' page of his R packages website (
>> > http://r-pkgs.had.co.nz/check.html) regarding test failing following
>> > R CMD
>> > check:
>> >
>> > Occasionally you may have a problem where the tests pass when run
>> > interactively with devtools::test(), but fail when in R CMD check.
>> > This
>> > usually indicates that you?ve made a faulty assumption about the
>> > testing
>> > environment, and it?s often hard to figure it out.
>> >
>> > Any thoughts on how to troubleshoot this problem?  I have no idea
>> > what
>> > assumption we could have made.
>>
>> Note that R CMD check runs R with environment variables set as follows
>> (at least on my system; you can check $R_HOME/bin/check to see what it does
>> on yours):
>>
>>  R_DEFAULT_PACKAGES= LC_COLLATE=C
>>
>> So try staring R like this:
>>
>>  R_DEFAULT_PACKAGES= LC_COLLATE=C  R
>>
>> And see if that reproduces the test failure. The locale setting could
>> affect tests of sort order, and the default package setting could
>> potentially affect other things.
>>
>> Dan
>>
>>
>>
>> >
>> > Regards,
>> > Charles
>> >
>> >       [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>
>

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Fri May 15 14:13:39 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Fri, 15 May 2015 07:13:39 -0500
Subject: [Rd] example fails during R CMD CHECK but works interactively?
In-Reply-To: <CAKxd1KMkW6mx9hYdDwtQ6k9R7BnvufZspFs8fJPovYJXXgW75Q@mail.gmail.com>
References: <CAKxd1KNtOjyq5DYEVmvw=NQUrnL5LVZYuSt=1cyfE=QQQquCLw@mail.gmail.com>
	<1612739531.2387533.1431543079541.JavaMail.root@fredhutch.org>
	<CAKxd1KMgT700+uKmD8v-QJoG5NmpeA+t3rSR-gg1L19=NbpzPw@mail.gmail.com>
	<CAKxd1KMkW6mx9hYdDwtQ6k9R7BnvufZspFs8fJPovYJXXgW75Q@mail.gmail.com>
Message-ID: <CABdHhvGRvmLfedUHDqVSFuUtqghOtikX9zd27o7PiO+j2xLm-g@mail.gmail.com>

Make the example print out Sys.getenv() and then manually inspect?

Otherwise, you'll need to debug the code by adding print statements.
Something clearly is not as you expect, so you need carefully
empirically verify your assumptions about the inputs to and
environment of the function.

Hadley

On Fri, May 15, 2015 at 7:05 AM, Charles Determan <cdetermanjr at gmail.com> wrote:
> Does anyone else have any thoughts about troubleshooting the R CMD check
> environment?
>
> Charles
>
> On Wed, May 13, 2015 at 1:57 PM, Charles Determan <cdetermanjr at gmail.com>
> wrote:
>
>> Thank you Dan but it isn't my tests that are failing (all of them pass
>> without problem) but one of the examples from the inst/examples directory.
>> I did try, however, to start R with the environmental variables as you
>> suggest but it had no effect on my tests.
>>
>> Charles
>>
>> On Wed, May 13, 2015 at 1:51 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
>> wrote:
>>
>>>
>>>
>>> ----- Original Message -----
>>> > From: "Charles Determan" <cdetermanjr at gmail.com>
>>> > To: r-devel at r-project.org
>>> > Sent: Wednesday, May 13, 2015 11:31:36 AM
>>> > Subject: [Rd] example fails during R CMD CHECK but works interactively?
>>> >
>>> > Greetings,
>>> >
>>> > I am collaborating with developing the bigmemory package and have run
>>> > in to
>>> > a strange problem when we run R CMD CHECK.  For some reason that
>>> > isn't
>>> > clear to us one of the examples crashes stating:
>>> >
>>> > Error:  memory could not be allocated for instance of type big.matrix
>>> >
>>> > You can see the output on the Travis CI page at
>>> > https://travis-ci.org/kaneplusplus/bigmemory where the error starts
>>> > at line
>>> > 1035.  This is completely reproducible when running
>>> > devtools::check(args='--as-cran') locally.  The part that is
>>> > confusing is
>>> > that the calls work perfectly when called interactively.
>>> >
>>> > Hadley comments on the 'check' page of his R packages website (
>>> > http://r-pkgs.had.co.nz/check.html) regarding test failing following
>>> > R CMD
>>> > check:
>>> >
>>> > Occasionally you may have a problem where the tests pass when run
>>> > interactively with devtools::test(), but fail when in R CMD check.
>>> > This
>>> > usually indicates that you?ve made a faulty assumption about the
>>> > testing
>>> > environment, and it?s often hard to figure it out.
>>> >
>>> > Any thoughts on how to troubleshoot this problem?  I have no idea
>>> > what
>>> > assumption we could have made.
>>>
>>> Note that R CMD check runs R with environment variables set as follows
>>> (at least on my system; you can check $R_HOME/bin/check to see what it does
>>> on yours):
>>>
>>>  R_DEFAULT_PACKAGES= LC_COLLATE=C
>>>
>>> So try staring R like this:
>>>
>>>  R_DEFAULT_PACKAGES= LC_COLLATE=C  R
>>>
>>> And see if that reproduces the test failure. The locale setting could
>>> affect tests of sort order, and the default package setting could
>>> potentially affect other things.
>>>
>>> Dan
>>>
>>>
>>>
>>> >
>>> > Regards,
>>> > Charles
>>> >
>>> >       [[alternative HTML version deleted]]
>>> >
>>> > ______________________________________________
>>> > R-devel at r-project.org mailing list
>>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>> >
>>>
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel



-- 
http://had.co.nz/


From edd at debian.org  Fri May 15 14:47:29 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 15 May 2015 07:47:29 -0500
Subject: [Rd] example fails during R CMD CHECK but works interactively?
In-Reply-To: <CABdHhvGRvmLfedUHDqVSFuUtqghOtikX9zd27o7PiO+j2xLm-g@mail.gmail.com>
References: <CAKxd1KNtOjyq5DYEVmvw=NQUrnL5LVZYuSt=1cyfE=QQQquCLw@mail.gmail.com>
	<1612739531.2387533.1431543079541.JavaMail.root@fredhutch.org>
	<CAKxd1KMgT700+uKmD8v-QJoG5NmpeA+t3rSR-gg1L19=NbpzPw@mail.gmail.com>
	<CAKxd1KMkW6mx9hYdDwtQ6k9R7BnvufZspFs8fJPovYJXXgW75Q@mail.gmail.com>
	<CABdHhvGRvmLfedUHDqVSFuUtqghOtikX9zd27o7PiO+j2xLm-g@mail.gmail.com>
Message-ID: <21845.60129.410996.217354@max.nulle.part>


On 15 May 2015 at 07:13, Hadley Wickham wrote:
| Make the example print out Sys.getenv() and then manually inspect?

On the systems I use    system("env")     is more efficient as it gets you
all at once. 
 
| Otherwise, you'll need to debug the code by adding print statements.
| Something clearly is not as you expect, so you need carefully
| empirically verify your assumptions about the inputs to and
| environment of the function.

Exactly. No magic here, just plainstaken debugging.

As an old ~/.signature of mine said: "In theory, theory and practice are the
same. In practie, they are not."  Assumptions are good.  We all get a good
laugh out of them after the fact.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From mtmorgan at fredhutch.org  Fri May 15 14:49:12 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Fri, 15 May 2015 05:49:12 -0700
Subject: [Rd] example fails during R CMD CHECK but works interactively?
In-Reply-To: <CAKxd1KMkW6mx9hYdDwtQ6k9R7BnvufZspFs8fJPovYJXXgW75Q@mail.gmail.com>
References: <CAKxd1KNtOjyq5DYEVmvw=NQUrnL5LVZYuSt=1cyfE=QQQquCLw@mail.gmail.com>	<1612739531.2387533.1431543079541.JavaMail.root@fredhutch.org>	<CAKxd1KMgT700+uKmD8v-QJoG5NmpeA+t3rSR-gg1L19=NbpzPw@mail.gmail.com>
	<CAKxd1KMkW6mx9hYdDwtQ6k9R7BnvufZspFs8fJPovYJXXgW75Q@mail.gmail.com>
Message-ID: <5555EB48.5080101@fredhutch.org>

On 05/15/2015 05:05 AM, Charles Determan wrote:
> Does anyone else have any thoughts about troubleshooting the R CMD check
> environment?

In the pkg.Rcheck directory there is a file pkg-Ex.R.

LANGUAGE=en _R_CHECK_INTERNALS2_=1 $(R_HOME)/bin/R --vanilla pkge-Ex.R

followed by the usual strategy of bisecting the file into smaller chunks that 
still reproduce the example.

(this is based on my parsing of the complicated source, most relevant at

   https://github.com/wch/r-source/blob/trunk/src/library/tools/R/check.R#L2467

and

   https://github.com/wch/r-source/blob/trunk/src/library/tools/R/check.R#L36

)

Martin

>
> Charles
>
> On Wed, May 13, 2015 at 1:57 PM, Charles Determan <cdetermanjr at gmail.com>
> wrote:
>
>> Thank you Dan but it isn't my tests that are failing (all of them pass
>> without problem) but one of the examples from the inst/examples directory.
>> I did try, however, to start R with the environmental variables as you
>> suggest but it had no effect on my tests.
>>
>> Charles
>>
>> On Wed, May 13, 2015 at 1:51 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
>> wrote:
>>
>>>
>>>
>>> ----- Original Message -----
>>>> From: "Charles Determan" <cdetermanjr at gmail.com>
>>>> To: r-devel at r-project.org
>>>> Sent: Wednesday, May 13, 2015 11:31:36 AM
>>>> Subject: [Rd] example fails during R CMD CHECK but works interactively?
>>>>
>>>> Greetings,
>>>>
>>>> I am collaborating with developing the bigmemory package and have run
>>>> in to
>>>> a strange problem when we run R CMD CHECK.  For some reason that
>>>> isn't
>>>> clear to us one of the examples crashes stating:
>>>>
>>>> Error:  memory could not be allocated for instance of type big.matrix
>>>>
>>>> You can see the output on the Travis CI page at
>>>> https://travis-ci.org/kaneplusplus/bigmemory where the error starts
>>>> at line
>>>> 1035.  This is completely reproducible when running
>>>> devtools::check(args='--as-cran') locally.  The part that is
>>>> confusing is
>>>> that the calls work perfectly when called interactively.
>>>>
>>>> Hadley comments on the 'check' page of his R packages website (
>>>> http://r-pkgs.had.co.nz/check.html) regarding test failing following
>>>> R CMD
>>>> check:
>>>>
>>>> Occasionally you may have a problem where the tests pass when run
>>>> interactively with devtools::test(), but fail when in R CMD check.
>>>> This
>>>> usually indicates that you?ve made a faulty assumption about the
>>>> testing
>>>> environment, and it?s often hard to figure it out.
>>>>
>>>> Any thoughts on how to troubleshoot this problem?  I have no idea
>>>> what
>>>> assumption we could have made.
>>>
>>> Note that R CMD check runs R with environment variables set as follows
>>> (at least on my system; you can check $R_HOME/bin/check to see what it does
>>> on yours):
>>>
>>>   R_DEFAULT_PACKAGES= LC_COLLATE=C
>>>
>>> So try staring R like this:
>>>
>>>   R_DEFAULT_PACKAGES= LC_COLLATE=C  R
>>>
>>> And see if that reproduces the test failure. The locale setting could
>>> affect tests of sort order, and the default package setting could
>>> potentially affect other things.
>>>
>>> Dan
>>>
>>>
>>>
>>>>
>>>> Regards,
>>>> Charles
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>
>>
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From edd at debian.org  Fri May 15 15:08:22 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Fri, 15 May 2015 08:08:22 -0500
Subject: [Rd] example fails during R CMD CHECK but works interactively?
In-Reply-To: <21845.60129.410996.217354@max.nulle.part>
References: <CAKxd1KNtOjyq5DYEVmvw=NQUrnL5LVZYuSt=1cyfE=QQQquCLw@mail.gmail.com>
	<1612739531.2387533.1431543079541.JavaMail.root@fredhutch.org>
	<CAKxd1KMgT700+uKmD8v-QJoG5NmpeA+t3rSR-gg1L19=NbpzPw@mail.gmail.com>
	<CAKxd1KMkW6mx9hYdDwtQ6k9R7BnvufZspFs8fJPovYJXXgW75Q@mail.gmail.com>
	<CABdHhvGRvmLfedUHDqVSFuUtqghOtikX9zd27o7PiO+j2xLm-g@mail.gmail.com>
	<21845.60129.410996.217354@max.nulle.part>
Message-ID: <21845.61382.928836.879391@max.nulle.part>


On 15 May 2015 at 07:47, Dirk Eddelbuettel wrote:
| 
| On 15 May 2015 at 07:13, Hadley Wickham wrote:
| | Make the example print out Sys.getenv() and then manually inspect?
| 
| On the systems I use    system("env")     is more efficient as it gets you
| all at once. 

Ahh, yes, and I have since been told (thanks, Hadley) that Sys.getenv() does
just that -- and I remain a big fan of how R generally abstracts the OS away.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From lawrence.michael at gene.com  Fri May 15 15:55:03 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Fri, 15 May 2015 06:55:03 -0700
Subject: [Rd] Defining Constant variable in a package
In-Reply-To: <5555BD3A.5000707@u-paris10.fr>
References: <5555BD3A.5000707@u-paris10.fr>
Message-ID: <CAOQ5NydrGVrOeP0VJ0_-Eyhq8YwgB4mny22-YWOFZp0O7pExUw@mail.gmail.com>

I'm guessing you just need to define them in /R/constants.R and then
export() them from the NAMESPACE.

On Fri, May 15, 2015 at 2:32 AM, Christophe Genolini <cgenolin at u-paris10.fr>
wrote:

> Hi all,
>
> In my package, I define some constant. In the previous version of R, I
> just define then in "/data/constants.R" but it seems that it is no longer
> possible. Instead, I am asked to "define them in the namespace". I am not
> sure to understand what it means. Shall I define them in the NAMESPACE file?
>
> Christophe
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From plummerm at iarc.fr  Fri May 15 16:44:59 2015
From: plummerm at iarc.fr (Martyn Plummer)
Date: Fri, 15 May 2015 14:44:59 +0000
Subject: [Rd] example fails during R CMD CHECK but works interactively?
In-Reply-To: <CAKxd1KMkW6mx9hYdDwtQ6k9R7BnvufZspFs8fJPovYJXXgW75Q@mail.gmail.com>
References: <CAKxd1KNtOjyq5DYEVmvw=NQUrnL5LVZYuSt=1cyfE=QQQquCLw@mail.gmail.com>
	<1612739531.2387533.1431543079541.JavaMail.root@fredhutch.org>
	<CAKxd1KMgT700+uKmD8v-QJoG5NmpeA+t3rSR-gg1L19=NbpzPw@mail.gmail.com>
	<CAKxd1KMkW6mx9hYdDwtQ6k9R7BnvufZspFs8fJPovYJXXgW75Q@mail.gmail.com>
Message-ID: <1431701098.2753.26.camel@iarc.fr>

The error can be reproduced by running the bigmemory-Ex.R script which
you can find in the bigmemory.Rcheck directory, either in batch mode or
via source() in an interactive session.

It seems that you have underlying memory allocation problems. I can get
the script to running by adding gc() calls when necessary (i.e. when a
failure is reported, add gc() just before this point in the script and
rerun).

Martyn

On Fri, 2015-05-15 at 07:05 -0500, Charles Determan wrote:
> Does anyone else have any thoughts about troubleshooting the R CMD check
> environment?
> 
> Charles
> 
> On Wed, May 13, 2015 at 1:57 PM, Charles Determan <cdetermanjr at gmail.com>
> wrote:
> 
> > Thank you Dan but it isn't my tests that are failing (all of them pass
> > without problem) but one of the examples from the inst/examples directory.
> > I did try, however, to start R with the environmental variables as you
> > suggest but it had no effect on my tests.
> >
> > Charles
> >
> > On Wed, May 13, 2015 at 1:51 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
> > wrote:
> >
> >>
> >>
> >> ----- Original Message -----
> >> > From: "Charles Determan" <cdetermanjr at gmail.com>
> >> > To: r-devel at r-project.org
> >> > Sent: Wednesday, May 13, 2015 11:31:36 AM
> >> > Subject: [Rd] example fails during R CMD CHECK but works interactively?
> >> >
> >> > Greetings,
> >> >
> >> > I am collaborating with developing the bigmemory package and have run
> >> > in to
> >> > a strange problem when we run R CMD CHECK.  For some reason that
> >> > isn't
> >> > clear to us one of the examples crashes stating:
> >> >
> >> > Error:  memory could not be allocated for instance of type big.matrix
> >> >
> >> > You can see the output on the Travis CI page at
> >> > https://travis-ci.org/kaneplusplus/bigmemory where the error starts
> >> > at line
> >> > 1035.  This is completely reproducible when running
> >> > devtools::check(args='--as-cran') locally.  The part that is
> >> > confusing is
> >> > that the calls work perfectly when called interactively.
> >> >
> >> > Hadley comments on the 'check' page of his R packages website (
> >> > http://r-pkgs.had.co.nz/check.html) regarding test failing following
> >> > R CMD
> >> > check:
> >> >
> >> > Occasionally you may have a problem where the tests pass when run
> >> > interactively with devtools::test(), but fail when in R CMD check.
> >> > This
> >> > usually indicates that you?ve made a faulty assumption about the
> >> > testing
> >> > environment, and it?s often hard to figure it out.
> >> >
> >> > Any thoughts on how to troubleshoot this problem?  I have no idea
> >> > what
> >> > assumption we could have made.
> >>
> >> Note that R CMD check runs R with environment variables set as follows
> >> (at least on my system; you can check $R_HOME/bin/check to see what it does
> >> on yours):
> >>
> >>  R_DEFAULT_PACKAGES= LC_COLLATE=C
> >>
> >> So try staring R like this:
> >>
> >>  R_DEFAULT_PACKAGES= LC_COLLATE=C  R
> >>
> >> And see if that reproduces the test failure. The locale setting could
> >> affect tests of sort order, and the default package setting could
> >> potentially affect other things.
> >>
> >> Dan
> >>
> >>
> >>
> >> >
> >> > Regards,
> >> > Charles
> >> >
> >> >       [[alternative HTML version deleted]]
> >> >
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >> >
> >>
> >
> >
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From cgenolin at u-paris10.fr  Fri May 15 16:52:12 2015
From: cgenolin at u-paris10.fr (Christophe Genolini)
Date: Fri, 15 May 2015 16:52:12 +0200
Subject: [Rd] Defining Constant variable in a package
In-Reply-To: <CAOQ5NydrGVrOeP0VJ0_-Eyhq8YwgB4mny22-YWOFZp0O7pExUw@mail.gmail.com>
References: <5555BD3A.5000707@u-paris10.fr>
	<CAOQ5NydrGVrOeP0VJ0_-Eyhq8YwgB4mny22-YWOFZp0O7pExUw@mail.gmail.com>
Message-ID: <5556081C.7090706@u-paris10.fr>

Hi Michael,

It works perfectly, thanks a lot!

Christophe

> I'm guessing you just need to define them in /R/constants.R and then export() them from the NAMESPACE.
>
> On Fri, May 15, 2015 at 2:32 AM, Christophe Genolini <cgenolin at u-paris10.fr 
> <mailto:cgenolin at u-paris10.fr>> wrote:
>
>     Hi all,
>
>     In my package, I define some constant. In the previous version of R, I just define then in
>     "/data/constants.R" but it seems that it is no longer possible. Instead, I am asked to "define
>     them in the namespace". I am not sure to understand what it means. Shall I define them in the
>     NAMESPACE file?
>
>     Christophe
>
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


	[[alternative HTML version deleted]]


From simon.urbanek at r-project.org  Fri May 15 17:01:58 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 15 May 2015 11:01:58 -0400
Subject: [Rd] Alternative for wildcard gnu extension in Makevars
In-Reply-To: <CAFDcVCSmrMqQBKpSiXFimEp_RHg4DavQ5fNtxv306_+3Kmy4Jw@mail.gmail.com>
References: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>
	<21843.29537.86236.300996@max.nulle.part>
	<20150513180509.Horde.AU5NdWEwhY5VU3Y1ROC1FeA@webmailnew.dds.nl>
	<CABtg=KkyH5qj2wC_oeinru10+vVqfhD+rriDAj5TdeZnSkhekQ@mail.gmail.com>
	<CAJXgQP1NnY1WXgnGj87qcxPkamMYasLOUnFZ9VkRC2uK5Ec9nQ@mail.gmail.com>
	<CAFDcVCSmrMqQBKpSiXFimEp_RHg4DavQ5fNtxv306_+3Kmy4Jw@mail.gmail.com>
Message-ID: <1E6BEBA1-5F60-44B6-AE75-7D4EAD9DC4CB@r-project.org>

On May 13, 2015, at 2:28 PM, Henrik Bengtsson <henrik.bengtsson at ucsf.edu> wrote:

> While at it:  'Makevars' is an R invention (i.e. documentation of it
> is only available through the R docs), correct?  /Henrik
> 

Well, it's just a Makefile fragment that gets included along with the rest of the Makefiles, so for all practical purposes it's just a Makefile which implicitly includes R's makefile on top so you don't have to do that by hand.

Cheers,
Simon



> On Wed, May 13, 2015 at 10:10 AM, Kevin Ushey <kevinushey at gmail.com> wrote:
>> One other solution that's only a little crazy: you could have a R
>> function within your package that generates the appropriate (portable)
>> Makevars, and within the package `configure` script call that
>> function. For example"
>> 
>>    R --vanilla --slave -e "source('R/makevars.R'); makevars()"
>> 
>> And that 'makevars()' function could generate portable
>> 'Makevars(.win)' files for your package.
>> 
>> Kevin
>> 
>> On Wed, May 13, 2015 at 9:08 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>>> On Wed, May 13, 2015 at 12:05 PM, Jan van der Laan <rhelp at eoos.dds.nl>
>>> wrote:
>>> [...]
>>> 
>>>> Too bad. Since it is only a handful of files, I will probably move them
>>>> directly into the src directory and prefix them. It would have been nice to
>>>> have been able to keep them separate.
>>>> 
>>> 
>>> If it is a couple of files, then you can also just list them in SOURCES (or
>>> even just OBJECTS, with a .o suffix), and leave them where they are.
>>> 
>>> Gabor
>>> 
>>> [...]
>>> 
>>>        [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Fri May 15 21:54:17 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 15 May 2015 14:54:17 -0500
Subject: [Rd] Installation error with R-devel
Message-ID: <2f3a88$ldppo@ironport10.mayo.edu>

I have a local library with functions that interrogates an institution-specific web API, 
so is not of interest to anyone outside of Mayo.  For some reason the R CMD INSTALL 
command fails.  See below:

Build the library, then install it.

tmt-local2127% R CMD build dart
* checking for file ?dart/DESCRIPTION? ... OK
* preparing ?dart?:
* checking DESCRIPTION meta-information ... OK
* installing the package to build vignettes
* creating vignettes ... OK
* checking for LF line-endings in source and make files
* checking for empty or unneeded directories
* looking to see if a ?data/datalist? file should be added
* building ?dart_1.0-6.tar.gz?

tmt-local2128% R CMD INSTALL dart_1.0-6.tar.gz
* installing to library ?/home/therneau/Rlib?
* installing *source* package ?dart? ...
** R
** data
*** moving datasets to lazyload DB
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** installing vignettes
Warning in file(con, "w") :
   cannot open file '/home/therneau/Rlib/dart/doc/index.html': No such file or directory
Error in file(con, "w") : cannot open the connection
ERROR: installing vignettes failed
* removing ?/home/therneau/Rlib/dart?

-- The installation works ok if I build it with the no-build-vignettes option.
-- If I do that, I can cd to the vignettes directory and Sweave runs fine, i.e., 
library(dart) works
-- A call to "tar -tf dart_1.0-6.tar.gz" reveals that the inst directory has only a NEWS file.
-- R CMD check fails with the same message

Hints anyone?
Here is the sessionInfo() data

 > sessionInfo()
R Under development (unstable) (2015-05-14 r68368)
Platform: i686-pc-linux-gnu (32-bit)
Running under: Ubuntu 14.04.1 LTS

locale:
  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
  [9] LC_ADDRESS=C               LC_TELEPHONE=C
[11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C

attached base packages:
[1] stats     graphics  grDevices utils     datasets  methods base
 >


From kevinushey at gmail.com  Fri May 15 22:05:47 2015
From: kevinushey at gmail.com (Kevin Ushey)
Date: Fri, 15 May 2015 13:05:47 -0700
Subject: [Rd] Installation error with R-devel
In-Reply-To: <2f3a88$ldppo@ironport10.mayo.edu>
References: <2f3a88$ldppo@ironport10.mayo.edu>
Message-ID: <CAJXgQP0qTy9WW-3WJQZ_ZMytoZdfbHe9Bj+dFVOXzvUZz-f_yg@mail.gmail.com>

It's hard to diagnose this without your package sources / a
reproducible example.

Shot in the dark: one thing worth checking is that you don't have an
entry in your `.Rbuildignore` that's removing files you don't expect
it to (maybe that's causing R to strip out the 'doc/index.html' file)

Kevin

On Fri, May 15, 2015 at 12:54 PM, Therneau, Terry M., Ph.D.
<therneau at mayo.edu> wrote:
> I have a local library with functions that interrogates an
> institution-specific web API, so is not of interest to anyone outside of
> Mayo.  For some reason the R CMD INSTALL command fails.  See below:
>
> Build the library, then install it.
>
> tmt-local2127% R CMD build dart
> * checking for file ?dart/DESCRIPTION? ... OK
> * preparing ?dart?:
> * checking DESCRIPTION meta-information ... OK
> * installing the package to build vignettes
> * creating vignettes ... OK
> * checking for LF line-endings in source and make files
> * checking for empty or unneeded directories
> * looking to see if a ?data/datalist? file should be added
> * building ?dart_1.0-6.tar.gz?
>
> tmt-local2128% R CMD INSTALL dart_1.0-6.tar.gz
> * installing to library ?/home/therneau/Rlib?
> * installing *source* package ?dart? ...
> ** R
> ** data
> *** moving datasets to lazyload DB
> ** inst
> ** preparing package for lazy loading
> ** help
> *** installing help indices
> ** building package indices
> ** installing vignettes
> Warning in file(con, "w") :
>   cannot open file '/home/therneau/Rlib/dart/doc/index.html': No such file
> or directory
> Error in file(con, "w") : cannot open the connection
> ERROR: installing vignettes failed
> * removing ?/home/therneau/Rlib/dart?
>
> -- The installation works ok if I build it with the no-build-vignettes
> option.
> -- If I do that, I can cd to the vignettes directory and Sweave runs fine,
> i.e., library(dart) works
> -- A call to "tar -tf dart_1.0-6.tar.gz" reveals that the inst directory has
> only a NEWS file.
> -- R CMD check fails with the same message
>
> Hints anyone?
> Here is the sessionInfo() data
>
>> sessionInfo()
> R Under development (unstable) (2015-05-14 r68368)
> Platform: i686-pc-linux-gnu (32-bit)
> Running under: Ubuntu 14.04.1 LTS
>
> locale:
>  [1] LC_CTYPE=en_US.UTF-8       LC_NUMERIC=C
>  [3] LC_TIME=en_US.UTF-8        LC_COLLATE=C
>  [5] LC_MONETARY=en_US.UTF-8    LC_MESSAGES=en_US.UTF-8
>  [7] LC_PAPER=en_US.UTF-8       LC_NAME=C
>  [9] LC_ADDRESS=C               LC_TELEPHONE=C
> [11] LC_MEASUREMENT=en_US.UTF-8 LC_IDENTIFICATION=C
>
> attached base packages:
> [1] stats     graphics  grDevices utils     datasets  methods base
>>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From therneau at mayo.edu  Fri May 15 22:12:51 2015
From: therneau at mayo.edu (Therneau, Terry M., Ph.D.)
Date: Fri, 15 May 2015 15:12:51 -0500
Subject: [Rd] Installation error with R-devel --solved
In-Reply-To: <CAJXgQP0qTy9WW-3WJQZ_ZMytoZdfbHe9Bj+dFVOXzvUZz-f_yg@mail.gmail.com>
References: <2f3a88$ldppo@ironport10.mayo.edu>
	<CAJXgQP0qTy9WW-3WJQZ_ZMytoZdfbHe9Bj+dFVOXzvUZz-f_yg@mail.gmail.com>
Message-ID: <2f3a88$le030@ironport10.mayo.edu>

Bingo!  So very obvious once it was pointed out.

Thanks,
    Terry

On 05/15/2015 03:05 PM, Kevin Ushey wrote:
> It's hard to diagnose this without your package sources / a
> reproducible example.
>
> Shot in the dark: one thing worth checking is that you don't have an
> entry in your `.Rbuildignore` that's removing files you don't expect
> it to (maybe that's causing R to strip out the 'doc/index.html' file)
>
> Kevin


From htl10 at users.sourceforge.net  Sat May 16 07:22:47 2015
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Sat, 16 May 2015 06:22:47 +0100
Subject: [Rd] That 'make check-all' problem with the survival package
Message-ID: <1431753767.50109.YahooMailBasic@web172306.mail.ir2.yahoo.com>

'make check-all' for current R has been showing this error in the middle
for a few months now - any thought on fixing this? I think cmprsk
should be either included in the recommended bundle, or
the survival vignette to not depend on it. Having 'make check-all' showing
glaring ERROR's for a few months seems to defeat the purpose of
doing any checking at all via 'make check-all'.

FWIW, I did look at when/how the issue was introduced, but it appeared
that svn://svn.r-forge.r-project.org/svnroot/survival is no longer being
updated, and git://github.com/cran/survival.git only shows release jumps.
Anyway, if first appears with survival 2.38-1 in February, and as the previous
2.37-7 was 13 months older, this info is of no use to anybody.
I didn't write earlier as I thought the issue would go away at some point;
but obviously this isn't the case after 3 months.

-----------------------------------------------
 ERROR
Errors in running code in vignettes:
when running code in ?compete.Rnw?
  ...
> temp$fstat <- as.numeric(event)

> temp$msex <- with(temp, 1 * (sex == "M"))

> fgfit1 <- with(temp, crr(etime, fstat, cov1 = cbind(age, 
+     msex, mspike), failcode = 2, cencode = 1, variance = TRUE))

  When sourcing ?compete.R?:
Error: could not find function "crr"
Execution halted

* checking re-building of vignette outputs ... NOTE
Error in re-building vignettes:
  ...
Warning in coxph(Surv(futime, death) ~ group:age2 + sex + strata(group),  :
  X matrix deemed to be singular; variable 23 24 25
Loading required package: cmprsk
Warning in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
  there is no package called ?cmprsk?

Error: processing vignette 'compete.Rnw' failed with diagnostics:
 chunk 15 (label = finegray) 
Error in eval(expr, envir, enclos) : could not find function "crr"
Execution halted


From january.weiner at gmail.com  Sat May 16 09:39:48 2015
From: january.weiner at gmail.com (January Weiner)
Date: Sat, 16 May 2015 09:39:48 +0200
Subject: [Rd] Creating a vignette which depends on a non-distributable
	file
In-Reply-To: <555534D5.1020803@fredhutch.org>
References: <CA+A1kV5uemT7obxhpYu6JA5t2Dpoq7UVVowCOYKV6+dfou0qeA@mail.gmail.com>
	<CAFDcVCS7_2LQNtje3H9iNQ=_mLmk1cWqGNLiDzG1KuvxduhDcw@mail.gmail.com>
	<555534D5.1020803@fredhutch.org>
Message-ID: <CA+A1kV4KLN8yhwfNFOyUZX1uZ5ZJ4jwXxk9uUaEpCfCrLwEQNg@mail.gmail.com>

Dear Martin,

thank you for the food for thought. My package does not depend on MSigDB
(it implements something better than MSigDB), but being able to work with
MSigDB (for comparative purposes) is important. Also, Bioconductor makes
sense only if you really want to take advantage of the Bioconductor
structures / tools, which I don't.

However, I find your suggestion with eval=FALSE and data subsets very good,
I will implement it, using hidden sections to simulate the output, thanks!

Kind regards,

j.


On 15 May 2015 at 01:50, Martin Morgan <mtmorgan at fredhutch.org> wrote:

> On 05/14/2015 04:33 PM, Henrik Bengtsson wrote:
>
>> On May 14, 2015 15:04, "January Weiner" <january.weiner at gmail.com> wrote:
>>
>>>
>>> Dear all,
>>>
>>> I am writing a vignette that requires a file which I am not allowed to
>>> distribute, but which the user can easily download manually. Moreover, it
>>> is not possible to download this file automatically from R: downloading
>>> requires a (free) registration that seems to work only through a browser.
>>> (I'm talking here about the MSigDB from the Broad Institute,
>>> http://www.broadinstitute.org/gsea/msigdb/index.jsp).
>>>
>>> In the vignette, I tell the user to download the file and then show how
>>> it
>>> can be parsed and used in R. Thus, I can compile the vignette only if
>>> this
>>> file is present in the vignettes/ directory of the package. However, it
>>> would then get included in the package -- which I am not allowed to do.
>>>
>>> What should I do?
>>>
>>> (1) finding an alternative to MSigDB is not a solution -- there simply is
>>> no alternative.
>>> (2) I could enter the code (and the results) in a verbatim environment
>>> instead of using Sweave. This has obvious drawbacks (for one thing, it
>>> would look incosistent).
>>>
>>
> use the chunk argument eval=FALSE instead of placing the code in a
> verbatim argument. See ?RweaveLatex if you're compiling a PDF vignette from
> Rnw or the knitr documentation for (much nicer for users of your vignette,
> in my opinion) Rmd vignettes processed to HTML.
>
> A common pattern is to process chunks 1, 2, 3, 4, and then there is a
> 'leap of faith' in chunk 5 (with eval=FALSE) and a second chunk (maybe with
> echo=FALSE, eval=TRUE) that reads the _result_ that would have been
> produced by chunk 5 from a serialized instance into the R session for
> processing in chunks 6, 7, 8...
>
> Also very often while it might make sense to analyse an entire data set as
> part of a typical work flow, for illustrative purposes a much smaller
> subset or simulated data might be relevant; again a strategy would be to
> illustrate the problematic steps with simulated data, and then resume the
> narrative with the analyzed full data.
>
> A secondary consideration may be that if your package _requires_ MSigDB to
> function, then it can't be automatically tested by repository build
> machines -- you'll want to have unit tests or other approaches to ensure
> that 'bit rot' does not set in without you being aware of it.
>
> If this is a Bioconductor package, then it's appropriate to ask on the
> Bioconductor devel mailing list.
>
>   http://bioconductor.org/developers/
>
> http://bioconductor.org/packages/BiocStyle/ might be your friend for
> producing stylish vignettes.
>
> Martin
>
>
>  (3) I could build vignette outside of the package and put it into the
>>> inst/doc directory. This also has obvious drawbacks.
>>> (4) Leaving this example out defies the purpose of my package.
>>>
>>> I am tending towards solution (2). What do you think?
>>>
>>
>> Not clear how big of a static piece you're taking about, but maybe you
>> could set it up such that you use (2) as a fallback, i.e. have the
>> vignette
>> include a static/pre-generated piece (which is clearly marked as such)
>> only
>> if the external dependency is not available.
>>
>> Just a thought
>>
>> Henrik
>>
>>
>>> Kind regards,
>>>
>>> j.
>>>
>>>
>>>
>>> --
>>> -------- January Weiner --------------------------------------
>>>
>>>          [[alternative HTML version deleted]]
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>



-- 
-------- January Weiner --------------------------------------

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Sat May 16 09:04:52 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Sat, 16 May 2015 09:04:52 +0200
Subject: [Rd] That 'make check-all' problem with the survival package
In-Reply-To: <1431753767.50109.YahooMailBasic@web172306.mail.ir2.yahoo.com>
References: <1431753767.50109.YahooMailBasic@web172306.mail.ir2.yahoo.com>
Message-ID: <5556EC14.9020005@statistik.tu-dortmund.de>

Not sure why this goes to R-devel. You just could have asked the 
maintainer. Terry Therneau is aware of it and promised he will fix it.

Best,
Uwe Ligges

On 16.05.2015 07:22, Hin-Tak Leung wrote:
> 'make check-all' for current R has been showing this error in the middle
> for a few months now - any thought on fixing this? I think cmprsk
> should be either included in the recommended bundle, or
> the survival vignette to not depend on it. Having 'make check-all' showing
> glaring ERROR's for a few months seems to defeat the purpose of
> doing any checking at all via 'make check-all'.
>
> FWIW, I did look at when/how the issue was introduced, but it appeared
> that svn://svn.r-forge.r-project.org/svnroot/survival is no longer being
> updated, and git://github.com/cran/survival.git only shows release jumps.
> Anyway, if first appears with survival 2.38-1 in February, and as the previous
> 2.37-7 was 13 months older, this info is of no use to anybody.
> I didn't write earlier as I thought the issue would go away at some point;
> but obviously this isn't the case after 3 months.
>
> -----------------------------------------------
>   ERROR
> Errors in running code in vignettes:
> when running code in ?compete.Rnw?
>    ...
>> temp$fstat <- as.numeric(event)
>
>> temp$msex <- with(temp, 1 * (sex == "M"))
>
>> fgfit1 <- with(temp, crr(etime, fstat, cov1 = cbind(age,
> +     msex, mspike), failcode = 2, cencode = 1, variance = TRUE))
>
>    When sourcing ?compete.R?:
> Error: could not find function "crr"
> Execution halted
>
> * checking re-building of vignette outputs ... NOTE
> Error in re-building vignettes:
>    ...
> Warning in coxph(Surv(futime, death) ~ group:age2 + sex + strata(group),  :
>    X matrix deemed to be singular; variable 23 24 25
> Loading required package: cmprsk
> Warning in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
>    there is no package called ?cmprsk?
>
> Error: processing vignette 'compete.Rnw' failed with diagnostics:
>   chunk 15 (label = finegray)
> Error in eval(expr, envir, enclos) : could not find function "crr"
> Execution halted
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From htl10 at users.sourceforge.net  Sat May 16 13:11:52 2015
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Sat, 16 May 2015 12:11:52 +0100
Subject: [Rd] That 'make check-all' problem with the survival package
Message-ID: <1431774712.43493.BPMail_high_carrier@web172306.mail.ir2.yahoo.com>



------------------------------
On Sat, May 16, 2015 8:04 AM BST Uwe Ligges wrote:

>Not sure why this goes to R-devel. You just could have asked the 
>maintainer. Terry Therneau is aware of it and promised he will fix it.
>

The quickest fix is to add cmprsk to the recommended list , and that's is an R-devel issue.

>On 16.05.2015 07:22, Hin-Tak Leung wrote:
>> 'make check-all' for current R has been showing this error in the middle
>> for a few months now - any thought on fixing this? I think cmprsk
>> should be either included in the recommended bundle, or
>> the survival vignette to not depend on it. Having 'make check-all' showing
>> glaring ERROR's for a few months seems to defeat the purpose of
>> doing any checking at all via 'make check-all'.
>>
>> FWIW, I did look at when/how the issue was introduced, but it appeared
>> that svn://svn.r-forge.r-project.org/svnroot/survival is no longer being
>> updated, and git://github.com/cran/survival.git only shows release jumps.
>> Anyway, if first appears with survival 2.38-1 in February, and as the previous
>> 2.37-7 was 13 months older, this info is of no use to anybody.
>> I didn't write earlier as I thought the issue would go away at some point;
>> but obviously this isn't the case after 3 months.
>>
>> -----------------------------------------------
>>   ERROR
>> Errors in running code in vignettes:
>> when running code in ?compete.Rnw?
>>    ...
>> temp$fstat <- as.numeric(event)
>>
>> temp$msex <- with(temp, 1 * (sex == "M"))
>>
>> fgfit1 <- with(temp, crr(etime, fstat, cov1 = cbind(age,
>> +     msex, mspike), failcode = 2, cencode = 1, variance = TRUE))
>>
>>    When sourcing ?compete.R?:
>> Error: could not find function "crr"
>> Execution halted
>>
>> * checking re-building of vignette outputs ... NOTE
>> Error in re-building vignettes:
>>    ...
>> Warning in coxph(Surv(futime, death) ~ group:age2 + sex + strata(group),  :
>>    X matrix deemed to be singular; variable 23 24 25
>> Loading required package: cmprsk
>> Warning in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
>>    there is no package called ?cmprsk?
>>
>> Error: processing vignette 'compete.Rnw' failed with diagnostics:
>>   chunk 15 (label = finegray)
>> Error in eval(expr, envir, enclos) : could not find function "crr"
>> Execution halted
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>


From edd at debian.org  Sat May 16 15:29:53 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 16 May 2015 08:29:53 -0500
Subject: [Rd] That 'make check-all' problem with the survival package
In-Reply-To: <1431774712.43493.BPMail_high_carrier@web172306.mail.ir2.yahoo.com>
References: <1431774712.43493.BPMail_high_carrier@web172306.mail.ir2.yahoo.com>
Message-ID: <21847.18001.574334.295751@max.nulle.part>


On 16 May 2015 at 12:11, Hin-Tak Leung wrote:
| The quickest fix is to add cmprsk to the recommended list , and that's is an R-devel issue.

Given that the set of recommended packages seems to change about once a
decade (give or take a few years as measurement error on my side) I am not
sure I agree with your use of the term "quickest" here.

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From marc_schwartz at me.com  Sat May 16 15:33:53 2015
From: marc_schwartz at me.com (Marc Schwartz)
Date: Sat, 16 May 2015 08:33:53 -0500
Subject: [Rd] That 'make check-all' problem with the survival package
In-Reply-To: <1431774712.43493.BPMail_high_carrier@web172306.mail.ir2.yahoo.com>
References: <1431774712.43493.BPMail_high_carrier@web172306.mail.ir2.yahoo.com>
Message-ID: <307A5F35-71BA-4648-8494-D594B7626F61@me.com>


> On May 16, 2015, at 6:11 AM, Hin-Tak Leung <htl10 at users.sourceforge.net> wrote:
> 
> 
> 
> ------------------------------
> On Sat, May 16, 2015 8:04 AM BST Uwe Ligges wrote:
> 
>> Not sure why this goes to R-devel. You just could have asked the 
>> maintainer. Terry Therneau is aware of it and promised he will fix it.
>> 
> 
> The quickest fix is to add cmprsk to the recommended list , and that's is an R-devel issue.


Actually, the easiest solution would be for Terry to either modify relevant code according to:

  http://cran.r-project.org/doc/manuals/r-release/R-exts.html#Suggested-packages

or perhaps better, as noted, to remove the need for cmprsk at all.

The latter raises the philosophical issue as to whether or not a Recommended package should or really needs to have any connections at all to third party CRAN packages. It seems to me that the default R distribution of ?Base? and ?Recommended? packages should be able to fully run in a stand alone manner without any declared external connections to other non-default packages.

The only other Recommended package that I found that has such a connection is nlme, which has a Suggests for Frank?s Hmisc. However, based upon a grep review of the package contents, there are only two code based references to Hmisc that I located:

./R/newFunc.R:264:      ## e.g. Hmisc's "labelled"
./tests/augPred_lab.R:2:if(require("Hmisc")) {

Neither of which is really needed (the first being a comment only, so benign) and of course the latter goes against the current guidance in R-exts. The second, within the if() code, uses the Hmisc label() function, which it seems to me is not really needed here.

Regards,

Marc Schwartz


> 
>> On 16.05.2015 07:22, Hin-Tak Leung wrote:
>>> 'make check-all' for current R has been showing this error in the middle
>>> for a few months now - any thought on fixing this? I think cmprsk
>>> should be either included in the recommended bundle, or
>>> the survival vignette to not depend on it. Having 'make check-all' showing
>>> glaring ERROR's for a few months seems to defeat the purpose of
>>> doing any checking at all via 'make check-all'.
>>> 
>>> FWIW, I did look at when/how the issue was introduced, but it appeared
>>> that svn://svn.r-forge.r-project.org/svnroot/survival is no longer being
>>> updated, and git://github.com/cran/survival.git only shows release jumps.
>>> Anyway, if first appears with survival 2.38-1 in February, and as the previous
>>> 2.37-7 was 13 months older, this info is of no use to anybody.
>>> I didn't write earlier as I thought the issue would go away at some point;
>>> but obviously this isn't the case after 3 months.
>>> 
>>> -----------------------------------------------
>>>  ERROR
>>> Errors in running code in vignettes:
>>> when running code in ?compete.Rnw?
>>>   ...
>>> temp$fstat <- as.numeric(event)
>>> 
>>> temp$msex <- with(temp, 1 * (sex == "M"))
>>> 
>>> fgfit1 <- with(temp, crr(etime, fstat, cov1 = cbind(age,
>>> +     msex, mspike), failcode = 2, cencode = 1, variance = TRUE))
>>> 
>>>   When sourcing ?compete.R?:
>>> Error: could not find function "crr"
>>> Execution halted
>>> 
>>> * checking re-building of vignette outputs ... NOTE
>>> Error in re-building vignettes:
>>>   ...
>>> Warning in coxph(Surv(futime, death) ~ group:age2 + sex + strata(group),  :
>>>   X matrix deemed to be singular; variable 23 24 25
>>> Loading required package: cmprsk
>>> Warning in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,  :
>>>   there is no package called ?cmprsk?
>>> 
>>> Error: processing vignette 'compete.Rnw' failed with diagnostics:
>>>  chunk 15 (label = finegray)
>>> Error in eval(expr, envir, enclos) : could not find function "crr"
>>> Execution halted
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From luke-tierney at uiowa.edu  Sat May 16 17:05:43 2015
From: luke-tierney at uiowa.edu (luke-tierney at uiowa.edu)
Date: Sat, 16 May 2015 10:05:43 -0500
Subject: [Rd] Why is the diag function so slow (for extraction)?
In-Reply-To: <CAFDcVCTs+EXzjfNJAygaq2-oe19-EvVjwZgLHfxLGDA9i_fstQ@mail.gmail.com>
References: <1430762350040-4706780.post@n4.nabble.com>
	<06F749E7-5096-438D-A299-667C7A77B477@gmail.com>
	<alpine.DEB.2.10.1505050844470.2460@luke-Latitude>
	<CAAVP=akUU10FPvkYhNBVQzi9jsMkCma-VVGgSqjGMpKF+G_4zA@mail.gmail.com>
	<21841.62252.436947.835265@stat.math.ethz.ch>
	<CAFDcVCQKCpJxkXq-gKcKg0UkAWS16mp8UJEQec83=42bQuFy2g@mail.gmail.com>
	<CAFDcVCTs+EXzjfNJAygaq2-oe19-EvVjwZgLHfxLGDA9i_fstQ@mail.gmail.com>
Message-ID: <alpine.DEB.2.10.1505161003520.2619@luke-Latitude>

Changing from c(x)[...] to x[...] without a pre-test does not seem to
cause any issues on CRAN or BIOC so that is done now in R-devel and
R-patched.

Best,

luke

On Wed, 13 May 2015, Henrik Bengtsson wrote:

> As kindly pointed out to me (oh my decaying gray matter), is.object()
> is better suited for this test;
>
> $ svn diff src/library/base/R/diag.R
> Index: src/library/base/R/diag.R
> ===================================================================
> --- src/library/base/R/diag.R   (revision 68345)
> +++ src/library/base/R/diag.R   (working copy)
> @@ -23,9 +23,11 @@
>             stop("'nrow' or 'ncol' cannot be specified when 'x' is a matrix")
>
>         if((m <- min(dim(x))) == 0L) return(vector(typeof(x), 0L))
> +        nms <- dimnames(x)
> +        nrow <- dim(x)[1L]
>         ## NB: need double index to avoid overflows.
> -        y <- c(x)[1 + 0L:(m - 1L) * (dim(x)[1L] + 1)]
> -        nms <- dimnames(x)
> +        if (is.object(x)) x <- c(x)
>
> /Henrik
>
> On Tue, May 12, 2015 at 8:24 PM, Henrik Bengtsson
> <henrik.bengtsson at ucsf.edu> wrote:
>> Along Luke's lines, would(n't) it be enough to look for existence of
>> attribute 'class' to decide whether to dispatch or not, i.e. if c() is
>> needed or not?  Even without .subset(), there is a remarkable
>> improvement.  I think it's worth condition the code on dispatch or
>> not.  For example:
>>
>> [HB-X201]{hb}: svn diff diag.R
>> Index: diag.R
>> ===================================================================
>> --- diag.R      (revision 68345)
>> +++ diag.R      (working copy)
>> @@ -23,9 +23,11 @@
>>              stop("'nrow' or 'ncol' cannot be specified when 'x' is a matrix")
>>
>>          if((m <- min(dim(x))) == 0L) return(vector(typeof(x), 0L))
>> +        nms <- dimnames(x)
>> +        nrow <- dim(x)[1L]
>>          ## NB: need double index to avoid overflows.
>> -        y <- c(x)[1 + 0L:(m - 1L) * (dim(x)[1L] + 1)]
>> -        nms <- dimnames(x)
>> +        if (!is.null(attr(x, "class"))) x <- c(x)
>> +        y <- x[1 + 0L:(m - 1L) * (nrow + 1)]
>>          if (is.list(nms) && !any(sapply(nms, is.null)) &&
>>              identical((nm <- nms[[1L]][seq_len(m)]), nms[[2L]][seq_len(m)]))
>>              names(y) <- nm
>>
>> ?
>>
>> /Henrik
>>
>> On Tue, May 12, 2015 at 5:33 AM, Martin Maechler
>> <maechler at lynne.stat.math.ethz.ch> wrote:
>>>>>>>> Steve Bronder <sbronder at stevebronder.com>
>>>>>>>>     on Thu, 7 May 2015 11:49:49 -0400 writes:
>>>
>>>    > Is it possible to replace c() with .subset()?
>>>
>>> It would be possible, but I think "entirely" wrong.
>>>
>>> .subset() is documented to be an internal function not to be
>>> used "lightly" and more to the point it is documented to *NOT*
>>> dispatch at all.
>>>
>>> If you read and understood what Peter and Luke wrote, you'd not
>>> special case here:
>>>
>>> diag() should not work only for pure matrices, but for all
>>> "matrix-like" objects for which ``the usual methods'' work, such
>>> as
>>>    as.vector(.), c(.)
>>>
>>> That's why there has been the c(.) in there.
>>>
>>> You can always make code faster if you write the code so it only
>>> has to work in one special case .. and work there very fast.
>>>
>>>
>>>    > Example below
>>>    > ####
>>>    > ####
>>>
>>>    > library(microbenchmark)
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Luke Tierney
Ralph E. Wareham Professor of Mathematical Sciences
University of Iowa                  Phone:             319-335-3386
Department of Statistics and        Fax:               319-335-3017
    Actuarial Science
241 Schaeffer Hall                  email:   luke-tierney at uiowa.edu
Iowa City, IA 52242                 WWW:  http://www.stat.uiowa.edu


From henrik.bengtsson at ucsf.edu  Sat May 16 19:15:31 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Sat, 16 May 2015 10:15:31 -0700
Subject: [Rd] Alternative for wildcard gnu extension in Makevars
In-Reply-To: <1E6BEBA1-5F60-44B6-AE75-7D4EAD9DC4CB@r-project.org>
References: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>
	<21843.29537.86236.300996@max.nulle.part>
	<20150513180509.Horde.AU5NdWEwhY5VU3Y1ROC1FeA@webmailnew.dds.nl>
	<CABtg=KkyH5qj2wC_oeinru10+vVqfhD+rriDAj5TdeZnSkhekQ@mail.gmail.com>
	<CAJXgQP1NnY1WXgnGj87qcxPkamMYasLOUnFZ9VkRC2uK5Ec9nQ@mail.gmail.com>
	<CAFDcVCSmrMqQBKpSiXFimEp_RHg4DavQ5fNtxv306_+3Kmy4Jw@mail.gmail.com>
	<1E6BEBA1-5F60-44B6-AE75-7D4EAD9DC4CB@r-project.org>
Message-ID: <CAFDcVCRs2i12dCSKXa8D5LX5gmBOtz1M2Jf9DjSy4nrPiZmK3g@mail.gmail.com>

On Fri, May 15, 2015 at 8:01 AM, Simon Urbanek
<simon.urbanek at r-project.org> wrote:
> On May 13, 2015, at 2:28 PM, Henrik Bengtsson <henrik.bengtsson at ucsf.edu> wrote:
>
>> While at it:  'Makevars' is an R invention (i.e. documentation of it
>> is only available through the R docs), correct?  /Henrik
>>
>
> Well, it's just a Makefile fragment that gets included along with the rest of the Makefiles, so for all practical purposes it's just a Makefile which implicitly includes R's makefile on top so you don't have to do that by hand.

Thanks for confirming.

/Henrik

>
> Cheers,
> Simon
>
>
>
>> On Wed, May 13, 2015 at 10:10 AM, Kevin Ushey <kevinushey at gmail.com> wrote:
>>> One other solution that's only a little crazy: you could have a R
>>> function within your package that generates the appropriate (portable)
>>> Makevars, and within the package `configure` script call that
>>> function. For example"
>>>
>>>    R --vanilla --slave -e "source('R/makevars.R'); makevars()"
>>>
>>> And that 'makevars()' function could generate portable
>>> 'Makevars(.win)' files for your package.
>>>
>>> Kevin
>>>
>>> On Wed, May 13, 2015 at 9:08 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>>>> On Wed, May 13, 2015 at 12:05 PM, Jan van der Laan <rhelp at eoos.dds.nl>
>>>> wrote:
>>>> [...]
>>>>
>>>>> Too bad. Since it is only a handful of files, I will probably move them
>>>>> directly into the src directory and prefix them. It would have been nice to
>>>>> have been able to keep them separate.
>>>>>
>>>>
>>>> If it is a couple of files, then you can also just list them in SOURCES (or
>>>> even just OBJECTS, with a .o suffix), and leave them where they are.
>>>>
>>>> Gabor
>>>>
>>>> [...]
>>>>
>>>>        [[alternative HTML version deleted]]
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From Virgil.Smith at flir.com  Sat May 16 22:13:32 2015
From: Virgil.Smith at flir.com (Smith, Virgil)
Date: Sat, 16 May 2015 20:13:32 +0000
Subject: [Rd] Installation using iconv from glibc
In-Reply-To: <5555A333.9090801@stats.ox.ac.uk>
References: <F14AEF751653024287138321000C846AF48222D4@BOS-DAG1.zone1.flir.net>
	<5555A333.9090801@stats.ox.ac.uk>
Message-ID: <F14AEF751653024287138321000C846AF4829577@BOS-DAG1.zone1.flir.net>

> > Is glibc is actually compatible (and/or is gnu libiconv essentially the only path)?
>
> R is built daily on Fedora 21 Linux which uses glibc 2.20 and has been for at least
> a decade with that and earlier versions of glibc.  No problems with installing
> using glibc have been reported in all that time (and many dialects of Linux have
> been used successfully).

Thank you for confirming that something stranger than my libiconv implementation
 selection must have been (and was) wrong with my environment.

Extracting the relevant test from the configure script and some manual hacking
showed that iconv_open worked for all of the tests except those involving
"latin1".  So some research revealed glibc's gconv uses plugin modules for
conversions and sure enough I was missing the ISO8859-1 module, a.k.a.
"latin1".  I got that compiled/installed and the configure tests passed.



> > If glibc should work, what should I check to troubleshoot my environment?
> >
> > The configure error I get is
> >      checking iconv.h usability... yes
> >      checking iconv.h presence... yes
> >      checking for iconv.h... yes
> >      checking for iconv... yes
> >      checking whether iconv accepts "UTF-8", "latin1", "ASCII" and "UCS-*"... no
> >      configure: error: a suitable iconv is essential
>
> You look in config.log for the details we cannot even guess at.

Sorry for the omission.  The log didn't seem to show anything other than that
the one specific test failed and I did not want to waste anyone's time combing
the log if it seemed my problem was very system specific rather than the
confusion of a novice user.

Thank you for being willing to dive deeper and my apologies if I consumed
more of anyone's time by NOT including more detail.

-- Virgil Smith

________________________________

Notice to recipient: This email is meant for only the intended recipient of the transmission, and may be a communication privileged by law, subject to export control restrictions or that otherwise contains proprietary information. If you receive this email by mistake, please notify us immediately by replying to this message and then destroy it and do not review, disclose, copy or distribute it. Thank you in advance for your cooperation.

From dongcan.jiang at gmail.com  Sun May 17 13:13:51 2015
From: dongcan.jiang at gmail.com (Dongcan Jiang)
Date: Sun, 17 May 2015 19:13:51 +0800
Subject: [Rd] The function cummax() seems to have a bug.
Message-ID: <CABwkPcou67H_t_zuncSNbnsyYVstcTT87FAtw9gqRPi7Z00FFQ@mail.gmail.com>

Hi,

The function cummax() seems to have a bug.

> x <- c(NA, 0)
> storage.mode(x) <- "integer"
> cummax(x)
[1] NA  0

The correct result of this case should be NA NA. The mistake in [
https://github.com/wch/r-source/blob/trunk/src/main/cum.c#L130-L136] may be
the reason.

Best Regards,
Dongcan

-- 
Dongcan Jiang
Team of Search Engine & Web Mining
School of Electronic Engineering & Computer Science
Peking University, Beijing, 100871, P.R.China

	[[alternative HTML version deleted]]


From htl10 at users.sourceforge.net  Mon May 18 00:19:30 2015
From: htl10 at users.sourceforge.net (Hin-Tak Leung)
Date: Sun, 17 May 2015 23:19:30 +0100
Subject: [Rd] That 'make check-all' problem with the survival package
Message-ID: <1431901170.59928.YahooMailBasic@web172301.mail.ir2.yahoo.com>

------------------------------
On Sat, May 16, 2015 2:33 PM BST Marc Schwartz wrote:

>
>> On May 16, 2015, at 6:11 AM, Hin-Tak Leung <htl10 at users.sourceforge.net> wrote:
>> 
>> 
>> 
>> ------------------------------
>> On Sat, May 16, 2015 8:04 AM BST Uwe Ligges wrote:
>> 
>> Not sure why this goes to R-devel. You just could have asked the 
>> maintainer. Terry Therneau is aware of it and promised he will fix it.
>> 
>> 
>> The quickest fix is to add cmprsk to the recommended list , and that's is an R-devel issue.
>
>
>Actually, the easiest solution would be for Terry to either modify relevant code according to:
>
>? http://cran.r-project.org/doc/manuals/r-release/R-exts.html#Suggested-packages
>
>or perhaps better, as noted, to remove the need for cmprsk at all.
>

We shall disagree on what is "quickest" - one other option I did not mention is to back
out the version upgrade to 2.38-1 in February, and ship the previous 2.37-7.

I trust that Terry made the addition for good reasons. So my thoughts are geared more towards
how to accommodate the new addition, rather than revert/remove it.
(though I'd be happier to isolate a smaller change than a bulk 2.37-7 -> 2.38.1 upgrade
and think more about that. Hence the mention of the repositories.).

>The latter raises the philosophical issue as to whether or not a Recommended package should or really needs to have any connections at all to third party CRAN packages. It seems to me that the default R distribution of ?Base? and ?Recommended? packages should be able to fully run in a stand alone manner without any declared external connections to other non-default packages.
>
>The only other Recommended package that I found that has such a connection is nlme, which has a Suggests for Frank?s Hmisc. However, based upon a grep review of the package contents, there are only two code based references to Hmisc that I located:
>
>./R/newFunc.R:264:? ? ? ## e.g. Hmisc's "labelled"
>./tests/augPred_lab.R:2:if(require("Hmisc")) {
>
>Neither of which is really needed (the first being a comment only, so benign) and of course the latter goes against the current guidance in R-exts. The second, within the if() code, uses the Hmisc label() function, which it seems to me is not really needed here.
>
>Regards,
>
>Marc Schwartz
>
>
>> 
>> On 16.05.2015 07:22, Hin-Tak Leung wrote:
>>> 'make check-all' for current R has been showing this error in the middle
>>> for a few months now - any thought on fixing this? I think cmprsk
>>> should be either included in the recommended bundle, or
>>> the survival vignette to not depend on it. Having 'make check-all' showing
>>> glaring ERROR's for a few months seems to defeat the purpose of
>>> doing any checking at all via 'make check-all'.
>>> 
>>> FWIW, I did look at when/how the issue was introduced, but it appeared
>>> that svn://svn.r-forge.r-project.org/svnroot/survival is no longer being
>>> updated, and git://github.com/cran/survival.git only shows release jumps.
>>> Anyway, if first appears with survival 2.38-1 in February, and as the previous
>>> 2.37-7 was 13 months older, this info is of no use to anybody.
>>> I didn't write earlier as I thought the issue would go away at some point;
>>> but obviously this isn't the case after 3 months.
>>> 
>>> -----------------------------------------------
>>>? ERROR
>>> Errors in running code in vignettes:
>>> when running code in ?compete.Rnw?
>>>???...
>>> temp$fstat <- as.numeric(event)
>>> 
>>> temp$msex <- with(temp, 1 * (sex == "M"))
>>> 
>>> fgfit1 <- with(temp, crr(etime, fstat, cov1 = cbind(age,
>>> +? ???msex, mspike), failcode = 2, cencode = 1, variance = TRUE))
>>> 
>>>???When sourcing ?compete.R?:
>>> Error: could not find function "crr"
>>> Execution halted
>>> 
>>> * checking re-building of vignette outputs ... NOTE
>>> Error in re-building vignettes:
>>>???...
>>> Warning in coxph(Surv(futime, death) ~ group:age2 + sex + strata(group),? :
>>>???X matrix deemed to be singular; variable 23 24 25
>>> Loading required package: cmprsk
>>> Warning in library(package, lib.loc = lib.loc, character.only = TRUE, logical.return = TRUE,? :
>>>???there is no package called ?cmprsk?
>>> 
>>> Error: processing vignette 'compete.Rnw' failed with diagnostics:
>>>? chunk 15 (label = finegray)
>>> Error in eval(expr, envir, enclos) : could not find function "crr"
>>> Execution halted
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From henrik.bengtsson at ucsf.edu  Mon May 18 02:13:15 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Sun, 17 May 2015 17:13:15 -0700
Subject: [Rd] install.packages() / update.packages() sometimes outputs to
 stdout and sometimes to stderr [and menu() & readline()]
Message-ID: <CAFDcVCTBW7NTa7YkK+avA9g0TA=kV2oOvVbH6YVMTOE7PukVjQ@mail.gmail.com>

I've noticed that install.packages()
[https://svn.r-project.org/R/trunk/src/library/utils/R/packages.R] and
update.packages()
[https://svn.r-project.org/R/trunk/src/library/utils/R/packages2.R]
sometimes output to stdout and sometimes to stderr.

It looks like stderr is used (e.g. via cat()) when the message is part
of querying the user, e.g.

update.packages <- function(lib.loc = NULL, repos = getOption("repos"),
[...]
            cat(old[k, "Package"], ":\n",
                "Version", old[k, "Installed"],
                "installed in", old[k, "LibPath"],
                if(checkBuilt) paste("built under R", old[k, "Built"]),
                "\n",
                "Version", old[k, "ReposVer"], "available at",
                simplifyRepos(old[k, "Repository"], type))
            cat("\n")
            answer <- substr(readline("Update (y/N/c)?  "), 1L, 1L)
            if(answer == "c" | answer == "C") {
                cat("cancelled by user\n")
                return(invisible())
            }

but it is not consistently so, because some are sent to stderr (e.g.
via message()), e.g.

install.packages <-
    function(pkgs, lib, repos = getOption("repos"),
[...]
                if(action == "interactive" && interactive()) {
                    msg <-
                        ngettext(sum(later & hasSrc),
                                 "Do you want to install from sources
the package which needs compilation?",
                                 "Do you want to install from sources
the packages which need compilation?")
                    message(msg, domain = NA)
                    res <- readline("y/n: ")
                    if(res != "y") later <- later & !hasSrc
                } else if (action == "never") {
                    cat("  Binaries will be installed\n")
                    later <- later & !hasSrc
                }

Also, as one see in the latter example, it is not only interactive
user queries for which stdout is used.  It's simply not consistent -
at least I cannot see pattern.

If these are not intended behaviors, I'm happy to provide patches.
I'd prefer stderr for all user queries (see below) - but I can also
see how this is something that needs considered thoughts and made an
official design policy across the R base distribution.


[Related to the above but could deserve it's own thread (feel free to
move the below to its own thread)]

utils::menu(..., graphics=FALSE)
[https://svn.r-project.org/R/trunk/src/library/utils/R/menu.R] queries
the user via standard output, which becomes an issue when running
interactive report generators, which mostly captures stdout and makes
it part of the produced artifact.  Personally, I'd argue that querying
the user via stderr would be a better choice in more cases.

Also, it's a bit weird that base::readline(), which is used for the
actual prompting of the user, is sent neither to R's stdout nor
stderr, e.g.

> zz <- file("all.Rout", open = "wt")
> sink(zz); sink(zz, type = "message")
> ans <- menu(letters[1:3], title="Select one:", graphics=FALSE)
Selection: 1

> sink(type = "message"); sink()
> ans
[1] 1

> cat(readLines("all.Rout"), sep="\n")
Select one:

1: a
2: b
3: c

Note the only thing displayed to the user is the prompt "Selection: ",
which is generated by readline().  It does however output to the
system's stdout (verified on Linux and Windows), e.g.

$ Rscript -e "readline('Press ENTER: ')" > stdout.log
$ cat stdout.log
Press ENTER:
[1] ""

Compare this to how it works in, for instance, bash:

$ read -p "Press ENTER: " ans > stdout.log
Press ENTER:
$ read -p "Press ENTER: " ans > stderr.log
$ cat stderr.log
Press ENTER:

My preference would be that menu() and readline() and other messages
for querying the user would output to the same connection/stream.
Again, I'd favor stderr over stdout, but possibly even a third
alternative designed specifically for user queries, cf. my R-devel
post '[Rd] Output to "raw console" rather than stdout/stderr?' on
2015-02-01 (https://stat.ethz.ch/pipermail/r-devel/2015-February/070578.html).
Just like when using menu(..., graphics=TRUE), this would not clutter
up the output to stdout (or stderr).  But even without this third
alternative, I argue that stderr is better than stdout. I'm happy to
provide patches for this as well.


Thanks,

Henrik


From henrik.bengtsson at ucsf.edu  Mon May 18 02:22:45 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Sun, 17 May 2015 17:22:45 -0700
Subject: [Rd] The function cummax() seems to have a bug.
In-Reply-To: <CABwkPcou67H_t_zuncSNbnsyYVstcTT87FAtw9gqRPi7Z00FFQ@mail.gmail.com>
References: <CABwkPcou67H_t_zuncSNbnsyYVstcTT87FAtw9gqRPi7Z00FFQ@mail.gmail.com>
Message-ID: <CAFDcVCQGiVUMOWNnwpT3EmQAqZh58p2hx2v3jhksSDQpMh_JuQ@mail.gmail.com>

Below is some further troubleshooting on this:

>From code inspection this bug happens for only:

* for integer values
* when the first element is NA_integer_ and the second is not.


Examples:

# Numeric/doubles works as expected
> cummax(c(NA_real_, 0, 1, 2, 3))
[1] NA NA NA NA NA

# It does not occur when the first value is non-NA
> cummax(c(0L, NA_integer_, 1L, 2L, 3L))
[1]  0 NA NA NA NA

# When first value is NA, it is not "remembered"
# (because internal for loop starts with 2nd element)
> cummax(c(NA_integer_, 0L, 1L, 2L, 3L))
[1] NA  0  1  2  3

The problem is not there for cummin():

> cummin(c(0L, NA_integer_, 1L, 2L, 3L))
[1]  0 NA NA NA NA
> cummin(c(NA_integer_, 0L, 1L, 2L, 3L))
[1] NA NA NA NA NA

but that is just "pure luck" due to the fact how NA_integer_ is
internally represented as the smallest possible 4-byte signed integer,
i.e.

LibExtern int    R_NaInt;   /* NA_INTEGER:= INT_MIN currently */
#define NA_INTEGER  R_NaInt

Note the comment, which implies that code should not rely on the
assumption that NA_integer_ == NA_INTEGER == R_NaInt == INT_MIN; it
could equally well have been INT_MAX, which in case cummin()would
return the wrong result whereas cummax() wouldn't. So, cummin() makes
the same mistake ascummax(), where the for-loop skips the test for NA
of the first element, cf.
https://github.com/wch/r-source/blob/trunk/src/main/cum.c#L145-L148

The simple solution is probably to do (cf. native icumsum):

[HB-X201]{hb}: svn diff src/main/cum.c
Index: src/main/cum.c
===================================================================
--- src/main/cum.c      (revision 68378)
+++ src/main/cum.c      (working copy)
@@ -130,7 +130,7 @@
     int *ix = INTEGER(x), *is = INTEGER(s);
     int max = ix[0];
     is[0] = max;
-    for (R_xlen_t i = 1 ; i < xlength(x) ; i++) {
+    for (R_xlen_t i = 0 ; i < xlength(x) ; i++) {
        if(ix[i] == NA_INTEGER) break;
        is[i] = max = (max > ix[i]) ? max : ix[i];
     }
@@ -142,7 +142,7 @@
     int *ix = INTEGER(x), *is = INTEGER(s);
     int min = ix[0];
     is[0] = min;
-    for (R_xlen_t i = 1 ; i < xlength(x) ; i++ ) {
+    for (R_xlen_t i = 0 ; i < xlength(x) ; i++ ) {
        if(ix[i] == NA_INTEGER) break;
        is[i] = min = (min < ix[i]) ? min : ix[i];
     }

/Henrik

On Sun, May 17, 2015 at 4:13 AM, Dongcan Jiang <dongcan.jiang at gmail.com> wrote:
> Hi,
>
> The function cummax() seems to have a bug.
>
>> x <- c(NA, 0)
>> storage.mode(x) <- "integer"
>> cummax(x)
> [1] NA  0
>
> The correct result of this case should be NA NA. The mistake in
> [https://github.com/wch/r-source/blob/trunk/src/main/cum.c#L130-L136] may be
> the reason.
>
> Best Regards,
> Dongcan
>
> --
> Dongcan Jiang
> Team of Search Engine & Web Mining
> School of Electronic Engineering & Computer Science
> Peking University, Beijing, 100871, P.R.China


From maechler at lynne.stat.math.ethz.ch  Mon May 18 14:14:04 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Mon, 18 May 2015 14:14:04 +0200
Subject: [Rd] \alias{} --> rather \concept{} for conceptual "links" to help
	pages
In-Reply-To: <CA+8X3fVXnyP4kJNV+D7fscap+ceL7WFw49=tFpC0-YcVDjAquw@mail.gmail.com>
References: <CALcakBaPjYfqzjqE8a5VhRF5NG4tvbsyOcn-6TiTH-dUvNZT1A@mail.gmail.com>
	<CACk-te1FO5rhrVrbkU8JF2ONOfBOAEGsB9JMAvShjG0cfBEGVQ@mail.gmail.com>
	<CALcakBbQpNzSHJCixYfn=2nPzS2mSX4u4jayBOq6tJ6wLx4BXg@mail.gmail.com>
	<CACk-te3y7CHniVYJLUnxNiK-Mg=3gXC8ZwG0NBd_Ganiawz2Ag@mail.gmail.com>
	<CA+8X3fVXnyP4kJNV+D7fscap+ceL7WFw49=tFpC0-YcVDjAquw@mail.gmail.com>
Message-ID: <21849.55180.666190.313680@stat.math.ethz.ch>

>From R-help, subject  "Variable number of loops"
I've opened a new thread, moving from R-help to R-devel ..

>>>>> Jim Lemon <drjimlemon at gmail.com>
>>>>>     on Sun, 17 May 2015 09:19:06 +1000 writes:

    > Hi all, Given the number of help requests that involve
    > permutations/combinations, and the less than obvious
    > naming of the expand.grid function, perhaps adding an
    > alias such as "permute.elements" or "combine.elements"
    > might ease the tasks of both searchers and those offering
    > help. Neither of the above names appear to be used at
    > present.

    > Jim


Using \alias{} is not a very good thing here, since as you know they
are *key*s that must remain unique if possible and they can be
linked to -- which I think would not be helpful for  'expand.grid'.

Rather, for quite a few years now, we have had \concept{} for
adding "search keywords", i.e., things that 
help.search()  and hence ??<topic>  will find.

The other advantage of \concept{} is that you can use short
phrases, i.e., 

\concept{all variable combinations}

would be possible here.

(Better wording proposals for this specific case are welcome! --
 maybe privately).

Martin Maechler, ETH Zurich


    > On Sun, May 17, 2015 at 5:54 AM, Bert Gunter
    > <gunter.berton at gene.com> wrote:
    >> 1. Please always reply to the list unless there is a
    >> compelling reason to keep the discussion private. You
    >> will have a better chance of getting something useful
    >> that way.
    >> 
    >> 2. I don't know what you mean by "I don't have a fixed
    >> number of variables." You have to specify at least the
    >> number of variables and how many levels each has in order
    >> to work out what you requested, which is **NOT** the
    >> number of permutations but the number of combinations
    >> AFAICS, which is exactly what expand.grid will give you.
    >> 
    >> 3. Maybe what you're looking for is the ... arguments in
    >> function calls, which would be used along the lines of:
    >> 
    >> myfun <- function( x,y,...)  { ## some code combs <-
    >> expand.grid(...)  ## some more code }
    >> 
    >> Any good R tutorial will tell you about this if this is
    >> unfamiliar.
    >> 
    >> 4. Another possibility might be to deliver a list of
    >> named variables as an argument and then use do.call, e.g.
    >> 
    >> myfun <- (x,y, alist) { ## some code combs <-
    >> do.call(expand.grid, alist) ## some more code }
    >> 
    >> ?do.call and/or a tutorial for details.
    >> 
    >> 5. Otherwise, maybe someone else can figure out what
    >> you're looking for.
    >> 
    >> Cheers, Bert
    >> 
    >> 
    >> 
    >> Bert Gunter Genentech Nonclinical Biostatistics (650)
    >> 467-7374
    >> 
    >> "Data is not information. Information is not
    >> knowledge. And knowledge is certainly not wisdom."
    >> Clifford Stoll
    >> 
    >> 
    >> 
    >> 
    >> On Sat, May 16, 2015 at 11:16 AM, WRAY NICHOLAS
    >> <nicholas.wray at ntlworld.com> wrote:
    >>> I might be but doesn't expand.grid need a defined and
    >>> listed number of inputs?  The problem I'm having is that
    >>> the number of variables is not fixed, so I'm not sure
    >>> whether I can reference the variable number of variables
    >>> by using a vector -- haven't had time to try yet But
    >>> thanks anyway Nick Wray
    >>> 
    >>> On 16 May 2015 at 14:28, Bert Gunter
    >>> <gunter.berton at gene.com> wrote:
    >>>> 
    >>>> Are you trying to reinvent ?expand.grid ?
    >>>> 
    >>>> -- Bert
    >>>> 
    >>>> Bert Gunter Genentech Nonclinical Biostatistics (650)
    >>>> 467-7374
    >>>> 
    >>>> "Data is not information. Information is not
    >>>> knowledge. And knowledge is certainly not wisdom."
    >>>> Clifford Stoll
    >>>> 
 [...............]


From joshmobrien at gmail.com  Mon May 18 19:29:49 2015
From: joshmobrien at gmail.com (Josh O'Brien)
Date: Mon, 18 May 2015 10:29:49 -0700
Subject: [Rd] How best to get around shadowing of executables by system()'s
 prepending of directories to Windows' PATH?
Message-ID: <CAOwKfPQXiGY9O_A-Bjv7LmOsB5ybVD86eKc-joLpm2abG1etxg@mail.gmail.com>

My question:

On Windows, R's system() command prepends several directories to those
in the Windows Path variable.

>From ?system

     The search path for 'command' may be system-dependent: it will
     include the R 'bin' directory, the working directory and the
     Windows system directories before 'PATH'.

This shadows any executables on the Path that share a name with, for
example, one of the Windows commands.

What should I do when I'd really like (the equivalent of) a call
passed to system() that would be executed using the same Path that
you'd get if working directly at the Windows command line? Is there a
recommended workaround for situtations like this? (It _seems_ like it
would be handy if system() et al. included an additional argument that
optionally disabled the prepending of those extra directories, to give
Windows users full control of the path seen by system(). Would adding
such an argument have undesirable ramifications?)


Motivation and reproducible example:

I'm motivated here by a desire to use the function plotdiff() from
Paul Murrell's gridGraphics package on my Windows laptop.  Getting
that to work will require a few code fixes, of which the masking of
ImageMagick's convert.exe by that in the C:/Windows/System32 seems to
be the most challenging. plotdiff() relies on system2() calls to
ImageMagick's 'convert'  function, as well as a call to
Sys.which(c("convert", "compare")) that tests for the presence of
ImageMagick on the Path. Even  if ImageMagick is placed early on the
Path, though, both calls to Sys.which() and system2() find Windows'
convert command  (which "Converts FAT volumes to NTFS") rather than
ImageMagick's convert.


Here's a reproducible example that shows what I'm seeing:

    ## In R, make a pdf
    pdf("a.pdf")
    plot(rnorm(99), col="red")
    dev.off()

    ## At Windows cmd command line
    where convert
    ## C:\Program Files\ImageMagick-6.8.8-Q16\convert.exe
    ## C:\Windows\System32\convert.exe
    convert -density 100x100 a.pdf a.png

    ## From R

    ## Unqualified references to convert find the 'wrong' one
    Sys.which("convert")
    ##                               convert
    ## "C:\\Windows\\system32\\convert.exe"
     system2("convert",  "-density 100x100 a.pdf b.png")
    ## Invalid Parameter - 100x100
    ## Warning message:
    ## running command '"convert" -density 100x100 a.pdf b.png' had status 4

    ## A fully qualified reference does work
    system2("C:/Program Files/ImageMagick-6.8.8-Q16/convert",
"-density 100x100 a.pdf b.png")


From xie at yihui.name  Mon May 18 20:08:10 2015
From: xie at yihui.name (Yihui Xie)
Date: Mon, 18 May 2015 13:08:10 -0500
Subject: [Rd] How best to get around shadowing of executables by
 system()'s prepending of directories to Windows' PATH?
In-Reply-To: <CAOwKfPQXiGY9O_A-Bjv7LmOsB5ybVD86eKc-joLpm2abG1etxg@mail.gmail.com>
References: <CAOwKfPQXiGY9O_A-Bjv7LmOsB5ybVD86eKc-joLpm2abG1etxg@mail.gmail.com>
Message-ID: <CANROs4fGuWFjE7a=CunKyC_rpcE40RRBLxzLeDf6TbCGMcQqGA@mail.gmail.com>

+1 I have exactly the same problem.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Mon, May 18, 2015 at 12:29 PM, Josh O'Brien <joshmobrien at gmail.com> wrote:
> My question:
>
> On Windows, R's system() command prepends several directories to those
> in the Windows Path variable.
>
> >From ?system
>
>      The search path for 'command' may be system-dependent: it will
>      include the R 'bin' directory, the working directory and the
>      Windows system directories before 'PATH'.
>
> This shadows any executables on the Path that share a name with, for
> example, one of the Windows commands.
>
> What should I do when I'd really like (the equivalent of) a call
> passed to system() that would be executed using the same Path that
> you'd get if working directly at the Windows command line? Is there a
> recommended workaround for situtations like this? (It _seems_ like it
> would be handy if system() et al. included an additional argument that
> optionally disabled the prepending of those extra directories, to give
> Windows users full control of the path seen by system(). Would adding
> such an argument have undesirable ramifications?)
>
>
> Motivation and reproducible example:
>
> I'm motivated here by a desire to use the function plotdiff() from
> Paul Murrell's gridGraphics package on my Windows laptop.  Getting
> that to work will require a few code fixes, of which the masking of
> ImageMagick's convert.exe by that in the C:/Windows/System32 seems to
> be the most challenging. plotdiff() relies on system2() calls to
> ImageMagick's 'convert'  function, as well as a call to
> Sys.which(c("convert", "compare")) that tests for the presence of
> ImageMagick on the Path. Even  if ImageMagick is placed early on the
> Path, though, both calls to Sys.which() and system2() find Windows'
> convert command  (which "Converts FAT volumes to NTFS") rather than
> ImageMagick's convert.
>
>
> Here's a reproducible example that shows what I'm seeing:
>
>     ## In R, make a pdf
>     pdf("a.pdf")
>     plot(rnorm(99), col="red")
>     dev.off()
>
>     ## At Windows cmd command line
>     where convert
>     ## C:\Program Files\ImageMagick-6.8.8-Q16\convert.exe
>     ## C:\Windows\System32\convert.exe
>     convert -density 100x100 a.pdf a.png
>
>     ## From R
>
>     ## Unqualified references to convert find the 'wrong' one
>     Sys.which("convert")
>     ##                               convert
>     ## "C:\\Windows\\system32\\convert.exe"
>      system2("convert",  "-density 100x100 a.pdf b.png")
>     ## Invalid Parameter - 100x100
>     ## Warning message:
>     ## running command '"convert" -density 100x100 a.pdf b.png' had status 4
>
>     ## A fully qualified reference does work
>     system2("C:/Program Files/ImageMagick-6.8.8-Q16/convert",
> "-density 100x100 a.pdf b.png")
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From tal.galili at gmail.com  Mon May 18 22:01:44 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 18 May 2015 23:01:44 +0300
Subject: [Rd] A "bug" in plot.dendrogram - can't plot lty with character
	color
Message-ID: <CANdJ3dXzdw+D-Bk3_rEeYh4RSTNq4TYj-tYK2wqTQ36UYZ=BZA@mail.gmail.com>

The problem:
===========
Once a dendrogram has a branch with both a line type AND a color (which is
a character color), the plot.dendrogram function will not plot and return
an error.

I say this is a bug because (I believe), we would like a dendrogram to be
able to use character colors, while also allowing control over line types.



This e-mail includes an example, and what I think a solution might be.

Reproducible example:
=================

install.packages('dendextend')
library('dendextend')

dend <- 1:2 %>% dist %>% hclust %>% as.dendrogram
plot(dend) # works fine

dend %>% set("branches_lty", 1:2) %>% plot # works fine
dend %>% set("branches_col", 1:2) %>% plot # works fine
dend %>% set("branches_col", as.character(1:2)) %>% plot # works fine
# Fails:
dend %>% set("branches_lty", 1:2) %>% set("branches_col",
as.character(1:2)) %>% plot

### Error:
# Error in segments(x0, y0, x1, y1, col = col, lty = lty, lwd = lwd) :
#    invalid line type: must be length 2, 4, 6 or 8

# This is because edgePar has to hold both "lty" and "col"
# Since "col" is a character, it forces "lty" to become a character also.
dend %>% set("branches_lty", 1:2) %>% set("branches_col",
as.character(1:2)) %>%
   unclass %>% str



Possible solution
==============
The simplest (and backward) compatible solution I can think of is to edit
the function:
stats:::plotNode

And change the following lines:
         col <- Xtract("col", ePar, default = par("col"),
                       i)
         lty <- Xtract("lty", ePar, default = par("lty"),
                       i)
         lwd <- Xtract("lwd", ePar, default = par("lwd"),
                       i)

With:

         col <- Xtract("col", ePar, default = par("col"),
                       i)
         lty <- as.numeric(Xtract("lty", ePar, default = par("lty"),
                       i))
         lwd <- as.numeric(Xtract("lwd", ePar, default = par("lwd"),
                       i))




With regards,
Tal

	[[alternative HTML version deleted]]


From hpages at fredhutch.org  Mon May 18 22:31:53 2015
From: hpages at fredhutch.org (=?windows-1252?Q?Herv=E9_Pag=E8s?=)
Date: Mon, 18 May 2015 13:31:53 -0700
Subject: [Rd] \alias{} --> rather \concept{} for conceptual "links" to
 help pages
In-Reply-To: <21849.55180.666190.313680@stat.math.ethz.ch>
References: <CALcakBaPjYfqzjqE8a5VhRF5NG4tvbsyOcn-6TiTH-dUvNZT1A@mail.gmail.com>	<CACk-te1FO5rhrVrbkU8JF2ONOfBOAEGsB9JMAvShjG0cfBEGVQ@mail.gmail.com>	<CALcakBbQpNzSHJCixYfn=2nPzS2mSX4u4jayBOq6tJ6wLx4BXg@mail.gmail.com>	<CACk-te3y7CHniVYJLUnxNiK-Mg=3gXC8ZwG0NBd_Ganiawz2Ag@mail.gmail.com>	<CA+8X3fVXnyP4kJNV+D7fscap+ceL7WFw49=tFpC0-YcVDjAquw@mail.gmail.com>
	<21849.55180.666190.313680@stat.math.ethz.ch>
Message-ID: <555A4C39.6000807@fredhutch.org>

Hi Martin,

On 05/18/2015 05:14 AM, Martin Maechler wrote:
>  From R-help, subject  "Variable number of loops"
> I've opened a new thread, moving from R-help to R-devel ..
>
>>>>>> Jim Lemon <drjimlemon at gmail.com>
>>>>>>      on Sun, 17 May 2015 09:19:06 +1000 writes:
>
>      > Hi all, Given the number of help requests that involve
>      > permutations/combinations, and the less than obvious
>      > naming of the expand.grid function, perhaps adding an
>      > alias such as "permute.elements" or "combine.elements"
>      > might ease the tasks of both searchers and those offering
>      > help. Neither of the above names appear to be used at
>      > present.
>
>      > Jim
>
>
> Using \alias{} is not a very good thing here, since as you know they
> are *key*s that must remain unique if possible and they can be
> linked to -- which I think would not be helpful for  'expand.grid'.

It seems to me that Jim was maybe suggesting to define an alias for the
expand.grid function i.e. something like:

   permute.elements <- expand.grid

or

   combine.elements <- expand.grid

as a way to address the "less than obvious naming of the expand.grid
function". But maybe I misunderstood...

Cheers,
H.

>
> Rather, for quite a few years now, we have had \concept{} for
> adding "search keywords", i.e., things that
> help.search()  and hence ??<topic>  will find.
>
> The other advantage of \concept{} is that you can use short
> phrases, i.e.,
>
> \concept{all variable combinations}
>
> would be possible here.
>
> (Better wording proposals for this specific case are welcome! --
>   maybe privately).
>
> Martin Maechler, ETH Zurich
>
>
>      > On Sun, May 17, 2015 at 5:54 AM, Bert Gunter
>      > <gunter.berton at gene.com> wrote:
>      >> 1. Please always reply to the list unless there is a
>      >> compelling reason to keep the discussion private. You
>      >> will have a better chance of getting something useful
>      >> that way.
>      >>
>      >> 2. I don't know what you mean by "I don't have a fixed
>      >> number of variables." You have to specify at least the
>      >> number of variables and how many levels each has in order
>      >> to work out what you requested, which is **NOT** the
>      >> number of permutations but the number of combinations
>      >> AFAICS, which is exactly what expand.grid will give you.
>      >>
>      >> 3. Maybe what you're looking for is the ... arguments in
>      >> function calls, which would be used along the lines of:
>      >>
>      >> myfun <- function( x,y,...)  { ## some code combs <-
>      >> expand.grid(...)  ## some more code }
>      >>
>      >> Any good R tutorial will tell you about this if this is
>      >> unfamiliar.
>      >>
>      >> 4. Another possibility might be to deliver a list of
>      >> named variables as an argument and then use do.call, e.g.
>      >>
>      >> myfun <- (x,y, alist) { ## some code combs <-
>      >> do.call(expand.grid, alist) ## some more code }
>      >>
>      >> ?do.call and/or a tutorial for details.
>      >>
>      >> 5. Otherwise, maybe someone else can figure out what
>      >> you're looking for.
>      >>
>      >> Cheers, Bert
>      >>
>      >>
>      >>
>      >> Bert Gunter Genentech Nonclinical Biostatistics (650)
>      >> 467-7374
>      >>
>      >> "Data is not information. Information is not
>      >> knowledge. And knowledge is certainly not wisdom."
>      >> Clifford Stoll
>      >>
>      >>
>      >>
>      >>
>      >> On Sat, May 16, 2015 at 11:16 AM, WRAY NICHOLAS
>      >> <nicholas.wray at ntlworld.com> wrote:
>      >>> I might be but doesn't expand.grid need a defined and
>      >>> listed number of inputs?  The problem I'm having is that
>      >>> the number of variables is not fixed, so I'm not sure
>      >>> whether I can reference the variable number of variables
>      >>> by using a vector -- haven't had time to try yet But
>      >>> thanks anyway Nick Wray
>      >>>
>      >>> On 16 May 2015 at 14:28, Bert Gunter
>      >>> <gunter.berton at gene.com> wrote:
>      >>>>
>      >>>> Are you trying to reinvent ?expand.grid ?
>      >>>>
>      >>>> -- Bert
>      >>>>
>      >>>> Bert Gunter Genentech Nonclinical Biostatistics (650)
>      >>>> 467-7374
>      >>>>
>      >>>> "Data is not information. Information is not
>      >>>> knowledge. And knowledge is certainly not wisdom."
>      >>>> Clifford Stoll
>      >>>>
>   [...............]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

-- 
Herv? Pag?s

Program in Computational Biology
Division of Public Health Sciences
Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N, M1-B514
P.O. Box 19024
Seattle, WA 98109-1024

E-mail: hpages at fredhutch.org
Phone:  (206) 667-5791
Fax:    (206) 667-1319


From henrik.bengtsson at ucsf.edu  Mon May 18 22:40:09 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Mon, 18 May 2015 13:40:09 -0700
Subject: [Rd] How best to get around shadowing of executables by
 system()'s prepending of directories to Windows' PATH?
In-Reply-To: <CANROs4fGuWFjE7a=CunKyC_rpcE40RRBLxzLeDf6TbCGMcQqGA@mail.gmail.com>
References: <CAOwKfPQXiGY9O_A-Bjv7LmOsB5ybVD86eKc-joLpm2abG1etxg@mail.gmail.com>
	<CANROs4fGuWFjE7a=CunKyC_rpcE40RRBLxzLeDf6TbCGMcQqGA@mail.gmail.com>
Message-ID: <CAFDcVCTNRcGU+yNrp=H0JAyeLsFz8yOZ7uMzz3GNbdfmqOonbQ@mail.gmail.com>

You probably already know, but you can at least work around it as:

Sys.which2 <- function(cmd) {
  stopifnot(length(cmd) == 1)
  if (.Platform$OS.type == "windows") {
    suppressWarnings({
      pathname <- shell(sprintf("where %s 2> NUL", cmd), intern=TRUE)[1]
   })
   if (!is.na(pathname)) return(setNames(pathname, cmd))
  }
  Sys.which(cmd)
}

(it falls back to Sys.which() if 'where %s' doesn't give anything)


> Sys.which2("convert")
                                                convert
"C:\\Program Files\\ImageMagick-6.8.3-Q16\\convert.exe"

> Sys.which("convert")
                             convert
"C:\\Windows\\system32\\convert.exe"

/Henrik

On Mon, May 18, 2015 at 11:08 AM, Yihui Xie <xie at yihui.name> wrote:
> +1 I have exactly the same problem.
>
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
>
>
> On Mon, May 18, 2015 at 12:29 PM, Josh O'Brien <joshmobrien at gmail.com> wrote:
>> My question:
>>
>> On Windows, R's system() command prepends several directories to those
>> in the Windows Path variable.
>>
>> >From ?system
>>
>>      The search path for 'command' may be system-dependent: it will
>>      include the R 'bin' directory, the working directory and the
>>      Windows system directories before 'PATH'.
>>
>> This shadows any executables on the Path that share a name with, for
>> example, one of the Windows commands.
>>
>> What should I do when I'd really like (the equivalent of) a call
>> passed to system() that would be executed using the same Path that
>> you'd get if working directly at the Windows command line? Is there a
>> recommended workaround for situtations like this? (It _seems_ like it
>> would be handy if system() et al. included an additional argument that
>> optionally disabled the prepending of those extra directories, to give
>> Windows users full control of the path seen by system(). Would adding
>> such an argument have undesirable ramifications?)
>>
>>
>> Motivation and reproducible example:
>>
>> I'm motivated here by a desire to use the function plotdiff() from
>> Paul Murrell's gridGraphics package on my Windows laptop.  Getting
>> that to work will require a few code fixes, of which the masking of
>> ImageMagick's convert.exe by that in the C:/Windows/System32 seems to
>> be the most challenging. plotdiff() relies on system2() calls to
>> ImageMagick's 'convert'  function, as well as a call to
>> Sys.which(c("convert", "compare")) that tests for the presence of
>> ImageMagick on the Path. Even  if ImageMagick is placed early on the
>> Path, though, both calls to Sys.which() and system2() find Windows'
>> convert command  (which "Converts FAT volumes to NTFS") rather than
>> ImageMagick's convert.
>>
>>
>> Here's a reproducible example that shows what I'm seeing:
>>
>>     ## In R, make a pdf
>>     pdf("a.pdf")
>>     plot(rnorm(99), col="red")
>>     dev.off()
>>
>>     ## At Windows cmd command line
>>     where convert
>>     ## C:\Program Files\ImageMagick-6.8.8-Q16\convert.exe
>>     ## C:\Windows\System32\convert.exe
>>     convert -density 100x100 a.pdf a.png
>>
>>     ## From R
>>
>>     ## Unqualified references to convert find the 'wrong' one
>>     Sys.which("convert")
>>     ##                               convert
>>     ## "C:\\Windows\\system32\\convert.exe"
>>      system2("convert",  "-density 100x100 a.pdf b.png")
>>     ## Invalid Parameter - 100x100
>>     ## Warning message:
>>     ## running command '"convert" -density 100x100 a.pdf b.png' had status 4
>>
>>     ## A fully qualified reference does work
>>     system2("C:/Program Files/ImageMagick-6.8.8-Q16/convert",
>> "-density 100x100 a.pdf b.png")
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From joshmobrien at gmail.com  Tue May 19 19:32:57 2015
From: joshmobrien at gmail.com (Josh O'Brien)
Date: Tue, 19 May 2015 10:32:57 -0700
Subject: [Rd] How best to get around shadowing of executables by
 system()'s prepending of directories to Windows' PATH?
In-Reply-To: <CAOwKfPQXiGY9O_A-Bjv7LmOsB5ybVD86eKc-joLpm2abG1etxg@mail.gmail.com>
References: <CAOwKfPQXiGY9O_A-Bjv7LmOsB5ybVD86eKc-joLpm2abG1etxg@mail.gmail.com>
Message-ID: <CAOwKfPTCXgDBCvqiThwZSF26PXSaAs18WZmiHgJ_N50zipQ7vA@mail.gmail.com>

On Mon, May 18, 2015 at 10:29 AM, Josh O'Brien <joshmobrien at gmail.com> wrote:
> My question:
>
> On Windows, R's system() command prepends several directories to those
> in the Windows Path variable.
>
> From ?system
>
>      The search path for 'command' may be system-dependent: it will
>      include the R 'bin' directory, the working directory and the
>      Windows system directories before 'PATH'.
>
> This shadows any executables on the Path that share a name with, for
> example, one of the Windows commands.
>
> What should I do when I'd really like (the equivalent of) a call
> passed to system() that would be executed using the same Path that
> you'd get if working directly at the Windows command line? Is there a

It appears that "use shell() instead of system()" is a reasonable, if
narrow, answer to this question.

Doing:

    shell("convert -density 100x100 a.pdf b.png")

constructs (and then uses system() to call) the following command:

    "C:\\Windows\\system32\\cmd.exe /c convert -density 100x100 a.pdf b.png"

which gives you just what you'd get if typing directly at the command line.

> recommended workaround for situtations like this? (It _seems_ like it
> would be handy if system() et al. included an additional argument that
> optionally disabled the prepending of those extra directories, to give
> Windows users full control of the path seen by system(). Would adding
> such an argument have undesirable ramifications?)
>
>
> Motivation and reproducible example:
>
> I'm motivated here by a desire to use the function plotdiff() from
> Paul Murrell's gridGraphics package on my Windows laptop.  Getting
> that to work will require a few code fixes, of which the masking of
> ImageMagick's convert.exe by that in the C:/Windows/System32 seems to
> be the most challenging. plotdiff() relies on system2() calls to
> ImageMagick's 'convert'  function, as well as a call to
> Sys.which(c("convert", "compare")) that tests for the presence of
> ImageMagick on the Path. Even  if ImageMagick is placed early on the
> Path, though, both calls to Sys.which() and system2() find Windows'
> convert command  (which "Converts FAT volumes to NTFS") rather than
> ImageMagick's convert.
>
>
> Here's a reproducible example that shows what I'm seeing:
>
>     ## In R, make a pdf
>     pdf("a.pdf")
>     plot(rnorm(99), col="red")
>     dev.off()
>
>     ## At Windows cmd command line
>     where convert
>     ## C:\Program Files\ImageMagick-6.8.8-Q16\convert.exe
>     ## C:\Windows\System32\convert.exe
>     convert -density 100x100 a.pdf a.png
>
>     ## From R
>
>     ## Unqualified references to convert find the 'wrong' one
>     Sys.which("convert")
>     ##                               convert
>     ## "C:\\Windows\\system32\\convert.exe"
>      system2("convert",  "-density 100x100 a.pdf b.png")
>     ## Invalid Parameter - 100x100
>     ## Warning message:
>     ## running command '"convert" -density 100x100 a.pdf b.png' had status 4
>
>     ## A fully qualified reference does work
>     system2("C:/Program Files/ImageMagick-6.8.8-Q16/convert",
> "-density 100x100 a.pdf b.png")


From PLRoebuck at mdanderson.org  Tue May 19 20:12:27 2015
From: PLRoebuck at mdanderson.org (Roebuck,Paul L)
Date: Tue, 19 May 2015 18:12:27 +0000
Subject: [Rd] How best to get around shadowing of executables by
 system()'s prepending of directories to Windows' PATH?
In-Reply-To: <CAOwKfPQXiGY9O_A-Bjv7LmOsB5ybVD86eKc-joLpm2abG1etxg@mail.gmail.com>
References: <CAOwKfPQXiGY9O_A-Bjv7LmOsB5ybVD86eKc-joLpm2abG1etxg@mail.gmail.com>
Message-ID: <D180E455.D5E1D%proebuck@mdanderson.org>

This is the code I use in my 'SuperCurve' R-Forge package:


##-------------------------------------------------------------------------
----
## Merge output graphs with source tiff file, save it as JPG file
.mergeGraphsAndImage <- function(antibody,
                                 prefix,
                                 outputdir,
                                 tiff) {
    ## Check arguments
    stopifnot(is.character(antibody)  && length(antibody) == 1)
    stopifnot(is.character(prefix)    && length(prefix) == 1)
    stopifnot(is.character(outputdir) && length(outputdir) == 1)
    stopifnot(is.character(tiff)      && length(tiff) == 1)

    ## Begin processing
    filename <- sprintf("%s_%s_1.png", prefix, antibody)
    pg1 <- file.path(outputdir, .portableFilename(filename))

    filename <- sprintf("%s_%s_2.png", prefix, antibody)
    pg2 <- file.path(outputdir, .portableFilename(filename))

    filename <- sprintf("%s.jpg", antibody)
    output <- file.path(outputdir, .portableFilename(filename))

    ## Use ImageMagick 'convert' binary to perform merge
    command <- paste("convert",
                     shQuote(pg1),
                     shQuote(pg2),
                     "+append",
                     shQuote(tiff),
                     "-append",
                     "-quality 100",
                     shQuote(output))
    rc <- switch(EXPR=.Platform$OS.type,
                 unix=system(command),
                 windows=shell(command),
                 stop(sprintf("unrecognized operating system family %s",
                              sQuote(.Platform$OS.type))))
    #cat("rc =", rc, ", command:", command, "\n")

    rc
}



Additionally, the package uses the .onLoad() method to verify
WHICH 'convert' would be used and alert user if missing (or
DOS command would be used instead of ImageMagick binary).


##-------------------------------------------------------------------------
----
.onLoad <- function(libname, pkgname) {

    
##-------------------------------------------------------------------------
    ## Preflight check use of ImageMagick 'convert' binary
    preflightCheck <- function() {
        command <- "convert --version"
        tryCatch({
                output <- switch(EXPR=.Platform$OS.type,
                                 unix=system(command,
                                             intern=TRUE,
                                             ignore.stderr=TRUE),
                                 windows=shell(command,
                                               intern=TRUE,
                                               ignore.stderr=TRUE),
                                 "")
                grepl("ImageMagick", output[1], fixed=TRUE)
            },
            error=function(e) {
                FALSE
            })
    }


    if (!preflightCheck()) {
        warning(sprintf("ImageMagick executable %s not installed or
unavailable via PATH",
                        sQuote("convert")),
                call.=FALSE)
    }

    ## [SNIP unrelated additional code]
}




On 5/18/15 12:29 PM, "Josh O'Brien" <joshmobrien at gmail.com> wrote:

>My question:
>
>On Windows, R's system() command prepends several directories to those
>in the Windows Path variable.
>
>>From ?system
>
>     The search path for 'command' may be system-dependent: it will
>     include the R 'bin' directory, the working directory and the
>     Windows system directories before 'PATH'.
>
>This shadows any executables on the Path that share a name with, for
>example, one of the Windows commands.
>
>What should I do when I'd really like (the equivalent of) a call
>passed to system() that would be executed using the same Path that
>you'd get if working directly at the Windows command line? Is there a
>recommended workaround for situtations like this? (It _seems_ like it
>would be handy if system() et al. included an additional argument that
>optionally disabled the prepending of those extra directories, to give
>Windows users full control of the path seen by system(). Would adding
>such an argument have undesirable ramifications?)
>
>
>Motivation and reproducible example:
>
>I'm motivated here by a desire to use the function plotdiff() from
>Paul Murrell's gridGraphics package on my Windows laptop.  Getting
>that to work will require a few code fixes, of which the masking of
>ImageMagick's convert.exe by that in the C:/Windows/System32 seems to
>be the most challenging. plotdiff() relies on system2() calls to
>ImageMagick's 'convert'  function, as well as a call to
>Sys.which(c("convert", "compare")) that tests for the presence of
>ImageMagick on the Path. Even  if ImageMagick is placed early on the
>Path, though, both calls to Sys.which() and system2() find Windows'
>convert command  (which "Converts FAT volumes to NTFS") rather than
>ImageMagick's convert.
>
>
>Here's a reproducible example that shows what I'm seeing:
>
>    ## In R, make a pdf
>    pdf("a.pdf")
>    plot(rnorm(99), col="red")
>    dev.off()
>
>    ## At Windows cmd command line
>    where convert
>    ## C:\Program Files\ImageMagick-6.8.8-Q16\convert.exe
>    ## C:\Windows\System32\convert.exe
>    convert -density 100x100 a.pdf a.png
>
>    ## From R
>
>    ## Unqualified references to convert find the 'wrong' one
>    Sys.which("convert")
>    ##                               convert
>    ## "C:\\Windows\\system32\\convert.exe"
>     system2("convert",  "-density 100x100 a.pdf b.png")
>    ## Invalid Parameter - 100x100
>    ## Warning message:
>    ## running command '"convert" -density 100x100 a.pdf b.png' had
>status 4
>
>    ## A fully qualified reference does work
>    system2("C:/Program Files/ImageMagick-6.8.8-Q16/convert",
>"-density 100x100 a.pdf b.png")
>
>______________________________________________
>R-devel at r-project.org mailing list
>https://stat.ethz.ch/mailman/listinfo/r-devel


From rhelp at eoos.dds.nl  Wed May 20 08:13:32 2015
From: rhelp at eoos.dds.nl (Jan van der Laan)
Date: Wed, 20 May 2015 08:13:32 +0200
Subject: [Rd] Alternative for wildcard gnu extension in Makevars
In-Reply-To: <21843.36303.612911.855609@max.nulle.part>
References: <20150513172750.Horde.XmEuGWEwhY5VU212D36XCEA@webmailnew.dds.nl>	<21843.29537.86236.300996@max.nulle.part>	<20150513180509.Horde.AU5NdWEwhY5VU3Y1ROC1FeA@webmailnew.dds.nl>	<CABtg=KkyH5qj2wC_oeinru10+vVqfhD+rriDAj5TdeZnSkhekQ@mail.gmail.com>	<CAJXgQP1NnY1WXgnGj87qcxPkamMYasLOUnFZ9VkRC2uK5Ec9nQ@mail.gmail.com>
	<21843.36303.612911.855609@max.nulle.part>
Message-ID: <555C260C.9050702@eoos.dds.nl>



On 13-05-15 19:45, Dirk Eddelbuettel wrote:
> On 13 May 2015 at 10:10, Kevin Ushey wrote:
> | One other solution that's only a little crazy: you could have a R
> | function within your package that generates the appropriate (portable)
> | Makevars, and within the package `configure` script call that
> | function. For example"
> |
> |     R --vanilla --slave -e "source('R/makevars.R'); makevars()"
> |
> | And that 'makevars()' function could generate portable
> | 'Makevars(.win)' files for your package.
>
> Seconded.  I do exactly that in another recent package where I needed another
> "verboten" idiom available only in the widespread and feature-rich GNU make
> but not the so-much-more constrained basic make: if statements.
>
> See https://github.com/eddelbuettel/Rblpapi/blob/master/configure where I
> need to encode 32 or 64 in the name of shared library.  By relying on Rscript
> I code around the constraint of not having GNU make.   [ That is still a
> non-CRAN package but for an unrelated, different reason. ]
>

Kevin, Dirk,

I finally opted for this solution. Thanks!

Jan


From maechler at lynne.stat.math.ethz.ch  Wed May 20 09:39:18 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 20 May 2015 09:39:18 +0200
Subject: [Rd] Probably a "bug" in the dendextend package
In-Reply-To: <CANdJ3dXzdw+D-Bk3_rEeYh4RSTNq4TYj-tYK2wqTQ36UYZ=BZA@mail.gmail.com>
References: <CANdJ3dXzdw+D-Bk3_rEeYh4RSTNq4TYj-tYK2wqTQ36UYZ=BZA@mail.gmail.com>
Message-ID: <21852.14886.8489.456253@stat.math.ethz.ch>

>>>>> Tal Galili <tal.galili at gmail.com>
>>>>>     on Mon, 18 May 2015 23:01:44 +0300 writes:

    > The problem:
    > ===========
    > Once a dendrogram has a branch with both a line type AND a color (which is
    > a character color), the plot.dendrogram function will not plot and return
    > an error.

If the dendrogram has been messed up ...  see below.


    > I say this is a bug because (I believe), we would like a dendrogram to be
    > able to use character colors, while also allowing control over line types.

I say this is clearly a bug in the code that messed up the
dendrogram, see below.


    > This e-mail includes an example, and what I think a solution might be.

    > Reproducible example:
    > =================

    > install.packages('dendextend')
    > library('dendextend')

    > dend <- 1:2 %>% dist %>% hclust %>% as.dendrogram
    > plot(dend) # works fine

    > dend %>% set("branches_lty", 1:2) %>% plot # works fine
    > dend %>% set("branches_col", 1:2) %>% plot # works fine
    > dend %>% set("branches_col", as.character(1:2)) %>% plot # works fine
    > # Fails:
    > dend %>% set("branches_lty", 1:2) %>% set("branches_col",
    > as.character(1:2)) %>% plot

    > ### Error:
    > # Error in segments(x0, y0, x1, y1, col = col, lty = lty, lwd = lwd) :
    > #    invalid line type: must be length 2, 4, 6 or 8

Well,  the above  magrittr pipe  mumbo-jumbo  does not make it easy
to deparse what you are doing ... and below you see why I think
the bug is only in your  'dendextend' package.

Please -- for supposed bugs in R, we do need reproducible examples *not*
making use of external packages !

    > # This is because edgePar has to hold both "lty" and "col"
    > # Since "col" is a character, it forces "lty" to become a character also.

This is nonsense, sorry: If you'd read the help for plot.dendrogram(),
edgePar is clearly defined as list, not vector, so it can well
contain character and integer vectors.... and that design (list,
not atomic vector) was exactly for this reason.

I'd tend to say the bug *is* in your package only: when your set()
function treats edgePar as atomic vector instead of list ???

    > dend %>% set("branches_lty", 1:2) %>% set("branches_col",
    > as.character(1:2)) %>%
    > unclass %>% str

again the pipe mumbo-jumbo ..  
I hope a version of dendextend::set() would allow
several arguments, so the above would back translate to
proper functional (*and* more efficient!) language 

d2 <- set(dend, branches_lty = 1:2, branches_col = c("1","2"))
str(unclass(d2))

[... what should  col = "1" mean ??
 a more convincing example would use   col = c("tomato", "orange") 
 (using ``eatable colors'' just for fun) [

Currently, I don't see a bug in R's dendrogram code 
but rather in your package.

    > Possible solution
    > ==============
    > The simplest (and backward) compatible solution I can think of is to edit
    > the function:
    > stats:::plotNode

    > And change the following lines:
    > col <- Xtract("col", ePar, default = par("col"),
    > i)
    > lty <- Xtract("lty", ePar, default = par("lty"),
    > i)
    > lwd <- Xtract("lwd", ePar, default = par("lwd"),
    > i)

    > With:

    > col <- Xtract("col", ePar, default = par("col"),
    > i)
    > lty <- as.numeric(Xtract("lty", ePar, default = par("lty"),
    > i))
    > lwd <- as.numeric(Xtract("lwd", ePar, default = par("lwd"),
    > i))

This would break cases where you'd make use of the feature that
lty in R has always been much more flexible than just taking the
few predefined integer line types:

Read  ?par  and grep for the several occurences of  'lty'..

    > With regards,
    > Tal

    > [[alternative HTML version deleted]]
       ^^^^^^^^^^
       hmm...

... after all that:  

Your dendextend *is* a nice package, Tal,
and so "best regards!",

but as I've said before on this topic: 

In real life, be very careful before denigrating a child to its
mother or father... so calling a something a bug in R which is
none, is evoking feelings among R's parents  .. ;-)

Martin


From tal.galili at gmail.com  Wed May 20 10:02:53 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Wed, 20 May 2015 11:02:53 +0300
Subject: [Rd] Probably a "bug" in the dendextend package
In-Reply-To: <21852.14886.8489.456253@stat.math.ethz.ch>
References: <CANdJ3dXzdw+D-Bk3_rEeYh4RSTNq4TYj-tYK2wqTQ36UYZ=BZA@mail.gmail.com>
	<21852.14886.8489.456253@stat.math.ethz.ch>
Message-ID: <CANdJ3dXMBZO2gP_ncMyM=n5NGoJi0rJ4uaC72Rw9kE3kmcpq=w@mail.gmail.com>

Dear Martin,

You are right. When implementing the dendextend::set function, I failed to
notice that edgePar should accept a list instead of a vector. So all I did
was to discover a bug in my own code.

I am both sorry for taking your time due to my own mistake, and
also grateful for your help (I will resolve this bug before submitting the
next release to CRAN).
I am sure that I would have had similar feelings if the situation happened
to me - so again, I apologize :)

With regards,
Tal












On Wed, May 20, 2015 at 10:39 AM, Martin Maechler <
maechler at lynne.stat.math.ethz.ch> wrote:

> u





----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------

	[[alternative HTML version deleted]]


From ivan.popivanov at gmail.com  Wed May 20 17:02:20 2015
From: ivan.popivanov at gmail.com (Ivan Popivanov)
Date: Wed, 20 May 2015 11:02:20 -0400
Subject: [Rd] Is the parallel package the right place for locking
	functionality?
Message-ID: <CAK7-yAiFpJdsRcJfw1zbHhx0MjXoQZVtwYJxx6Sz3SZfRj26OQ@mail.gmail.com>

Hello,

Sometime ago I had to solve the problem of writing to common files from
parallel R processes. For the synchronization, I created a small package (
https://r-forge.r-project.org/projects/flock/) to perform a lock/unlock
between different processes. My feeling is that this is something that
belongs to the parallel package.

There is at least one other package (synchronicity -
http://cran.r-project.org/web/packages/synchronicity/index.html) providing
similar (and more) functionality.

Regards,
Ivan

	[[alternative HTML version deleted]]


From pperry at stern.nyu.edu  Wed May 20 22:41:36 2015
From: pperry at stern.nyu.edu (Patrick Perry)
Date: Wed, 20 May 2015 16:41:36 -0400
Subject: [Rd] Fix for bug in arima function
In-Reply-To: <C12E9FD6-C398-407E-92B7-87C18FB922FD@gmail.com>
References: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>
	<C12E9FD6-C398-407E-92B7-87C18FB922FD@gmail.com>
Message-ID: <CABAt4HdvK6U+YHUN=fG=Z-fS50VCq4ivuc4MnEpnsHGMq+6NdA@mail.gmail.com>

I noticed that the 3.2.1 release cycle is about to start.  Is there any
chance that this fix will make it into the next version of R?

This bug is fairly serious: getting the wrong variance estimate leads to
the wrong log-likelihood and the wrong AIC, BIC etc, which can and does
lead to suboptimal model selection.  If it's not fixed, this issue will
affect every student taking our time series course in Fall 2015 (and
probably lots of other students in other time series courses).  When I
taught time series in Spring 2015, I had to teach students how to work
around the bug, which wasted class time and shook student confidence in R.
It'd be great if we didn?t have to deal with this issue next semester.

Again, the fix is trivial:

--- a/src/library/stats/R/arima.R
+++ b/src/library/stats/R/arima.R
@@ -211,8 +211,10 @@ arima <- function(x, order = c(0L, 0L, 0L),
         if(fit$rank == 0L) {
             ## Degenerate model. Proceed anyway so as not to break old code
             fit <- lm(x ~ xreg - 1, na.action = na.omit)
+            n.used <- sum(!is.na(resid(fit))) - length(Delta)
+        } else {
+            n.used <- sum(!is.na(resid(fit)))
         }
-        n.used <- sum(!is.na(resid(fit))) - length(Delta)
         init0 <- c(init0, coef(fit))
         ses <- summary(fit)$coefficients[, 2L]
         parscale <- c(parscale, 10 * ses)


The patch that introduced the bug (
https://github.com/wch/r-source/commit/32f633885a903bc422537dc426644f743cc645e0
) was designed to change the initialization for the optimization routine.
The proposed fix leaves the deliberate part of the patch unchanged (it
preserves the value of "init0").

--

Patrick Perry
Assistant Professor
Stern School of Business
New York University





On Tue, Apr 21, 2015 at 7:34 AM, peter dalgaard <pdalgd at gmail.com> wrote:

> The bug repository is like an elephant: It doesn't forget, but the
> gestation period is long.
>
> In the present case, it is clear that something is not right, but someone
> needs to have sufficient recall and insight to check that your proposed fix
> is not unfixing a deliberate change. We should get to it eventually. (For
> some value of "we" not including "me"...)
>
> -pd
>
> On 20 Apr 2015, at 18:34 , Patrick Perry <pperry at stern.nyu.edu> wrote:
>
> > There is currently a bug in the arima function. Namely, for arima models
> with differencing or seasonal differencing, the innovation variance
> estimator uses the wrong denominator whenever xreg is non-null. This is the
> case, for example, when fitting an ARIMA(p,1,q) model with a drift term
> (common in financial applications). I reported the bug (and a fix) at
> https://bugs.r-project.org/bugzilla3/show_bug.cgi?id=16278 , but my
> report may have fallen through the cracks due to the timing around the
> 3.2.0 release.
> >
> > The bug was introduced in the patch displayed here:
> >
> >
> https://github.com/wch/r-source/commit/32f633885a903bc422537dc426644f743cc645e0
> >
> > The fix is very simple:
> >
> >
> https://github.com/patperry/r-source/commit/c1701c05ad91d5631eef196c2007ad9897b01f85
> >
> > I?ve posted a script that demonstrates the bug at
> >
> > https://gist.github.com/patperry/90a388b056e09cf6a51b
> >
> > Please let me know if there?s anything I can do to help get this fix
> incorporated.
> >
> >
> > --
> > Patrick Perry
> > Assistant Professor
> > Stern School of Business
> > New York University
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> --
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com
>
>
>
>
>
>
>
>
>
>

	[[alternative HTML version deleted]]


From maechler at lynne.stat.math.ethz.ch  Thu May 21 10:35:38 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Thu, 21 May 2015 10:35:38 +0200
Subject: [Rd] Fix for bug in arima function
In-Reply-To: <CABAt4HdvK6U+YHUN=fG=Z-fS50VCq4ivuc4MnEpnsHGMq+6NdA@mail.gmail.com>
References: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>
	<C12E9FD6-C398-407E-92B7-87C18FB922FD@gmail.com>
	<CABAt4HdvK6U+YHUN=fG=Z-fS50VCq4ivuc4MnEpnsHGMq+6NdA@mail.gmail.com>
Message-ID: <21853.39130.479116.797885@stat.math.ethz.ch>


> I noticed that the 3.2.1 release cycle is about to start.  Is there any
> chance that this fix will make it into the next version of R?
> 
> This bug is fairly serious: getting the wrong variance estimate leads to
> the wrong log-likelihood and the wrong AIC, BIC etc, which can and does
> lead to suboptimal model selection.  If it's not fixed, this issue will
> affect every student taking our time series course in Fall 2015 (and
> probably lots of other students in other time series courses).  When I
> taught time series in Spring 2015, I had to teach students how to work
> around the bug, which wasted class time and shook student confidence in R.
> It'd be great if we didn?t have to deal with this issue next semester.
> 
> Again, the fix is trivial:
> 
> --- a/src/library/stats/R/arima.R
> +++ b/src/library/stats/R/arima.R
> @@ -211,8 +211,10 @@ arima <- function(x, order = c(0L, 0L, 0L),
>          if(fit$rank == 0L) {
>              ## Degenerate model. Proceed anyway so as not to break old code
>              fit <- lm(x ~ xreg - 1, na.action = na.omit)
> +            n.used <- sum(!is.na(resid(fit))) - length(Delta)
> +        } else {
> +            n.used <- sum(!is.na(resid(fit)))
>          }
> -        n.used <- sum(!is.na(resid(fit))) - length(Delta)
>          init0 <- c(init0, coef(fit))
>          ses <- summary(fit)$coefficients[, 2L]
>          parscale <- c(parscale, 10 * ses)
> 

Yes, such a change *is* small in the source code.
But we have to be sure about  its desirability.

In another post about this you mention "REML", and I think we
really are discussing if variance estimates should use a
denominator of  'n'  or 'n - p' in this case.


> The patch that introduced the bug (
> https://github.com/wch/r-source/commit/32f633885a903bc422537dc426644f743cc645e0
> ) was designed to change the initialization for the optimization routine.

> The proposed fix leaves the deliberate part of the patch unchanged (it
> preserves the value of "init0").

I can confirm this... a change introduced in R 3.0.2.

I'm about to commit changes ... after also adding a proper
regression test.

Martin Maechler, ETH Zurich


From maechler at lynne.stat.math.ethz.ch  Thu May 21 10:59:38 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Thu, 21 May 2015 10:59:38 +0200
Subject: [Rd] The R Foundation announces new mailing list 'R-package-devel'
Message-ID: <21853.40570.120772.8143@stat.math.ethz.ch>

New Mailing list   *** R-package-devel -- User R Packages Development ***  

At last week's monthly meeting, the R foundation has decided to
create a new mailing list in order to help R package authors in
their package development and testing.

The idea is that some experienced R programmers (often those
currently helping on R-devel or also R-help) will help package
authors and thus unload some of the burden of the CRAN team
members.

We expect impact for R-devel: I'm expecting somewhat less traffic there, 
and the focus returning to implementation of R and future features of R 
itself.

Please read the description of the mailing list here
       https://stat.ethz.ch/mailman/listinfo/r-package-devel
or below, subscribe and start using it!


For the R foundation,
Martin Maechler,  Secretary General


------------------- "About R-package-devel"  (from above URL): ---------

This list is to get help about package development in R. The goal of the list is to provide a forum for learning about the package development process. We hope to build a community of R package developers who can help each other solve problems, and reduce some of the burden on the CRAN maintainers. If you are having problems developing a package or passing R CMD check, this is the place to ask!

Please note that while R-package-devel contributors will do their best to provide you accurate and authoritative information, the final arbiters of CRAN submission is the CRAN team.

    Please keep it civil. It's easy to get frustrated when building a package, or when answering the same question for what feels like the thousandth time. But everyone involved in the process is a volunteer.
    Include a reproducible example. We can't help if we don't know what the problem is. For packages, if possible, include a link to the package source. If you're having a problem with R CMD check, include the relevant message inline.
    If you're in violation of this code, one of the moderators will send you a gentle admonishment off-list.
    For more about such "Netiquette", read the Debian code of conduct.

Note that there may be some overlap of topics with the R-devel mailing list notably as before the existence of R-package-devel, many package developers have used R-devel for questions that are now meant to be asked on this list. Beware that cross-posting, i.e., posting to both, is generally considered as impolite ? with rare exceptions, e.g., if a thread is being moved from one list to the other for good reasons.


From pdalgd at gmail.com  Thu May 21 11:03:05 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 21 May 2015 11:03:05 +0200
Subject: [Rd] Fix for bug in arima function
In-Reply-To: <21853.39130.479116.797885@stat.math.ethz.ch>
References: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>
	<C12E9FD6-C398-407E-92B7-87C18FB922FD@gmail.com>
	<CABAt4HdvK6U+YHUN=fG=Z-fS50VCq4ivuc4MnEpnsHGMq+6NdA@mail.gmail.com>
	<21853.39130.479116.797885@stat.math.ethz.ch>
Message-ID: <D75099B3-0574-4DE8-83E7-DE867E6A352F@gmail.com>


On 21 May 2015, at 10:35 , Martin Maechler <maechler at lynne.stat.math.ethz.ch> wrote:

>> 
>> I noticed that the 3.2.1 release cycle is about to start.  Is there any
>> chance that this fix will make it into the next version of R?
>> 
>> This bug is fairly serious: getting the wrong variance estimate leads to
>> the wrong log-likelihood and the wrong AIC, BIC etc, which can and does
>> lead to suboptimal model selection.  If it's not fixed, this issue will
>> affect every student taking our time series course in Fall 2015 (and
>> probably lots of other students in other time series courses).  When I
>> taught time series in Spring 2015, I had to teach students how to work
>> around the bug, which wasted class time and shook student confidence in R.
>> It'd be great if we didn?t have to deal with this issue next semester.
>> 
>> Again, the fix is trivial:
>> 
>> --- a/src/library/stats/R/arima.R
>> +++ b/src/library/stats/R/arima.R
>> @@ -211,8 +211,10 @@ arima <- function(x, order = c(0L, 0L, 0L),
>>         if(fit$rank == 0L) {
>>             ## Degenerate model. Proceed anyway so as not to break old code
>>             fit <- lm(x ~ xreg - 1, na.action = na.omit)
>> +            n.used <- sum(!is.na(resid(fit))) - length(Delta)
>> +        } else {
>> +            n.used <- sum(!is.na(resid(fit)))
>>         }
>> -        n.used <- sum(!is.na(resid(fit))) - length(Delta)
>>         init0 <- c(init0, coef(fit))
>>         ses <- summary(fit)$coefficients[, 2L]
>>         parscale <- c(parscale, 10 * ses)
>> 
> 
> Yes, such a change *is* small in the source code.
> But we have to be sure about  its desirability.
> 
> In another post about this you mention "REML", and I think we
> really are discussing if variance estimates should use a
> denominator of  'n'  or 'n - p' in this case.
> 
> 
>> The patch that introduced the bug (
>> https://github.com/wch/r-source/commit/32f633885a903bc422537dc426644f743cc645e0
>> ) was designed to change the initialization for the optimization routine.
> 
>> The proposed fix leaves the deliberate part of the patch unchanged (it
>> preserves the value of "init0").
> 
> I can confirm this... a change introduced in R 3.0.2.
> 
> I'm about to commit changes ... after also adding a proper
> regression test.
> 

Be careful here! I was just about to say that the diagnosis is dubious, and that the patch could very well be wrong!!

AFAICT, the issue is that n.used got changed from being based on lm(x~...) to lm(dx~...) where dx is the differenced series. Now that surely loses one observation in arima(.,1,.), most likely unintentionally, but it is not at all clear that the fix is not to subtract length(Delta) -- that code has been there long before the changes in 3.0.2.

I'd expect that a safer fix would be to add back the orders of the the two differencing operations.

> Martin Maechler, ETH Zurich

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at lynne.stat.math.ethz.ch  Thu May 21 12:49:09 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Thu, 21 May 2015 12:49:09 +0200
Subject: [Rd] Fix for bug in arima function
In-Reply-To: <D75099B3-0574-4DE8-83E7-DE867E6A352F@gmail.com>
References: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>
	<C12E9FD6-C398-407E-92B7-87C18FB922FD@gmail.com>
	<CABAt4HdvK6U+YHUN=fG=Z-fS50VCq4ivuc4MnEpnsHGMq+6NdA@mail.gmail.com>
	<21853.39130.479116.797885@stat.math.ethz.ch>
	<D75099B3-0574-4DE8-83E7-DE867E6A352F@gmail.com>
Message-ID: <21853.47141.218962.268511@stat.math.ethz.ch>

>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>     on Thu, 21 May 2015 11:03:05 +0200 writes:

    > On 21 May 2015, at 10:35 , Martin Maechler <maechler at lynne.stat.math.ethz.ch> wrote:

    >>> 
    >>> I noticed that the 3.2.1 release cycle is about to start.  Is there any
    >>> chance that this fix will make it into the next version of R?
    >>> 
    >>> This bug is fairly serious: getting the wrong variance estimate leads to
    >>> the wrong log-likelihood and the wrong AIC, BIC etc, which can and does
    >>> lead to suboptimal model selection.  If it's not fixed, this issue will
    >>> affect every student taking our time series course in Fall 2015 (and
    >>> probably lots of other students in other time series courses).  When I
    >>> taught time series in Spring 2015, I had to teach students how to work
    >>> around the bug, which wasted class time and shook student confidence in R.
    >>> It'd be great if we didn?t have to deal with this issue next semester.
    >>> 
    >>> Again, the fix is trivial:
    >>> 
    >>> --- a/src/library/stats/R/arima.R
    >>> +++ b/src/library/stats/R/arima.R
    >>> @@ -211,8 +211,10 @@ arima <- function(x, order = c(0L, 0L, 0L),
    >>> if(fit$rank == 0L) {
    >>> ## Degenerate model. Proceed anyway so as not to break old code
    >>> fit <- lm(x ~ xreg - 1, na.action = na.omit)
    >>> +            n.used <- sum(!is.na(resid(fit))) - length(Delta)
    >>> +        } else {
    >>> +            n.used <- sum(!is.na(resid(fit)))
    >>> }
    >>> -        n.used <- sum(!is.na(resid(fit))) - length(Delta)
    >>> init0 <- c(init0, coef(fit))
    >>> ses <- summary(fit)$coefficients[, 2L]
    >>> parscale <- c(parscale, 10 * ses)
    >>> 
    >> 
    >> Yes, such a change *is* small in the source code.
    >> But we have to be sure about  its desirability.
    >> 
    >> In another post about this you mention "REML", and I think we
    >> really are discussing if variance estimates should use a
    >> denominator of  'n'  or 'n - p' in this case.
    >> 
    >> 
    >>> The patch that introduced the bug (
    >>> https://github.com/wch/r-source/commit/32f633885a903bc422537dc426644f743cc645e0
    >>> ) was designed to change the initialization for the optimization routine.
    >> 
    >>> The proposed fix leaves the deliberate part of the patch unchanged (it
    >>> preserves the value of "init0").
    >> 
    >> I can confirm this... a change introduced in R 3.0.2.
    >> 
    >> I'm about to commit changes ... after also adding a proper
    >> regression test.
    >> 

    > Be careful here! I was just about to say that the diagnosis is dubious, and that the patch could very well be wrong!!

    > AFAICT, the issue is that n.used got changed from being based on lm(x~...) to lm(dx~...) where dx is the differenced series. Now that surely loses one observation in arima(.,1,.), most likely unintentionally, but it is not at all clear that the fix is not to subtract length(Delta) -- that code has been there long before the changes in 3.0.2.

well... yes,  but as you say for the case of the original lm()
fit where the resulting residuals and hence is.na(resid(.)) have
been longer....

    > I'd expect that a safer fix would be to add back the orders of the the two differencing operations.

What I did check before replying is that the patch *does* revert to 'R <= 3.0.1'
behavior for simple 'xreg' cases.  

I do see changes in the S.Es of the regression coefficients, as
they are expected. 

The few cases I've looked at where all giving results compatible
with R <= 3.0.1 (or the bug triggered which was fixed in R 3.0.2),
but I am happy for other examples where the
degrees of freedom should be computed differently, e.g., by
taking account the differencing orders as you suggest.

Seeing how relatively easy it still is to get the internal call
to optim() to produce an error, I do wonder if there are such
extensively tested arima(*, xreg = .) examples.

If we do not get more suggestions here, I'd like to commit to
R-devel only.   This would still not mean that this is going to
be in R 3.2.1 ... though it would be nice if others confirmed or
helped with more references.

Martin


From pdalgd at gmail.com  Thu May 21 14:36:03 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 21 May 2015 14:36:03 +0200
Subject: [Rd] Fix for bug in arima function
In-Reply-To: <21853.47141.218962.268511@stat.math.ethz.ch>
References: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>
	<C12E9FD6-C398-407E-92B7-87C18FB922FD@gmail.com>
	<CABAt4HdvK6U+YHUN=fG=Z-fS50VCq4ivuc4MnEpnsHGMq+6NdA@mail.gmail.com>
	<21853.39130.479116.797885@stat.math.ethz.ch>
	<D75099B3-0574-4DE8-83E7-DE867E6A352F@gmail.com>
	<21853.47141.218962.268511@stat.math.ethz.ch>
Message-ID: <57DB0FCD-7D29-4299-8923-37600E233508@gmail.com>


On 21 May 2015, at 12:49 , Martin Maechler <maechler at lynne.stat.math.ethz.ch> wrote:

>>>>>> peter dalgaard <pdalgd at gmail.com>
>>>>>>    on Thu, 21 May 2015 11:03:05 +0200 writes:
> 
>> On 21 May 2015, at 10:35 , Martin Maechler <maechler at lynne.stat.math.ethz.ch> wrote:
> 
>>>> 
>>>> I noticed that the 3.2.1 release cycle is about to start.  Is there any
>>>> chance that this fix will make it into the next version of R?
>>>> 
>>>> This bug is fairly serious: getting the wrong variance estimate leads to
>>>> the wrong log-likelihood and the wrong AIC, BIC etc, which can and does
>>>> lead to suboptimal model selection.  If it's not fixed, this issue will
>>>> affect every student taking our time series course in Fall 2015 (and
>>>> probably lots of other students in other time series courses).  When I
>>>> taught time series in Spring 2015, I had to teach students how to work
>>>> around the bug, which wasted class time and shook student confidence in R.
>>>> It'd be great if we didn?t have to deal with this issue next semester.
>>>> 
>>>> Again, the fix is trivial:
>>>> 
>>>> --- a/src/library/stats/R/arima.R
>>>> +++ b/src/library/stats/R/arima.R
>>>> @@ -211,8 +211,10 @@ arima <- function(x, order = c(0L, 0L, 0L),
>>>> if(fit$rank == 0L) {
>>>> ## Degenerate model. Proceed anyway so as not to break old code
>>>> fit <- lm(x ~ xreg - 1, na.action = na.omit)
>>>> +            n.used <- sum(!is.na(resid(fit))) - length(Delta)
>>>> +        } else {
>>>> +            n.used <- sum(!is.na(resid(fit)))
>>>> }
>>>> -        n.used <- sum(!is.na(resid(fit))) - length(Delta)
>>>> init0 <- c(init0, coef(fit))
>>>> ses <- summary(fit)$coefficients[, 2L]
>>>> parscale <- c(parscale, 10 * ses)
>>>> 
>>> 
>>> Yes, such a change *is* small in the source code.
>>> But we have to be sure about  its desirability.
>>> 
>>> In another post about this you mention "REML", and I think we
>>> really are discussing if variance estimates should use a
>>> denominator of  'n'  or 'n - p' in this case.
>>> 
>>> 
>>>> The patch that introduced the bug (
>>>> https://github.com/wch/r-source/commit/32f633885a903bc422537dc426644f743cc645e0
>>>> ) was designed to change the initialization for the optimization routine.
>>> 
>>>> The proposed fix leaves the deliberate part of the patch unchanged (it
>>>> preserves the value of "init0").
>>> 
>>> I can confirm this... a change introduced in R 3.0.2.
>>> 
>>> I'm about to commit changes ... after also adding a proper
>>> regression test.
>>> 
> 
>> Be careful here! I was just about to say that the diagnosis is dubious, and that the patch could very well be wrong!!
> 
>> AFAICT, the issue is that n.used got changed from being based on lm(x~...) to lm(dx~...) where dx is the differenced series. Now that surely loses one observation in arima(.,1,.), most likely unintentionally, but it is not at all clear that the fix is not to subtract length(Delta) -- that code has been there long before the changes in 3.0.2.
> 
> well... yes,  but as you say for the case of the original lm()
> fit where the resulting residuals and hence is.na(resid(.)) have
> been longer....
> 
>> I'd expect that a safer fix would be to add back the orders of the the two differencing operations.
> 
> What I did check before replying is that the patch *does* revert to 'R <= 3.0.1'
> behavior for simple 'xreg' cases.  
> 
> I do see changes in the S.Es of the regression coefficients, as
> they are expected. 
> 
> The few cases I've looked at where all giving results compatible
> with R <= 3.0.1 (or the bug triggered which was fixed in R 3.0.2),
> but I am happy for other examples where the
> degrees of freedom should be computed differently, e.g., by
> taking account the differencing orders as you suggest.
> 
> Seeing how relatively easy it still is to get the internal call
> to optim() to produce an error, I do wonder if there are such
> extensively tested arima(*, xreg = .) examples.
> 
> If we do not get more suggestions here, I'd like to commit to
> R-devel only.   This would still not mean that this is going to
> be in R 3.2.1 ... though it would be nice if others confirmed or
> helped with more references.


Hmm: Delta comes from the following computation at the start of arima()

    "%+%" <- function(a, b) .Call(C_TSconv, a, b)
....
    Delta <- 1.
    for(i in seq_len(order[2L])) Delta <- Delta %+% c(1., -1.)
    for(i in seq_len(seasonal$order[2L]))
        Delta <- Delta %+% c(1, rep.int(0, seasonal$period-1), -1)
    Delta <- - Delta[-1L]
    nd <- order[2L] + seasonal$order[2L]
    n.used <- sum(!is.na(x)) - length(Delta)

and C_TSconv is defined in C code to have a result of length(a)+length(b) -1 

So length(Delta) increases by 1 for each order of ordinary differencing and by the number of periods for each seasonal differencing. 

So length(Delta) really is the number of observations that get "lost" by differencing. That makes sense, at least in the complete-data case. I still worry that it could get things wrong if there are NAs in the middle of the series, since say

> x
 [1]  5  4  3  5 NA  5  4  6  4  3
> diff(x)
[1] -1 -1  2 NA NA -1  2 -2 -1
> diff(x,,2)
[1]  0  3 NA NA NA  3 -4  1



I suspect that what we really need is 

	fitI <- lm(x ~ xreg - 1, na.action = na.omit)
        fit <- if(length(dx) > ncol(dxreg))
            lm(dx ~ dxreg - 1, na.action = na.omit)
        else list(rank = 0L)
        if(fit$rank == 0L) {
            ## Degenerate model. Proceed anyway so as not to break old code
            fit <- fitI
        }
        n.used <- sum(!is.na(resid(fitI))) - length(Delta)
        init0 <- c(init0, coef(fit))

At least that would be the conservative change to get n.used indentical to what it was in 3.0.1


> 
> Martin

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From pperry at stern.nyu.edu  Thu May 21 18:50:49 2015
From: pperry at stern.nyu.edu (Patrick Perry)
Date: Thu, 21 May 2015 12:50:49 -0400
Subject: [Rd] Fix for bug in arima function
In-Reply-To: <57DB0FCD-7D29-4299-8923-37600E233508@gmail.com>
References: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>
	<C12E9FD6-C398-407E-92B7-87C18FB922FD@gmail.com>
	<CABAt4HdvK6U+YHUN=fG=Z-fS50VCq4ivuc4MnEpnsHGMq+6NdA@mail.gmail.com>
	<21853.39130.479116.797885@stat.math.ethz.ch>
	<D75099B3-0574-4DE8-83E7-DE867E6A352F@gmail.com>
	<21853.47141.218962.268511@stat.math.ethz.ch>
	<57DB0FCD-7D29-4299-8923-37600E233508@gmail.com>
Message-ID: <D8E16C55E055417F974952443E140369@stern.nyu.edu>

Thanks for your help, Martin and Peter.

I tried taking the value of ?n.used? from the C functions (ARIMA_CSS and ARIMA_Like) instead of computing n.used on the R side.  Here is a patch, in case you?re interested:

https://github.com/patperry/r-source/commit/8fed79a6d2d558ef34738624a2a4f9e795bcf8b9

I don't recommend applying this new patch without further follow-up.  The patch highlights some strange behavior in the ARIMA_Like function, which sometimes gives missing values the same weights as observations, resulting in values of n.used that are too high.

See the commit message for more details.


Patrick


On Thursday, May 21, 2015 at 8:36 AM, peter dalgaard wrote:

>  
> On 21 May 2015, at 12:49 , Martin Maechler <maechler at lynne.stat.math.ethz.ch (mailto:maechler at lynne.stat.math.ethz.ch)> wrote:
>  
> > > > > > > peter dalgaard <pdalgd at gmail.com (mailto:pdalgd at gmail.com)>
> > > > > > > on Thu, 21 May 2015 11:03:05 +0200 writes:
> > > > > > >  
> > > > > >  
> > > > >  
> > > >  
> > >  
> >  
> >  
> > > On 21 May 2015, at 10:35 , Martin Maechler <maechler at lynne.stat.math.ethz.ch (mailto:maechler at lynne.stat.math.ethz.ch)> wrote:
> >  
> > > > >  
> > > > > I noticed that the 3.2.1 release cycle is about to start. Is there any
> > > > > chance that this fix will make it into the next version of R?
> > > > >  
> > > > > This bug is fairly serious: getting the wrong variance estimate leads to
> > > > > the wrong log-likelihood and the wrong AIC, BIC etc, which can and does
> > > > > lead to suboptimal model selection. If it's not fixed, this issue will
> > > > > affect every student taking our time series course in Fall 2015 (and
> > > > > probably lots of other students in other time series courses). When I
> > > > > taught time series in Spring 2015, I had to teach students how to work
> > > > > around the bug, which wasted class time and shook student confidence in R.
> > > > > It'd be great if we didn?t have to deal with this issue next semester.
> > > > >  
> > > > > Again, the fix is trivial:
> > > > >  
> > > > > --- a/src/library/stats/R/arima.R
> > > > > +++ b/src/library/stats/R/arima.R
> > > > > @@ -211,8 +211,10 @@ arima <- function(x, order = c(0L, 0L, 0L),
> > > > > if(fit$rank == 0L) {
> > > > > ## Degenerate model. Proceed anyway so as not to break old code
> > > > > fit <- lm(x ~ xreg - 1, na.action = na.omit)
> > > > > + n.used <- sum(!is.na(resid(fit))) - length(Delta)
> > > > > + } else {
> > > > > + n.used <- sum(!is.na(resid(fit)))
> > > > > }
> > > > > - n.used <- sum(!is.na(resid(fit))) - length(Delta)
> > > > > init0 <- c(init0, coef(fit))
> > > > > ses <- summary(fit)$coefficients[, 2L]
> > > > > parscale <- c(parscale, 10 * ses)
> > > > >  
> > > >  
> > > >  
> > > > Yes, such a change *is* small in the source code.
> > > > But we have to be sure about its desirability.
> > > >  
> > > > In another post about this you mention "REML", and I think we
> > > > really are discussing if variance estimates should use a
> > > > denominator of 'n' or 'n - p' in this case.
> > > >  
> > > >  
> > > > > The patch that introduced the bug (
> > > > > https://github.com/wch/r-source/commit/32f633885a903bc422537dc426644f743cc645e0
> > > > > ) was designed to change the initialization for the optimization routine.
> > > > >  
> > > >  
> > > >  
> > > > > The proposed fix leaves the deliberate part of the patch unchanged (it
> > > > > preserves the value of "init0").
> > > > >  
> > > >  
> > > >  
> > > > I can confirm this... a change introduced in R 3.0.2.
> > > >  
> > > > I'm about to commit changes ... after also adding a proper
> > > > regression test.
> > > >  
> > >  
> >  
> >  
> > > Be careful here! I was just about to say that the diagnosis is dubious, and that the patch could very well be wrong!!
> >  
> > > AFAICT, the issue is that n.used got changed from being based on lm(x~...) to lm(dx~...) where dx is the differenced series. Now that surely loses one observation in arima(.,1,.), most likely unintentionally, but it is not at all clear that the fix is not to subtract length(Delta) -- that code has been there long before the changes in 3.0.2.
> >  
> > well... yes, but as you say for the case of the original lm()
> > fit where the resulting residuals and hence is.na(resid(.)) have
> > been longer....
> >  
> > > I'd expect that a safer fix would be to add back the orders of the the two differencing operations.
> >  
> > What I did check before replying is that the patch *does* revert to 'R <= 3.0.1'
> > behavior for simple 'xreg' cases.  
> >  
> > I do see changes in the S.Es of the regression coefficients, as
> > they are expected.  
> >  
> > The few cases I've looked at where all giving results compatible
> > with R <= 3.0.1 (or the bug triggered which was fixed in R 3.0.2),
> > but I am happy for other examples where the
> > degrees of freedom should be computed differently, e.g., by
> > taking account the differencing orders as you suggest.
> >  
> > Seeing how relatively easy it still is to get the internal call
> > to optim() to produce an error, I do wonder if there are such
> > extensively tested arima(*, xreg = .) examples.
> >  
> > If we do not get more suggestions here, I'd like to commit to
> > R-devel only. This would still not mean that this is going to
> > be in R 3.2.1 ... though it would be nice if others confirmed or
> > helped with more references.
> >  
>  
>  
>  
> Hmm: Delta comes from the following computation at the start of arima()
>  
> "%+%" <- function(a, b) .Call(C_TSconv, a, b)
> ....
> Delta <- 1.
> for(i in seq_len(order[2L])) Delta <- Delta %+% c(1., -1.)
> for(i in seq_len(seasonal$order[2L]))
> Delta <- Delta %+% c(1, rep.int(0, seasonal$period-1), -1)
> Delta <- - Delta[-1L]
> nd <- order[2L] + seasonal$order[2L]
> n.used <- sum(!is.na(x)) - length(Delta)
>  
> and C_TSconv is defined in C code to have a result of length(a)+length(b) -1  
>  
> So length(Delta) increases by 1 for each order of ordinary differencing and by the number of periods for each seasonal differencing.  
>  
> So length(Delta) really is the number of observations that get "lost" by differencing. That makes sense, at least in the complete-data case. I still worry that it could get things wrong if there are NAs in the middle of the series, since say
>  
> > x
> [1] 5 4 3 5 NA 5 4 6 4 3
> > diff(x)
>  
> [1] -1 -1 2 NA NA -1 2 -2 -1
> > diff(x,,2)
>  
> [1] 0 3 NA NA NA 3 -4 1
>  
>  
>  
> I suspect that what we really need is  
>  
> fitI <- lm(x ~ xreg - 1, na.action = na.omit)
> fit <- if(length(dx) > ncol(dxreg))
> lm(dx ~ dxreg - 1, na.action = na.omit)
> else list(rank = 0L)
> if(fit$rank == 0L) {
> ## Degenerate model. Proceed anyway so as not to break old code
> fit <- fitI
> }
> n.used <- sum(!is.na(resid(fitI))) - length(Delta)
> init0 <- c(init0, coef(fit))
>  
> At least that would be the conservative change to get n.used indentical to what it was in 3.0.1
>  
>  
> >  
> > Martin
>  
> --  
> Peter Dalgaard, Professor,
> Center for Statistics, Copenhagen Business School
> Solbjerg Plads 3, 2000 Frederiksberg, Denmark
> Phone: (+45)38153501
> Office: A 4.23
> Email: pd.mes at cbs.dk (mailto:pd.mes at cbs.dk) Priv: PDalgd at gmail.com (mailto:PDalgd at gmail.com)
>  
>  



	[[alternative HTML version deleted]]


From ggrothendieck at gmail.com  Sat May 23 00:25:36 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 22 May 2015 18:25:36 -0400
Subject: [Rd] returnValue()
Message-ID: <CAP01uR=ZeVze+n8O0zesN_HKN5BSjZYyw=7fcQCO8qp3c2pJYg@mail.gmail.com>

In R devel rev.66393 (2014-08-15) it was possible to do this:

   trace(optim, exit = quote(str(returnValue())))

but returnValue() does not seem to be available any more.  The above
was useful to get the output of a function when it was called deep
within another function that I have no control over.

Has this been replaced by some other equivalent function?

P.S. This demonstrates that it no longer works.  The error message is
that it cannot find function 'returnValue`:

> trace(optim, exit = quote(str(returnValue())))
Tracing function "optim" in package "stats"
[1] "optim"
> arima(presidents, order = c(1, 0, 0))
Tracing optim(init[mask], armafn, method = optim.method, hessian =
TRUE,  .... on exit
Error in str(returnValue()) : could not find function "returnValue"


-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From ggrothendieck at gmail.com  Sat May 23 02:31:30 2015
From: ggrothendieck at gmail.com (Gabor Grothendieck)
Date: Fri, 22 May 2015 20:31:30 -0400
Subject: [Rd] returnValue()
In-Reply-To: <CAP01uR=ZeVze+n8O0zesN_HKN5BSjZYyw=7fcQCO8qp3c2pJYg@mail.gmail.com>
References: <CAP01uR=ZeVze+n8O0zesN_HKN5BSjZYyw=7fcQCO8qp3c2pJYg@mail.gmail.com>
Message-ID: <CAP01uR=aMpS+J-gQfCJnx9syhXnRxkcmyrWQK1m2bWaL=9y4FA@mail.gmail.com>

Please disregard. I was running an older version of R at the time.  In
R version 3.2.0 Patched (2015-04-19 r68205) returnValue() does work.

On Fri, May 22, 2015 at 6:25 PM, Gabor Grothendieck
<ggrothendieck at gmail.com> wrote:
> In R devel rev.66393 (2014-08-15) it was possible to do this:
>
>    trace(optim, exit = quote(str(returnValue())))
>
> but returnValue() does not seem to be available any more.  The above
> was useful to get the output of a function when it was called deep
> within another function that I have no control over.
>
> Has this been replaced by some other equivalent function?
>
> P.S. This demonstrates that it no longer works.  The error message is
> that it cannot find function 'returnValue`:
>
>> trace(optim, exit = quote(str(returnValue())))
> Tracing function "optim" in package "stats"
> [1] "optim"
>> arima(presidents, order = c(1, 0, 0))
> Tracing optim(init[mask], armafn, method = optim.method, hessian =
> TRUE,  .... on exit
> Error in str(returnValue()) : could not find function "returnValue"
>
>
> --
> Statistics & Software Consulting
> GKX Group, GKX Associates Inc.
> tel: 1-877-GKX-GROUP
> email: ggrothendieck at gmail.com



-- 
Statistics & Software Consulting
GKX Group, GKX Associates Inc.
tel: 1-877-GKX-GROUP
email: ggrothendieck at gmail.com


From i.costigan at me.com  Sat May 23 02:49:19 2015
From: i.costigan at me.com (Imanuel Costigan)
Date: Sat, 23 May 2015 10:49:19 +1000
Subject: [Rd] NEWS.md support on CRAN
Message-ID: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>

Are there any plans for CRAN to support NEWS files in markdown? Bit of a hassle to go the the package?s Github (or other like) site to read NEWS.

From murdoch.duncan at gmail.com  Sat May 23 03:08:14 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Fri, 22 May 2015 21:08:14 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
Message-ID: <555FD2FE.8050600@gmail.com>

On 22/05/2015 8:49 PM, Imanuel Costigan wrote:
> Are there any plans for CRAN to support NEWS files in markdown? Bit of a hassle to go the the package?s Github (or other like) site to read NEWS.

Not as far as I know.  There have been discussions about increasing the
support of Markdown, but so far the conclusion has been that it's too
hard to do -- the support is not stable enough on all the platforms
where R runs.

Markdown is allowed for vignettes (because the package author processes
those), so I'd suggest putting your news into a vignette instead of a
news file.  Put in a token news file that points to the vignette so
users can find it.

Duncan Murdoch


From i.costigan at me.com  Sat May 23 04:04:36 2015
From: i.costigan at me.com (Imanuel Costigan)
Date: Sat, 23 May 2015 12:04:36 +1000
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <555FD2FE.8050600@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
Message-ID: <DC89531E-B9FA-47AA-BC64-F808250367C5@me.com>

What about treating it as a plain text file (i.e. no need for CRAN to support parsing)?

> On 23 May 2015, at 11:08 am, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 22/05/2015 8:49 PM, Imanuel Costigan wrote:
>> Are there any plans for CRAN to support NEWS files in markdown? Bit of a hassle to go the the package?s Github (or other like) site to read NEWS.
> 
> Not as far as I know.  There have been discussions about increasing the
> support of Markdown, but so far the conclusion has been that it's too
> hard to do -- the support is not stable enough on all the platforms
> where R runs.
> 
> Markdown is allowed for vignettes (because the package author processes
> those), so I'd suggest putting your news into a vignette instead of a
> news file.  Put in a token news file that points to the vignette so
> users can find it.
> 
> Duncan Murdoch
> 


From xie at yihui.name  Sat May 23 04:04:48 2015
From: xie at yihui.name (Yihui Xie)
Date: Fri, 22 May 2015 21:04:48 -0500
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <555FD2FE.8050600@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
Message-ID: <CANROs4fq+SNYxkLRpBfMxMvVbmYk-68O-MGO6zakoN_44xZVJg@mail.gmail.com>

What I do is to use inst/NEWS.Rd as a placeholder that points to the
NEWS.md on Github, e.g.
http://cran.rstudio.com/web/packages/knitr/index.html

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Fri, May 22, 2015 at 8:08 PM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> On 22/05/2015 8:49 PM, Imanuel Costigan wrote:
>> Are there any plans for CRAN to support NEWS files in markdown? Bit of a hassle to go the the package?s Github (or other like) site to read NEWS.
>
> Not as far as I know.  There have been discussions about increasing the
> support of Markdown, but so far the conclusion has been that it's too
> hard to do -- the support is not stable enough on all the platforms
> where R runs.
>
> Markdown is allowed for vignettes (because the package author processes
> those), so I'd suggest putting your news into a vignette instead of a
> news file.  Put in a token news file that points to the vignette so
> users can find it.
>
> Duncan Murdoch


From Kurt.Hornik at wu.ac.at  Sat May 23 10:05:16 2015
From: Kurt.Hornik at wu.ac.at (Kurt Hornik)
Date: Sat, 23 May 2015 10:05:16 +0200
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <555FD2FE.8050600@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
Message-ID: <21856.13500.513608.759602@fangorn.hornik.net>

>>>>> Duncan Murdoch writes:

> On 22/05/2015 8:49 PM, Imanuel Costigan wrote:
>> Are there any plans for CRAN to support NEWS files in markdown? Bit of a hassle to go the the package?s Github (or other like) site to read NEWS.

> Not as far as I know.  There have been discussions about increasing the
> support of Markdown, but so far the conclusion has been that it's too
> hard to do -- the support is not stable enough on all the platforms
> where R runs.

There are actually two issues here.

For CRAN, we could in principle take inst/NEWS.md files, convert these
to HTML using pandoc, and use the HTML for the package web page.  (Would
need the CRAN incoming checks to be taught about inst/NEWS.md.)

However, we cannot use such files for utils::news() because we do not
(yet?) know how to reliably parse such files and extract the news items
(and hence cannot really compute on the news information).

Btw, currently only one package on CRAN has inst/NEWS.md (another one
has NEWS.md at top level).

Best
-k

> Markdown is allowed for vignettes (because the package author processes
> those), so I'd suggest putting your news into a vignette instead of a
> news file.  Put in a token news file that points to the vignette so
> users can find it.

> Duncan Murdoch

> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Sat May 23 14:14:17 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 23 May 2015 08:14:17 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <21856.13500.513608.759602@fangorn.hornik.net>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
Message-ID: <55606F19.3080106@gmail.com>

On 23/05/2015 4:05 AM, Kurt Hornik wrote:
>>>>>> Duncan Murdoch writes:
> 
>> On 22/05/2015 8:49 PM, Imanuel Costigan wrote:
>>> Are there any plans for CRAN to support NEWS files in markdown? Bit of a hassle to go the the package?s Github (or other like) site to read NEWS.
> 
>> Not as far as I know.  There have been discussions about increasing the
>> support of Markdown, but so far the conclusion has been that it's too
>> hard to do -- the support is not stable enough on all the platforms
>> where R runs.
> 
> There are actually two issues here.
> 
> For CRAN, we could in principle take inst/NEWS.md files, convert these
> to HTML using pandoc, and use the HTML for the package web page.  (Would
> need the CRAN incoming checks to be taught about inst/NEWS.md.)
> 
> However, we cannot use such files for utils::news() because we do not
> (yet?) know how to reliably parse such files and extract the news items
> (and hence cannot really compute on the news information).

It would be quite easy to modify the news() parser to parse a suitably
described Markdown format.  The main change from the current text parser
would be to expect a prefix on the line introducing each version or
category.

I think the harder problem is display.  CRAN can run pandoc, but can
users who install the package from source?  I would expect some obscure
platforms (like Windows ;-) would not have it available.  I could add it
to Rtools on Windows, but I think platforms that normally install tools
from source will have more trouble, because it has an unusual
prerequisite (Haskell).  We could fall back to displaying the NEWS.md
file without processing, but that makes lots of code more complicated.

> 
> Btw, currently only one package on CRAN has inst/NEWS.md (another one
> has NEWS.md at top level).

I'd guess if someone solved the problems mentioned above, it would
become more popular.  Many people would convert their text NEWS to
NEWS.md if it would display better; that's a lot easier than converting
to NEWS.Rd.

Duncan Murdoch



> 
> Best
> -k
> 
>> Markdown is allowed for vignettes (because the package author processes
>> those), so I'd suggest putting your news into a vignette instead of a
>> news file.  Put in a token news file that points to the vignette so
>> users can find it.
> 
>> Duncan Murdoch
> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel


From edd at debian.org  Sat May 23 14:40:13 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sat, 23 May 2015 07:40:13 -0500
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <55606F19.3080106@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
Message-ID: <21856.29997.145029.663348@max.nulle.part>


On 23 May 2015 at 08:14, Duncan Murdoch wrote:
| I think the harder problem is display.  CRAN can run pandoc, but can
| users who install the package from source?  I would expect some obscure
| platforms (like Windows ;-) would not have it available.  I could add it
| to Rtools on Windows, but I think platforms that normally install tools
| from source will have more trouble, because it has an unusual
| prerequisite (Haskell).  We could fall back to displaying the NEWS.md
| file without processing, but that makes lots of code more complicated.

If you had spare time, you could coordinate with JJ.  He somehow managed to
get pandoc to build as a standalone binary without any runtime requirements
so that it could be included with RStudio.  And so it has been for quite some
time.  Every machine with an RStudio installation has pandoc.

Maybe we could consider carrying this over from RStudio into Rtools?
Similarly, on OS X and Linux maybe we could add a layer that would R allow to
query an RStudio instance, if present, to tell it where its pandoc is, if no
suitable pandoc binary is in the path.  Just thinking out loud...

Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From ripley at stats.ox.ac.uk  Sat May 23 14:53:13 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 23 May 2015 13:53:13 +0100
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <55606F19.3080106@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>	<555FD2FE.8050600@gmail.com>	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
Message-ID: <55607839.8010608@stats.ox.ac.uk>

On 23/05/2015 13:14, Duncan Murdoch wrote:
> On 23/05/2015 4:05 AM, Kurt Hornik wrote:
>>>>>>> Duncan Murdoch writes:
>>
>>> On 22/05/2015 8:49 PM, Imanuel Costigan wrote:
>>>> Are there any plans for CRAN to support NEWS files in markdown? Bit of a hassle to go the the package?s Github (or other like) site to read NEWS.
>>
>>> Not as far as I know.  There have been discussions about increasing the
>>> support of Markdown, but so far the conclusion has been that it's too
>>> hard to do -- the support is not stable enough on all the platforms
>>> where R runs.
>>
>> There are actually two issues here.
>>
>> For CRAN, we could in principle take inst/NEWS.md files, convert these
>> to HTML using pandoc, and use the HTML for the package web page.  (Would
>> need the CRAN incoming checks to be taught about inst/NEWS.md.)
>>
>> However, we cannot use such files for utils::news() because we do not
>> (yet?) know how to reliably parse such files and extract the news items
>> (and hence cannot really compute on the news information).
>
> It would be quite easy to modify the news() parser to parse a suitably
> described Markdown format.  The main change from the current text parser
> would be to expect a prefix on the line introducing each version or
> category.
>
> I think the harder problem is display.  CRAN can run pandoc, but can
> users who install the package from source?  I would expect some obscure
> platforms (like Windows ;-) would not have it available.  I could add it
> to Rtools on Windows, but I think platforms that normally install tools
> from source will have more trouble, because it has an unusual
> prerequisite (Haskell).  We could fall back to displaying the NEWS.md
> file without processing, but that makes lots of code more complicated.

pandoc is only viable on platforms with a pre-compiled binary, which 
does not even cover all the CRAN check platforms.  (It is not easy to 
compile ab initio from source even on a mainstream Linux, but they 
mostly have pandoc binaries.)

The next problem is that using pandoc as the de facto standard for .md 
depends on the version of pandoc, and .md seems to have no way to 
specify the version required.  (If it does, people are failing to use it 
....)


-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


From csardi.gabor at gmail.com  Sat May 23 15:25:57 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sat, 23 May 2015 09:25:57 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <55606F19.3080106@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
Message-ID: <CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>

On Sat, May 23, 2015 at 8:14 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:
[...]

> I think the harder problem is display.  CRAN can run pandoc, but can
> users who install the package from source?  I would expect some obscure
> platforms (like Windows ;-) would not have it available.
>
[...]

I don't think pandoc is the best way to go with NEWS.md (and README.md,
actually). I would be surprised if many package maintainer built their
NEWS/README files with pandoc. They just look at them at GitHub (or another
similar service).

GitHub has API for building HTML from MarkDown:
https://developer.github.com/v3/markdown/
It can build GitHub-flavored MarkDown, in which case you get links to
GitHub issues, etc. or just plain MarkDown, like a GitHub README.

If you don't want to rely on their service, then there are a multitude of
lightweight MarkDown parsers available, e.g.
https://github.com/markdown-it/markdown-it is a good one IMO.

Pandoc is great for vignettes, but you don't need its full power for
READMEs and especially not for NEWS files. In fact most NEWS.md files look
good as text.

Gabor

	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Sat May 23 16:02:18 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sat, 23 May 2015 10:02:18 -0400
Subject: [Rd] MetaCran website v1.0.0-alpha
Message-ID: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>

Dear All,

[ I was wondering if this should have gone to the new mailing list. Maybe. ]

As some of you maybe know from my earlier posts, I am building a simple
search engine for R packages. Now the search engine has a proper web site,
where you can also browse CRAN packages.

http://www.r-pkg.org/

As I see the value is in
1. package search (search box on top right)
2. APIs, see http://www.r-pkg.org/services

It is in alpha version, meaning that things seem to work, some pages are a
bit slow and there are a lot of glitches to fix.

Please tell me what you think.

Best,
Gabor

	[[alternative HTML version deleted]]


From xie at yihui.name  Sat May 23 17:31:32 2015
From: xie at yihui.name (Yihui Xie)
Date: Sat, 23 May 2015 10:31:32 -0500
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
Message-ID: <CANROs4c9-w_gdsoP-7VVfD3Zm94V+P1Ej-Qtiaqu6JgDCoC5nw@mail.gmail.com>

I agree. It is not worth all the trouble just to save the "bit of
hassle to go to the package's Github site". In fact, the release notes
on Github are more meaningful than a plain text NEWS.md or even a
converted NEWS.html from Pandoc, e.g. you can include bug report
numbers and attribute to users by @username (they all have hyperlinks
attached on them, so it is easy to see more details of bugs/features
if one really cares). Personally, I feel it is very worthwhile going
to Github and reading the release notes there. I'd be unhappy with
converting NEWS.md to NEWS.html by Pandoc. I know not all people use
Github, but I feel if a package author has a NEWS.md, chances are this
package is on Github.

Re Kurt's analysis of NEWS.md on CRAN, I guess that is because R CMD
check will warn against NEWS.md at the top level. I know a lot of
packages on Github have the NEWS.md file, and it has been removed from
the tarball to make R CMD check happy.

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Sat, May 23, 2015 at 8:25 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> On Sat, May 23, 2015 at 8:14 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
> wrote:
> [...]
>
>> I think the harder problem is display.  CRAN can run pandoc, but can
>> users who install the package from source?  I would expect some obscure
>> platforms (like Windows ;-) would not have it available.
>>
> [...]
>
> I don't think pandoc is the best way to go with NEWS.md (and README.md,
> actually). I would be surprised if many package maintainer built their
> NEWS/README files with pandoc. They just look at them at GitHub (or another
> similar service).
>
> GitHub has API for building HTML from MarkDown:
> https://developer.github.com/v3/markdown/
> It can build GitHub-flavored MarkDown, in which case you get links to
> GitHub issues, etc. or just plain MarkDown, like a GitHub README.
>
> If you don't want to rely on their service, then there are a multitude of
> lightweight MarkDown parsers available, e.g.
> https://github.com/markdown-it/markdown-it is a good one IMO.
>
> Pandoc is great for vignettes, but you don't need its full power for
> READMEs and especially not for NEWS files. In fact most NEWS.md files look
> good as text.
>
> Gabor


From csardi.gabor at gmail.com  Sat May 23 20:22:31 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sat, 23 May 2015 14:22:31 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <CANROs4c9-w_gdsoP-7VVfD3Zm94V+P1Ej-Qtiaqu6JgDCoC5nw@mail.gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<CANROs4c9-w_gdsoP-7VVfD3Zm94V+P1Ej-Qtiaqu6JgDCoC5nw@mail.gmail.com>
Message-ID: <CABtg=Kk+y_1ME-ERdP3GChjGufw0kybjzvqazvTgAyefmRAr7A@mail.gmail.com>

On Sat, May 23, 2015 at 11:31 AM, Yihui Xie <xie at yihui.name> wrote:

> I agree. It is not worth all the trouble just to save the "bit of
> hassle to go to the package's Github site". In fact, the release notes
> on Github are more meaningful than a plain text NEWS.md or even a
> converted NEWS.html from Pandoc, e.g. you can include bug report
> numbers and attribute to users by @username (they all have hyperlinks
> attached on them, so it is easy to see more details of bugs/features
> if one really cares).


Indeed. Although the GitHub API I linked can build a HTML that includes
these links, and that's already pretty good.

[...]

> Re Kurt's analysis of NEWS.md on CRAN, I guess that is because R CMD
> check will warn against NEWS.md at the top level. I know a lot of
> packages on Github have the NEWS.md file, and it has been removed from
> the tarball to make R CMD check happy.
>

I agree. The only package with inst/NEWS.md on CRAN is in fact mine
(crayon), and I put NEWS.md (and README.md) in inst/ so that

1) R CMD check and CRAN are both happy (CRAN was unhappy about non-valid
HTML build by Pandoc from README.md), and

2) they are included in the package.

Gabor

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun May 24 01:43:45 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 23 May 2015 19:43:45 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <CANROs4c9-w_gdsoP-7VVfD3Zm94V+P1Ej-Qtiaqu6JgDCoC5nw@mail.gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<CANROs4c9-w_gdsoP-7VVfD3Zm94V+P1Ej-Qtiaqu6JgDCoC5nw@mail.gmail.com>
Message-ID: <556110B1.8080701@gmail.com>

On 23/05/2015 11:31 AM, Yihui Xie wrote:
> I agree. It is not worth all the trouble just to save the "bit of
> hassle to go to the package's Github site". 

I'm sorry, but in my opinion this is not negotiable.  R needs to run on
systems without Internet connections.  It's not just a "bit of hassle".
R is used in places where not everyone has good Internet all the time.

In fact, the release notes
> on Github are more meaningful than a plain text NEWS.md or even a
> converted NEWS.html from Pandoc, e.g. you can include bug report
> numbers and attribute to users by @username (they all have hyperlinks
> attached on them, so it is easy to see more details of bugs/features
> if one really cares). Personally, I feel it is very worthwhile going
> to Github and reading the release notes there. I'd be unhappy with
> converting NEWS.md to NEWS.html by Pandoc. I know not all people use
> Github, but I feel if a package author has a NEWS.md, chances are this
> package is on Github.

Yes, NEWS.md would allow richer content than NEWS does.  That's true if
it is hosted on Github or not.  (So does NEWS.Rd, but it is so
inconvenient to write, that I think a local copy of NEWS.md would be a
better solution.)

Duncan Murdoch

> Re Kurt's analysis of NEWS.md on CRAN, I guess that is because R CMD
> check will warn against NEWS.md at the top level. I know a lot of
> packages on Github have the NEWS.md file, and it has been removed from
> the tarball to make R CMD check happy.
> 
> Regards,
> Yihui
> --
> Yihui Xie <xieyihui at gmail.com>
> Web: http://yihui.name
> 
> 
> On Sat, May 23, 2015 at 8:25 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
>> On Sat, May 23, 2015 at 8:14 AM, Duncan Murdoch <murdoch.duncan at gmail.com>
>> wrote:
>> [...]
>>
>>> I think the harder problem is display.  CRAN can run pandoc, but can
>>> users who install the package from source?  I would expect some obscure
>>> platforms (like Windows ;-) would not have it available.
>>>
>> [...]
>>
>> I don't think pandoc is the best way to go with NEWS.md (and README.md,
>> actually). I would be surprised if many package maintainer built their
>> NEWS/README files with pandoc. They just look at them at GitHub (or another
>> similar service).
>>
>> GitHub has API for building HTML from MarkDown:
>> https://developer.github.com/v3/markdown/
>> It can build GitHub-flavored MarkDown, in which case you get links to
>> GitHub issues, etc. or just plain MarkDown, like a GitHub README.
>>
>> If you don't want to rely on their service, then there are a multitude of
>> lightweight MarkDown parsers available, e.g.
>> https://github.com/markdown-it/markdown-it is a good one IMO.
>>
>> Pandoc is great for vignettes, but you don't need its full power for
>> READMEs and especially not for NEWS files. In fact most NEWS.md files look
>> good as text.
>>
>> Gabor


From murdoch.duncan at gmail.com  Sun May 24 02:00:12 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 23 May 2015 20:00:12 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>	<555FD2FE.8050600@gmail.com>	<21856.13500.513608.759602@fangorn.hornik.net>	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
Message-ID: <5561148C.7030205@gmail.com>

On 23/05/2015 9:25 AM, G?bor Cs?rdi wrote:
> On Sat, May 23, 2015 at 8:14 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> [...]
> 
>     I think the harder problem is display.  CRAN can run pandoc, but can
>     users who install the package from source?  I would expect some obscure
>     platforms (like Windows ;-) would not have it available. 
> 
> [...] 
> 
> I don't think pandoc is the best way to go with NEWS.md (and README.md,
> actually). I would be surprised if many package maintainer built their
> NEWS/README files with pandoc. They just look at them at GitHub (or
> another similar service). 
> 
> GitHub has API for building HTML from
> MarkDown: https://developer.github.com/v3/markdown/
> It can build GitHub-flavored MarkDown, in which case you get links to
> GitHub issues, etc. or just plain MarkDown, like a GitHub README.
> 
> If you don't want to rely on their service, then there are a multitude
> of lightweight MarkDown parsers available,
> e.g. https://github.com/markdown-it/markdown-it is a good one IMO.

I wouldn't want R builds to depend on GitHub, so this sounds more
interesting.  I took a look at that website, and it looks problematic to
me:  the parser appears to be written in Javascript, and the install
instructions (using "npm" and "bower", whatever those are) depend on
some unstated prerequisites.  In principle there's no reason not to
allow R builds to depend on these things, but adding a dependency like
that implies so much testing that I can't imagine anyone who could do it
would want to.

It's likely that a suitable parser could be written in some combination
of C and R -- Markdown is not a complicated language.

> Pandoc is great for vignettes, but you don't need its full power for
> READMEs and especially not for NEWS files. In fact most NEWS.md files
> look good as text.

But we do need something, and it needs to be essentially universally
available, or small enough to include in the R sources.  I think R
should eventually support Markdown as an acceptable language for
documentation (including NEWS.md, and also help files for functions),
but I think the effort required to do it now is too much.

Duncan Murdoch

> 
> Gabor
>


From csardi.gabor at gmail.com  Sun May 24 02:50:25 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sat, 23 May 2015 20:50:25 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <5561148C.7030205@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
Message-ID: <CABtg=Kksyrpk1+BLQDwO6NkJz2LCSZbYMauobugRYrr_zMBvEQ@mail.gmail.com>

On Sat, May 23, 2015 at 8:00 PM, Duncan Murdoch <murdoch.duncan at gmail.com>
wrote:
[...]

> I wouldn't want R builds to depend on GitHub, so this sounds more
> interesting.  I took a look at that website, and it looks problematic to
> me:  the parser appears to be written in Javascript, and the install
> instructions (using "npm" and "bower", whatever those are) depend on
> some unstated prerequisites.  In principle there's no reason not to
> allow R builds to depend on these things, but adding a dependency like
> that implies so much testing that I can't imagine anyone who could do it
> would want to.
>

markdown-it is already in an R package, so all you need is
devtools::install_github("jeroenooms/markdownit")
to try it.

Actually an even better alternative is 'sundown' (
https://github.com/vmg/sundown), which already has R bindings, in the
'markdown' package. I should have suggested this in the first place, sorry
for missing it.

[...]

Gabor

	[[alternative HTML version deleted]]


From i.costigan at me.com  Sun May 24 03:15:59 2015
From: i.costigan at me.com (Imanuel Costigan)
Date: Sun, 24 May 2015 11:15:59 +1000
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
	<CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
Message-ID: <7D4658B5-AE08-4477-93CE-4EE946444FA0@me.com>

While a parsed HTML version of the NEWS.md file would be nice, I would like something much simpler: being able to "see? this file in the Help pane in RStudio or being about to run something like show_news(?packagename?). Duncan mentioned issues with the news() function being able to process metadata represented in the Md file. What is the motivation of this structure? 


> On 24 May 2015, at 10:51 am, Baptiste Auguie <baptiste.auguie at gmail.com> wrote:
> 
> John MacFarlane, the author of Pandoc, has been working on a project (http://commonmark.org/) to define a standard reference for Markdown*. There are already two reference implementations, one in javascript, the other in C:  https://github.com/jgm/cmark
> 
> Regards,
> 
> baptiste
> 
> * There was some initial controversy with the original author of markdown, but in the long term it's probably one of the more reliable sources to follow.
> 
> On 24 May 2015 at 12:00, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> On 23/05/2015 9:25 AM, G?bor Cs?rdi wrote:
> > On Sat, May 23, 2015 at 8:14 AM, Duncan Murdoch
> > <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> > [...]
> >
> >     I think the harder problem is display.  CRAN can run pandoc, but can
> >     users who install the package from source?  I would expect some obscure
> >     platforms (like Windows ;-) would not have it available.
> >
> > [...]
> >
> > I don't think pandoc is the best way to go with NEWS.md (and README.md,
> > actually). I would be surprised if many package maintainer built their
> > NEWS/README files with pandoc. They just look at them at GitHub (or
> > another similar service).
> >
> > GitHub has API for building HTML from
> > MarkDown: https://developer.github.com/v3/markdown/
> > It can build GitHub-flavored MarkDown, in which case you get links to
> > GitHub issues, etc. or just plain MarkDown, like a GitHub README.
> >
> > If you don't want to rely on their service, then there are a multitude
> > of lightweight MarkDown parsers available,
> > e.g. https://github.com/markdown-it/markdown-it is a good one IMO.
> 
> I wouldn't want R builds to depend on GitHub, so this sounds more
> interesting.  I took a look at that website, and it looks problematic to
> me:  the parser appears to be written in Javascript, and the install
> instructions (using "npm" and "bower", whatever those are) depend on
> some unstated prerequisites.  In principle there's no reason not to
> allow R builds to depend on these things, but adding a dependency like
> that implies so much testing that I can't imagine anyone who could do it
> would want to.
> 
> It's likely that a suitable parser could be written in some combination
> of C and R -- Markdown is not a complicated language.
> 
> > Pandoc is great for vignettes, but you don't need its full power for
> > READMEs and especially not for NEWS files. In fact most NEWS.md files
> > look good as text.
> 
> But we do need something, and it needs to be essentially universally
> available, or small enough to include in the R sources.  I think R
> should eventually support Markdown as an acceptable language for
> documentation (including NEWS.md, and also help files for functions),
> but I think the effort required to do it now is too much.
> 
> Duncan Murdoch
> 
> >
> > Gabor
> >
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From murdoch.duncan at gmail.com  Sun May 24 04:01:14 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 23 May 2015 22:01:14 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>	<555FD2FE.8050600@gmail.com>	<21856.13500.513608.759602@fangorn.hornik.net>	<55606F19.3080106@gmail.com>	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>	<5561148C.7030205@gmail.com>
	<CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
Message-ID: <556130EA.8030904@gmail.com>

On 23/05/2015 8:51 PM, Baptiste Auguie wrote:
> John MacFarlane, the author of Pandoc, has been working on a project
> (http://commonmark.org/) to define a standard reference for Markdown*.
> There are already two reference implementations, one in javascript, the
> other in C:  https://github.com/jgm/cmark

It sounds as though there are at least two possibilities for parsers
that could be included in R:  Sundown and commonmark.  The "markdown"
package does some of what R would need to make use of Sundown, but not
all:  we really do need an R object representation of the parse tree,
for functions like news() to work with in the short term, and the help
system in the longer term.  To allow NEWS.md to be used, we'd also need
someone to work out the conventions for what's allowed (probably very
similar to the conventions for NEWS or NEWS.Rd), and write code to work
with those files.

Does anyone want to work on this?

Duncan Murdoch


> 
> Regards,
> 
> baptiste
> 
> * There was some initial controversy with the original author of
> markdown, but in the long term it's probably one of the more reliable
> sources to follow.
> 
> On 24 May 2015 at 12:00, Duncan Murdoch <murdoch.duncan at gmail.com
> <mailto:murdoch.duncan at gmail.com>> wrote:
> 
>     On 23/05/2015 9:25 AM, G?bor Cs?rdi wrote:
>     > On Sat, May 23, 2015 at 8:14 AM, Duncan Murdoch
>     > <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>
>     <mailto:murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>>>
>     wrote:
>     > [...]
>     >
>     >     I think the harder problem is display.  CRAN can run pandoc, but can
>     >     users who install the package from source?  I would expect some obscure
>     >     platforms (like Windows ;-) would not have it available.
>     >
>     > [...]
>     >
>     > I don't think pandoc is the best way to go with NEWS.md (and README.md,
>     > actually). I would be surprised if many package maintainer built their
>     > NEWS/README files with pandoc. They just look at them at GitHub (or
>     > another similar service).
>     >
>     > GitHub has API for building HTML from
>     > MarkDown: https://developer.github.com/v3/markdown/
>     > It can build GitHub-flavored MarkDown, in which case you get links to
>     > GitHub issues, etc. or just plain MarkDown, like a GitHub README.
>     >
>     > If you don't want to rely on their service, then there are a multitude
>     > of lightweight MarkDown parsers available,
>     > e.g. https://github.com/markdown-it/markdown-it is a good one IMO.
> 
>     I wouldn't want R builds to depend on GitHub, so this sounds more
>     interesting.  I took a look at that website, and it looks problematic to
>     me:  the parser appears to be written in Javascript, and the install
>     instructions (using "npm" and "bower", whatever those are) depend on
>     some unstated prerequisites.  In principle there's no reason not to
>     allow R builds to depend on these things, but adding a dependency like
>     that implies so much testing that I can't imagine anyone who could do it
>     would want to.
> 
>     It's likely that a suitable parser could be written in some combination
>     of C and R -- Markdown is not a complicated language.
> 
>     > Pandoc is great for vignettes, but you don't need its full power for
>     > READMEs and especially not for NEWS files. In fact most NEWS.md files
>     > look good as text.
> 
>     But we do need something, and it needs to be essentially universally
>     available, or small enough to include in the R sources.  I think R
>     should eventually support Markdown as an acceptable language for
>     documentation (including NEWS.md, and also help files for functions),
>     but I think the effort required to do it now is too much.
> 
>     Duncan Murdoch
> 
>     >
>     > Gabor
>     >
> 
>     ______________________________________________
>     R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>     https://stat.ethz.ch/mailman/listinfo/r-devel
> 
>


From murdoch.duncan at gmail.com  Sun May 24 04:07:00 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 23 May 2015 22:07:00 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <7D4658B5-AE08-4477-93CE-4EE946444FA0@me.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
	<CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
	<7D4658B5-AE08-4477-93CE-4EE946444FA0@me.com>
Message-ID: <55613244.8040407@gmail.com>

On 23/05/2015 9:15 PM, Imanuel Costigan wrote:
> While a parsed HTML version of the NEWS.md file would be nice, I would like something much simpler: being able to "see? this file in the Help pane in RStudio 

That isn't really any simpler.  RStudio is just displaying HTML whenever
it shows you anything in the Help pane.


or being about to run something like show_news(?packagename?). Duncan
mentioned issues with the news() function being able to process metadata
represented in the Md file. What is the motivation of this structure?

I don't understand your question.  What issues did I mention?  Or are
you talking about Kurt's post, who first mentioned news()?  And what
structure are you talking about?

Duncan Murdoch


> 
> 
>> On 24 May 2015, at 10:51 am, Baptiste Auguie <baptiste.auguie at gmail.com> wrote:
>>
>> John MacFarlane, the author of Pandoc, has been working on a project (http://commonmark.org/) to define a standard reference for Markdown*. There are already two reference implementations, one in javascript, the other in C:  https://github.com/jgm/cmark
>>
>> Regards,
>>
>> baptiste
>>
>> * There was some initial controversy with the original author of markdown, but in the long term it's probably one of the more reliable sources to follow.
>>
>> On 24 May 2015 at 12:00, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> On 23/05/2015 9:25 AM, G?bor Cs?rdi wrote:
>>> On Sat, May 23, 2015 at 8:14 AM, Duncan Murdoch
>>> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>>> [...]
>>>
>>>     I think the harder problem is display.  CRAN can run pandoc, but can
>>>     users who install the package from source?  I would expect some obscure
>>>     platforms (like Windows ;-) would not have it available.
>>>
>>> [...]
>>>
>>> I don't think pandoc is the best way to go with NEWS.md (and README.md,
>>> actually). I would be surprised if many package maintainer built their
>>> NEWS/README files with pandoc. They just look at them at GitHub (or
>>> another similar service).
>>>
>>> GitHub has API for building HTML from
>>> MarkDown: https://developer.github.com/v3/markdown/
>>> It can build GitHub-flavored MarkDown, in which case you get links to
>>> GitHub issues, etc. or just plain MarkDown, like a GitHub README.
>>>
>>> If you don't want to rely on their service, then there are a multitude
>>> of lightweight MarkDown parsers available,
>>> e.g. https://github.com/markdown-it/markdown-it is a good one IMO.
>>
>> I wouldn't want R builds to depend on GitHub, so this sounds more
>> interesting.  I took a look at that website, and it looks problematic to
>> me:  the parser appears to be written in Javascript, and the install
>> instructions (using "npm" and "bower", whatever those are) depend on
>> some unstated prerequisites.  In principle there's no reason not to
>> allow R builds to depend on these things, but adding a dependency like
>> that implies so much testing that I can't imagine anyone who could do it
>> would want to.
>>
>> It's likely that a suitable parser could be written in some combination
>> of C and R -- Markdown is not a complicated language.
>>
>>> Pandoc is great for vignettes, but you don't need its full power for
>>> READMEs and especially not for NEWS files. In fact most NEWS.md files
>>> look good as text.
>>
>> But we do need something, and it needs to be essentially universally
>> available, or small enough to include in the R sources.  I think R
>> should eventually support Markdown as an acceptable language for
>> documentation (including NEWS.md, and also help files for functions),
>> but I think the effort required to do it now is too much.
>>
>> Duncan Murdoch
>>
>>>
>>> Gabor
>>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>


From i.costigan at me.com  Sun May 24 04:08:53 2015
From: i.costigan at me.com (Imanuel Costigan)
Date: Sun, 24 May 2015 12:08:53 +1000
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <556130EA.8030904@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
	<CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
	<556130EA.8030904@gmail.com>
Message-ID: <5715F035-4DC1-42CD-A308-5C9BFED8736C@me.com>

I?d suggest going with CommonMark if this will be the basis of broader support for Markdown as it is well defined whereas GruberMarkdown is defined by broad conventions with specifics determined by parsers. 

> On 24 May 2015, at 12:01 pm, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 23/05/2015 8:51 PM, Baptiste Auguie wrote:
>> John MacFarlane, the author of Pandoc, has been working on a project
>> (http://commonmark.org/) to define a standard reference for Markdown*.
>> There are already two reference implementations, one in javascript, the
>> other in C:  https://github.com/jgm/cmark
> 
> It sounds as though there are at least two possibilities for parsers
> that could be included in R:  Sundown and commonmark.  The "markdown"
> package does some of what R would need to make use of Sundown, but not
> all:  we really do need an R object representation of the parse tree,
> for functions like news() to work with in the short term, and the help
> system in the longer term.  To allow NEWS.md to be used, we'd also need
> someone to work out the conventions for what's allowed (probably very
> similar to the conventions for NEWS or NEWS.Rd), and write code to work
> with those files.
> 
> Does anyone want to work on this?
> 
> Duncan Murdoch
> 


From i.costigan at me.com  Sun May 24 04:26:58 2015
From: i.costigan at me.com (Imanuel Costigan)
Date: Sun, 24 May 2015 12:26:58 +1000
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <55613244.8040407@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
	<CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
	<7D4658B5-AE08-4477-93CE-4EE946444FA0@me.com>
	<55613244.8040407@gmail.com>
Message-ID: <C93B1DF2-6D4F-4333-8CCF-C2036FA2B6A9@me.com>


> On 24 May 2015, at 12:07 pm, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
> 
> On 23/05/2015 9:15 PM, Imanuel Costigan wrote:
>> While a parsed HTML version of the NEWS.md file would be nice, I would like something much simpler: being able to "see? this file in the Help pane in RStudio 
> 
> That isn't really any simpler.  RStudio is just displaying HTML whenever
> it shows you anything in the Help pane.

Ok yes, point taken. My post was more in relation to a short-term ?fix? of being able to save the NEWS.md file in the package?s top level directory. Users could still be able to read it as a plain text file in their R session (esp. if they don?t have web access) AND be able to see the pretty marked up version on Github if they wished. At the moment, it isn?t possible to make this work without triggering CRAN errors (by storing it in the top-level) or losing the NEWS.md file from top level directory of the package (by saving to inst/) and making it less conventional / accessible on Github. Ideally, one should be able to get the best of both: save this in top-level directory and when necessary, just present it as a text file (at least until such time as Markdown is officially supported). 

> 
> 
> or being about to run something like show_news(?packagename?). Duncan
> mentioned issues with the news() function being able to process metadata
> represented in the Md file. What is the motivation of this structure?
> 
> I don't understand your question.  What issues did I mention?  Or are
> you talking about Kurt's post, who first mentioned news()?  And what
> structure are you talking about?

Yes I was referring to Kurt?s comments. As I understand it, the short-term ?fix? I outlined above wouldn?t work because news() expects a certain structure and can?t extract the elements that it expects from  Markdown files yet. What I am asking is why it isn?t possible / desirable for news() to simply print to the console the contents of `system.file(?NEWS.md?, package = ?packagename?)`? For example, `news(package = ?devtools?)` returns nothing because it uses ?NEWS.md?. 

> 
> Duncan Murdoch
> 
> 
>> 
>> 
>>> On 24 May 2015, at 10:51 am, Baptiste Auguie <baptiste.auguie at gmail.com> wrote:
>>> 
>>> John MacFarlane, the author of Pandoc, has been working on a project (http://commonmark.org/) to define a standard reference for Markdown*. There are already two reference implementations, one in javascript, the other in C:  https://github.com/jgm/cmark
>>> 
>>> Regards,
>>> 
>>> baptiste
>>> 
>>> * There was some initial controversy with the original author of markdown, but in the long term it's probably one of the more reliable sources to follow.
>>> 
>>> On 24 May 2015 at 12:00, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> On 23/05/2015 9:25 AM, G?bor Cs?rdi wrote:
>>>> On Sat, May 23, 2015 at 8:14 AM, Duncan Murdoch
>>>> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>>>> [...]
>>>> 
>>>>    I think the harder problem is display.  CRAN can run pandoc, but can
>>>>    users who install the package from source?  I would expect some obscure
>>>>    platforms (like Windows ;-) would not have it available.
>>>> 
>>>> [...]
>>>> 
>>>> I don't think pandoc is the best way to go with NEWS.md (and README.md,
>>>> actually). I would be surprised if many package maintainer built their
>>>> NEWS/README files with pandoc. They just look at them at GitHub (or
>>>> another similar service).
>>>> 
>>>> GitHub has API for building HTML from
>>>> MarkDown: https://developer.github.com/v3/markdown/
>>>> It can build GitHub-flavored MarkDown, in which case you get links to
>>>> GitHub issues, etc. or just plain MarkDown, like a GitHub README.
>>>> 
>>>> If you don't want to rely on their service, then there are a multitude
>>>> of lightweight MarkDown parsers available,
>>>> e.g. https://github.com/markdown-it/markdown-it is a good one IMO.
>>> 
>>> I wouldn't want R builds to depend on GitHub, so this sounds more
>>> interesting.  I took a look at that website, and it looks problematic to
>>> me:  the parser appears to be written in Javascript, and the install
>>> instructions (using "npm" and "bower", whatever those are) depend on
>>> some unstated prerequisites.  In principle there's no reason not to
>>> allow R builds to depend on these things, but adding a dependency like
>>> that implies so much testing that I can't imagine anyone who could do it
>>> would want to.
>>> 
>>> It's likely that a suitable parser could be written in some combination
>>> of C and R -- Markdown is not a complicated language.
>>> 
>>>> Pandoc is great for vignettes, but you don't need its full power for
>>>> READMEs and especially not for NEWS files. In fact most NEWS.md files
>>>> look good as text.
>>> 
>>> But we do need something, and it needs to be essentially universally
>>> available, or small enough to include in the R sources.  I think R
>>> should eventually support Markdown as an acceptable language for
>>> documentation (including NEWS.md, and also help files for functions),
>>> but I think the effort required to do it now is too much.
>>> 
>>> Duncan Murdoch
>>> 
>>>> 
>>>> Gabor
>>>> 
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>> 
>> 
> 


From Rainer at krugs.de  Sun May 24 11:44:50 2015
From: Rainer at krugs.de (Rainer M Krug)
Date: Sun, 24 May 2015 11:44:50 +0200
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	(=?utf-8?Q?=22G=C3=A1bor_Cs=C3=A1rdi=22's?= message of "Sat, 23 May 2015
	10:02:18 -0400")
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
Message-ID: <m2wpzyl371.fsf@krugs.de>

G?bor Cs?rdi <csardi.gabor at gmail.com> writes:

> Dear All,
>
> [ I was wondering if this should have gone to the new mailing list. Maybe. ]
>
> As some of you maybe know from my earlier posts, I am building a simple
> search engine for R packages. Now the search engine has a proper web site,
> where you can also browse CRAN packages.
>
> http://www.r-pkg.org/
>
> As I see the value is in
> 1. package search (search box on top right)
> 2. APIs, see http://www.r-pkg.org/services
>
> It is in alpha version, meaning that things seem to work, some pages are a
> bit slow and there are a lot of glitches to fix.

I had a quick peek, and it looks really nice! I particularly think the
github integration for diff-ing versions can be very use full!

It might be an idea, to also add R itself to the github repo for
diff-ing?

Thanks a lot,

Rainer

>
> Please tell me what you think.
>
> Best,
> Gabor
>
> 	[[alternative HTML version deleted]]
>

-- 
Rainer M. Krug
email: Rainer<at>krugs<dot>de
PGP: 0x0F52F982
-------------- next part --------------
A non-text attachment was scrubbed...
Name: not available
Type: application/pgp-signature
Size: 494 bytes
Desc: not available
URL: <https://stat.ethz.ch/pipermail/r-devel/attachments/20150524/5f7f1776/attachment.bin>

From baptiste.auguie at gmail.com  Sun May 24 02:51:16 2015
From: baptiste.auguie at gmail.com (Baptiste Auguie)
Date: Sun, 24 May 2015 12:51:16 +1200
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <5561148C.7030205@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
Message-ID: <CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>

John MacFarlane, the author of Pandoc, has been working on a project (
http://commonmark.org/) to define a standard reference for Markdown*. There
are already two reference implementations, one in javascript, the other in
C:  https://github.com/jgm/cmark

Regards,

baptiste

* There was some initial controversy with the original author of markdown,
but in the long term it's probably one of the more reliable sources to
follow.

On 24 May 2015 at 12:00, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> On 23/05/2015 9:25 AM, G?bor Cs?rdi wrote:
> > On Sat, May 23, 2015 at 8:14 AM, Duncan Murdoch
> > <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
> > [...]
> >
> >     I think the harder problem is display.  CRAN can run pandoc, but can
> >     users who install the package from source?  I would expect some
> obscure
> >     platforms (like Windows ;-) would not have it available.
> >
> > [...]
> >
> > I don't think pandoc is the best way to go with NEWS.md (and README.md,
> > actually). I would be surprised if many package maintainer built their
> > NEWS/README files with pandoc. They just look at them at GitHub (or
> > another similar service).
> >
> > GitHub has API for building HTML from
> > MarkDown: https://developer.github.com/v3/markdown/
> > It can build GitHub-flavored MarkDown, in which case you get links to
> > GitHub issues, etc. or just plain MarkDown, like a GitHub README.
> >
> > If you don't want to rely on their service, then there are a multitude
> > of lightweight MarkDown parsers available,
> > e.g. https://github.com/markdown-it/markdown-it is a good one IMO.
>
> I wouldn't want R builds to depend on GitHub, so this sounds more
> interesting.  I took a look at that website, and it looks problematic to
> me:  the parser appears to be written in Javascript, and the install
> instructions (using "npm" and "bower", whatever those are) depend on
> some unstated prerequisites.  In principle there's no reason not to
> allow R builds to depend on these things, but adding a dependency like
> that implies so much testing that I can't imagine anyone who could do it
> would want to.
>
> It's likely that a suitable parser could be written in some combination
> of C and R -- Markdown is not a complicated language.
>
> > Pandoc is great for vignettes, but you don't need its full power for
> > READMEs and especially not for NEWS files. In fact most NEWS.md files
> > look good as text.
>
> But we do need something, and it needs to be essentially universally
> available, or small enough to include in the R sources.  I think R
> should eventually support Markdown as an acceptable language for
> documentation (including NEWS.md, and also help files for functions),
> but I think the effort required to do it now is too much.
>
> Duncan Murdoch
>
> >
> > Gabor
> >
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From baptiste.auguie at gmail.com  Sun May 24 04:30:04 2015
From: baptiste.auguie at gmail.com (Baptiste Auguie)
Date: Sun, 24 May 2015 14:30:04 +1200
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <556130EA.8030904@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
	<CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
	<556130EA.8030904@gmail.com>
Message-ID: <CANLFJPqP-uRh4pGTh=++NDaXFecU9u3cZEEF7rd2dE=qZ-spPQ@mail.gmail.com>

On 24 May 2015 at 14:01, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:

> It sounds as though there are at least two possibilities for parsers
> that could be included in R:  Sundown and commonmark.
>

Sundown is in fact deprecated,
https://github.com/vmg/sundown/commit/37728fb2d7137ff7c37d0a474cb827a8d6d846d8
in favor of commonmark which will likely become the standard tool for
StackExchange, github, Reddit, among others.

The markdown package has been somewhat superseded by rmarkdown, based on
Pandoc. However commonmark would be easier to include (no dependency on
Haskell), much faster, and more memory efficient. The good folks at Rstudio
will probably have considered this option, and may even have started
working on R bindings. Commonmark seems to use an intermediate Abstract
Syntax Tree, which could be also useful for custom processing.

Regards,

baptiste

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun May 24 13:20:06 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 24 May 2015 07:20:06 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <C93B1DF2-6D4F-4333-8CCF-C2036FA2B6A9@me.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
	<CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
	<7D4658B5-AE08-4477-93CE-4EE946444FA0@me.com>
	<55613244.8040407@gmail.com>
	<C93B1DF2-6D4F-4333-8CCF-C2036FA2B6A9@me.com>
Message-ID: <5561B3E6.3060803@gmail.com>

On 23/05/2015 10:26 PM, Imanuel Costigan wrote:
> 
>> On 24 May 2015, at 12:07 pm, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>
>> On 23/05/2015 9:15 PM, Imanuel Costigan wrote:
>>> While a parsed HTML version of the NEWS.md file would be nice, I would like something much simpler: being able to "see? this file in the Help pane in RStudio 
>>
>> That isn't really any simpler.  RStudio is just displaying HTML whenever
>> it shows you anything in the Help pane.
> 
> Ok yes, point taken. My post was more in relation to a short-term ?fix? of being able to save the NEWS.md file in the package?s top level directory. Users could still be able to read it as a plain text file in their R session (esp. if they don?t have web access) AND be able to see the pretty marked up version on Github if they wished. At the moment, it isn?t possible to make this work without triggering CRAN errors (by storing it in the top-level) or losing the NEWS.md file from top level directory of the package (by saving to inst/) and making it less conventional / accessible on Github. Ideally, one should be able to get the best of both: save this in top-level directory and when necessary, just present it as a text file (at least until such time as Markdown is officially supported). 
> 
>>
>>
>> or being about to run something like show_news(?packagename?). Duncan
>> mentioned issues with the news() function being able to process metadata
>> represented in the Md file. What is the motivation of this structure?
>>
>> I don't understand your question.  What issues did I mention?  Or are
>> you talking about Kurt's post, who first mentioned news()?  And what
>> structure are you talking about?
> 
> Yes I was referring to Kurt?s comments. As I understand it, the short-term ?fix? I outlined above wouldn?t work because news() expects a certain structure and can?t extract the elements that it expects from  Markdown files yet. What I am asking is why it isn?t possible / desirable for news() to simply print to the console the contents of `system.file(?NEWS.md?, package = ?packagename?)`? For example, `news(package = ?devtools?)` returns nothing because it uses ?NEWS.md?. 

Short term fixes are generally a bad way to design software.  We should
do this right if we do it at all.  It might require people using Github
to change the way they do things, if that turns out to make more sense
than accommodating them.

Duncan Murdoch

>>
>> Duncan Murdoch
>>
>>
>>>
>>>
>>>> On 24 May 2015, at 10:51 am, Baptiste Auguie <baptiste.auguie at gmail.com> wrote:
>>>>
>>>> John MacFarlane, the author of Pandoc, has been working on a project (http://commonmark.org/) to define a standard reference for Markdown*. There are already two reference implementations, one in javascript, the other in C:  https://github.com/jgm/cmark
>>>>
>>>> Regards,
>>>>
>>>> baptiste
>>>>
>>>> * There was some initial controversy with the original author of markdown, but in the long term it's probably one of the more reliable sources to follow.
>>>>
>>>> On 24 May 2015 at 12:00, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>> On 23/05/2015 9:25 AM, G?bor Cs?rdi wrote:
>>>>> On Sat, May 23, 2015 at 8:14 AM, Duncan Murdoch
>>>>> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>>>>> [...]
>>>>>
>>>>>    I think the harder problem is display.  CRAN can run pandoc, but can
>>>>>    users who install the package from source?  I would expect some obscure
>>>>>    platforms (like Windows ;-) would not have it available.
>>>>>
>>>>> [...]
>>>>>
>>>>> I don't think pandoc is the best way to go with NEWS.md (and README.md,
>>>>> actually). I would be surprised if many package maintainer built their
>>>>> NEWS/README files with pandoc. They just look at them at GitHub (or
>>>>> another similar service).
>>>>>
>>>>> GitHub has API for building HTML from
>>>>> MarkDown: https://developer.github.com/v3/markdown/
>>>>> It can build GitHub-flavored MarkDown, in which case you get links to
>>>>> GitHub issues, etc. or just plain MarkDown, like a GitHub README.
>>>>>
>>>>> If you don't want to rely on their service, then there are a multitude
>>>>> of lightweight MarkDown parsers available,
>>>>> e.g. https://github.com/markdown-it/markdown-it is a good one IMO.
>>>>
>>>> I wouldn't want R builds to depend on GitHub, so this sounds more
>>>> interesting.  I took a look at that website, and it looks problematic to
>>>> me:  the parser appears to be written in Javascript, and the install
>>>> instructions (using "npm" and "bower", whatever those are) depend on
>>>> some unstated prerequisites.  In principle there's no reason not to
>>>> allow R builds to depend on these things, but adding a dependency like
>>>> that implies so much testing that I can't imagine anyone who could do it
>>>> would want to.
>>>>
>>>> It's likely that a suitable parser could be written in some combination
>>>> of C and R -- Markdown is not a complicated language.
>>>>
>>>>> Pandoc is great for vignettes, but you don't need its full power for
>>>>> READMEs and especially not for NEWS files. In fact most NEWS.md files
>>>>> look good as text.
>>>>
>>>> But we do need something, and it needs to be essentially universally
>>>> available, or small enough to include in the R sources.  I think R
>>>> should eventually support Markdown as an acceptable language for
>>>> documentation (including NEWS.md, and also help files for functions),
>>>> but I think the effort required to do it now is too much.
>>>>
>>>> Duncan Murdoch
>>>>
>>>>>
>>>>> Gabor
>>>>>
>>>>
>>>> ______________________________________________
>>>> R-devel at r-project.org mailing list
>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>
>>>
>>
>


From henrik.bengtsson at ucsf.edu  Sun May 24 13:40:35 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Sun, 24 May 2015 04:40:35 -0700
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <m2wpzyl371.fsf@krugs.de>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
Message-ID: <CAFDcVCRhyawMtoOEAm6+prDc4F81BuxJXtnt4nktCT+tUSR-KQ@mail.gmail.com>

On May 24, 2015 2:44 AM, "Rainer M Krug" <Rainer at krugs.de> wrote:
>
> G?bor Cs?rdi <csardi.gabor at gmail.com> writes:
>
> > Dear All,
> >
> > [ I was wondering if this should have gone to the new mailing list.
Maybe. ]
> >
> > As some of you maybe know from my earlier posts, I am building a simple
> > search engine for R packages. Now the search engine has a proper web
site,
> > where you can also browse CRAN packages.
> >
> > http://www.r-pkg.org/
> >
> > As I see the value is in
> > 1. package search (search box on top right)
> > 2. APIs, see http://www.r-pkg.org/services
> >
> > It is in alpha version, meaning that things seem to work, some pages
are a
> > bit slow and there are a lot of glitches to fix.
>
> I had a quick peek, and it looks really nice! I particularly think the
> github integration for diff-ing versions can be very use full!
>
> It might be an idea, to also add R itself to the github repo for
> diff-ing?

You'll find that at:

https://github.com/wch/r-source

Henrik

>
> Thanks a lot,
>
> Rainer
>
> >
> > Please tell me what you think.
> >
> > Best,
> > Gabor
> >
> >       [[alternative HTML version deleted]]
> >
>
> --
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sun May 24 14:58:35 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sun, 24 May 2015 08:58:35 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <5561B3E6.3060803@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
	<CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
	<7D4658B5-AE08-4477-93CE-4EE946444FA0@me.com>
	<55613244.8040407@gmail.com>
	<C93B1DF2-6D4F-4333-8CCF-C2036FA2B6A9@me.com>
	<5561B3E6.3060803@gmail.com>
Message-ID: <5561CAFB.1060006@gmail.com>

On 24/05/2015 7:20 AM, Duncan Murdoch wrote:
> On 23/05/2015 10:26 PM, Imanuel Costigan wrote:
>>
>>> On 24 May 2015, at 12:07 pm, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>
>>> On 23/05/2015 9:15 PM, Imanuel Costigan wrote:
>>>> While a parsed HTML version of the NEWS.md file would be nice, I would like something much simpler: being able to "see? this file in the Help pane in RStudio 
>>>
>>> That isn't really any simpler.  RStudio is just displaying HTML whenever
>>> it shows you anything in the Help pane.
>>
>> Ok yes, point taken. My post was more in relation to a short-term ?fix? of being able to save the NEWS.md file in the package?s top level directory. Users could still be able to read it as a plain text file in their R session (esp. if they don?t have web access) AND be able to see the pretty marked up version on Github if they wished. At the moment, it isn?t possible to make this work without triggering CRAN errors (by storing it in the top-level) or losing the NEWS.md file from top level directory of the package (by saving to inst/) and making it less conventional / accessible on Github. Ideally, one should be able to get the best of both: save this in top-level directory and when necessary, just present it as a text file (at least until such time as Markdown is officially supported). 
>>
>>>
>>>
>>> or being about to run something like show_news(?packagename?). Duncan
>>> mentioned issues with the news() function being able to process metadata
>>> represented in the Md file. What is the motivation of this structure?
>>>
>>> I don't understand your question.  What issues did I mention?  Or are
>>> you talking about Kurt's post, who first mentioned news()?  And what
>>> structure are you talking about?
>>
>> Yes I was referring to Kurt?s comments. As I understand it, the short-term ?fix? I outlined above wouldn?t work because news() expects a certain structure and can?t extract the elements that it expects from  Markdown files yet. What I am asking is why it isn?t possible / desirable for news() to simply print to the console the contents of `system.file(?NEWS.md?, package = ?packagename?)`? For example, `news(package = ?devtools?)` returns nothing because it uses ?NEWS.md?. 
> 
> Short term fixes are generally a bad way to design software.  We should
> do this right if we do it at all.  It might require people using Github
> to change the way they do things, if that turns out to make more sense
> than accommodating them.

I imagine GitHub users could have both NEWS.md and NEWS, with one being
a symlink to the other, and .Rbuildignore set to ignore NEWS.md.  Why
not try it, and post instructions for other Github users?  news() won't
be able to understand the headings, but it should display the file as a
bunch of text.

Duncan Murdoch

> 
> Duncan Murdoch
> 
>>>
>>> Duncan Murdoch
>>>
>>>
>>>>
>>>>
>>>>> On 24 May 2015, at 10:51 am, Baptiste Auguie <baptiste.auguie at gmail.com> wrote:
>>>>>
>>>>> John MacFarlane, the author of Pandoc, has been working on a project (http://commonmark.org/) to define a standard reference for Markdown*. There are already two reference implementations, one in javascript, the other in C:  https://github.com/jgm/cmark
>>>>>
>>>>> Regards,
>>>>>
>>>>> baptiste
>>>>>
>>>>> * There was some initial controversy with the original author of markdown, but in the long term it's probably one of the more reliable sources to follow.
>>>>>
>>>>> On 24 May 2015 at 12:00, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>>>> On 23/05/2015 9:25 AM, G?bor Cs?rdi wrote:
>>>>>> On Sat, May 23, 2015 at 8:14 AM, Duncan Murdoch
>>>>>> <murdoch.duncan at gmail.com <mailto:murdoch.duncan at gmail.com>> wrote:
>>>>>> [...]
>>>>>>
>>>>>>    I think the harder problem is display.  CRAN can run pandoc, but can
>>>>>>    users who install the package from source?  I would expect some obscure
>>>>>>    platforms (like Windows ;-) would not have it available.
>>>>>>
>>>>>> [...]
>>>>>>
>>>>>> I don't think pandoc is the best way to go with NEWS.md (and README.md,
>>>>>> actually). I would be surprised if many package maintainer built their
>>>>>> NEWS/README files with pandoc. They just look at them at GitHub (or
>>>>>> another similar service).
>>>>>>
>>>>>> GitHub has API for building HTML from
>>>>>> MarkDown: https://developer.github.com/v3/markdown/
>>>>>> It can build GitHub-flavored MarkDown, in which case you get links to
>>>>>> GitHub issues, etc. or just plain MarkDown, like a GitHub README.
>>>>>>
>>>>>> If you don't want to rely on their service, then there are a multitude
>>>>>> of lightweight MarkDown parsers available,
>>>>>> e.g. https://github.com/markdown-it/markdown-it is a good one IMO.
>>>>>
>>>>> I wouldn't want R builds to depend on GitHub, so this sounds more
>>>>> interesting.  I took a look at that website, and it looks problematic to
>>>>> me:  the parser appears to be written in Javascript, and the install
>>>>> instructions (using "npm" and "bower", whatever those are) depend on
>>>>> some unstated prerequisites.  In principle there's no reason not to
>>>>> allow R builds to depend on these things, but adding a dependency like
>>>>> that implies so much testing that I can't imagine anyone who could do it
>>>>> would want to.
>>>>>
>>>>> It's likely that a suitable parser could be written in some combination
>>>>> of C and R -- Markdown is not a complicated language.
>>>>>
>>>>>> Pandoc is great for vignettes, but you don't need its full power for
>>>>>> READMEs and especially not for NEWS files. In fact most NEWS.md files
>>>>>> look good as text.
>>>>>
>>>>> But we do need something, and it needs to be essentially universally
>>>>> available, or small enough to include in the R sources.  I think R
>>>>> should eventually support Markdown as an acceptable language for
>>>>> documentation (including NEWS.md, and also help files for functions),
>>>>> but I think the effort required to do it now is too much.
>>>>>
>>>>> Duncan Murdoch
>>>>>
>>>>>>
>>>>>> Gabor
>>>>>>
>>>>>
>>>>> ______________________________________________
>>>>> R-devel at r-project.org mailing list
>>>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>>>>
>>>>
>>>
>>
>


From xie at yihui.name  Sun May 24 19:20:59 2015
From: xie at yihui.name (Yihui Xie)
Date: Sun, 24 May 2015 12:20:59 -0500
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <5561CAFB.1060006@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
	<CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
	<7D4658B5-AE08-4477-93CE-4EE946444FA0@me.com>
	<55613244.8040407@gmail.com>
	<C93B1DF2-6D4F-4333-8CCF-C2036FA2B6A9@me.com>
	<5561B3E6.3060803@gmail.com> <5561CAFB.1060006@gmail.com>
Message-ID: <CANROs4c81FW1OR-g4trWPdtzMopR94FBSFLpEBbbiKXdfdw+FA@mail.gmail.com>

That is more or less what I had been doing for a long time (having
both NEWS.md and NEWS), but decided not to do it any more last year.
In fact, you can easily convert NEWS.md to a NEWS file that R's news()
can understand, e.g.
https://github.com/yihui/knitr/blob/947ad5fc94/Makefile#L8-L10 (if
your NEWS.md is like this
https://raw.githubusercontent.com/yihui/knitr/947ad5fc94/NEWS.md)

I stopped doing this because as I said, I found Github release notes
much more pleasant to read (https://github.com/yihui/knitr/releases),
and I do not care much about the possibility that some users do not
have internet connections when reading the NEWS (it is a legitimate
concern, though). IMHO, it is totally worth it if we are talking about
official support of Markdown in R's documentation system (.Rd files),
and it is probably not worth the time and effort if we only want to
support NEWS.md in particular. That is just a tiny problem compared to
the effort of porting CommonMark or whatever Markdown rendering
engines into R.

Regards,
Yihui


On Sun, May 24, 2015 at 7:58 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
>
> I imagine GitHub users could have both NEWS.md and NEWS, with one being
> a symlink to the other, and .Rbuildignore set to ignore NEWS.md.  Why
> not try it, and post instructions for other Github users?  news() won't
> be able to understand the headings, but it should display the file as a
> bunch of text.
>
> Duncan Murdoch


From kevinushey at gmail.com  Sun May 24 20:15:20 2015
From: kevinushey at gmail.com (Kevin Ushey)
Date: Sun, 24 May 2015 11:15:20 -0700
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <CANROs4c81FW1OR-g4trWPdtzMopR94FBSFLpEBbbiKXdfdw+FA@mail.gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
	<CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
	<7D4658B5-AE08-4477-93CE-4EE946444FA0@me.com>
	<55613244.8040407@gmail.com>
	<C93B1DF2-6D4F-4333-8CCF-C2036FA2B6A9@me.com>
	<5561B3E6.3060803@gmail.com> <5561CAFB.1060006@gmail.com>
	<CANROs4c81FW1OR-g4trWPdtzMopR94FBSFLpEBbbiKXdfdw+FA@mail.gmail.com>
Message-ID: <CAJXgQP072aoPm-_ZGkQmSd+pr2zV6O7rLXzhvNptyuJc8WANDg@mail.gmail.com>

I like the idea of supporting a small, strict subset of Markdown that
can be used to translate from NEWS.md to NEWS.

Following from Yihui's example, it would be pretty easy to write a
parser in R for such a format (and I'd be willing to try implementing
one, if that would be of interest).

Kevin

On Sun, May 24, 2015 at 10:20 AM, Yihui Xie <xie at yihui.name> wrote:
> That is more or less what I had been doing for a long time (having
> both NEWS.md and NEWS), but decided not to do it any more last year.
> In fact, you can easily convert NEWS.md to a NEWS file that R's news()
> can understand, e.g.
> https://github.com/yihui/knitr/blob/947ad5fc94/Makefile#L8-L10 (if
> your NEWS.md is like this
> https://raw.githubusercontent.com/yihui/knitr/947ad5fc94/NEWS.md)
>
> I stopped doing this because as I said, I found Github release notes
> much more pleasant to read (https://github.com/yihui/knitr/releases),
> and I do not care much about the possibility that some users do not
> have internet connections when reading the NEWS (it is a legitimate
> concern, though). IMHO, it is totally worth it if we are talking about
> official support of Markdown in R's documentation system (.Rd files),
> and it is probably not worth the time and effort if we only want to
> support NEWS.md in particular. That is just a tiny problem compared to
> the effort of porting CommonMark or whatever Markdown rendering
> engines into R.
>
> Regards,
> Yihui
>
>
> On Sun, May 24, 2015 at 7:58 AM, Duncan Murdoch
> <murdoch.duncan at gmail.com> wrote:
>>
>> I imagine GitHub users could have both NEWS.md and NEWS, with one being
>> a symlink to the other, and .Rbuildignore set to ignore NEWS.md.  Why
>> not try it, and post instructions for other Github users?  news() won't
>> be able to understand the headings, but it should display the file as a
>> bunch of text.
>>
>> Duncan Murdoch
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From jeroenooms at gmail.com  Sun May 24 21:14:16 2015
From: jeroenooms at gmail.com (Jeroen Ooms)
Date: Sun, 24 May 2015 21:14:16 +0200
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <556130EA.8030904@gmail.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<55606F19.3080106@gmail.com>
	<CABtg=KkjFu7Jn8xJqQjyn5bRD8nJG_aJ-QS6ET4BY+ic_d3SBw@mail.gmail.com>
	<5561148C.7030205@gmail.com>
	<CANLFJPqcFO6EJyjmmW2CFWG1C+QMgz+GMSQi+qpKW8+3K17CAA@mail.gmail.com>
	<556130EA.8030904@gmail.com>
Message-ID: <CABFfbXvY9MJ9w8AxanQ=PYz9m_nPp08cwYaT6VOibOS-ZG_ooQ@mail.gmail.com>

On Sun, May 24, 2015 at 4:01 AM, Duncan Murdoch
<murdoch.duncan at gmail.com> wrote:
> The "markdown" package does some of what R would need to make use of Sundown, but not all:  we really do need an R object representation of the parse tree, for functions like news() to work with in the short term, and the help system in the longer term.

John MacFarlane's reference implementation does provide the markdown
parsing tree, although by default it is only exposed in xml form. A
quick example:

  devtools::install_github("jeroenooms/commonmark")
  help(commonmark)

>From the xml tree you can easily extract news items using xpath, or we
could hack the libcmark library a bit to get the parse tree as an R
list.


From tim.triche at gmail.com  Sun May 24 23:23:42 2015
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Sun, 24 May 2015 14:23:42 -0700
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
Message-ID: <CAC+N9BXie9iYynG3gPJNKxe67F4Ag+HiTR6CoRhuoEBzb1_tUw@mail.gmail.com>

> Please tell me what you think.

I think it is awesome, just like the CRAN-github bridge.

It would be cool if you provided CRAN authors with instructions on how to
fork the CRAN-github clones of the source code so that I don't have to
retarget pull requests ;-)

In conclusion, keep up the great work


Statistics is the grammar of science.
Karl Pearson <http://en.wikipedia.org/wiki/The_Grammar_of_Science>

On Sat, May 23, 2015 at 7:02 AM, G?bor Cs?rdi <csardi.gabor at gmail.com>
wrote:

> Dear All,
>
> [ I was wondering if this should have gone to the new mailing list. Maybe.
> ]
>
> As some of you maybe know from my earlier posts, I am building a simple
> search engine for R packages. Now the search engine has a proper web site,
> where you can also browse CRAN packages.
>
> http://www.r-pkg.org/
>
> As I see the value is in
> 1. package search (search box on top right)
> 2. APIs, see http://www.r-pkg.org/services
>
> It is in alpha version, meaning that things seem to work, some pages are a
> bit slow and there are a lot of glitches to fix.
>
> Please tell me what you think.
>
> Best,
> Gabor
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Mon May 25 01:40:16 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 25 May 2015 01:40:16 +0200
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <m2wpzyl371.fsf@krugs.de>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
Message-ID: <55626160.50806@statistik.tu-dortmund.de>

Thanks for letting us know about the new website. Some comments:

- Download statistics: Where are they from? CRAN does not monitor 
downloads generally, maybe some selected mirrors do.
- Section "Recently updated" can only hold 9 packages, but frequently 
more than 9 get accepted even within an hour, hence not sure if this 
makes sense.
- The links "Download R" and "CRAN homepage" point to a particular link 
of a mirror rather than the official pages. I'd appreciate if you do not 
link to selected mirrors. The R homepage on purpose links to 
http://cran.r-project.org/mirrors.html when pointing to CRAN.

Best,
Uwe Ligges



On 24.05.2015 11:44, Rainer M Krug wrote:
> G?bor Cs?rdi <csardi.gabor at gmail.com> writes:
>
>> Dear All,
>>
>> [ I was wondering if this should have gone to the new mailing list. Maybe. ]
>>
>> As some of you maybe know from my earlier posts, I am building a simple
>> search engine for R packages. Now the search engine has a proper web site,
>> where you can also browse CRAN packages.
>>
>> http://www.r-pkg.org/
>>
>> As I see the value is in
>> 1. package search (search box on top right)
>> 2. APIs, see http://www.r-pkg.org/services
>>
>> It is in alpha version, meaning that things seem to work, some pages are a
>> bit slow and there are a lot of glitches to fix.
>
> I had a quick peek, and it looks really nice! I particularly think the
> github integration for diff-ing versions can be very use full!
>
> It might be an idea, to also add R itself to the github repo for
> diff-ing?
>
> Thanks a lot,
>
> Rainer
>
>>
>> Please tell me what you think.
>>
>> Best,
>> Gabor
>>
>> 	[[alternative HTML version deleted]]
>>
>
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From edd at debian.org  Mon May 25 02:29:39 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Sun, 24 May 2015 19:29:39 -0500
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <55626160.50806@statistik.tu-dortmund.de>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de> <55626160.50806@statistik.tu-dortmund.de>
Message-ID: <21858.27891.426194.718663@max.nulle.part>


Hi Uwe,

On 25 May 2015 at 01:40, Uwe Ligges wrote:
| Thanks for letting us know about the new website. Some comments:
| 
| - Download statistics: Where are they from? CRAN does not monitor 
| downloads generally, maybe some selected mirrors do.

This is the "standard" data set which has been provided by RStudio based on
the downloads from their 0-cloud content-delivery network.

This is not new; if you ever looked at rdocumentation.org (the nice and
useful site by the datacamp folks), they show(ed?) time-series plots of
downloads on the per-package pages.

Gabor has worked for quite some time on nice databasing of these number and
APIs.  He by now has a boatload of repositories at GitHub. For more on
download stats, see eg http://cranlogs.r-pkg.org/ and follow the API docs.

| - Section "Recently updated" can only hold 9 packages, but frequently 
| more than 9 get accepted even within an hour, hence not sure if this 
| makes sense.

C'est la vie.

For any cutoff one suggests, someone else will suggest that the number may be
exceeded. I on the other hand find the site nicely symmetric offering 'top
nine' in all three sections.

| - The links "Download R" and "CRAN homepage" point to a particular link 
| of a mirror rather than the official pages. I'd appreciate if you do not 
| link to selected mirrors. The R homepage on purpose links to 
| http://cran.r-project.org/mirrors.html when pointing to CRAN.

It may not be so clearcut. As previously discussed, I happen to take the
other side here. I have long changed my scripts and settings on various
machines as the CDN is _clearly_ superior in performance to the various US
mirror I used over the years, some as hardcoded names, some as DNS
round-robin or preference wrappers (eg cran.us.r-project.org).

And by pointing to the "cloud" CDN I don't even need to change the entries
on, say, my laptop when I travel to Europe.  Also, given the popularity and
load on CRAN, I can assure you that throughput is better at cran.rstudio.com.

Hth,  Dirk

| 
| Best,
| Uwe Ligges
| 
| 
| 
| On 24.05.2015 11:44, Rainer M Krug wrote:
| > G?bor Cs?rdi <csardi.gabor at gmail.com> writes:
| >
| >> Dear All,
| >>
| >> [ I was wondering if this should have gone to the new mailing list. Maybe. ]
| >>
| >> As some of you maybe know from my earlier posts, I am building a simple
| >> search engine for R packages. Now the search engine has a proper web site,
| >> where you can also browse CRAN packages.
| >>
| >> http://www.r-pkg.org/
| >>
| >> As I see the value is in
| >> 1. package search (search box on top right)
| >> 2. APIs, see http://www.r-pkg.org/services
| >>
| >> It is in alpha version, meaning that things seem to work, some pages are a
| >> bit slow and there are a lot of glitches to fix.
| >
| > I had a quick peek, and it looks really nice! I particularly think the
| > github integration for diff-ing versions can be very use full!
| >
| > It might be an idea, to also add R itself to the github repo for
| > diff-ing?
| >
| > Thanks a lot,
| >
| > Rainer
| >
| >>
| >> Please tell me what you think.
| >>
| >> Best,
| >> Gabor
| >>
| >> 	[[alternative HTML version deleted]]
| >>
| >
| >
| >
| > ______________________________________________
| > R-devel at r-project.org mailing list
| > https://stat.ethz.ch/mailman/listinfo/r-devel
| >
| 
| ______________________________________________
| R-devel at r-project.org mailing list
| https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From csardi.gabor at gmail.com  Mon May 25 02:29:54 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Sun, 24 May 2015 20:29:54 -0400
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <55626160.50806@statistik.tu-dortmund.de>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de> <55626160.50806@statistik.tu-dortmund.de>
Message-ID: <CABtg=KmpoM+VLdQtPCuRjk4jDnj_cGhyPXoNF-aKbNOF=n=R4w@mail.gmail.com>

On Sun, May 24, 2015 at 7:40 PM, Uwe Ligges <ligges at statistik.tu-dortmund.de
> wrote:

> Thanks for letting us know about the new website. Some comments:





- Download statistics: Where are they from? CRAN does not monitor downloads
> generally, maybe some selected mirrors do.
>

It's the RStudio mirror only. It is mentioned on the Services page and on
the page of the download count API. It should probably be on the main page,
but 'Most downloaded from the RStudio mirror' sounded very clumsy, even if
it is correct..... Anyway, I'll put it there in some form in a minute.

Btw. I do not think this statistics is the best:
- single mirror, although this is the least of my concerns to be honest.
- if a package is updated frequently, then it is downloaded more
frequently, even if it is not used by more people.
- if a popular package depends on another one, that is downloaded often,
too. Even if it is not used much directly. You would probably want to rank
down these packages  a bit in the search result list. A good example is my
'rversions' package, that is trending like crazy, but nobody really wants
it, only the last version of 'devtools' depends on it.

Ideally, I would want to count the number of 'install.packages()'
invocations, and this is actually technically easy without tracking anyone.
Is CRAN open to talk about this?

- Section "Recently updated" can only hold 9 packages, but frequently more
> than 9 get accepted even within an hour, hence not sure if this makes sense.
>

Click on "Recently updated", and you get the latest 100. You can get even
more with the API, if you want.


> - The links "Download R" and "CRAN homepage" point to a particular link of
> a mirror rather than the official pages. I'd appreciate if you do not link
> to selected mirrors. The R homepage on purpose links to
> http://cran.r-project.org/mirrors.html when pointing to CRAN.
>

Good points, I'll fix these. I put in that mirror, because it was fast, and
it is bound to be fast from anywhere in the world, whereas the main site
was sluggish from my location at that time.

Thanks!
Gabor

Best,
> Uwe Ligges
>
>
>
>
> On 24.05.2015 11:44, Rainer M Krug wrote:
>
>> G?bor Cs?rdi <csardi.gabor at gmail.com> writes:
>>
>>  Dear All,
>>>
>>> [ I was wondering if this should have gone to the new mailing list.
>>> Maybe. ]
>>>
>>> As some of you maybe know from my earlier posts, I am building a simple
>>> search engine for R packages. Now the search engine has a proper web
>>> site,
>>> where you can also browse CRAN packages.
>>>
>>> http://www.r-pkg.org/
>>>
>>> As I see the value is in
>>> 1. package search (search box on top right)
>>> 2. APIs, see http://www.r-pkg.org/services
>>>
>>> It is in alpha version, meaning that things seem to work, some pages are
>>> a
>>> bit slow and there are a lot of glitches to fix.
>>>
>>
>> I had a quick peek, and it looks really nice! I particularly think the
>> github integration for diff-ing versions can be very use full!
>>
>> It might be an idea, to also add R itself to the github repo for
>> diff-ing?
>>
>> Thanks a lot,
>>
>> Rainer
>>
>>
>>> Please tell me what you think.
>>>
>>> Best,
>>> Gabor
>>>
>>>         [[alternative HTML version deleted]]
>>>
>>>
>>
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>

	[[alternative HTML version deleted]]


From tal.galili at gmail.com  Mon May 25 10:57:31 2015
From: tal.galili at gmail.com (Tal Galili)
Date: Mon, 25 May 2015 11:57:31 +0300
Subject: [Rd] Probably a "bug" in the dendextend package
In-Reply-To: <CANdJ3dXMBZO2gP_ncMyM=n5NGoJi0rJ4uaC72Rw9kE3kmcpq=w@mail.gmail.com>
References: <CANdJ3dXzdw+D-Bk3_rEeYh4RSTNq4TYj-tYK2wqTQ36UYZ=BZA@mail.gmail.com>
	<21852.14886.8489.456253@stat.math.ethz.ch>
	<CANdJ3dXMBZO2gP_ncMyM=n5NGoJi0rJ4uaC72Rw9kE3kmcpq=w@mail.gmail.com>
Message-ID: <CANdJ3dW9MZLWct36PbOX+gM6WQUBOPpmAUqu7O4MiPajb3vCMg@mail.gmail.com>

To followup on the previous e-mail, I wanted to update that this bug in
dendextend has been fixed in the new version (1.0.0), which is available on
github:
https://github.com/talgalili/dendextend
Which will be submitted to CRAN in the upcoming month (before useR).

My apologies again for raising a false alarm.

With regards,
Tal



----------------Contact
Details:-------------------------------------------------------
Contact me: Tal.Galili at gmail.com |
Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
www.r-statistics.com (English)
----------------------------------------------------------------------------------------------


On Wed, May 20, 2015 at 11:02 AM, Tal Galili <tal.galili at gmail.com> wrote:

> Dear Martin,
>
> You are right. When implementing the dendextend::set function, I failed to
> notice that edgePar should accept a list instead of a vector. So all I
> did was to discover a bug in my own code.
>
> I am both sorry for taking your time due to my own mistake, and
> also grateful for your help (I will resolve this bug before submitting the
> next release to CRAN).
> I am sure that I would have had similar feelings if the situation happened
> to me - so again, I apologize :)
>
> With regards,
> Tal
>
>
>
>
>
>
>
>
>
>
>
>
> On Wed, May 20, 2015 at 10:39 AM, Martin Maechler <
> maechler at lynne.stat.math.ethz.ch> wrote:
>
>> u
>
>
>
>
>
> ----------------Contact
> Details:-------------------------------------------------------
> Contact me: Tal.Galili at gmail.com |
> Read me: www.talgalili.com (Hebrew) | www.biostatistics.co.il (Hebrew) |
> www.r-statistics.com (English)
>
> ----------------------------------------------------------------------------------------------
>
>

	[[alternative HTML version deleted]]


From ligges at statistik.tu-dortmund.de  Mon May 25 10:59:48 2015
From: ligges at statistik.tu-dortmund.de (Uwe Ligges)
Date: Mon, 25 May 2015 10:59:48 +0200
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CABtg=KmpoM+VLdQtPCuRjk4jDnj_cGhyPXoNF-aKbNOF=n=R4w@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>	<m2wpzyl371.fsf@krugs.de>	<55626160.50806@statistik.tu-dortmund.de>
	<CABtg=KmpoM+VLdQtPCuRjk4jDnj_cGhyPXoNF-aKbNOF=n=R4w@mail.gmail.com>
Message-ID: <5562E484.5000005@statistik.tu-dortmund.de>



On 25.05.2015 02:29, G?bor Cs?rdi wrote:
> On Sun, May 24, 2015 at 7:40 PM, Uwe Ligges
> <ligges at statistik.tu-dortmund.de
> <mailto:ligges at statistik.tu-dortmund.de>> wrote:
>
>     Thanks for letting us know about the new website. Some comments:
>
>     - Download statistics: Where are they from? CRAN does not monitor
>     downloads generally, maybe some selected mirrors do.
>
>
> It's the RStudio mirror only. It is mentioned on the Services page and
> on the page of the download count API. It should probably be on the main
> page, but 'Most downloaded from the RStudio mirror' sounded very clumsy,
> even if it is correct..... Anyway, I'll put it there in some form in a
> minute.
>
> Btw. I do not think this statistics is the best:
> - single mirror, although this is the least of my concerns to be honest.
> - if a package is updated frequently, then it is downloaded more
> frequently, even if it is not used by more people.
> - if a popular package depends on another one, that is downloaded often,
> too. Even if it is not used much directly. You would probably want to
> rank down these packages  a bit in the search result list. A good
> example is my 'rversions' package, that is trending like crazy, but
> nobody really wants it, only the last version of 'devtools' depends on it.
>
> Ideally, I would want to count the number of 'install.packages()'
> invocations, and this is actually technically easy without tracking
> anyone. Is CRAN open to talk about this?
>
>     - Section "Recently updated" can only hold 9 packages, but
>     frequently more than 9 get accepted even within an hour, hence not
>     sure if this makes sense.
>
>
> Click on "Recently updated", and you get the latest 100. You can get
> even more with the API, if you want.
>
>     - The links "Download R" and "CRAN homepage" point to a particular
>     link of a mirror rather than the official pages. I'd appreciate if
>     you do not link to selected mirrors. The R homepage on purpose links
>     to http://cran.r-project.org/mirrors.html when pointing to CRAN.
>
>
> Good points, I'll fix these. I put in that mirror, because it was fast,
> and it is bound to be fast from anywhere in the world, whereas the main
> site was sluggish from my location at that time.


OK, thanks!

Uwe

> Thanks!
> Gabor
>
>     Best,
>     Uwe Ligges
>
>
>
>
>     On 24.05.2015 11 <tel:24.05.2015%2011>:44, Rainer M Krug wrote:
>
>         G?bor Cs?rdi <csardi.gabor at gmail.com
>         <mailto:csardi.gabor at gmail.com>> writes:
>
>             Dear All,
>
>             [ I was wondering if this should have gone to the new
>             mailing list. Maybe. ]
>
>             As some of you maybe know from my earlier posts, I am
>             building a simple
>             search engine for R packages. Now the search engine has a
>             proper web site,
>             where you can also browse CRAN packages.
>
>             http://www.r-pkg.org/
>
>             As I see the value is in
>             1. package search (search box on top right)
>             2. APIs, see http://www.r-pkg.org/services
>
>             It is in alpha version, meaning that things seem to work,
>             some pages are a
>             bit slow and there are a lot of glitches to fix.
>
>
>         I had a quick peek, and it looks really nice! I particularly
>         think the
>         github integration for diff-ing versions can be very use full!
>
>         It might be an idea, to also add R itself to the github repo for
>         diff-ing?
>
>         Thanks a lot,
>
>         Rainer
>
>
>             Please tell me what you think.
>
>             Best,
>             Gabor
>
>                      [[alternative HTML version deleted]]
>
>
>
>
>         ______________________________________________
>         R-devel at r-project.org <mailto:R-devel at r-project.org> mailing list
>         https://stat.ethz.ch/mailman/listinfo/r-devel
>
>


From richierocks at gmail.com  Mon May 25 15:38:05 2015
From: richierocks at gmail.com (Richard Cotton)
Date: Mon, 25 May 2015 16:38:05 +0300
Subject: [Rd] Unicode display problem with data frames under Windows
Message-ID: <CAPp_+=fxGdbPvQ7cdS8uopK5kRmcVydO0DVAfN4hPF56Rpeirg@mail.gmail.com>

Here's a data frame with some Unicode symbols (set intersection and union).

d <- data.frame(x = "A \u222a B \u2229 C")

Printing this data frame under R 3.2.0 patched (r68378) and Windows 7, I see

d
##                  x
## 1 A <U+222A> B n C

Printing the column itself works fine.

d$x
## [1] A ? B ? C
## Levels: A ? B ? C

The encoding is correctly UTF-8.

Encoding(as.character(d$x))
## [1] "UTF-8"

Under Linux both forms of printing are fine for me.

I'm not quite sure whether I've missed a setting or if this is a bug, so

Am I doing something silly?
Can anyone else reproduce this?

-- 
Regards,
Richie

Learning R
4dpiecharts.com

	[[alternative HTML version deleted]]


From istazahn at gmail.com  Mon May 25 17:37:50 2015
From: istazahn at gmail.com (Ista Zahn)
Date: Mon, 25 May 2015 11:37:50 -0400
Subject: [Rd] Unicode display problem with data frames under Windows
In-Reply-To: <CAPp_+=fxGdbPvQ7cdS8uopK5kRmcVydO0DVAfN4hPF56Rpeirg@mail.gmail.com>
References: <CAPp_+=fxGdbPvQ7cdS8uopK5kRmcVydO0DVAfN4hPF56Rpeirg@mail.gmail.com>
Message-ID: <CA+vqiLHCD26qXDpmiwEWGQ6EQBu-zMsWb6hUeJzWtSp-veQFww@mail.gmail.com>

AFAIK this is the way it works on Windows. It has been discussed in several
places, e.g.
http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r
,
http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r
(both of these came up when I googled the subject line of your email).

Best,
Ista
On May 25, 2015 9:39 AM, "Richard Cotton" <richierocks at gmail.com> wrote:

> Here's a data frame with some Unicode symbols (set intersection and union).
>
> d <- data.frame(x = "A \u222a B \u2229 C")
>
> Printing this data frame under R 3.2.0 patched (r68378) and Windows 7, I
> see
>
> d
> ##                  x
> ## 1 A <U+222A> B n C
>
> Printing the column itself works fine.
>
> d$x
> ## [1] A ? B ? C
> ## Levels: A ? B ? C
>
> The encoding is correctly UTF-8.
>
> Encoding(as.character(d$x))
> ## [1] "UTF-8"
>
> Under Linux both forms of printing are fine for me.
>
> I'm not quite sure whether I've missed a setting or if this is a bug, so
>
> Am I doing something silly?
> Can anyone else reproduce this?
>
> --
> Regards,
> Richie
>
> Learning R
> 4dpiecharts.com
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Mon May 25 18:43:32 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 25 May 2015 12:43:32 -0400
Subject: [Rd] Unicode display problem with data frames under Windows
In-Reply-To: <CA+vqiLHCD26qXDpmiwEWGQ6EQBu-zMsWb6hUeJzWtSp-veQFww@mail.gmail.com>
References: <CAPp_+=fxGdbPvQ7cdS8uopK5kRmcVydO0DVAfN4hPF56Rpeirg@mail.gmail.com>
	<CA+vqiLHCD26qXDpmiwEWGQ6EQBu-zMsWb6hUeJzWtSp-veQFww@mail.gmail.com>
Message-ID: <55635134.4070407@gmail.com>

On 25/05/2015 11:37 AM, Ista Zahn wrote:
> AFAIK this is the way it works on Windows. It has been discussed in several
> places, e.g.
> http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r
> ,
> http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r
> (both of these came up when I googled the subject line of your email).

Yes, but it is a bug, just a hard one to fix.  It needs someone to 
dedicate a serious amount of time to deal with it.

Since most of the people who tend to do that generally use systems in 
UTF-8 locales where this isn't a problem, or don't use Windows, it is 
languishing.

Duncan Murdoch
>
> Best,
> Ista
> On May 25, 2015 9:39 AM, "Richard Cotton" <richierocks at gmail.com> wrote:
>
> > Here's a data frame with some Unicode symbols (set intersection and union).
> >
> > d <- data.frame(x = "A \u222a B \u2229 C")
> >
> > Printing this data frame under R 3.2.0 patched (r68378) and Windows 7, I
> > see
> >
> > d
> > ##                  x
> > ## 1 A <U+222A> B n C
> >
> > Printing the column itself works fine.
> >
> > d$x
> > ## [1] A ? B ? C
> > ## Levels: A ? B ? C
> >
> > The encoding is correctly UTF-8.
> >
> > Encoding(as.character(d$x))
> > ## [1] "UTF-8"
> >
> > Under Linux both forms of printing are fine for me.
> >
> > I'm not quite sure whether I've missed a setting or if this is a bug, so
> >
> > Am I doing something silly?
> > Can anyone else reproduce this?
> >
> > --
> > Regards,
> > Richie
> >
> > Learning R
> > 4dpiecharts.com
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Mon May 25 18:45:33 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 25 May 2015 12:45:33 -0400
Subject: [Rd] Unicode display problem with data frames under Windows
In-Reply-To: <55635134.4070407@gmail.com>
References: <CAPp_+=fxGdbPvQ7cdS8uopK5kRmcVydO0DVAfN4hPF56Rpeirg@mail.gmail.com>
	<CA+vqiLHCD26qXDpmiwEWGQ6EQBu-zMsWb6hUeJzWtSp-veQFww@mail.gmail.com>
	<55635134.4070407@gmail.com>
Message-ID: <556351AD.30007@gmail.com>

On 25/05/2015 12:43 PM, Duncan Murdoch wrote:
> On 25/05/2015 11:37 AM, Ista Zahn wrote:
> > AFAIK this is the way it works on Windows. It has been discussed in several
> > places, e.g.
> > http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r
> > ,
> > http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r
> > (both of these came up when I googled the subject line of your email).
>
> Yes, but it is a bug, just a hard one to fix.  It needs someone to
> dedicate a serious amount of time to deal with it.
>
> Since most of the people who tend to do that generally use systems in
> UTF-8 locales where this isn't a problem, or don't use Windows, it is
> languishing.

Oops, I meant to write "or don't use non-ascii characters", the UTF-8 
locales implies non-Windows.

Duncan Murdoch


From David.Teller at nielsen.com  Mon May 25 19:25:50 2015
From: David.Teller at nielsen.com (Teller, David)
Date: Mon, 25 May 2015 17:25:50 +0000
Subject: [Rd] foreach hangs when using doMPI on Windows with Microsoft MPI
Message-ID: <BY1PR0701MB187888302F4588EC635ACB3E95CD0@BY1PR0701MB1878.namprd07.prod.outlook.com>

??I installed Microsoft MPI.

Then installed the foreach and Rmpi packages.

Then built doMPI from source.


mpi.remote.exec works.

foreach hangs with the main process and all worker processes idle.


I launch my script with mpiexec:


"C:\Program Files\Microsoft MPI\Bin\mpiexec" -n 3 "C:\Program Files\R\R-3.2.0\bin\x64\Rterm.exe" --no-save -q -f "MPI Test.r"

The script is:


library(Rmpi)
library(doMPI)
library(foreach)


cl <- startMPIcluster()
print(cl)

registerDoMPI(cl)


mpi.remote.exec(paste(Sys.info()[['nodename']], Sys.getpid(), mpi.comm.rank(), "of", mpi.comm.size()))


# Hangs at this point

# Main process and worker processes are all idle

ni <- foreach(i=1:10) %dopar% {
  paste(Sys.info()[['nodename']], Sys.getpid(), mpi.comm.rank(), "of", mpi.comm.size())
}


mpi.close.Rslaves()
mpi.quit()

Prints:


C:\Users\dteller\Documents\MPI>"C:\Program Files\Microsoft MPI\Bin\mpiexec" -n 3
 "C:\Program Files\R\R-3.2.0\bin\x64\Rterm.exe" --no-save -q -f "MPI Test.r"
master (rank 0, comm 1) of size 3 is running on: dteller-dv7
slave1 (rank 1, comm 1) of size 3 is running on: dteller-dv7
slave2 (rank 2, comm 1) of size 3 is running on: dteller-dv7
> library(Rmpi)
> library(doMPI)
Loading required package: foreach
Loading required package: iterators
> library(foreach)
>
> cl <- startMPIcluster()
> print(cl)
$comm
[1] 0

$workerCount
[1] 2

$workerid
[1] 0

$verbose
[1] FALSE

$mtag
[1] 10

$wtag
[1] 11

attr(,"class")
[1] "mpicluster"   "dompicluster"
> registerDoMPI(cl)
>
> mpi.remote.exec(paste(Sys.info()[['nodename']], Sys.getpid(), mpi.comm.rank(),
 "of", mpi.comm.size()))
$slave1
[1] "DTELLER-DV7 1116 1 of 3"

$slave2
[1] "DTELLER-DV7 9436 2 of 3"

>
> ni <- foreach(i=1:10) %dopar% {
+   paste(Sys.info()[['nodename']], Sys.getpid(), mpi.comm.rank(), "of", mpi.com
m.size())
+ }



Thanks for any help.


Dave Teller



	[[alternative HTML version deleted]]


From retep.meissner at gmail.com  Mon May 25 21:12:05 2015
From: retep.meissner at gmail.com (Peter Meissner)
Date: Mon, 25 May 2015 21:12:05 +0200
Subject: [Rd] Unicode display problem with data frames under Windows
In-Reply-To: <55635134.4070407@gmail.com>
References: <CAPp_+=fxGdbPvQ7cdS8uopK5kRmcVydO0DVAfN4hPF56Rpeirg@mail.gmail.com>
	<CA+vqiLHCD26qXDpmiwEWGQ6EQBu-zMsWb6hUeJzWtSp-veQFww@mail.gmail.com>
	<55635134.4070407@gmail.com>
Message-ID: <op.xy7gyfiz3euttn@peter-think.fritz.box>

Am .05.2015, 18:43 Uhr, schrieb Duncan Murdoch <murdoch.duncan at gmail.com>:

> On 25/05/2015 11:37 AM, Ista Zahn wrote:
>> AFAIK this is the way it works on Windows. It has been discussed in  
>> several
>> places, e.g.
>> http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r
>> ,
>> http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r
>> (both of these came up when I googled the subject line of your email).
>
> Yes, but it is a bug, just a hard one to fix.  It needs someone to  
> dedicate a serious amount of time to deal with it.
>
> Since most of the people who tend to do that generally use systems in  
> UTF-8 locales where this isn't a problem, or don't use Windows, it is  
> languishing.
>
> Duncan Murdoch


I understand that these problems are not easy to fix but ...

I think that
"most of the people who tend to do that generally use systems in UTF-8  
locales"
is a biased perception. Developers might tend to use Mac or Linux most  
often. For others Windows still is and probably will be the OS most often  
used. For most of them switching to something else is a major hurdle.

What I often witness is that those non existent Windows users try to  
muddle through with numerous calls to Encoding() , iconv() and the like  
while at the same time never being sure if the strange behavior is due to  
their lack of understanding, Windows specifics or due to R. In the end  
they either succeed with their muddling or give up,  - but do not change  
the system.

So whoever might attempt the Hercules task will be praised by thousands ;-)

Best, Peter


>>
>> Best,
>> Ista
>> On May 25, 2015 9:39 AM, "Richard Cotton" <richierocks at gmail.com> wrote:
>>
>> > Here's a data frame with some Unicode symbols (set intersection and  
>> union).
>> >
>> > d <- data.frame(x = "A \u222a B \u2229 C")
>> >
>> > Printing this data frame under R 3.2.0 patched (r68378) and Windows  
>> 7, I
>> > see
>> >
>> > d
>> > ##                  x
>> > ## 1 A <U+222A> B n C
>> >
>> > Printing the column itself works fine.
>> >
>> > d$x
>> > ## [1] A ? B ? C
>> > ## Levels: A ? B ? C
>> >
>> > The encoding is correctly UTF-8.
>> >
>> > Encoding(as.character(d$x))
>> > ## [1] "UTF-8"
>> >
>> > Under Linux both forms of printing are fine for me.
>> >
>> > I'm not quite sure whether I've missed a setting or if this is a bug,  
>> so
>> >
>> > Am I doing something silly?
>> > Can anyone else reproduce this?
>> >
>> > --
>> > Regards,
>> > Richie
>> >
>> > Learning R
>> > 4dpiecharts.com
>> >
>> >         [[alternative HTML version deleted]]
>> >
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>> >
>>
>> 	[[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From murdoch.duncan at gmail.com  Mon May 25 21:35:03 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Mon, 25 May 2015 15:35:03 -0400
Subject: [Rd] Unicode display problem with data frames under Windows
In-Reply-To: <op.xy7gyfiz3euttn@peter-think.fritz.box>
References: <CAPp_+=fxGdbPvQ7cdS8uopK5kRmcVydO0DVAfN4hPF56Rpeirg@mail.gmail.com>	<CA+vqiLHCD26qXDpmiwEWGQ6EQBu-zMsWb6hUeJzWtSp-veQFww@mail.gmail.com>	<55635134.4070407@gmail.com>
	<op.xy7gyfiz3euttn@peter-think.fritz.box>
Message-ID: <55637967.9070701@gmail.com>

On 25/05/2015 3:12 PM, Peter Meissner wrote:
> Am .05.2015, 18:43 Uhr, schrieb Duncan Murdoch <murdoch.duncan at gmail.com>:
>
> > On 25/05/2015 11:37 AM, Ista Zahn wrote:
> >> AFAIK this is the way it works on Windows. It has been discussed in
> >> several
> >> places, e.g.
> >> http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r
> >> ,
> >> http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r
> >> (both of these came up when I googled the subject line of your email).
> >
> > Yes, but it is a bug, just a hard one to fix.  It needs someone to
> > dedicate a serious amount of time to deal with it.
> >
> > Since most of the people who tend to do that generally use systems in
> > UTF-8 locales where this isn't a problem, or don't use Windows, it is
> > languishing.
> >
> > Duncan Murdoch
>
>
> I understand that these problems are not easy to fix but ...
>
> I think that
> "most of the people who tend to do that generally use systems in UTF-8
> locales"
> is a biased perception. Developers might tend to use Mac or Linux most
> often. For others Windows still is and probably will be the OS most often
> used. For most of them switching to something else is a major hurdle.
>
> What I often witness is that those non existent Windows users try to
> muddle through with numerous calls to Encoding() , iconv() and the like
> while at the same time never being sure if the strange behavior is due to
> their lack of understanding, Windows specifics or due to R. In the end
> they either succeed with their muddling or give up,  - but do not change
> the system.
>
> So whoever might attempt the Hercules task will be praised by thousands ;-)
I'm not sure we disagree.  R is a volunteer project, and the things that 
get done are the things that someone volunteers to do.  But in this 
particular case, the volunteer needs a lot of knowledge about R 
internals to make progress, and there just aren't that many people like 
that.   They are all "developers".

If you aren't one of those people, you need to motivate one of them to 
volunteer to take this on.  I don't think a financial contribution would 
work, but people do return favours:  so do something that makes one of 
the developers' lives a lot easier, and then point out how this 
particular bug is causing trouble for you, and maybe they'll choose to 
return the favour.

Duncan Murdoch


From simon.urbanek at r-project.org  Tue May 26 02:28:44 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Mon, 25 May 2015 20:28:44 -0400
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <m2wpzyl371.fsf@krugs.de>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
Message-ID: <0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>

One issue I have with this is that it doesn't point to the original GitHub repositories of the packages, so you end up with additional repositories on Github in Gabor's name that have nothing to do with the actual Github repositories of the packages. I understand that it's technically necessary, but I fear it will lead to a lot of confusion...


On May 24, 2015, at 5:44 AM, Rainer M Krug <Rainer at krugs.de> wrote:

> G?bor Cs?rdi <csardi.gabor at gmail.com> writes:
> 
>> Dear All,
>> 
>> [ I was wondering if this should have gone to the new mailing list. Maybe. ]
>> 
>> As some of you maybe know from my earlier posts, I am building a simple
>> search engine for R packages. Now the search engine has a proper web site,
>> where you can also browse CRAN packages.
>> 
>> http://www.r-pkg.org/
>> 
>> As I see the value is in
>> 1. package search (search box on top right)
>> 2. APIs, see http://www.r-pkg.org/services
>> 
>> It is in alpha version, meaning that things seem to work, some pages are a
>> bit slow and there are a lot of glitches to fix.
> 
> I had a quick peek, and it looks really nice! I particularly think the
> github integration for diff-ing versions can be very use full!
> 
> It might be an idea, to also add R itself to the github repo for
> diff-ing?
> 
> Thanks a lot,
> 
> Rainer
> 
>> 
>> Please tell me what you think.
>> 
>> Best,
>> Gabor
>> 
>> 	[[alternative HTML version deleted]]
>> 
> 
> -- 
> Rainer M. Krug
> email: Rainer<at>krugs<dot>de
> PGP: 0x0F52F982
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From richierocks at gmail.com  Tue May 26 09:01:00 2015
From: richierocks at gmail.com (Richard Cotton)
Date: Tue, 26 May 2015 10:01:00 +0300
Subject: [Rd] Unicode display problem with data frames under Windows
In-Reply-To: <55635134.4070407@gmail.com>
References: <CAPp_+=fxGdbPvQ7cdS8uopK5kRmcVydO0DVAfN4hPF56Rpeirg@mail.gmail.com>
	<CA+vqiLHCD26qXDpmiwEWGQ6EQBu-zMsWb6hUeJzWtSp-veQFww@mail.gmail.com>
	<55635134.4070407@gmail.com>
Message-ID: <CAPp_+=erhTeV56Sg=ycZpT9oKXT9h6+7UJ6AyaSxD7iceNJShA@mail.gmail.com>

On 25 May 2015 at 19:43, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>> http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r

> Yes, but it is a bug, just a hard one to fix.  It needs someone to dedicate
> a serious amount of time to deal with it.
>
> Since most of the people who tend to do that generally use systems in UTF-8
> locales where this isn't a problem, or don't use Windows, it is languishing.

Thanks for the link and the explanation of why the bug exists.

>> On May 25, 2015 9:39 AM, "Richard Cotton" <richierocks at gmail.com> wrote:
>>
>> > Here's a data frame with some Unicode symbols (set intersection and
>> > union).
>> >
>> > d <- data.frame(x = "A \u222a B \u2229 C")
>> >
>> > Printing this data frame under R 3.2.0 patched (r68378) and Windows 7, I
>> > see
>> >
>> > d
>> > ##                  x
>> > ## 1 A <U+222A> B n C

For future readers searching for a solution to this, you can get
correct printing by setting the CTYPE part of the locale to
Chinese/Japanese/Korean.

Sys.setlocale("LC_CTYPE", "Chinese")
## [1] "Chinese (Simplified)_People's Republic of China.936"

d
##            x
## 1 A ? B ? C

-- 
Regards,
Richie

Learning R
4dpiecharts.com


From retep.meissner at gmail.com  Tue May 26 09:29:17 2015
From: retep.meissner at gmail.com (Peter Meissner)
Date: Tue, 26 May 2015 09:29:17 +0200
Subject: [Rd] Unicode display problem with data frames under Windows
In-Reply-To: <CAPp_+=erhTeV56Sg=ycZpT9oKXT9h6+7UJ6AyaSxD7iceNJShA@mail.gmail.com>
References: <CAPp_+=fxGdbPvQ7cdS8uopK5kRmcVydO0DVAfN4hPF56Rpeirg@mail.gmail.com>
	<CA+vqiLHCD26qXDpmiwEWGQ6EQBu-zMsWb6hUeJzWtSp-veQFww@mail.gmail.com>
	<55635134.4070407@gmail.com>
	<CAPp_+=erhTeV56Sg=ycZpT9oKXT9h6+7UJ6AyaSxD7iceNJShA@mail.gmail.com>
Message-ID: <op.xy8e23y43euttn@peter-think.fritz.box>

Am .05.2015, 09:01 Uhr, schrieb Richard Cotton <richierocks at gmail.com>:

> On 25 May 2015 at 19:43, Duncan Murdoch <murdoch.duncan at gmail.com> wrote:
>>> http://stackoverflow.com/questions/17715956/why-do-some-unicode-characters-display-in-matrices-but-not-data-frames-in-r
>
>> Yes, but it is a bug, just a hard one to fix.  It needs someone to  
>> dedicate
>> a serious amount of time to deal with it.
>>
>> Since most of the people who tend to do that generally use systems in  
>> UTF-8
>> locales where this isn't a problem, or don't use Windows, it is  
>> languishing.
>
> Thanks for the link and the explanation of why the bug exists.
>
>>> On May 25, 2015 9:39 AM, "Richard Cotton" <richierocks at gmail.com>  
>>> wrote:
>>>
>>> > Here's a data frame with some Unicode symbols (set intersection and
>>> > union).
>>> >
>>> > d <- data.frame(x = "A \u222a B \u2229 C")
>>> >
>>> > Printing this data frame under R 3.2.0 patched (r68378) and Windows  
>>> 7, I
>>> > see
>>> >
>>> > d
>>> > ##                  x
>>> > ## 1 A <U+222A> B n C
>
> For future readers searching for a solution to this, you can get
> correct printing by setting the CTYPE part of the locale to
> Chinese/Japanese/Korean.
>
> Sys.setlocale("LC_CTYPE", "Chinese")
> ## [1] "Chinese (Simplified)_People's Republic of China.936"
>
> d
> ##            x
> ## 1 A ? B ? C
>


There is another workaround.

The problem with the character transformation on printing data frames  
stems from format() used within print.default(). Defining your own class  
and print function that does not use format() allows for correct printing  
in all locales.

Like this:


d <- data.frame(x = "A \u222a B \u2229 C")
d
##                  x
## 1 A <U+222A> B n C


class(d) <- c("unicode_df","data.frame")

# this is print.default from base R with only two lines modified, see #old#
print.unicode_df <- function (x, ..., digits = NULL, quote = FALSE, right  
= TRUE,
     row.names = TRUE)
{
     n <- length(row.names(x))
     if (length(x) == 0L) {
         cat(sprintf(ngettext(n, "data frame with 0 columns and %d row",
             "data frame with 0 columns and %d rows", domain = "R-base"),
             n), "\n", sep = "")
     }
     else if (n == 0L) {
         print.default(names(x), quote = FALSE)
         cat(gettext("<0 rows> (or 0-length row.names)\n"))
     }
     else {
         #old# m <- as.matrix(format.data.frame(x, digits = digits,
         #old#     na.encode = FALSE))
         m <- as.matrix(x)
         if (!isTRUE(row.names))
             dimnames(m)[[1L]] <- if (identical(row.names, FALSE))
                 rep.int("", n)
             else row.names
         print(m, ..., quote = quote, right = right)
     }
     invisible(x)
}


d
##              x
## [1,] A ? B ? C




-- 
Erstellt mit Operas E-Mail-Modul: http://www.opera.com/mail/


From csardi.gabor at gmail.com  Tue May 26 09:45:31 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 26 May 2015 03:45:31 -0400
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
Message-ID: <CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>

On Mon, May 25, 2015 at 8:28 PM, Simon Urbanek <simon.urbanek at r-project.org>
wrote:

> One issue I have with this is that it doesn't point to the original GitHub
> repositories of the packages, so you end up with additional repositories on
> Github in Gabor's name that have nothing to do with the actual Github
> repositories of the packages. I understand that it's technically necessary,
> but I fear it will lead to a lot of confusion...


Well, we point to the original GitHub repo is that is given in the URL
field. It would be nice to have an "official" field for source code
repository in DESCRIPTION.

But I agree with you that this has great potential for confusion. Several
people have been sending pull requests to github.com/cran repos, most of
them not realizing that they are not the right repos to fork. (Although
many packages are not on GH or any other similar service, and then are kind
of the places to fork.)

I could have a large warning popup on the link from r-pkg.org, with red
flags, and you would see this before the actual repo. But this has its own
problems, like being annoying after a while, how to turn it off with
browser cookies, etc.

The best would be to somehow have a warning on the GitHub repo pages, but
there isn't a lot I can modify there if I don't want to change/add the
README file, which would effectively change the package. I could probably
add 'WARNING: this is a read-only mirror, and not the original package
repository' to the one-line description on the top.

If you have other ideas, please let me know.

Gabor


> On May 24, 2015, at 5:44 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>
> > G?bor Cs?rdi <csardi.gabor at gmail.com> writes:
> >
> >> Dear All,
> >>
> >> [ I was wondering if this should have gone to the new mailing list.
> Maybe. ]
> >>
> >> As some of you maybe know from my earlier posts, I am building a simple
> >> search engine for R packages. Now the search engine has a proper web
> site,
> >> where you can also browse CRAN packages.
> >>
> >> http://www.r-pkg.org/
> >>
> >> As I see the value is in
> >> 1. package search (search box on top right)
> >> 2. APIs, see http://www.r-pkg.org/services
> >>
> >> It is in alpha version, meaning that things seem to work, some pages
> are a
> >> bit slow and there are a lot of glitches to fix.
> >
> > I had a quick peek, and it looks really nice! I particularly think the
> > github integration for diff-ing versions can be very use full!
> >
> > It might be an idea, to also add R itself to the github repo for
> > diff-ing?
> >
> > Thanks a lot,
> >
> > Rainer
> >
> >>
> >> Please tell me what you think.
> >>
> >> Best,
> >> Gabor
> >>
> >>      [[alternative HTML version deleted]]
> >>
> >
> > --
> > Rainer M. Krug
> > email: Rainer<at>krugs<dot>de
> > PGP: 0x0F52F982
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
>

	[[alternative HTML version deleted]]


From cgenolin at u-paris10.fr  Tue May 26 11:31:42 2015
From: cgenolin at u-paris10.fr (cgenolin)
Date: Tue, 26 May 2015 02:31:42 -0700 (PDT)
Subject: [Rd] Compatibility issue between lme4 and kml (operateur "[")
Message-ID: <1432632702476-4707670.post@n4.nabble.com>

Hi all,

There is a compatibility issue between the package 'lme4' and my package
'kml'. I define the "[" operator. It works just fine in my package (1). If I
try to use the lme4 package, then it does no longer work (2). Moreover, it
has some kind of strange behavior (3). Do you know what is wrong? Any idea
of how I can correct that?

Thanks for your help
Christophe

--- 8< ----------------- Code for reproductible example -------------------
library(kml)
dn <- gald(1)
dn["traj"]
library(lme4)
dn["traj"]
setMethod(   ### Simplified version ###
  "[",
  signature=signature(x="ClusterLongData", i="character",
j="ANY",drop="ANY"),
  definition=function (x, i, j="missing", ..., drop = TRUE){
      x <- as(x, "LongData")
      return(x[i, j])
    }
)
dn["traj"]
dn["traj"]

--- 8< ----------------- Execution of the previous code -------------------

> library(kml)
Le chargement a n?cessit? le package : clv
Le chargement a n?cessit? le package : cluster
Le chargement a n?cessit? le package : class
Le chargement a n?cessit? le package : longitudinalData
Le chargement a n?cessit? le package : rgl
Le chargement a n?cessit? le package : misc3d
> dn <- gald(1)

  ###########
 #### (1] ####
### (1) the "[" operator works just fine

> dn["traj"]
      t0   t1    t2    t3    t4   t5   t6    t7    t8    t9   t10
i1 -3.11 4.32  2.17  1.82  4.90 7.34 0.83 -2.70  5.36  4.96  3.16
i2 -7.11 1.40 -2.40 -2.96  4.31 0.50 1.25  0.52 -0.04  7.55  5.50
i3  2.80 6.23  6.08  2.87  2.58 2.88 6.58 -2.38  2.30 -1.74 -3.23
i4  2.24 0.91  6.50 10.92 11.32 7.79 7.78 10.69  9.15  1.07 -0.51

  ###########
 #### (2) ####
### using 'lme4', it does no longer work

> library(lme4)
Le chargement a n?cessit? le package : Matrix
Le chargement a n?cessit? le package : Rcpp
> dn["traj"]
Error in x[i, j] : 
  erreur d'?valuation de l'argument 'j' lors de la s?lection d'une m?thode
pour la fonction '[' : Erreur : l'argument "j" est manquant, avec aucune
valeur par d?faut

  ###########
 #### (3) ####
### If I define again the "[", it does not work the first time I call it,
but it work the second time!
> setMethod(
+   "[",
+   signature=signature(x="ClusterLongData", i="character",
j="ANY",drop="ANY"),
+   definition=function (x, i, j="missing", ..., drop = TRUE){
+       x <- as(x, "LongData")
+       return(x[i, j])
+     }
+ )
[1] "["

### No working the first time I use it
> dn["traj"]
Error in dn["traj"] : 
  l'argument "j" est manquant, avec aucune valeur par d?faut

### But working the second time
> dn["traj"]
      t0   t1    t2    t3    t4   t5   t6    t7    t8    t9   t10
i1 -3.11 4.32  2.17  1.82  4.90 7.34 0.83 -2.70  5.36  4.96  3.16
i2 -7.11 1.40 -2.40 -2.96  4.31 0.50 1.25  0.52 -0.04  7.55  5.50
i3  2.80 6.23  6.08  2.87  2.58 2.88 6.58 -2.38  2.30 -1.74 -3.23
i4  2.24 0.91  6.50 10.92 11.32 7.79 7.78 10.69  9.15  1.07 -0.51






--
View this message in context: http://r.789695.n4.nabble.com/Compatibility-issue-between-lme4-and-kml-operateur-tp4707670.html
Sent from the R devel mailing list archive at Nabble.com.


From bbolker at gmail.com  Tue May 26 16:00:06 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 May 2015 10:00:06 -0400
Subject: [Rd] building with tcltk on Ubuntu 14.04
Message-ID: <55647C66.6060702@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


  I'm having some issues trying to compile R-devel on Ubuntu 14.04.
library("tcltk") works fine on the version of R as installed from
Debian packages; I've done "apt-get build-dep r-base" so I think I
have all the tcltk libraries I need installed ... (and going back to
things like apt-get tcl-dev and apt-get tk-dev confirms that they're
really there ...)

  When I configure and build R without doing anything special, tcltk
is not found and capabilities()["tcltk"] is FALSE.  I modified
config.site as follows:

## Use TCLTK_LIBS for all '-L' and '-l' options needed for linking
TCLTK_LIBS="-L/usr/lib/x86_64-linux-gnu"
## Use TCLTK_CPPFLAGS for all '-I' options needed for finding the tcl.h
TCLTK_CPPFLAGS="-I/usr/include/tcl"

  This makes capabilities()["tcltk"] TRUE, but trying library("tcltk")
still returns

Error : .onLoad failed in loadNamespace() for 'tcltk', details:
  call: fun(libname, pkgname)
  error: Tcl/Tk support is not available on this system

  Any more suggestions on troubleshooting/diagnosing?  I'm not sure
what I should be telling R to look for ...

  thanks
    Ben Bolker


PS  (I chose /usr/lib/x86_64-linux_gnu for TCLTK_LIBS because that's
where the tcl libraries seem to be located ...

ls /usr/lib/x86_64-linux-gnu/libtcl*
/usr/lib/x86_64-linux-gnu/libtcl8.5.a
/usr/lib/x86_64-linux-gnu/libtcl8.6.so
/usr/lib/x86_64-linux-gnu/libtclstub8.5.a
/usr/lib/x86_64-linux-gnu/libtcl8.5.so
/usr/lib/x86_64-linux-gnu/libtcl8.6.so.0
/usr/lib/x86_64-linux-gnu/libtclstub8.6.a
/usr/lib/x86_64-linux-gnu/libtcl8.5.so.0
/usr/lib/x86_64-linux-gnu/libtcl.a
/usr/lib/x86_64-linux-gnu/libtclstub.a
/usr/lib/x86_64-linux-gnu/libtcl8.6.a
/usr/lib/x86_64-linux-gnu/libtcl.so
)


-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVZHxmAAoJEOCV5YRblxUHfe4IAL4RYDa89Hri91j7T//+RS+6
+/rnB6DH3QMVCYRtxmKFIZELhFyaU1pxe3/2p8gIWz8jIcVkGk3BEcdIeS0VgySk
wwrnfwv1PNE6gaun4CIWC/ICFQlCTAjo+eLFFYtSElETcm7UbRKMlojyWQSHjrf9
0ioloHZ72uajbzxcZdezRsYG/8+VwgkKWtoa5MfmggH5T8EL5QGD5S2aGqEPtWJe
UZUZCQFN43vRnHPgYxIQO3oXmjnnn0BsZlx+lXwqsRR7dplknCgQWyP0TEcv9Sur
GaemV2oEuUIpAgkMBZt2vTSGIrDgWUIfGcKT0nHNwtvh+cLcDuysj6M+6/JZCaQ=
=xkGy
-----END PGP SIGNATURE-----


From edd at debian.org  Tue May 26 16:25:06 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Tue, 26 May 2015 09:25:06 -0500
Subject: [Rd] building with tcltk on Ubuntu 14.04
In-Reply-To: <55647C66.6060702@gmail.com>
References: <55647C66.6060702@gmail.com>
Message-ID: <21860.33346.581909.652856@max.nulle.part>


Ben,

At work with little time so _real brief_:

 -- we build r-devel "all the time", in fact nightly for rocker; and there
    are Dockerfiles to look at
    
 -- we build R all the time in Debian, Ubuntu, ... and my sources for that
    are not on GH but you can fetch the diff.gz

 -- there is an entire list dedicated to this: r-sig-debian so could you
    pretty-please post there (after registering, if needed)

I'll be glad to help, preferably on r-sig-debian.

Cheers, Dirk

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From bbolker at gmail.com  Tue May 26 17:13:41 2015
From: bbolker at gmail.com (Ben Bolker)
Date: Tue, 26 May 2015 11:13:41 -0400
Subject: [Rd] building with tcltk on Ubuntu 14.04
In-Reply-To: <21860.33346.581909.652856@max.nulle.part>
References: <55647C66.6060702@gmail.com>
	<21860.33346.581909.652856@max.nulle.part>
Message-ID: <55648DA5.2070709@gmail.com>

-----BEGIN PGP SIGNED MESSAGE-----
Hash: SHA1


  False alarm.  Completely wiping out my build directory followed by

../R-devel/configure --with-tcl-config=/usr/lib/tclConfig.sh
- --with-tk-config=/usr/lib/tkConfig.sh; make

  seems to work.  (My fault for assuming repeated cycles of
./configure; make would actually do the right thing ...)

  There seems to be a corollary of Clarke's Law ("any sufficient
advanced technology is indistinguishable from magic") that says that
any sufficiently complex software system may *not* be magic, but it's
just easier to treat it as though it is ...

  Thanks for the offer of help ...

  Ben


On 15-05-26 10:25 AM, Dirk Eddelbuettel wrote:
> 
> Ben,
> 
> At work with little time so _real brief_:
> 
> -- we build r-devel "all the time", in fact nightly for rocker; and
> there are Dockerfiles to look at
> 
> -- we build R all the time in Debian, Ubuntu, ... and my sources
> for that are not on GH but you can fetch the diff.gz
> 
> -- there is an entire list dedicated to this: r-sig-debian so could
> you pretty-please post there (after registering, if needed)
> 
> I'll be glad to help, preferably on r-sig-debian.
> 
> Cheers, Dirk
> 

-----BEGIN PGP SIGNATURE-----
Version: GnuPG v1.4.11 (GNU/Linux)

iQEcBAEBAgAGBQJVZI2kAAoJEOCV5YRblxUHYEIH/j6jViruOP479yPNkRWXKNlA
0uXDYmZek/Zd2hwH6iHtmyTTLY3gR61metvLxFx/mpY3W/skM83Wpc9vWVHfUa8/
8aOaOndZnREEs5AT2TZwuYymXKYO7zEUeqL1cArXyzzqej0irUi5MjpWQsxD5hNA
M1LvpK3h31EWeJaJPdQHooZUMjgKKt1bJDrjIhs09J/jyVjUj5XANhsVfNUUbru5
pwXyMc3OMXfElgKM6/vO6gt1u2x7VHHpAZX7NrxgFksTaG4ceT0H8jUYIolCQmDy
RC7//onh0t8sqZCS3a4koZWy5mfnrcSc8M5PZaTZFnEQtU6D0jFSGCGGQ3Ncmow=
=UCFD
-----END PGP SIGNATURE-----


From xie at yihui.name  Tue May 26 18:25:37 2015
From: xie at yihui.name (Yihui Xie)
Date: Tue, 26 May 2015 11:25:37 -0500
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
Message-ID: <CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>

I cannot speak for other package authors, but for all my own packages,
I have provided the BugReports field in DESCRIPTION that points to the
Github issues page. You can probably use this field to check if a
package is on Github or not. If it is, you may just fork the original
repo instead of creating a new one from the CRAN package. I'm not sure
how technically difficult it would be for you. Thanks for the
wonderful work!

Regards,
Yihui
--
Yihui Xie <xieyihui at gmail.com>
Web: http://yihui.name


On Tue, May 26, 2015 at 2:45 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> On Mon, May 25, 2015 at 8:28 PM, Simon Urbanek <simon.urbanek at r-project.org>
> wrote:
>
>> One issue I have with this is that it doesn't point to the original GitHub
>> repositories of the packages, so you end up with additional repositories on
>> Github in Gabor's name that have nothing to do with the actual Github
>> repositories of the packages. I understand that it's technically necessary,
>> but I fear it will lead to a lot of confusion...
>
>
> Well, we point to the original GitHub repo is that is given in the URL
> field. It would be nice to have an "official" field for source code
> repository in DESCRIPTION.
>
> But I agree with you that this has great potential for confusion. Several
> people have been sending pull requests to github.com/cran repos, most of
> them not realizing that they are not the right repos to fork. (Although
> many packages are not on GH or any other similar service, and then are kind
> of the places to fork.)
>
> I could have a large warning popup on the link from r-pkg.org, with red
> flags, and you would see this before the actual repo. But this has its own
> problems, like being annoying after a while, how to turn it off with
> browser cookies, etc.
>
> The best would be to somehow have a warning on the GitHub repo pages, but
> there isn't a lot I can modify there if I don't want to change/add the
> README file, which would effectively change the package. I could probably
> add 'WARNING: this is a read-only mirror, and not the original package
> repository' to the one-line description on the top.
>
> If you have other ideas, please let me know.
>
> Gabor


From gmbecker at ucdavis.edu  Tue May 26 19:18:35 2015
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 26 May 2015 10:18:35 -0700
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>
Message-ID: <CADwqtCNcCB1i_OON0F1Nv5SxEHdYY=o++XEwF0bgttA0p+Chzw@mail.gmail.com>

On Tue, May 26, 2015 at 9:25 AM, Yihui Xie <xie at yihui.name> wrote:

> I cannot speak for other package authors, but for all my own packages,
> I have provided the BugReports field in DESCRIPTION that points to the
> Github issues page. You can probably use this field to check if a
> package is on Github or not. If it is, you may just fork the original
> repo instead of creating a new one from the CRAN package.


Maybe I'm missing something, but why would you fork the repo instead of
just using the existing repo?

-- 
Gabriel Becker, PhD
Computational Biologist
Bioinformatics and Computational Biology
Genentech, Inc.

	[[alternative HTML version deleted]]


From h.wickham at gmail.com  Tue May 26 19:26:42 2015
From: h.wickham at gmail.com (Hadley Wickham)
Date: Tue, 26 May 2015 12:26:42 -0500
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CADwqtCNcCB1i_OON0F1Nv5SxEHdYY=o++XEwF0bgttA0p+Chzw@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>
	<CADwqtCNcCB1i_OON0F1Nv5SxEHdYY=o++XEwF0bgttA0p+Chzw@mail.gmail.com>
Message-ID: <CABdHhvHT6Pc6a89GNTUpW26Y=E_n6mD1hNwX160Kcx638OY3nQ@mail.gmail.com>

On Tue, May 26, 2015 at 12:18 PM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> On Tue, May 26, 2015 at 9:25 AM, Yihui Xie <xie at yihui.name> wrote:
>
>> I cannot speak for other package authors, but for all my own packages,
>> I have provided the BugReports field in DESCRIPTION that points to the
>> Github issues page. You can probably use this field to check if a
>> package is on Github or not. If it is, you may just fork the original
>> repo instead of creating a new one from the CRAN package.
>
>
> Maybe I'm missing something, but why would you fork the repo instead of
> just using the existing repo?

One advantage of a fork is that you have permanent archive even if the
original goes away.

Hadley

-- 
http://had.co.nz/


From csardi.gabor at gmail.com  Tue May 26 19:43:24 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 26 May 2015 13:43:24 -0400
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CABdHhvHT6Pc6a89GNTUpW26Y=E_n6mD1hNwX160Kcx638OY3nQ@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>
	<CADwqtCNcCB1i_OON0F1Nv5SxEHdYY=o++XEwF0bgttA0p+Chzw@mail.gmail.com>
	<CABdHhvHT6Pc6a89GNTUpW26Y=E_n6mD1hNwX160Kcx638OY3nQ@mail.gmail.com>
Message-ID: <CABtg=KmXiH1t8NtnmOfF-BuT9us=_uM_oX6+1UFRqjZQ1u9U6A@mail.gmail.com>

On Tue, May 26, 2015 at 1:26 PM, Hadley Wickham <h.wickham at gmail.com> wrote:

> > Maybe I'm missing something, but why would you fork the repo instead of
> > just using the existing repo?
>
> One advantage of a fork is that you have permanent archive even if the
> original goes away.
>

Exactly. Even if the original repo is on GitHub, I want to use one under
github.com/cran. Actually, I don't even want to fork the original repo,
because I want the github.com/cran repos to look the same: one commit per
package version, tagged with the version number. This way it is easy to
compare different versions of a package, easy to link to the code of a
specific version, etc.

If I link to the original repo, then I need the maintainer to tag releases
properly, etc. Many of them do, but still, I don't want to rely on that.

I obviously want to send potential contributors to the original upstream
repo, and I think I can do a better job at that, with warnings both on the
web page and in the github.com/cran repos. E.g. on the web page, we can
have a "Contribute" button, that goes upstream. On the cran GH page I can
have a warning line on top, with the link to the original repo.

Gabor

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Tue May 26 19:46:36 2015
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 26 May 2015 10:46:36 -0700
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CABdHhvHT6Pc6a89GNTUpW26Y=E_n6mD1hNwX160Kcx638OY3nQ@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>
	<CADwqtCNcCB1i_OON0F1Nv5SxEHdYY=o++XEwF0bgttA0p+Chzw@mail.gmail.com>
	<CABdHhvHT6Pc6a89GNTUpW26Y=E_n6mD1hNwX160Kcx638OY3nQ@mail.gmail.com>
Message-ID: <CADwqtCMfGisC+g_M29Sx+H8mz30wnfUBAOqE_rBvueiNjhNPgA@mail.gmail.com>

That's true, but issues, checkouts, comments, credit, etc should all be
going to the original repo. Anything else seems grossly unfair to the
package author(s). This issue is exacerbated even further when the the
author isn't developing the package on github at all, and github users may
unintentionally begin to view the forks as the actual canonical sources for
the package.

Also, the archive use-case, while near and dear to my own heart, seems
explicitly different from the "look at the package as it is now" use-case
that the forks are actually being used for.

To be clear, I think a lot of the metacran stuff is great. I use the APIs
myself and Gabor's work on this stuff is great.  I just think there are
some pitfalls here.

>From the email Gabor just sent out, it sounds like he and I agree about
this stuff anyway. I was really responding to the proposal that the
repositories actually be forked.

~G

On Tue, May 26, 2015 at 10:26 AM, Hadley Wickham <h.wickham at gmail.com>
wrote:

> On Tue, May 26, 2015 at 12:18 PM, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
> > On Tue, May 26, 2015 at 9:25 AM, Yihui Xie <xie at yihui.name> wrote:
> >
> >> I cannot speak for other package authors, but for all my own packages,
> >> I have provided the BugReports field in DESCRIPTION that points to the
> >> Github issues page. You can probably use this field to check if a
> >> package is on Github or not. If it is, you may just fork the original
> >> repo instead of creating a new one from the CRAN package.
> >
> >
> > Maybe I'm missing something, but why would you fork the repo instead of
> > just using the existing repo?
>
> One advantage of a fork is that you have permanent archive even if the
> original goes away.
>
> Hadley
>
> --
> http://had.co.nz/
>



-- 
Gabriel Becker, PhD
Computational Biologist
Bioinformatics and Computational Biology
Genentech, Inc.

	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Tue May 26 19:49:07 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 26 May 2015 13:49:07 -0400
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CAFDcVCRAyzvGD0A9O+9Cn_Nf3Q76nuH62ttrmcPgJq5WWO36kg@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CAFDcVCRAyzvGD0A9O+9Cn_Nf3Q76nuH62ttrmcPgJq5WWO36kg@mail.gmail.com>
Message-ID: <CABtg=K=hRRVbFggPgoRQNZJBPostDAze1cBJ11YkLiaTZCJN6A@mail.gmail.com>

On Tue, May 26, 2015 at 1:43 PM, Henrik Bengtsson <henrik.bengtsson at ucsf.edu
> wrote:
[...]

> If people send pull requests, maybe adding a generic open pull request
> to each repository with title "MIRROR ONLY: Do not send pull requests
> here" would help.  The fancy version would be to say "MIRROR ONLY: All
> patches/pull requests should be sent to <URL>", where <URL> is from
> the DESCRIPTION field 'URL'.  That might prevent a few more.
>

The problem with that

1) if I put in ~7000 fake pull requests, then it is messy for me to find
the "real" pull requests, put in by other people, and
2) I am pretty sure that many people do not look at previous pull requests,
when they put in theirs.

But it is so far not such a big deal, I only got ~50 of them during ~12
months. And in many cases, they are useful, because they can be moved
upstream. I will write a short tutorial about that.

Gabor

	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Tue May 26 19:55:02 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 26 May 2015 13:55:02 -0400
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CADwqtCMfGisC+g_M29Sx+H8mz30wnfUBAOqE_rBvueiNjhNPgA@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>
	<CADwqtCNcCB1i_OON0F1Nv5SxEHdYY=o++XEwF0bgttA0p+Chzw@mail.gmail.com>
	<CABdHhvHT6Pc6a89GNTUpW26Y=E_n6mD1hNwX160Kcx638OY3nQ@mail.gmail.com>
	<CADwqtCMfGisC+g_M29Sx+H8mz30wnfUBAOqE_rBvueiNjhNPgA@mail.gmail.com>
Message-ID: <CABtg=KkOODVm7WmSrm0cCos_gDXc6f4NYZYa_p5QpzDdiNhCvw@mail.gmail.com>

On Tue, May 26, 2015 at 1:46 PM, Gabriel Becker <gmbecker at ucdavis.edu>
wrote:

> That's true, but issues, checkouts, comments, credit, etc should all be
> going to the original repo.


You mean the links? They are, aren't they?

[...]

> >From the email Gabor just sent out, it sounds like he and I agree about
> this stuff anyway. I was really responding to the proposal that the
> repositories actually be forked.
>

I cannot do much about that. Issues and wiki are turned off, but you cannot
turn off forking or pull requests. Even the official mirrors at GitHub have
them, e.g. the Apache Spark mirror at https://github.com/apache/spark

And I don't actually want to turn off forks for these repos, because they
are useful for repos that are originally not on CRAN.

Anyway, in summary I'll try to do a better job at directing people to the
original sources.

Gabor

[...]

	[[alternative HTML version deleted]]


From henrik.bengtsson at ucsf.edu  Tue May 26 19:43:20 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Tue, 26 May 2015 10:43:20 -0700
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
Message-ID: <CAFDcVCRAyzvGD0A9O+9Cn_Nf3Q76nuH62ttrmcPgJq5WWO36kg@mail.gmail.com>

On Tue, May 26, 2015 at 12:45 AM, G?bor Cs?rdi <csardi.gabor at gmail.com> wrote:
> On Mon, May 25, 2015 at 8:28 PM, Simon Urbanek <simon.urbanek at r-project.org>
> wrote:
>
>> One issue I have with this is that it doesn't point to the original GitHub
>> repositories of the packages, so you end up with additional repositories on
>> Github in Gabor's name that have nothing to do with the actual Github
>> repositories of the packages. I understand that it's technically necessary,
>> but I fear it will lead to a lot of confusion...
>
>
> Well, we point to the original GitHub repo is that is given in the URL
> field. It would be nice to have an "official" field for source code
> repository in DESCRIPTION.
>
> But I agree with you that this has great potential for confusion. Several
> people have been sending pull requests to github.com/cran repos, most of
> them not realizing that they are not the right repos to fork. (Although
> many packages are not on GH or any other similar service, and then are kind
> of the places to fork.)
>
> I could have a large warning popup on the link from r-pkg.org, with red
> flags, and you would see this before the actual repo. But this has its own
> problems, like being annoying after a while, how to turn it off with
> browser cookies, etc.
>
> The best would be to somehow have a warning on the GitHub repo pages, but
> there isn't a lot I can modify there if I don't want to change/add the
> README file, which would effectively change the package. I could probably
> add 'WARNING: this is a read-only mirror, and not the original package
> repository' to the one-line description on the top.
>
> If you have other ideas, please let me know.

If people send pull requests, maybe adding a generic open pull request
to each repository with title "MIRROR ONLY: Do not send pull requests
here" would help.  The fancy version would be to say "MIRROR ONLY: All
patches/pull requests should be sent to <URL>", where <URL> is from
the DESCRIPTION field 'URL'.  That might prevent a few more.
<blink>You can boost it with lots of colorful "WARNING", "NO
TRESPASSING", ... labels as well</blink>.   The next level up is to
have a service that automatically reject pull requests with an
informative error message.

/Henrik


>
> Gabor
>
>
>> On May 24, 2015, at 5:44 AM, Rainer M Krug <Rainer at krugs.de> wrote:
>>
>> > G?bor Cs?rdi <csardi.gabor at gmail.com> writes:
>> >
>> >> Dear All,
>> >>
>> >> [ I was wondering if this should have gone to the new mailing list.
>> Maybe. ]
>> >>
>> >> As some of you maybe know from my earlier posts, I am building a simple
>> >> search engine for R packages. Now the search engine has a proper web
>> site,
>> >> where you can also browse CRAN packages.
>> >>
>> >> http://www.r-pkg.org/
>> >>
>> >> As I see the value is in
>> >> 1. package search (search box on top right)
>> >> 2. APIs, see http://www.r-pkg.org/services
>> >>
>> >> It is in alpha version, meaning that things seem to work, some pages
>> are a
>> >> bit slow and there are a lot of glitches to fix.
>> >
>> > I had a quick peek, and it looks really nice! I particularly think the
>> > github integration for diff-ing versions can be very use full!
>> >
>> > It might be an idea, to also add R itself to the github repo for
>> > diff-ing?
>> >
>> > Thanks a lot,
>> >
>> > Rainer
>> >
>> >>
>> >> Please tell me what you think.
>> >>
>> >> Best,
>> >> Gabor
>> >>
>> >>      [[alternative HTML version deleted]]
>> >>
>> >
>> > --
>> > Rainer M. Krug
>> > email: Rainer<at>krugs<dot>de
>> > PGP: 0x0F52F982
>> > ______________________________________________
>> > R-devel at r-project.org mailing list
>> > https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From dtenenba at fredhutch.org  Tue May 26 20:01:18 2015
From: dtenenba at fredhutch.org (Dan Tenenbaum)
Date: Tue, 26 May 2015 11:01:18 -0700 (PDT)
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CABtg=KkOODVm7WmSrm0cCos_gDXc6f4NYZYa_p5QpzDdiNhCvw@mail.gmail.com>
Message-ID: <1544621911.2778044.1432663278817.JavaMail.root@fredhutch.org>



----- Original Message -----
> From: "G?bor Cs?rdi" <csardi.gabor at gmail.com>
> To: "Gabriel Becker" <gmbecker at ucdavis.edu>
> Cc: "Simon Urbanek" <simon.urbanek at r-project.org>, "Rainer M Krug" <Rainer at krugs.de>, r-devel at r-project.org
> Sent: Tuesday, May 26, 2015 10:55:02 AM
> Subject: Re: [Rd] MetaCran website v1.0.0-alpha
> 
> On Tue, May 26, 2015 at 1:46 PM, Gabriel Becker
> <gmbecker at ucdavis.edu>
> wrote:
> 
> > That's true, but issues, checkouts, comments, credit, etc should
> > all be
> > going to the original repo.
> 
> 
> You mean the links? They are, aren't they?
> 
> [...]
> 
> > >From the email Gabor just sent out, it sounds like he and I agree
> > >about
> > this stuff anyway. I was really responding to the proposal that the
> > repositories actually be forked.
> >
> 
> I cannot do much about that. Issues and wiki are turned off, but you
> cannot
> turn off forking or pull requests. 

No, but you can set up a 'bot' which listens for pull requests and then immediately denies them with a customizable message, perhaps giving people the url where they should be making their pull requests. Example:

https://github.com/bioconductor/prbot

Dan



> Even the official mirrors at
> GitHub have
> them, e.g. the Apache Spark mirror at https://github.com/apache/spark
> 
> And I don't actually want to turn off forks for these repos, because
> they
> are useful for repos that are originally not on CRAN.
> 
> Anyway, in summary I'll try to do a better job at directing people to
> the
> original sources.
> 
> Gabor
> 
> [...]
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From csardi.gabor at gmail.com  Tue May 26 20:04:13 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 26 May 2015 14:04:13 -0400
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <1544621911.2778044.1432663278817.JavaMail.root@fredhutch.org>
References: <CABtg=KkOODVm7WmSrm0cCos_gDXc6f4NYZYa_p5QpzDdiNhCvw@mail.gmail.com>
	<1544621911.2778044.1432663278817.JavaMail.root@fredhutch.org>
Message-ID: <CABtg=KnrYU+v1nifi0u_E4y7738XJj+bviCrXf=4vgcLKyM4GQ@mail.gmail.com>

On Tue, May 26, 2015 at 2:01 PM, Dan Tenenbaum <dtenenba at fredhutch.org>
wrote:
[...]

>
> No, but you can set up a 'bot' which listens for pull requests and then
> immediately denies them with a customizable message, perhaps giving people
> the url where they should be making their pull requests. Example:


> https://github.com/bioconductor/prbot


Yes, that's what I am doing, by hand currently. I closed all of them and
explained that this is not the right place for them. It's one PR per week
so far, and sometimes I need to interact with the people, so it is fine. If
it will be more, I'll use your robot, thanks!

Gabor



> Dan
>
>
>
> > Even the official mirrors at
> > GitHub have
> > them, e.g. the Apache Spark mirror at https://github.com/apache/spark
> >
> > And I don't actually want to turn off forks for these repos, because
> > they
> > are useful for repos that are originally not on CRAN.
> >
> > Anyway, in summary I'll try to do a better job at directing people to
> > the
> > original sources.
> >
> > Gabor
> >
> > [...]
> >
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >
>

	[[alternative HTML version deleted]]


From gmbecker at ucdavis.edu  Tue May 26 20:10:43 2015
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Tue, 26 May 2015 11:10:43 -0700
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CABtg=KkOODVm7WmSrm0cCos_gDXc6f4NYZYa_p5QpzDdiNhCvw@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>
	<CADwqtCNcCB1i_OON0F1Nv5SxEHdYY=o++XEwF0bgttA0p+Chzw@mail.gmail.com>
	<CABdHhvHT6Pc6a89GNTUpW26Y=E_n6mD1hNwX160Kcx638OY3nQ@mail.gmail.com>
	<CADwqtCMfGisC+g_M29Sx+H8mz30wnfUBAOqE_rBvueiNjhNPgA@mail.gmail.com>
	<CABtg=KkOODVm7WmSrm0cCos_gDXc6f4NYZYa_p5QpzDdiNhCvw@mail.gmail.com>
Message-ID: <CADwqtCME7DfMozU1OmGXX4et7MfQXwgLqaFn_JeaWPyDQ_jtSg@mail.gmail.com>

On Tue, May 26, 2015 at 10:55 AM, G?bor Cs?rdi <csardi.gabor at gmail.com>
wrote:

> On Tue, May 26, 2015 at 1:46 PM, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
>
>> That's true, but issues, checkouts, comments, credit, etc should all be
>> going to the original repo.
>
>
> You mean the links? They are, aren't they?
>

Sort of, the link for browsing source code doesn't have any indication that
you're looking at a frozen snapshot of the source-code for the latest
version on CRAN. Typically links with that description point to trunk, I
think. Maybe a different a description for that link would help make the
source-code it points to sound less official?


>
> [...]
>
>> >From the email Gabor just sent out, it sounds like he and I agree about
>> this stuff anyway. I was really responding to the proposal that the
>> repositories actually be forked.
>>
>
> I cannot do much about that. Issues and wiki are turned off, but you
> cannot turn off forking or pull requests. Even the official mirrors at
> GitHub have them, e.g. the Apache Spark mirror at
> https://github.com/apache/spark
>
> And I don't actually want to turn off forks for these repos, because they
> are useful for repos that are originally not on CRAN.
>

Well, sort of. I mean if the package is being actively developed not on
github, forking your archive repo and developing a patch/etc against it
won't necessarily be particularly effective, as there is no way to have the
right starting point (state of trunk), right?


~G


-- 
Gabriel Becker, PhD
Computational Biologist
Bioinformatics and Computational Biology
Genentech, Inc.

	[[alternative HTML version deleted]]


From csardi.gabor at gmail.com  Tue May 26 20:16:00 2015
From: csardi.gabor at gmail.com (=?UTF-8?B?R8OhYm9yIENzw6FyZGk=?=)
Date: Tue, 26 May 2015 14:16:00 -0400
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CADwqtCME7DfMozU1OmGXX4et7MfQXwgLqaFn_JeaWPyDQ_jtSg@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>
	<CADwqtCNcCB1i_OON0F1Nv5SxEHdYY=o++XEwF0bgttA0p+Chzw@mail.gmail.com>
	<CABdHhvHT6Pc6a89GNTUpW26Y=E_n6mD1hNwX160Kcx638OY3nQ@mail.gmail.com>
	<CADwqtCMfGisC+g_M29Sx+H8mz30wnfUBAOqE_rBvueiNjhNPgA@mail.gmail.com>
	<CABtg=KkOODVm7WmSrm0cCos_gDXc6f4NYZYa_p5QpzDdiNhCvw@mail.gmail.com>
	<CADwqtCME7DfMozU1OmGXX4et7MfQXwgLqaFn_JeaWPyDQ_jtSg@mail.gmail.com>
Message-ID: <CABtg=K=_wimtHb6ha3OS0hk4-Uksw4r3gD1yK-enCRp2Bxp61g@mail.gmail.com>

On Tue, May 26, 2015 at 2:10 PM, Gabriel Becker <gmbecker at ucdavis.edu>
wrote:
[...]

>
> Well, sort of. I mean if the package is being actively developed not on
> github, forking your archive repo and developing a patch/etc against it
> won't necessarily be particularly effective, as there is no way to have the
> right starting point (state of trunk), right?
>

Well, then you can do 1) git rebase or 2) get the patch if the original
repo is not in git.

Yes, this is not ideal. I could remove that "Browse the source" completely,
that is an option, and remove the link from the version number as well.
There there will be no links to github.com/cran. Experienced users will
just type in the URL. That's fine with me, too.

Btw. how does this look for a warning: https://github.com/cran/crayon
This is the most red I could find.

G.

	[[alternative HTML version deleted]]


From tim.triche at gmail.com  Tue May 26 21:00:01 2015
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Tue, 26 May 2015 12:00:01 -0700
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CAFDcVCRAyzvGD0A9O+9Cn_Nf3Q76nuH62ttrmcPgJq5WWO36kg@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CAFDcVCRAyzvGD0A9O+9Cn_Nf3Q76nuH62ttrmcPgJq5WWO36kg@mail.gmail.com>
Message-ID: <CAC+N9BUn3vD2Wsxd_boanwH1_2uaCVmOoYJqCn1=q=FP+AOMEQ@mail.gmail.com>

Or maybe it would be sensible to ask GitHub if they can fix this.

If it's a common-ish use case (e.g. for mirrors), it's not something that
should be terribly challenging engineering-wise, and it would prevent a lot
of hooha.

Funfact: GitHub is run and staffed by actual people, most of them pretty
cool



Statistics is the grammar of science.
Karl Pearson <http://en.wikipedia.org/wiki/The_Grammar_of_Science>

On Tue, May 26, 2015 at 10:43 AM, Henrik Bengtsson <
henrik.bengtsson at ucsf.edu> wrote:

> On Tue, May 26, 2015 at 12:45 AM, G?bor Cs?rdi <csardi.gabor at gmail.com>
> wrote:
> > On Mon, May 25, 2015 at 8:28 PM, Simon Urbanek <
> simon.urbanek at r-project.org>
> > wrote:
> >
> >> One issue I have with this is that it doesn't point to the original
> GitHub
> >> repositories of the packages, so you end up with additional
> repositories on
> >> Github in Gabor's name that have nothing to do with the actual Github
> >> repositories of the packages. I understand that it's technically
> necessary,
> >> but I fear it will lead to a lot of confusion...
> >
> >
> > Well, we point to the original GitHub repo is that is given in the URL
> > field. It would be nice to have an "official" field for source code
> > repository in DESCRIPTION.
> >
> > But I agree with you that this has great potential for confusion. Several
> > people have been sending pull requests to github.com/cran repos, most of
> > them not realizing that they are not the right repos to fork. (Although
> > many packages are not on GH or any other similar service, and then are
> kind
> > of the places to fork.)
> >
> > I could have a large warning popup on the link from r-pkg.org, with red
> > flags, and you would see this before the actual repo. But this has its
> own
> > problems, like being annoying after a while, how to turn it off with
> > browser cookies, etc.
> >
> > The best would be to somehow have a warning on the GitHub repo pages, but
> > there isn't a lot I can modify there if I don't want to change/add the
> > README file, which would effectively change the package. I could probably
> > add 'WARNING: this is a read-only mirror, and not the original package
> > repository' to the one-line description on the top.
> >
> > If you have other ideas, please let me know.
>
> If people send pull requests, maybe adding a generic open pull request
> to each repository with title "MIRROR ONLY: Do not send pull requests
> here" would help.  The fancy version would be to say "MIRROR ONLY: All
> patches/pull requests should be sent to <URL>", where <URL> is from
> the DESCRIPTION field 'URL'.  That might prevent a few more.
> <blink>You can boost it with lots of colorful "WARNING", "NO
> TRESPASSING", ... labels as well</blink>.   The next level up is to
> have a service that automatically reject pull requests with an
> informative error message.
>
> /Henrik
>
>
> >
> > Gabor
> >
> >
> >> On May 24, 2015, at 5:44 AM, Rainer M Krug <Rainer at krugs.de> wrote:
> >>
> >> > G?bor Cs?rdi <csardi.gabor at gmail.com> writes:
> >> >
> >> >> Dear All,
> >> >>
> >> >> [ I was wondering if this should have gone to the new mailing list.
> >> Maybe. ]
> >> >>
> >> >> As some of you maybe know from my earlier posts, I am building a
> simple
> >> >> search engine for R packages. Now the search engine has a proper web
> >> site,
> >> >> where you can also browse CRAN packages.
> >> >>
> >> >> http://www.r-pkg.org/
> >> >>
> >> >> As I see the value is in
> >> >> 1. package search (search box on top right)
> >> >> 2. APIs, see http://www.r-pkg.org/services
> >> >>
> >> >> It is in alpha version, meaning that things seem to work, some pages
> >> are a
> >> >> bit slow and there are a lot of glitches to fix.
> >> >
> >> > I had a quick peek, and it looks really nice! I particularly think the
> >> > github integration for diff-ing versions can be very use full!
> >> >
> >> > It might be an idea, to also add R itself to the github repo for
> >> > diff-ing?
> >> >
> >> > Thanks a lot,
> >> >
> >> > Rainer
> >> >
> >> >>
> >> >> Please tell me what you think.
> >> >>
> >> >> Best,
> >> >> Gabor
> >> >>
> >> >>      [[alternative HTML version deleted]]
> >> >>
> >> >
> >> > --
> >> > Rainer M. Krug
> >> > email: Rainer<at>krugs<dot>de
> >> > PGP: 0x0F52F982
> >> > ______________________________________________
> >> > R-devel at r-project.org mailing list
> >> > https://stat.ethz.ch/mailman/listinfo/r-devel
> >>
> >>
> >
> >         [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From tim.triche at gmail.com  Tue May 26 21:04:49 2015
From: tim.triche at gmail.com (Tim Triche, Jr.)
Date: Tue, 26 May 2015 12:04:49 -0700
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CABtg=K=_wimtHb6ha3OS0hk4-Uksw4r3gD1yK-enCRp2Bxp61g@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>
	<CADwqtCNcCB1i_OON0F1Nv5SxEHdYY=o++XEwF0bgttA0p+Chzw@mail.gmail.com>
	<CABdHhvHT6Pc6a89GNTUpW26Y=E_n6mD1hNwX160Kcx638OY3nQ@mail.gmail.com>
	<CADwqtCMfGisC+g_M29Sx+H8mz30wnfUBAOqE_rBvueiNjhNPgA@mail.gmail.com>
	<CABtg=KkOODVm7WmSrm0cCos_gDXc6f4NYZYa_p5QpzDdiNhCvw@mail.gmail.com>
	<CADwqtCME7DfMozU1OmGXX4et7MfQXwgLqaFn_JeaWPyDQ_jtSg@mail.gmail.com>
	<CABtg=K=_wimtHb6ha3OS0hk4-Uksw4r3gD1yK-enCRp2Bxp61g@mail.gmail.com>
Message-ID: <CAC+N9BXRKPX3XR9Hwm0Zicb+R5ukBHF8g1kgnQ2vtrnH-bZUbg@mail.gmail.com>

What you are doing is great, and that's a pretty clear warning (I would go
ahead and add "DO NOT FORK ME" to the verbiage since I am one of the
dumbasses who submitted a pull request in such a fashion, whereupon the
original author got to set up a Git repo, I re-PR'ed against that, and all
was well).  But the fact that Dan wrote a bot for the BioC git mirror
specifically to bounce PR's... well, it's unlikely that this is an isolated
need.

A simple switch indicating that a repo is a mirror and should not accept
pull requests would be something that GitHub could implement once, and an
entire class of users would benefit from it.  It might even be a selling
point for business users, people who pay for private repos, etc.

I am going to get in touch with a former coworker who now works at GitHub
and ask him how much trouble this would really be on their end.  It's so
easy to underestimate the scope of features from outside, but if it really
is as easy as adding a hook to bounce PRs, I hope they will consider it as
a use case.




Statistics is the grammar of science.
Karl Pearson <http://en.wikipedia.org/wiki/The_Grammar_of_Science>

On Tue, May 26, 2015 at 11:16 AM, G?bor Cs?rdi <csardi.gabor at gmail.com>
wrote:

> On Tue, May 26, 2015 at 2:10 PM, Gabriel Becker <gmbecker at ucdavis.edu>
> wrote:
> [...]
>
> >
> > Well, sort of. I mean if the package is being actively developed not on
> > github, forking your archive repo and developing a patch/etc against it
> > won't necessarily be particularly effective, as there is no way to have
> the
> > right starting point (state of trunk), right?
> >
>
> Well, then you can do 1) git rebase or 2) get the patch if the original
> repo is not in git.
>
> Yes, this is not ideal. I could remove that "Browse the source" completely,
> that is an option, and remove the link from the version number as well.
> There there will be no links to github.com/cran. Experienced users will
> just type in the URL. That's fine with me, too.
>
> Btw. how does this look for a warning: https://github.com/cran/crayon
> This is the most red I could find.
>
> G.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>

	[[alternative HTML version deleted]]


From henrik.bengtsson at ucsf.edu  Tue May 26 22:44:36 2015
From: henrik.bengtsson at ucsf.edu (Henrik Bengtsson)
Date: Tue, 26 May 2015 13:44:36 -0700
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CADwqtCMfGisC+g_M29Sx+H8mz30wnfUBAOqE_rBvueiNjhNPgA@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>
	<CADwqtCNcCB1i_OON0F1Nv5SxEHdYY=o++XEwF0bgttA0p+Chzw@mail.gmail.com>
	<CABdHhvHT6Pc6a89GNTUpW26Y=E_n6mD1hNwX160Kcx638OY3nQ@mail.gmail.com>
	<CADwqtCMfGisC+g_M29Sx+H8mz30wnfUBAOqE_rBvueiNjhNPgA@mail.gmail.com>
Message-ID: <CAFDcVCSz+S+5eF5iR9G6wSN-9y+S_ztDp4phBJGUcXpB-Q5Xkg@mail.gmail.com>

On Tue, May 26, 2015 at 10:46 AM, Gabriel Becker <gmbecker at ucdavis.edu> wrote:
> That's true, but issues, checkouts, comments, credit, etc should all be
> going to the original repo. Anything else seems grossly unfair to the
> package author(s). This issue is exacerbated even further when the the
> author isn't developing the package on github at all, and github users may
> unintentionally begin to view the forks as the actual canonical sources for
> the package.

The same problem exists for CRAN (and for some of the Bioconductor
packages), i.e. the "source" tarballs (*.tar.gz files) on the
repository are often mistakenly seen as the main/root source of the
package.  The risk for this is less so when the package maintainer
share the source on a public version control system.  I think of CRAN
as an archive of specific package versions.  I look at Gabor's
MetaCRAN exactly the same way.  (I agree that the concept of a
"commit" may be confusing though, where it should really be a
"release").

/Henrik

>
> Also, the archive use-case, while near and dear to my own heart, seems
> explicitly different from the "look at the package as it is now" use-case
> that the forks are actually being used for.
>
> To be clear, I think a lot of the metacran stuff is great. I use the APIs
> myself and Gabor's work on this stuff is great.  I just think there are
> some pitfalls here.
>
> >From the email Gabor just sent out, it sounds like he and I agree about
> this stuff anyway. I was really responding to the proposal that the
> repositories actually be forked.
>
> ~G
>
> On Tue, May 26, 2015 at 10:26 AM, Hadley Wickham <h.wickham at gmail.com>
> wrote:
>
>> On Tue, May 26, 2015 at 12:18 PM, Gabriel Becker <gmbecker at ucdavis.edu>
>> wrote:
>> > On Tue, May 26, 2015 at 9:25 AM, Yihui Xie <xie at yihui.name> wrote:
>> >
>> >> I cannot speak for other package authors, but for all my own packages,
>> >> I have provided the BugReports field in DESCRIPTION that points to the
>> >> Github issues page. You can probably use this field to check if a
>> >> package is on Github or not. If it is, you may just fork the original
>> >> repo instead of creating a new one from the CRAN package.
>> >
>> >
>> > Maybe I'm missing something, but why would you fork the repo instead of
>> > just using the existing repo?
>>
>> One advantage of a fork is that you have permanent archive even if the
>> original goes away.
>>
>> Hadley
>>
>> --
>> http://had.co.nz/
>>
>
>
>
> --
> Gabriel Becker, PhD
> Computational Biologist
> Bioinformatics and Computational Biology
> Genentech, Inc.
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From maechler at lynne.stat.math.ethz.ch  Wed May 27 12:11:37 2015
From: maechler at lynne.stat.math.ethz.ch (Martin Maechler)
Date: Wed, 27 May 2015 12:11:37 +0200
Subject: [Rd] MetaCran website v1.0.0-alpha
In-Reply-To: <CABtg=K=_wimtHb6ha3OS0hk4-Uksw4r3gD1yK-enCRp2Bxp61g@mail.gmail.com>
References: <CABtg=Km1Vi1SHK=X2vGiUf+rDrm-05U4n0Gqdbk=rE5o-+xnxw@mail.gmail.com>
	<m2wpzyl371.fsf@krugs.de>
	<0A08CC22-72B9-4FB4-B6E8-50E885F0506A@r-project.org>
	<CABtg=KmPdieqPJP4nn-bGX+5LOJh1L3yAg+tS36UxXOMRhTn8g@mail.gmail.com>
	<CANROs4fC5ytjrgrOkABtouF-8aZ6pBL6u9vDCQey4_ezwSB+2A@mail.gmail.com>
	<CADwqtCNcCB1i_OON0F1Nv5SxEHdYY=o++XEwF0bgttA0p+Chzw@mail.gmail.com>
	<CABdHhvHT6Pc6a89GNTUpW26Y=E_n6mD1hNwX160Kcx638OY3nQ@mail.gmail.com>
	<CADwqtCMfGisC+g_M29Sx+H8mz30wnfUBAOqE_rBvueiNjhNPgA@mail.gmail.com>
	<CABtg=KkOODVm7WmSrm0cCos_gDXc6f4NYZYa_p5QpzDdiNhCvw@mail.gmail.com>
	<CADwqtCME7DfMozU1OmGXX4et7MfQXwgLqaFn_JeaWPyDQ_jtSg@mail.gmail.com>
	<CABtg=K=_wimtHb6ha3OS0hk4-Uksw4r3gD1yK-enCRp2Bxp61g@mail.gmail.com>
Message-ID: <21861.39001.954041.819558@stat.math.ethz.ch>

Hi G?bor,
just to you :

>>>>> G?bor Cs?rdi <csardi.gabor at gmail.com>
>>>>>     on Tue, 26 May 2015 14:16:00 -0400 writes:

    > On Tue, May 26, 2015 at 2:10 PM, Gabriel Becker <gmbecker at ucdavis.edu>
    > wrote:
    > [...]

    >> 
    >> Well, sort of. I mean if the package is being actively developed not on
    >> github, forking your archive repo and developing a patch/etc against it
    >> won't necessarily be particularly effective, as there is no way to have the
    >> right starting point (state of trunk), right?
    >> 

    > Well, then you can do 1) git rebase or 2) get the patch if the original
    > repo is not in git.

    > Yes, this is not ideal. I could remove that "Browse the source" completely,
    > that is an option, and remove the link from the version number as well.
    > There there will be no links to github.com/cran. Experienced users will
    > just type in the URL. That's fine with me, too.

    > Btw. how does this look for a warning: https://github.com/cran/crayon
    > This is the most red I could find.

This looks good and sufficient to me.

    > G.

    > [[alternative HTML version deleted]]

Gabor, could you try to set a good example  and *not* post in
HTML  (even though your messages are fine when transformed to
       plain text).

Thank you Gabor for your effort,
and best regards,

Martin

--
Martin <Maechler at stat.math.ethz.ch>  http://stat.ethz.ch/people/maechler
Seminar f?r Statistik, ETH Z?rich  HG G 16      R?mistrasse 101
CH-8092 Zurich, SWITZERLAND
phone: +41-44-632-3408       fax: ...-1228      <><


From murdoch.duncan at gmail.com  Wed May 27 14:26:14 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Wed, 27 May 2015 08:26:14 -0400
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
Message-ID: <5565B7E6.7090402@gmail.com>

On 22/05/2015 8:49 PM, Imanuel Costigan wrote:
> Are there any plans for CRAN to support NEWS files in markdown? Bit of a hassle to go the the package?s Github (or other like) site to read NEWS.

In answer to your original question:  plans are now being formed.  It
seems as though full support should be feasible, but someone needs to
volunteer to do it and maintain it.

By full support, I mean support that's equal to the support for NEWS.Rd
on CRAN and in R.

It's possible we'll get weaker support sooner, e.g. display of the
Markdown source in R and pandoc output on CRAN; that remains to be
determined.

No predicted time line for any of this.

Duncan Murdoch


From pperry at stern.nyu.edu  Thu May 28 05:19:09 2015
From: pperry at stern.nyu.edu (Patrick Perry)
Date: Wed, 27 May 2015 23:19:09 -0400
Subject: [Rd] Fix for bug in arima function
In-Reply-To: <57DB0FCD-7D29-4299-8923-37600E233508@gmail.com>
References: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>
	<C12E9FD6-C398-407E-92B7-87C18FB922FD@gmail.com>
	<CABAt4HdvK6U+YHUN=fG=Z-fS50VCq4ivuc4MnEpnsHGMq+6NdA@mail.gmail.com>
	<21853.39130.479116.797885@stat.math.ethz.ch>
	<D75099B3-0574-4DE8-83E7-DE867E6A352F@gmail.com>
	<21853.47141.218962.268511@stat.math.ethz.ch>
	<57DB0FCD-7D29-4299-8923-37600E233508@gmail.com>
Message-ID: <C0E2E32FA34F43BF9DC62D00BA80C4D9@stern.nyu.edu>


> I suspect that what we really need is  
>  
> fitI <- lm(x ~ xreg - 1, na.action = na.omit)
> fit <- if(length(dx) > ncol(dxreg))
> lm(dx ~ dxreg - 1, na.action = na.omit)
> else list(rank = 0L)
> if(fit$rank == 0L) {
> ## Degenerate model. Proceed anyway so as not to break old code
> fit <- fitI
> }
> n.used <- sum(!is.na(resid(fitI))) - length(Delta)
> init0 <- c(init0, coef(fit))
>  
> At least that would be the conservative change to get n.used indentical to what it was in 3.0.1

Along the same lines, here?s a solution that avoids the extra call to lm:

fit <- if(length(dx) > ncol(dxreg))
lm(dx ~ dxreg - 1, na.action = na.omit)
else list(rank = 0L)
if(fit$rank == 0L) {
## Degenerate model. Proceed anyway so as not to break old code
fit <- lm(x ~ xreg - 1, na.action = na.omit)
}
isna <- apply(is.na(xreg), 1, any) | is.na(x)
n.used <- sum(!isna) - length(Delta)
init0 <- c(init0, coef(fit))


From maechler at stat.math.ethz.ch  Thu May 28 10:17:23 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 28 May 2015 10:17:23 +0200
Subject: [Rd] Fix for bug in arima function
In-Reply-To: <C0E2E32FA34F43BF9DC62D00BA80C4D9@stern.nyu.edu>
References: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>
	<C12E9FD6-C398-407E-92B7-87C18FB922FD@gmail.com>
	<CABAt4HdvK6U+YHUN=fG=Z-fS50VCq4ivuc4MnEpnsHGMq+6NdA@mail.gmail.com>
	<21853.39130.479116.797885@stat.math.ethz.ch>
	<D75099B3-0574-4DE8-83E7-DE867E6A352F@gmail.com>
	<21853.47141.218962.268511@stat.math.ethz.ch>
	<57DB0FCD-7D29-4299-8923-37600E233508@gmail.com>
	<C0E2E32FA34F43BF9DC62D00BA80C4D9@stern.nyu.edu>
Message-ID: <21862.53011.702221.588468@stat.math.ethz.ch>

>>>>> Patrick Perry <pperry at stern.nyu.edu>
>>>>>     on Wed, 27 May 2015 23:19:09 -0400 writes:

 {@PP, you forgot this part:}
 >>>>> peter dalgaard <pdalgd at gmail.com>
 >>>>>     on Thu, 21 May 2015 14:36:03 +0200 writes:

    >> I suspect that what we really need is  
    >> 
    >> fitI <- lm(x ~ xreg - 1, na.action = na.omit)
    >> fit <- if(length(dx) > ncol(dxreg))
    >>     lm(dx ~ dxreg - 1, na.action = na.omit)
    >> else list(rank = 0L)
    >> if(fit$rank == 0L) {
    >>    ## Degenerate model. Proceed anyway so as not to break old code
    >>    fit <- fitI
    >> }
    >> n.used <- sum(!is.na(resid(fitI))) - length(Delta)
    >> init0 <- c(init0, coef(fit))
    >> 
    >> At least that would be the conservative change to get n.used indentical to what it was in 3.0.1

(Sorry for not taking up the thread ..)
That's definitely conservative and hence safest from that point
of view.  

On the other hand, to me, it did look a bit strange or "ugly" to always
perform to different lm()s and the coefficients of one and the
residuals of the other.

    > Along the same lines, here?s a solution that avoids the extra call to lm:

    > fit <- if(length(dx) > ncol(dxreg))
    >    lm(dx ~ dxreg - 1, na.action = na.omit)
    > else list(rank = 0L)
    > if(fit$rank == 0L) {
    >    ## Degenerate model. Proceed anyway so as not to break old code
    >    fit <- lm(x ~ xreg - 1, na.action = na.omit)
    > }
    > isna <- apply(is.na(xreg), 1, any) | is.na(x)
    > n.used <- sum(!isna) - length(Delta)
    > init0 <- c(init0, coef(fit))

That is indeed nicer ... and with logic closer to the current
code. I have very slightly changed it, e.g., using  anyNA(.),
and tested it with some more examples... and this does look good
to me in the sense that it is "internally more consistent".

To get this going and "exposed to CRAN", I'm committing it
(with the regression tests, and other necessary "entries") to
R-devel only, but with the intent to port to R-patched in a
couple of days.

Martin


From pdalgd at gmail.com  Thu May 28 10:55:13 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Thu, 28 May 2015 10:55:13 +0200
Subject: [Rd] Fix for bug in arima function
In-Reply-To: <21862.53011.702221.588468@stat.math.ethz.ch>
References: <25B343E47D08442686D0BB09924080F2@stern.nyu.edu>
	<C12E9FD6-C398-407E-92B7-87C18FB922FD@gmail.com>
	<CABAt4HdvK6U+YHUN=fG=Z-fS50VCq4ivuc4MnEpnsHGMq+6NdA@mail.gmail.com>
	<21853.39130.479116.797885@stat.math.ethz.ch>
	<D75099B3-0574-4DE8-83E7-DE867E6A352F@gmail.com>
	<21853.47141.218962.268511@stat.math.ethz.ch>
	<57DB0FCD-7D29-4299-8923-37600E233508@gmail.com>
	<C0E2E32FA34F43BF9DC62D00BA80C4D9@stern.nyu.edu>
	<21862.53011.702221.588468@stat.math.ethz.ch>
Message-ID: <074CC3C6-2B00-4C53-A9F5-9CF63989E826@gmail.com>


On 28 May 2015, at 10:17 , Martin Maechler <maechler at stat.math.ethz.ch> wrote:

> 
> On the other hand, to me, it did look a bit strange or "ugly" to always
> perform to different lm()s and the coefficients of one and the
> residuals of the other.

Yes, but the whole point was that if you do OLS on an integrated series, the only thing you get right is the number of observations (which you, slightly oddly, obtain as the length of the residuals) - the coefficients of that analysis will be inconsistent or at least severely inefficient. If you do OLS of the differenced series, you get coefficients that are good enough for starting values, but might not use  all observations. 

A WLS would get both right, but you need to fit the model to find the weight matrix (which in general is N x N, non-sparse)...

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Office: A 4.23
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From maechler at stat.math.ethz.ch  Thu May 28 10:57:38 2015
From: maechler at stat.math.ethz.ch (Martin Maechler)
Date: Thu, 28 May 2015 10:57:38 +0200
Subject: [Rd] building with tcltk on Ubuntu 14.04
In-Reply-To: <55648DA5.2070709@gmail.com>
References: <55647C66.6060702@gmail.com>
	<21860.33346.581909.652856@max.nulle.part>
	<55648DA5.2070709@gmail.com>
Message-ID: <21862.55426.720415.633252@stat.math.ethz.ch>

>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>     on Tue, 26 May 2015 11:13:41 -0400 writes:


    > False alarm.  Completely wiping out my build directory followed by

    > ../R-devel/configure --with-tcl-config=/usr/lib/tclConfig.sh
    > - --with-tk-config=/usr/lib/tkConfig.sh; make

    > seems to work.  (My fault for assuming repeated cycles of
    > ./configure; make would actually do the right thing ...)

    > There seems to be a corollary of Clarke's Law ("any sufficient
    > advanced technology is indistinguishable from magic") that says that
    > any sufficiently complex software system may *not* be magic, but it's
    > just easier to treat it as though it is ...

    > Thanks for the offer of help ...

I also run several computers on Ubuntu 14.04
and never had to anything special, I mean *no*  
--with-tcl-...  or --with-tk-....
where ever needed for me on 14.04 or earlier Ubuntu's... so I do
wonder how you got into problems at all.

Martin


    > Ben


    > On 15-05-26 10:25 AM, Dirk Eddelbuettel wrote:
    >> 
    >> Ben,
    >> 
    >> At work with little time so _real brief_:
    >> 
    >> -- we build r-devel "all the time", in fact nightly for rocker; and
    >> there are Dockerfiles to look at
    >> 
    >> -- we build R all the time in Debian, Ubuntu, ... and my sources
    >> for that are not on GH but you can fetch the diff.gz
    >> 
    >> -- there is an entire list dedicated to this: r-sig-debian so could
    >> you pretty-please post there (after registering, if needed)
    >> 
    >> I'll be glad to help, preferably on r-sig-debian.
    >> 
    >> Cheers, Dirk
    >>


From jari.oksanen at oulu.fi  Thu May 28 11:38:06 2015
From: jari.oksanen at oulu.fi (Jari Oksanen)
Date: Thu, 28 May 2015 09:38:06 +0000
Subject: [Rd] building with tcltk on Ubuntu 14.04
In-Reply-To: <21862.55426.720415.633252@stat.math.ethz.ch>
References: <55647C66.6060702@gmail.com>
	<21860.33346.581909.652856@max.nulle.part>	<55648DA5.2070709@gmail.com>
	<21862.55426.720415.633252@stat.math.ethz.ch>
Message-ID: <73FAD31E-FCDE-4AD6-8DFB-027C55EC67CA@oulu.fi>


On 28/05/2015, at 11:57 AM, Martin Maechler wrote:

>>>>>> Ben Bolker <bbolker at gmail.com>
>>>>>>    on Tue, 26 May 2015 11:13:41 -0400 writes:
> 
> 
>> False alarm.  Completely wiping out my build directory followed by
> 
>> ../R-devel/configure --with-tcl-config=/usr/lib/tclConfig.sh
>> - --with-tk-config=/usr/lib/tkConfig.sh; make
> 
>> seems to work.  (My fault for assuming repeated cycles of
>> ./configure; make would actually do the right thing ...)
> 
>> There seems to be a corollary of Clarke's Law ("any sufficient
>> advanced technology is indistinguishable from magic") that says that
>> any sufficiently complex software system may *not* be magic, but it's
>> just easier to treat it as though it is ...
> 
>> Thanks for the offer of help ...
> 
> I also run several computers on Ubuntu 14.04
> and never had to anything special, I mean *no*  
> --with-tcl-...  or --with-tk-....
> where ever needed for me on 14.04 or earlier Ubuntu's... so I do
> wonder how you got into problems at all.
> 
I also have the same problem with Ubuntu (at least in 14.04, now in 15.04): ./configure does not find tcl/tk without --with-tcl-? and --with-tk-? 

They are in quite normal places, but still need manual setting. Currently I use something like --with-tcl-config=/usr/lib/tclConfig.sh --with-tk-config=/usr/lib/tkConfig.sh

I need these explicit switches only when configure is overwritten. Normal compilation with ./configure works OK and finds Tcl/Tk, but a couple of times per year the configure seems to change so much that I need to use these switches. I have had this problem a couple of years. 

If I need to guess, I do something wrong and against instructions, and therefore I won't complain.

Cheers, Jari Oksanen


From julien.ide.fr at gmail.com  Thu May 28 11:49:56 2015
From: julien.ide.fr at gmail.com (=?UTF-8?Q?Julien_Id=C3=A9?=)
Date: Thu, 28 May 2015 11:49:56 +0200
Subject: [Rd] S4 inheritance and old class
Message-ID: <CAMDmGSbB+0wOfCCfnpBY4ENDkrKozb0iaUFW10sXprDp_7WTEw@mail.gmail.com>

Hey everyone,

I would like to develop a package using S4 classes.
I have to define several S4 classes that inherits from each others as
follow:

# A <- B <- C <- D

I also would like to define .DollarNames methods for these class so, if I
have understood well, I also have to define an old class as follow:

# AOld <- A <- B <- C <- D

setOldClass(Classes = "AOld")

setClass(
  Class = "A",
  contains = "AOld",
  slots = list(A = "character")
)

.DollarNames.A <- function(x, pattern)
  grep(pattern, slotNames(x), value = TRUE)

setClass(
  Class = "B",
  contains = "A",
  slots = list(B = "character"),
  validity = function(object){
    cat("Testing an object of class '", class(object),
        "'' with valitity function of class 'B'", sep = "")
    cat("Validity test for class 'B': ", object at A, sep = "")
    return(TRUE)
  }
)

setClass(
  Class = "C",
  contains = c("B"),
  slots = list(C = "character"),
  validity = function(object){
    cat("Testing an object of class '", class(object),
        "'' with valitity function of class 'C'", sep = "")
    cat("Validity test for class 'C': ", object at A, sep = "")
    return(TRUE)
  }
)

setClass(
  Class = "D",
  contains = "C",
  slots = list(D = "character"),
  validity = function(object){
    cat("Testing an object of class '", class(object),
        "'' with valitity function of class 'D'", sep = "")
    cat("Validity test for class 'D': ", object at A, sep = "")
    return(TRUE)
  }
)

My problem is that when I try to create an object of class "D" and test its
validity

validObject(new("D"))

it seems that at some point the object is coerced to an object of class
"AOld" and tested by the validity function of class "B". What am I missing
here?

Julien

	[[alternative HTML version deleted]]


From edd at debian.org  Thu May 28 13:34:51 2015
From: edd at debian.org (Dirk Eddelbuettel)
Date: Thu, 28 May 2015 06:34:51 -0500
Subject: [Rd] building with tcltk on Ubuntu 14.04
In-Reply-To: <73FAD31E-FCDE-4AD6-8DFB-027C55EC67CA@oulu.fi>
References: <55647C66.6060702@gmail.com>
	<21860.33346.581909.652856@max.nulle.part>
	<55648DA5.2070709@gmail.com>
	<21862.55426.720415.633252@stat.math.ethz.ch>
	<73FAD31E-FCDE-4AD6-8DFB-027C55EC67CA@oulu.fi>
Message-ID: <21862.64859.593123.312658@max.nulle.part>


On 28 May 2015 at 09:38, Jari Oksanen wrote:
| On 28/05/2015, at 11:57 AM, Martin Maechler wrote:
| >>>>>> Ben Bolker <bbolker at gmail.com>
| >> False alarm.  Completely wiping out my build directory followed by
| > 
| >> ../R-devel/configure --with-tcl-config=/usr/lib/tclConfig.sh
| >> - --with-tk-config=/usr/lib/tkConfig.sh; make

| > I also run several computers on Ubuntu 14.04
| > and never had to anything special, I mean *no*  
| > --with-tcl-...  or --with-tk-....
| > where ever needed for me on 14.04 or earlier Ubuntu's... so I do
| > wonder how you got into problems at all.
| > 
| I also have the same problem with Ubuntu (at least in 14.04, now in 15.04): ./configure does not find tcl/tk without --with-tcl-? and --with-tk-? 
| 
| They are in quite normal places, but still need manual setting. Currently I use something like --with-tcl-config=/usr/lib/tclConfig.sh --with-tk-config=/usr/lib/tkConfig.sh

Wild guess:  You are still using tcl85-dev and tk8.5-dev.

Switch to 8.6 for both and defaults should work.

See eg this Dockerfile with the 'recipe' for building R(-devel) from source;
it too relies on tck/tk 8.6 now.

Dirk

PS Allow me to reiterate that this discussion would have felt more at home on
the r-sig-debian list.

-- 
http://dirk.eddelbuettel.com | @eddelbuettel | edd at debian.org


From julien.ide.fr at gmail.com  Thu May 28 15:23:12 2015
From: julien.ide.fr at gmail.com (julien_ide)
Date: Thu, 28 May 2015 06:23:12 -0700 (PDT)
Subject: [Rd] S4 inheritance and old class
Message-ID: <1432819392786-4707840.post@n4.nabble.com>

Hey everyone,

I would like to develop a package using S4 classes.
I have to define several S4 classes that inherits from each others as
follow:

# A <- B <- C <- D

I also would like to define .DollarNames methods for these classes so, if I
have understood well, I also have to define an old class as follow:

# AOld <- A <- B <- C <- D

setOldClass(Classes = "AOld")

setClass(
  Class = "A",
  contains = "AOld",
  slots = list(A = "character")
)

.DollarNames.A <- function(x, pattern)
  grep(pattern, slotNames(x), value = TRUE)

setClass(
  Class = "B",
  contains = "A",
  slots = list(B = "character"),
  validity = function(object){
    cat("Testing an object of class '", class(object),
        "'' with valitity function of class 'B'", sep = "")
    cat("Validity test for class 'B': ", object at A, sep = "")
    return(TRUE)
  }
)

setClass(
  Class = "C",
  contains = c("B"),
  slots = list(C = "character"),
  validity = function(object){
    cat("Testing an object of class '", class(object),
        "'' with valitity function of class 'C'", sep = "")
    cat("Validity test for class 'C': ", object at A, sep = "")
    return(TRUE)
  }
)

setClass(
  Class = "D",
  contains = "C",
  slots = list(D = "character"),
  validity = function(object){
    cat("Testing an object of class '", class(object),
        "'' with valitity function of class 'D'", sep = "")
    cat("Validity test for class 'D': ", object at A, sep = "")
    return(TRUE)
  }
)

My problem is that when I try to create an object of class "D" and test its
validity 

validObject(new("D"))

it seems that at some point the object is coerced to an object of class
"AOld" and tested by the validity function of class "B".
Of course it returns an error. What am I missing here?

Julien



--
View this message in context: http://r.789695.n4.nabble.com/S4-inheritance-and-old-class-tp4707840.html
Sent from the R devel mailing list archive at Nabble.com.


From mtmorgan at fredhutch.org  Thu May 28 16:30:13 2015
From: mtmorgan at fredhutch.org (Martin Morgan)
Date: Thu, 28 May 2015 07:30:13 -0700
Subject: [Rd] S4 inheritance and old class
In-Reply-To: <CAMDmGSbB+0wOfCCfnpBY4ENDkrKozb0iaUFW10sXprDp_7WTEw@mail.gmail.com>
References: <CAMDmGSbB+0wOfCCfnpBY4ENDkrKozb0iaUFW10sXprDp_7WTEw@mail.gmail.com>
Message-ID: <55672675.7020104@fredhutch.org>

On 05/28/2015 02:49 AM, Julien Id? wrote:
> Hey everyone,
>
> I would like to develop a package using S4 classes.
> I have to define several S4 classes that inherits from each others as
> follow:
>
> # A <- B <- C <- D
>
> I also would like to define .DollarNames methods for these class so, if I
> have understood well, I also have to define an old class as follow:
>
> # AOld <- A <- B <- C <- D
>
> setOldClass(Classes = "AOld")
>
> setClass(
>    Class = "A",
>    contains = "AOld",
>    slots = list(A = "character")
> )
>
> .DollarNames.A <- function(x, pattern)
>    grep(pattern, slotNames(x), value = TRUE)

Instead of setOldClass, define a $ method on A

     setMethod("$", "A", function(x, name) slot(x, name))

And then

   a = new("A")
   a$<tab>
   d = new("D")
   d$<tab>

I don't know about the setOldClass problem; it seems like a bug.

Martin Morgan

>
> setClass(
>    Class = "B",
>    contains = "A",
>    slots = list(B = "character"),
>    validity = function(object){
>      cat("Testing an object of class '", class(object),
>          "'' with valitity function of class 'B'", sep = "")
>      cat("Validity test for class 'B': ", object at A, sep = "")
>      return(TRUE)
>    }
> )
>
> setClass(
>    Class = "C",
>    contains = c("B"),
>    slots = list(C = "character"),
>    validity = function(object){
>      cat("Testing an object of class '", class(object),
>          "'' with valitity function of class 'C'", sep = "")
>      cat("Validity test for class 'C': ", object at A, sep = "")
>      return(TRUE)
>    }
> )
>
> setClass(
>    Class = "D",
>    contains = "C",
>    slots = list(D = "character"),
>    validity = function(object){
>      cat("Testing an object of class '", class(object),
>          "'' with valitity function of class 'D'", sep = "")
>      cat("Validity test for class 'D': ", object at A, sep = "")
>      return(TRUE)
>    }
> )
>
> My problem is that when I try to create an object of class "D" and test its
> validity
>
> validObject(new("D"))
>
> it seems that at some point the object is coerced to an object of class
> "AOld" and tested by the validity function of class "B". What am I missing
> here?
>
> Julien
>
> 	[[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


-- 
Computational Biology / Fred Hutchinson Cancer Research Center
1100 Fairview Ave. N.
PO Box 19024 Seattle, WA 98109

Location: Arnold Building M1 B861
Phone: (206) 667-2793


From gmbecker at ucdavis.edu  Thu May 28 18:57:44 2015
From: gmbecker at ucdavis.edu (Gabriel Becker)
Date: Thu, 28 May 2015 09:57:44 -0700
Subject: [Rd] S4 inheritance and old class
In-Reply-To: <55672675.7020104@fredhutch.org>
References: <CAMDmGSbB+0wOfCCfnpBY4ENDkrKozb0iaUFW10sXprDp_7WTEw@mail.gmail.com>
	<55672675.7020104@fredhutch.org>
Message-ID: <CADwqtCMHX1K5kNSid2RtRDYLfGjD+YDXnJiPu8SiX9H0ADqhrA@mail.gmail.com>

The problem seems to be with coercion, actually, not validity methods per
se:

> myd
Object of class "D"
<S4 Type Object>
attr(,"class")
[1] "AOldclass"
Slot "D":
character(0)

Slot "C":
character(0)

Slot "B":
character(0)

Slot "A":
character(0)

> as(myd, "B")
Object of class "AOldclass"
<S4 Type Object>
attr(,"class")
[1] "AOldclass"

This comes from the coercion method that is automatically generated for
going from D to B. Recreating what as() does, we get (emphasis mine, of
course):

> thisClass = "D"
> Class = "B"
>    where <- .classEnv(thisClass, mustFind = FALSE)
> coerceMethods <- methods:::.getMethodsTable(coerceFun,
environment(coerceFun),
+ inherited=TRUE)
> asMethod = methods:::.quickCoerceSelect(thisClass, Class, coerceFun,
+ coerceMethods, where)
> asMethod
Method Definition:

function (from, to = "B", *strict = TRUE*)

*if (strict) {    S3Part(from)*
} else from

Signatures:
        from to
target  "D"  "B"
defined "D"  "B"

Since S3 classes can't have validity methods anyway, I would conjecture
that passing strict = FALSE to the line

           errors <- c(errors, anyStrings(validityMethod(as(object,
                superClass))))

in validObject() would fix this.  I haven't tested that hypothesis though,
so there may be cases where such a patch breaks other functionality.

~G


On Thu, May 28, 2015 at 7:30 AM, Martin Morgan <mtmorgan at fredhutch.org>
wrote:

> On 05/28/2015 02:49 AM, Julien Id? wrote:
>
>> Hey everyone,
>>
>> I would like to develop a package using S4 classes.
>> I have to define several S4 classes that inherits from each others as
>> follow:
>>
>> # A <- B <- C <- D
>>
>> I also would like to define .DollarNames methods for these class so, if I
>> have understood well, I also have to define an old class as follow:
>>
>> # AOld <- A <- B <- C <- D
>>
>> setOldClass(Classes = "AOld")
>>
>> setClass(
>>    Class = "A",
>>    contains = "AOld",
>>    slots = list(A = "character")
>> )
>>
>> .DollarNames.A <- function(x, pattern)
>>    grep(pattern, slotNames(x), value = TRUE)
>>
>
> Instead of setOldClass, define a $ method on A
>
>     setMethod("$", "A", function(x, name) slot(x, name))
>
> And then
>
>   a = new("A")
>   a$<tab>
>   d = new("D")
>   d$<tab>
>
> I don't know about the setOldClass problem; it seems like a bug.
>
> Martin Morgan
>
>
>
>> setClass(
>>    Class = "B",
>>    contains = "A",
>>    slots = list(B = "character"),
>>    validity = function(object){
>>      cat("Testing an object of class '", class(object),
>>          "'' with valitity function of class 'B'", sep = "")
>>      cat("Validity test for class 'B': ", object at A, sep = "")
>>      return(TRUE)
>>    }
>> )
>>
>> setClass(
>>    Class = "C",
>>    contains = c("B"),
>>    slots = list(C = "character"),
>>    validity = function(object){
>>      cat("Testing an object of class '", class(object),
>>          "'' with valitity function of class 'C'", sep = "")
>>      cat("Validity test for class 'C': ", object at A, sep = "")
>>      return(TRUE)
>>    }
>> )
>>
>> setClass(
>>    Class = "D",
>>    contains = "C",
>>    slots = list(D = "character"),
>>    validity = function(object){
>>      cat("Testing an object of class '", class(object),
>>          "'' with valitity function of class 'D'", sep = "")
>>      cat("Validity test for class 'D': ", object at A, sep = "")
>>      return(TRUE)
>>    }
>> )
>>
>> My problem is that when I try to create an object of class "D" and test
>> its
>> validity
>>
>> validObject(new("D"))
>>
>> it seems that at some point the object is coerced to an object of class
>> "AOld" and tested by the validity function of class "B". What am I missing
>> here?
>>
>> Julien
>>
>>         [[alternative HTML version deleted]]
>>
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel
>>
>>
>
> --
> Computational Biology / Fred Hutchinson Cancer Research Center
> 1100 Fairview Ave. N.
> PO Box 19024 Seattle, WA 98109
>
> Location: Arnold Building M1 B861
> Phone: (206) 667-2793
>
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>



-- 
Gabriel Becker, PhD
Computational Biologist
Bioinformatics and Computational Biology
Genentech, Inc.

	[[alternative HTML version deleted]]


From lawrence.michael at gene.com  Thu May 28 23:32:24 2015
From: lawrence.michael at gene.com (Michael Lawrence)
Date: Thu, 28 May 2015 14:32:24 -0700
Subject: [Rd] S4 inheritance and old class
In-Reply-To: <CAMDmGSbB+0wOfCCfnpBY4ENDkrKozb0iaUFW10sXprDp_7WTEw@mail.gmail.com>
References: <CAMDmGSbB+0wOfCCfnpBY4ENDkrKozb0iaUFW10sXprDp_7WTEw@mail.gmail.com>
Message-ID: <CAOQ5NydxE=2uzEqqu2nFUkvrDT2TFT2SUu2y6Gcon0gFB8zuJg@mail.gmail.com>

On Thu, May 28, 2015 at 2:49 AM, Julien Id? <julien.ide.fr at gmail.com> wrote:
> Hey everyone,
>
> I would like to develop a package using S4 classes.
> I have to define several S4 classes that inherits from each others as
> follow:
>
> # A <- B <- C <- D
>
> I also would like to define .DollarNames methods for these class so, if I
> have understood well, I also have to define an old class as follow:
>
> # AOld <- A <- B <- C <- D
>
> setOldClass(Classes = "AOld")
>

No, you don't need to define an old class for dispatching on an S3
generic. Forget the AOld and things will dispatch to .DollarNames.A
just fine.

That said, a few notes for posterity:

First, if you're going to define an S4 class that extends an old
class, you probably want to give the old class a prototype, so that
calling e.g. new("A") will actually give an object that is valid for
existing S3 methods on that class.

Second, there seems to be a bug that breaks that strategy, because
even when the old class has a prototype, it is not taken as the
prototype of the extension (A). Instead, there is a plain "S4"
prototype, with the class set to "Old".

> setOldClass("Old", prototype=structure(list(), class="Old"))
> setClass("New", contains="Old")
> new("New")
Object of class "New"
<S4 Type Object>
attr(,"class")
[1] "Old"

But this is still possible:
> new("New", structure(list(), class="Old"))
Object of class "New"
An object of class "Old"

Third, the fact that as(new("C"), "B") works as expected but not
as(new("D"), "B") is probably also a bug.

Fourth, calling setOldClass is essentially specifying a contract to
which the S3 system is not bound, so it is extremely risky. If it is
absolutely necessary to include an S3 object in an S4 representation,
best practice is to isolate that dependency to the greatest extent
possible, i.e., create an object that specifically encapsulates that
S3 object, thus centralizing all of the necessary consistency checks.

> setClass(
>   Class = "A",
>   contains = "AOld",
>   slots = list(A = "character")
> )
>
> .DollarNames.A <- function(x, pattern)
>   grep(pattern, slotNames(x), value = TRUE)
>
> setClass(
>   Class = "B",
>   contains = "A",
>   slots = list(B = "character"),
>   validity = function(object){
>     cat("Testing an object of class '", class(object),
>         "'' with valitity function of class 'B'", sep = "")
>     cat("Validity test for class 'B': ", object at A, sep = "")
>     return(TRUE)
>   }
> )
>
> setClass(
>   Class = "C",
>   contains = c("B"),
>   slots = list(C = "character"),
>   validity = function(object){
>     cat("Testing an object of class '", class(object),
>         "'' with valitity function of class 'C'", sep = "")
>     cat("Validity test for class 'C': ", object at A, sep = "")
>     return(TRUE)
>   }
> )
>
> setClass(
>   Class = "D",
>   contains = "C",
>   slots = list(D = "character"),
>   validity = function(object){
>     cat("Testing an object of class '", class(object),
>         "'' with valitity function of class 'D'", sep = "")
>     cat("Validity test for class 'D': ", object at A, sep = "")
>     return(TRUE)
>   }
> )
>
> My problem is that when I try to create an object of class "D" and test its
> validity
>
> validObject(new("D"))
>
> it seems that at some point the object is coerced to an object of class
> "AOld" and tested by the validity function of class "B". What am I missing
> here?
>
> Julien
>
>         [[alternative HTML version deleted]]
>
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel


From ivan.popivanov at gmail.com  Fri May 29 06:11:47 2015
From: ivan.popivanov at gmail.com (Ivan Popivanov)
Date: Fri, 29 May 2015 04:11:47 +0000
Subject: [Rd] Why my messages are filtered from the list?
Message-ID: <CAK7-yAiOXviM9y5jQnhnSB=xk-R-_pnBYf9XGjOUQ=o_1v3yMg@mail.gmail.com>

Hello,

Over the last two months I have sent two messages (same topic) to the list.
None of them showed on the list. For the first, I got a message that it is
in some queue and waiting for an administrator to look at it. Is the queue
THAT long?!

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri May 29 06:43:20 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 28 May 2015 21:43:20 -0700
Subject: [Rd] Why my messages are filtered from the list?
In-Reply-To: <CAK7-yAiOXviM9y5jQnhnSB=xk-R-_pnBYf9XGjOUQ=o_1v3yMg@mail.gmail.com>
References: <CAK7-yAiOXviM9y5jQnhnSB=xk-R-_pnBYf9XGjOUQ=o_1v3yMg@mail.gmail.com>
Message-ID: <F1541CAD-218A-41A5-A86D-F9EECF00787E@comcast.net>


On May 28, 2015, at 9:11 PM, Ivan Popivanov wrote:

> Hello,
> 
> Over the last two months I have sent two messages (same topic) to the list.
> None of them showed on the list. For the first, I got a message that it is
> in some queue and waiting for an administrator to look at it. Is the queue
> THAT long?!

The moderators don't know all the spam rules but we are fairly sure that the Spam filter increases the probability of diverting to the queue especially for Nabble postings , but we suspect also for certain high-risk domains, and using HTML mail.

The queue's are fairly short and if your posting doesn't get to the list within 12 hours you can be reasonably sure it was intercepted and will never appear. Some postings from Nabble do not even reach teh moderator queue. If it had a blank Subject or a Subject that was all question marks the moderator might have simply discarded it without even looking at it. I do not see any posting from your address in the Archives for May or April.

> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

David Winsemius
Alameda, CA, USA


From ivan.popivanov at gmail.com  Fri May 29 07:05:13 2015
From: ivan.popivanov at gmail.com (Ivan Popivanov)
Date: Fri, 29 May 2015 05:05:13 +0000
Subject: [Rd] Why my messages are filtered from the list?
In-Reply-To: <F1541CAD-218A-41A5-A86D-F9EECF00787E@comcast.net>
References: <CAK7-yAiOXviM9y5jQnhnSB=xk-R-_pnBYf9XGjOUQ=o_1v3yMg@mail.gmail.com>
	<F1541CAD-218A-41A5-A86D-F9EECF00787E@comcast.net>
Message-ID: <CAK7-yAjTppN__8NYbR_QyvsH8Us9+S5kvUPcP3-xCPYsZ0heNA@mail.gmail.com>

Now I am getting confused. I see two postings from me in the archives:

https://stat.ethz.ch/pipermail/r-devel/2015-May/071205.html
https://stat.ethz.ch/pipermail/r-devel/2015-April/070982.html

Were these actually published to the list? If so - big apology.

Regards,
Ivan

On Fri, May 29, 2015 at 12:43 AM David Winsemius <dwinsemius at comcast.net>
wrote:

>
> On May 28, 2015, at 9:11 PM, Ivan Popivanov wrote:
>
> > Hello,
> >
> > Over the last two months I have sent two messages (same topic) to the
> list.
> > None of them showed on the list. For the first, I got a message that it
> is
> > in some queue and waiting for an administrator to look at it. Is the
> queue
> > THAT long?!
>
> The moderators don't know all the spam rules but we are fairly sure that
> the Spam filter increases the probability of diverting to the queue
> especially for Nabble postings , but we suspect also for certain high-risk
> domains, and using HTML mail.
>
> The queue's are fairly short and if your posting doesn't get to the list
> within 12 hours you can be reasonably sure it was intercepted and will
> never appear. Some postings from Nabble do not even reach teh moderator
> queue. If it had a blank Subject or a Subject that was all question marks
> the moderator might have simply discarded it without even looking at it. I
> do not see any posting from your address in the Archives for May or April.
>
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
>
> David Winsemius
> Alameda, CA, USA
>
>

	[[alternative HTML version deleted]]


From dwinsemius at comcast.net  Fri May 29 07:49:47 2015
From: dwinsemius at comcast.net (David Winsemius)
Date: Thu, 28 May 2015 22:49:47 -0700
Subject: [Rd] Why my messages are filtered from the list?
In-Reply-To: <CAK7-yAjTppN__8NYbR_QyvsH8Us9+S5kvUPcP3-xCPYsZ0heNA@mail.gmail.com>
References: <CAK7-yAiOXviM9y5jQnhnSB=xk-R-_pnBYf9XGjOUQ=o_1v3yMg@mail.gmail.com>
	<F1541CAD-218A-41A5-A86D-F9EECF00787E@comcast.net>
	<CAK7-yAjTppN__8NYbR_QyvsH8Us9+S5kvUPcP3-xCPYsZ0heNA@mail.gmail.com>
Message-ID: <AACA5B66-1CF6-4A23-9859-4B12FB5CECDF@comcast.net>


On May 28, 2015, at 10:05 PM, Ivan Popivanov wrote:

> Now I am getting confused. I see two postings from me in the archives:
> 
> https://stat.ethz.ch/pipermail/r-devel/2015-May/071205.html
> https://stat.ethz.ch/pipermail/r-devel/2015-April/070982.html
> 
> Were these actually published to the list? If so - big apology.
> 

Yes they were, to r-devel. Just not the r-help mailing list Archive I looked in. 

Sorry for my noise, too.

-- 
David.
> Regards,
> Ivan
> 
> On Fri, May 29, 2015 at 12:43 AM David Winsemius <dwinsemius at comcast.net> wrote:
> 
> On May 28, 2015, at 9:11 PM, Ivan Popivanov wrote:
> 
> > Hello,
> >
> > Over the last two months I have sent two messages (same topic) to the list.
> > None of them showed on the list. For the first, I got a message that it is
> > in some queue and waiting for an administrator to look at it. Is the queue
> > THAT long?!
> 
> The moderators don't know all the spam rules but we are fairly sure that the Spam filter increases the probability of diverting to the queue especially for Nabble postings , but we suspect also for certain high-risk domains, and using HTML mail.
> 
> The queue's are fairly short and if your posting doesn't get to the list within 12 hours you can be reasonably sure it was intercepted and will never appear. Some postings from Nabble do not even reach teh moderator queue. If it had a blank Subject or a Subject that was all question marks the moderator might have simply discarded it without even looking at it. I do not see any posting from your address in the Archives for May or April.
> 
> >       [[alternative HTML version deleted]]
> >
> > ______________________________________________
> > R-devel at r-project.org mailing list
> > https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> David Winsemius
> Alameda, CA, USA
> 

David Winsemius
Alameda, CA, USA


From simon.urbanek at r-project.org  Fri May 29 14:17:08 2015
From: simon.urbanek at r-project.org (Simon Urbanek)
Date: Fri, 29 May 2015 08:17:08 -0400
Subject: [Rd] Why my messages are filtered from the list?
In-Reply-To: <CAK7-yAjTppN__8NYbR_QyvsH8Us9+S5kvUPcP3-xCPYsZ0heNA@mail.gmail.com>
References: <CAK7-yAiOXviM9y5jQnhnSB=xk-R-_pnBYf9XGjOUQ=o_1v3yMg@mail.gmail.com>
	<F1541CAD-218A-41A5-A86D-F9EECF00787E@comcast.net>
	<CAK7-yAjTppN__8NYbR_QyvsH8Us9+S5kvUPcP3-xCPYsZ0heNA@mail.gmail.com>
Message-ID: <4F5ED622-D678-42EE-9E1C-C1A277361C6B@r-project.org>


On May 29, 2015, at 1:05 AM, Ivan Popivanov <ivan.popivanov at gmail.com> wrote:

> Now I am getting confused. I see two postings from me in the archives:
> 
> https://stat.ethz.ch/pipermail/r-devel/2015-May/071205.html
> https://stat.ethz.ch/pipermail/r-devel/2015-April/070982.html
> 
> Were these actually published to the list?


Yes, I remember seeing those, because it did spark my interest. I'm swamped with other stuff, but the topic is on my (long) stack to look at.

Cheers,
Simon


> If so - big apology.
> 
> Regards,
> Ivan
> 
> On Fri, May 29, 2015 at 12:43 AM David Winsemius <dwinsemius at comcast.net>
> wrote:
> 
>> 
>> On May 28, 2015, at 9:11 PM, Ivan Popivanov wrote:
>> 
>>> Hello,
>>> 
>>> Over the last two months I have sent two messages (same topic) to the
>> list.
>>> None of them showed on the list. For the first, I got a message that it
>> is
>>> in some queue and waiting for an administrator to look at it. Is the
>> queue
>>> THAT long?!
>> 
>> The moderators don't know all the spam rules but we are fairly sure that
>> the Spam filter increases the probability of diverting to the queue
>> especially for Nabble postings , but we suspect also for certain high-risk
>> domains, and using HTML mail.
>> 
>> The queue's are fairly short and if your posting doesn't get to the list
>> within 12 hours you can be reasonably sure it was intercepted and will
>> never appear. Some postings from Nabble do not even reach teh moderator
>> queue. If it had a blank Subject or a Subject that was all question marks
>> the moderator might have simply discarded it without even looking at it. I
>> do not see any posting from your address in the Archives for May or April.
>> 
>>>     [[alternative HTML version deleted]]
>>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
>> 
>> David Winsemius
>> Alameda, CA, USA
>> 
>> 
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
> 


From i.costigan at me.com  Sat May 30 01:20:00 2015
From: i.costigan at me.com (Imanuel Costigan)
Date: Sat, 30 May 2015 09:20:00 +1000
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <21856.13500.513608.759602@fangorn.hornik.net>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
Message-ID: <B98D36A9-901A-4413-88C0-22D7E923612E@me.com>

So I assume this commit means NEWS.md is now no longer on blacklist? 

https://github.com/wch/r-source/commit/9ffe87264a1cd59a31a829f72d57af0f1bfa327a

Sent from my iPad

On 23 May 2015, at 6:05 pm, Kurt Hornik <Kurt.Hornik at wu.ac.at> wrote:

>>>>>> Duncan Murdoch writes:
> 
>>> On 22/05/2015 8:49 PM, Imanuel Costigan wrote:
>>> Are there any plans for CRAN to support NEWS files in markdown? Bit of a hassle to go the the package?s Github (or other like) site to read NEWS.
> 
>> Not as far as I know.  There have been discussions about increasing the
>> support of Markdown, but so far the conclusion has been that it's too
>> hard to do -- the support is not stable enough on all the platforms
>> where R runs.
> 
> There are actually two issues here.
> 
> For CRAN, we could in principle take inst/NEWS.md files, convert these
> to HTML using pandoc, and use the HTML for the package web page.  (Would
> need the CRAN incoming checks to be taught about inst/NEWS.md.)
> 
> However, we cannot use such files for utils::news() because we do not
> (yet?) know how to reliably parse such files and extract the news items
> (and hence cannot really compute on the news information).
> 
> Btw, currently only one package on CRAN has inst/NEWS.md (another one
> has NEWS.md at top level).
> 
> Best
> -k
> 
>> Markdown is allowed for vignettes (because the package author processes
>> those), so I'd suggest putting your news into a vignette instead of a
>> news file.  Put in a token news file that points to the vignette so
>> users can find it.
> 
>> Duncan Murdoch
> 
>> ______________________________________________
>> R-devel at r-project.org mailing list
>> https://stat.ethz.ch/mailman/listinfo/r-devel

	[[alternative HTML version deleted]]


From pdalgd at gmail.com  Sat May 30 08:53:11 2015
From: pdalgd at gmail.com (peter dalgaard)
Date: Sat, 30 May 2015 08:53:11 +0200
Subject: [Rd] NEWS.md support on CRAN
In-Reply-To: <B98D36A9-901A-4413-88C0-22D7E923612E@me.com>
References: <4819669E-8260-47B0-96BF-DC2B29E6BE21@me.com>
	<555FD2FE.8050600@gmail.com>
	<21856.13500.513608.759602@fangorn.hornik.net>
	<B98D36A9-901A-4413-88C0-22D7E923612E@me.com>
Message-ID: <581D2C19-ED47-4D1D-8FC7-C4B4F368E637@gmail.com>



> On 30 May 2015, at 01:20 , Imanuel Costigan <i.costigan at me.com> wrote:
> 
> So I assume this commit means NEWS.md is now no longer on blacklist? 
> 

....in the development version. Not true of released versions.

-pd


> https://github.com/wch/r-source/commit/9ffe87264a1cd59a31a829f72d57af0f1bfa327a
> 
> Sent from my iPad
> 
> On 23 May 2015, at 6:05 pm, Kurt Hornik <Kurt.Hornik at wu.ac.at> wrote:
> 
>>>>>>> Duncan Murdoch writes:
>> 
>>>> On 22/05/2015 8:49 PM, Imanuel Costigan wrote:
>>>> Are there any plans for CRAN to support NEWS files in markdown? Bit of a hassle to go the the package?s Github (or other like) site to read NEWS.
>> 
>>> Not as far as I know.  There have been discussions about increasing the
>>> support of Markdown, but so far the conclusion has been that it's too
>>> hard to do -- the support is not stable enough on all the platforms
>>> where R runs.
>> 
>> There are actually two issues here.
>> 
>> For CRAN, we could in principle take inst/NEWS.md files, convert these
>> to HTML using pandoc, and use the HTML for the package web page.  (Would
>> need the CRAN incoming checks to be taught about inst/NEWS.md.)
>> 
>> However, we cannot use such files for utils::news() because we do not
>> (yet?) know how to reliably parse such files and extract the news items
>> (and hence cannot really compute on the news information).
>> 
>> Btw, currently only one package on CRAN has inst/NEWS.md (another one
>> has NEWS.md at top level).
>> 
>> Best
>> -k
>> 
>>> Markdown is allowed for vignettes (because the package author processes
>>> those), so I'd suggest putting your news into a vignette instead of a
>>> news file.  Put in a token news file that points to the vignette so
>>> users can find it.
>> 
>>> Duncan Murdoch
>> 
>>> ______________________________________________
>>> R-devel at r-project.org mailing list
>>> https://stat.ethz.ch/mailman/listinfo/r-devel
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel

-- 
Peter Dalgaard, Professor,
Center for Statistics, Copenhagen Business School
Solbjerg Plads 3, 2000 Frederiksberg, Denmark
Phone: (+45)38153501
Email: pd.mes at cbs.dk  Priv: PDalgd at gmail.com


From sudomeme at gmail.com  Fri May 29 22:16:57 2015
From: sudomeme at gmail.com (Sue McDonald)
Date: Fri, 29 May 2015 15:16:57 -0500
Subject: [Rd] Compiling 64bit static library for Windows (Rtools33, MSYS2,
 cross-compile on linux)
Message-ID: <CAOkNWZUga3MvKMn0K2i01U2dWZ+3LuLDp-v4u0WXjtTV_7y3Ew@mail.gmail.com>

My apologies for cross-posting. I found this site, after I had posted on
stack-overflow.

I need to compile several static libraries (C & Fortran) which will later
be linked with an R package. Rtools33 directory includes /i686-w64-mingw32
directory which I understand creates 32 bit binaries. Yet, there are other
64 bit directories as well.

I have three related questions:

   1.

   Can Rtools33 be used to compile static libraries as a separate step
   using -m64 flag?
   2.

   MSYS2 is very convenient for compiling many of these libraries. Can a
   static library compiled with x86_64-w64-mingw32 (gcc 4.9.2) be used with
   Rtools33 (v 4.6.2)?
   3.

   Can a static library compiled using x86_64-w64-mingw32-gcc
   cross-compiler (v 4.6.2) on linux be used with Rtools33?

Options 2 and 3 are preferable for convenience and speed.

Compiling all libraries as part of the R-package is not currently an option.

Thanks,

SM

	[[alternative HTML version deleted]]


From murdoch.duncan at gmail.com  Sat May 30 14:14:08 2015
From: murdoch.duncan at gmail.com (Duncan Murdoch)
Date: Sat, 30 May 2015 08:14:08 -0400
Subject: [Rd] Compiling 64bit static library for Windows (Rtools33, MSYS2,
 cross-compile on linux)
In-Reply-To: <CAOkNWZUga3MvKMn0K2i01U2dWZ+3LuLDp-v4u0WXjtTV_7y3Ew@mail.gmail.com>
References: <CAOkNWZUga3MvKMn0K2i01U2dWZ+3LuLDp-v4u0WXjtTV_7y3Ew@mail.gmail.com>
Message-ID: <5569A990.7020004@gmail.com>

On 29/05/2015 4:16 PM, Sue McDonald wrote:
> My apologies for cross-posting. I found this site, after I had posted on
> stack-overflow.
> 
> I need to compile several static libraries (C & Fortran) which will later
> be linked with an R package. Rtools33 directory includes /i686-w64-mingw32
> directory which I understand creates 32 bit binaries. Yet, there are other
> 64 bit directories as well.

The current Rtools is set up for multilib operation.  You only need to
use the binaries in Rtools/gcc-4.6.3/bin.  The executables there will
choose files from the other directories depending on the -m32 or -m64
flag, for 32 bit or 64 bit operation.

> 
> I have three related questions:
> 
>    1.
> 
>    Can Rtools33 be used to compile static libraries as a separate step
>    using -m64 flag?

Yes, I believe so.  They would be 64 bit static libraries.

>    2.
> 
>    MSYS2 is very convenient for compiling many of these libraries. Can a
>    static library compiled with x86_64-w64-mingw32 (gcc 4.9.2) be used with
>    Rtools33 (v 4.6.2)?

Rtools uses 4.6.3, not 4.6.2.  I would assume the runtime libraries are
different between 4.6.3 and 4.9.2, so you won't be able to mix versions
like that.

However, you should be able to use your MSYS2 system for all
compilation, if you create a MkRules.local file with the right settings.
 You will need to compile R and all packages and libraries using that
system, don't expect to be able to mix binaries from different versions
of gcc.


>    3.
> 
>    Can a static library compiled using x86_64-w64-mingw32-gcc
>    cross-compiler (v 4.6.2) on linux be used with Rtools33?

Some libraries used by packages are compiled by Brian Ripley using a
cross-compiler on linux.  I'd assume he's using 4.6.3 as with the Rtools
build, but I'm not sure about that.

Duncan Murdoch

> 
> Options 2 and 3 are preferable for convenience and speed.
> 
> Compiling all libraries as part of the R-package is not currently an option.
> 
> Thanks,
> 
> SM
> 
> 	[[alternative HTML version deleted]]
> 
> ______________________________________________
> R-devel at r-project.org mailing list
> https://stat.ethz.ch/mailman/listinfo/r-devel
>


From jeroen.ooms at stat.ucla.edu  Sat May 30 16:07:22 2015
From: jeroen.ooms at stat.ucla.edu (Jeroen Ooms)
Date: Sat, 30 May 2015 16:07:22 +0200
Subject: [Rd] Compiling 64bit static library for Windows (Rtools33, MSYS2,
 cross-compile on linux)
In-Reply-To: <CAOkNWZUga3MvKMn0K2i01U2dWZ+3LuLDp-v4u0WXjtTV_7y3Ew@mail.gmail.com>
References: <CAOkNWZUga3MvKMn0K2i01U2dWZ+3LuLDp-v4u0WXjtTV_7y3Ew@mail.gmail.com>
Message-ID: <CABFfbXvC_zeLgYQZs584rwAyUzK95t3e2=SvBduOnPrse1Wqgw@mail.gmail.com>

Hi Sue,

I maintain a few static libs for R packages on
https://github.com/rwinlib. If your R packages are open source I can
try to add the libraries you need. Answers inline:

>    Can Rtools33 be used to compile static libraries as a separate step
>    using -m64 flag?

Yes, but usually you'll need msys to as well to run configure, etc.

>    MSYS2 is very convenient for compiling many of these libraries. Can a
>    static library compiled with x86_64-w64-mingw32 (gcc 4.9.2) be used with
>    Rtools33 (v 4.6.2)?

Sometimes. It will not work for c++ libraries because the gcc build
included with msys2 uses a different exception and threading models.
For C libraries, sometimes building in msys2 leads the static library
to depend on certain system libraries that are included with msys2 but
not with rtools.

>    Can a static library compiled using x86_64-w64-mingw32-gcc
>    cross-compiler (v 4.6.2) on linux be used with Rtools33?

If the library is built properly, this is usually not a problem; most
builds do not depend on a particular gcc version. For example static
and dynamic libraries for libcurl and dependencies (openssl, libssh2,
libz, etc) are available via http://curl.haxx.se/gknw.net/7.40.0/ and
in my experience these can be linked with any somewhat recent version
of gcc.


From ripley at stats.ox.ac.uk  Sat May 30 21:06:13 2015
From: ripley at stats.ox.ac.uk (Prof Brian Ripley)
Date: Sat, 30 May 2015 20:06:13 +0100
Subject: [Rd] Compiling 64bit static library for Windows (Rtools33, MSYS2,
 cross-compile on linux)
In-Reply-To: <5569A990.7020004@gmail.com>
References: <CAOkNWZUga3MvKMn0K2i01U2dWZ+3LuLDp-v4u0WXjtTV_7y3Ew@mail.gmail.com>
	<5569A990.7020004@gmail.com>
Message-ID: <556A0A25.5050001@stats.ox.ac.uk>

On 30/05/2015 13:14, Duncan Murdoch wrote:
> On 29/05/2015 4:16 PM, Sue McDonald wrote:
>> My apologies for cross-posting. I found this site, after I had posted on
>> stack-overflow.
>>
>> I need to compile several static libraries (C & Fortran) which will later
>> be linked with an R package. Rtools33 directory includes /i686-w64-mingw32
>> directory which I understand creates 32 bit binaries. Yet, there are other
>> 64 bit directories as well.
>
> The current Rtools is set up for multilib operation.  You only need to
> use the binaries in Rtools/gcc-4.6.3/bin.  The executables there will
> choose files from the other directories depending on the -m32 or -m64
> flag, for 32 bit or 64 bit operation.
>
>>
>> I have three related questions:
>>
>>     1.
>>
>>     Can Rtools33 be used to compile static libraries as a separate step
>>     using -m64 flag?
>
> Yes, I believe so.  They would be 64 bit static libraries.
>
>>     2.
>>
>>     MSYS2 is very convenient for compiling many of these libraries. Can a
>>     static library compiled with x86_64-w64-mingw32 (gcc 4.9.2) be used with
>>     Rtools33 (v 4.6.2)?
>
> Rtools uses 4.6.3, not 4.6.2.  I would assume the runtime libraries are
> different between 4.6.3 and 4.9.2, so you won't be able to mix versions
> like that.
>
> However, you should be able to use your MSYS2 system for all
> compilation, if you create a MkRules.local file with the right settings.
>   You will need to compile R and all packages and libraries using that
> system, don't expect to be able to mix binaries from different versions
> of gcc.
>
>
>>     3.
>>
>>     Can a static library compiled using x86_64-w64-mingw32-gcc
>>     cross-compiler (v 4.6.2) on linux be used with Rtools33?
>
> Some libraries used by packages are compiled by Brian Ripley using a
> cross-compiler on linux.  I'd assume he's using 4.6.3 as with the Rtools
> build, but I'm not sure about that.

Correct, I used the cross-compiler that was used to compile the native 
compilers in Rtools.

My experience (this had to work for thousands of packages for CRAN) is 
that only an exact match for the cross-compiler to the compiler used to 
compile R works reliably.  Even very slightly different builds can cause 
segfaults.

-- 
Brian D. Ripley,                  ripley at stats.ox.ac.uk
Emeritus Professor of Applied Statistics, University of Oxford
1 South Parks Road, Oxford OX1 3TG, UK


